
\title{TITCHMARSH'S PHENOMENON FOR $\zeta (s)$}
\markright{Titchmarsh's Phenomenon for $\zeta (s)$}

\author{By~ R. Balasubramanian$^\ast$ and K. Ramachandra$^{\ast\ast}$}

\date{}
\maketitle

\setcounter{pageoriginal}{12} 

\section{Introduction}\label{art2-sec1}
Under\pageoriginale  the title ``On the frequency of Titchmarsh's phenomenon for $\zeta(s)$'' we have written seven papers [11, 12, 2, 1, 3, 4, 13] sometimes individually and sometimes jointly. the present article is a summary of these results. The function $\zeta(s) (s = \sigma + it)$ is defined in $\sigma > 0$ by 
$$
\zeta(s) = \sum\limits^\infty_{n=1} \left(\frac{1}{n^s} - \int\limits^{n+1}_n \frac{du}{u^s} \right) + \frac{1}{s-1}. 
$$
The sum on the right can be easily shown to be an entire function by a repetition of the trick which we have employed to prove that this is an analytic continuation of $\zeta(s) = \sum\limits^\infty_{n-1} n^{-s} (\sigma >1)$ in $\sigma >0$. Thus the serious problem about $\zeta(s)$ is not the analytic continuation. But the conjecture $\zeta(s) \neq 0$ in $\sigma > 1/2$ is really a very serious problem. [This is called Riemann hypothesis (R.H.)]. To serve as an introduction to our results we will first state some results (free from any hypothesis). We next recall some well-known consequences of Riemann hypothesis for comparison with these results. We will be concerned with the size of $|\zeta(\sigma + it)|$ in $1/2 \leqslant \sigma \leqslant 1$, $t \geqslant t_0$ where $t_0$ is a large positive constant which may depend on parameters like $\sigma$ and other constants like (arbitrarily small positive) $\epsilon$ when they appear. The letter $A$ will denote an absolute positive constant and $C$ will denote a positive constant independent of $t$ but may depend on other parameters. There may not be the same at each occurrence. 
\begin{equation}
|\zeta(1/2) + it| < t^{\mu+ \epsilon} \label{art2-eq1}
\end{equation}
($\mu = 1/2$ is easy; $\mu = 1/4$ is a little more difficult, the fundamental result $\mu = 1/6$ is due to G. H. Hardy, J.E. Littlewood and H. Weyl \cite{art2-key19}. There have been a number of important papers by various authors which reduce $\mu =1/6$, the latest being $\mu = 9/56$ due to E. Bombieri and H. Iwaniec \cite{art2-key7} and a further reduction by $\frac{1}{560}$ due to M. N. Huxley and N. Watt. A. result of N. V. Kuznetsov proved by him in a paper presented by him in this conference implies that we can take $\mu = 1/8$).
\begin{equation}
|\zeta(\sigma + it)| < (t^{(1-\sigma)^{3/2}} \log t)^A \label{art2-eq2}
\end{equation}\pageoriginale
(due to the ideas of I.M. Vinogradov, see A. Walfisz's book \cite{art2-key20}; see also H.-E. Richert \cite{art2-key18}).
\begin{equation*}
|\zeta(\sigma + it)| < t^{\mu(\sigma) +\epsilon}
\tag{2$'$}\label{art2-eq2'}
\end{equation*}
(various values of $\mu(\sigma)$ are obtained by various methods by various authors; see E. C. Titchmarsh's book \cite{art2-key19}.)
\begin{equation}
|\zeta(1+it)| < A( \log t)^{2/3} \label{art2-eq3}
\end{equation}
(due to the ideas of I.M. Vinogradov, see A. Walfisz's book \cite{art2-key20}.)

We now state consequences of R.H.
\begin{equation}
|\zeta(1/2 + it)| < \Exp (A \log t /\log\log t) \label{art2-eq4}
\end{equation}
(due to J.E. Littlewood, see \cite{art2-key19})
\begin{equation}
|\zeta (\sigma + it)| \Exp (C (\log t)^{2(1-\sigma)}/ \log \log t),C = C (\delta),
\label{art2-eq5}
\end{equation}
uniformly in $1/2 \leqslant \sigma \leqslant 1 -\delta (\delta > 0)$. (This is due to J.E. Littlewood, E.C. Titchmarsh and others, see \cite{art1-key19})
\begin{equation}
|\zeta(1+it)| < (2e^\gamma+ \epsilon) \log \log t
\end{equation}
(due to J.E. Littlewood, see \cite{art2-key19}. Littlewood's method shows that if $\theta$ defined as the least upper bound of the real parts of the zeros of $\zeta(s)$ is less than 1, then \eqref{art2-eq6} would follow with some positive constant in place of $2e^\gamma$. Here as elsewhere we denote by $\gamma$ the Euler's constant).

If we compare \eqref{art2-eq1}, \eqref{art2-eq2}, \eqref{art2-eq3} with \eqref{art2-eq4}, \eqref{art2-eq5}, \eqref{art2-eq6} we see how much has been achieved in the direction of Lindel\"of hypothesis (L. H.) (which is a consequence of R.H.) with states that in \eqref{art2-eq1} we can take $\mu=0$. A consequence of L.H. is that we can take $\mu(\sigma) = 0$ in (2$'$). The L.H. has also remained unsolved for a long time. We do not know whether we can take $\mu(\sigma)=0$ for any value of $\sigma$ in $1/2 \leqslant \sigma < 1$. These results seem to be out of reach for many centuries to come. Also we do not know whether the results \eqref{art2-eq4}, \eqref{art2-eq5}, \eqref{art2-eq6} can be improved on the assumption of R.H.. However we can show that in \eqref{art2-eq6} $2e^\gamma$ cannot be replaced by any constant less than $e^\gamma$. The corresponding results regarding \eqref{art2-eq4} and \eqref{art2-eq5} are not so satisfactory. In \eqref{art2-eq4}, we can show that we cannot replace the right hand side by $\Exp ((\log t)^{\frac{1}{2}- \epsilon})$  and that the right hand side in \eqref{art2-eq5} cannot be replaced by $\Exp ((\log t)^{1-\sigma -\epsilon})$ in $1/2 + \delta \leqslant \sigma \leqslant 1 -\delta$. These results (which are called $\Omega$ results) are due to J.E. Littlewood and E.C. Titchmarsh. Littlewood generally\pageoriginale assumes R.H. and Titchmarsh's results are independent of any hypothesis. For references to the work of Littlewood and Titchmarsh see \cite{art2-key19}.

\medskip
\noindent
THE PROBLEM. Let $\sigma$ be fixed in $\sigma \geqslant 1/2$ ($\sigma$ may depend on $T$ and $H$ to follow). Let $I$ denote an interval of length $H$ contained in $[T, 2T]$, where $H > 1000$. (We may also make $\sigma$ depend on $T$ and $H$; for example, we can take $\sigma =1 +1 /\log H$). In the first two papers \cite{art2-key11, art2-key12} of the series max second author investigated $\begin{matrix} \max \\  t \text{ in } I\end{matrix} |\zeta(\sigma + it)|$ and also $\begin{matrix} \max\\ \alpha \geqslant \sigma 
\end{matrix} \begin{matrix}
\max\\\eqref{art2-eq1}
t \text{ in } I
\end{matrix} |\zeta(\alpha + it)|$ and other problems like $\begin{matrix}
\max\\
t \text{ in } I
\end{matrix} |\zeta(\sigma + it)|$ where the minimum is taken over all intervals $I$ of length $H$ contained in $[T, 2T]$. (He has also improved Theorem 3 of \cite{art2-key11} as follows. Let $(\zeta_K(s))^{1/2} = \sum\limits^\infty_{n=1} \dfrac{a_n(K)}{n^s}$). Then the RHS in Theorem 3 can be replaced by $U \times \sum\limits_{n \leqslant U} \dfrac{|a_n(K)|^2}{n^{2\sigma_0}} (\log n)^l$  with the condition 1000 $\log \log X \leqslant U \leqslant X$). These and other problems were studied further in papers [2, 1, 3, 4, 13].

\section{Key result and its applications.}\label{art2-sec2}
The method employed in the first paper of series was systematized by the second of us in \cite{art2-key14}. This was improved by us in \cite{art2-key5}; but this improvement (though a significant progress) does not give any new $\Omega$ results. The net result is as follows.

\begin{theorem}\label{art2-thm1}
Let $\{a_n\}$ be a sequence of complex numbers satisfying $a_1 = 1$ and for $n \geqslant 2$, $|a_n| < (n(H+2))^A$, where $H>0$ and $A$ is an arbitrary positive constant. Let $0 < H \leqslant T$ and $F(s) = \sum\limits^\infty_{n=1} a_n n^{-s}$  be analytically continuable in $\sigma > 0$ and continuous in $\sigma \geqslant 0$.  Then 
\begin{gather*}
\begin{matrix}
\max \\
\sigma \geqslant 0 
\end{matrix}
\left(\frac{1}{H} \int\limits_I |F(\sigma + it)|^2 dt \right) \geqslant \\
\begin{matrix}
C_A \Sigma\\
n \leqslant \frac{H}{100} + 1 
\end{matrix} |a_n|^2
\left(1 - \frac{\log n}{\log H} + \frac{1}{\log \log H} \right)
\end{gather*}
where $C_A \geqslant 0$ is effective and depends only on $A$.
\end{theorem}

\begin{coro*}
If $\begin{matrix}
\max\\
\sigma \geqslant 0, t \text{ in } I
\end{matrix} |F(\sigma + it)| < \Exp \Exp \dfrac{H}{100}$, then $\dfrac{1}{H} \int\limits_I |F(it)|^2 dt > \dfrac{1}{2} C_A \sum\limits_{n \leqslant \frac{H}{100} +1} |a_n|^2 \left(1-\dfrac{\log n }{\log H} + \dfrac{1}{\log \log H} \right)$. 
\end{coro*}

\noindent
\textsc{Proof of the corollary.}\pageoriginale One method of deduction of the corollary is by Gabriel's two variable two variable convexity theorem coupled with the kernel $\Exp. (\sin (z/100)^2)$, (see the appendix to \cite{art2-key15}). For another method see \cite{art2-key14}. Note that this kernel decays in $|\re z | \leqslant 1/2$ uniformly at most like a constant multiple of $(\Exp \Exp (c |\Iim z|))^{-1}$ where $c >0$ is a constant. Given faster decaying kernels we can deduce the Corollary with more relaxed conditions. The same applies to all applications of the key theorem. It may be remarked that we do not know any kernel which decays (uniformly in $|z | \leqslant 1/2$) at most like a constant multiple of $(\Exp\Exp (c|\Iim z|))^{-1}$ where $c$ is any large positive constant. 

We begin the applications by the following remark, which follows from The theorem by putting $F(s) =(\zeta (\alpha +s ))^k$ where $\alpha \geqslant 1/2$ (we may assume without loss of generality that $H$ exceeds a large positive constant) and $k$ is a positive integer which may depend on $H$.

\begin{theorem}\label{art2-thm2}
We have, for $\alpha \geqslant 1/2$,
\begin{equation*}
\begin{matrix}
\max \\
\sigma \geqslant \alpha, t \text{ in } I 
\end{matrix}
|\zeta (\sigma + it)| >  \left(C_A \sum\limits_{n \leqslant \frac{H}{100}} \frac{(d_k (n))^2}{n^{2\alpha}} \left(1 - \frac{\log n }{\log H} + \frac{1}{\log \log H}\right) \right)^{1/2k},
\end{equation*}
where $k \leqslant \log H$ so that the condition $d_k (n) \leqslant (n(H+2))^A$ is satisfied. (In fact it may be noted that the maximum of {\rm RHS} is attained in $k \leqslant \log H$ itself).
\end{theorem}

\begin{remark*}
We may also state a similar theorem for 
$$
\begin{matrix}
\max\\
\sigma \geqslant \alpha, t \in I
\end{matrix} |\zeta (\sigma + it)|^{-1}
$$
where $\alpha \geqslant 1/2 + \delta$ and $(\sigma \geqslant \alpha - \delta/2, t \text{ in } I)$ is free from zeros of $\zeta(s)$. Here $\delta$ is an arbitrary positive constant. 

It is not very difficult to investigate the order of magnitude of $\begin{matrix}
\max\\ k \geqslant 1
\end{matrix}$ (R.H.S.) in Theorem 2. By a very ingenious argument, R. Balasubramanian has shown (see \cite{art2-key1}) that its logarithm is asymptotic to 
$$
C_0 (\log H/ \log \log H)^{1/2}
$$
where $C_0 = 0.75 \ldots, $ when $\alpha =1/2$. This gives the best known $\Omega$ result
$\begin{matrix}
\max\\
\sigma \geqslant \frac{1}{2}, t \text{ in  } I 
\end{matrix}|\zeta (\sigma + it) | > \Exp \left[\frac{3}{4} \left(\frac{\log H}{\log \log H} \right)^{1/2} \right].$ 

Earlier\pageoriginale in \cite{art2-key2}, we had obtained a small positive constant in place of $3/4$. Balasubramanian's asymptotic formula shows that it is not possible to replace $3/4$ by even 0.76 by our method. Earlier to our result \cite{art2-key2}, nearly around the same time, H.L. Montgomery \cite{art2-key9} had obtained the constant 1/20 (in place of 3/4) on the assumption of Riemann hypothesis. We would also like to remark that in order to obtain the maximum order (of RHS in Theorem \ref{art2-thm2}) as $k$ varies, we have to take (in case $\alpha=1/2$) a large number of terms of the sum and ignore the rest. One the contrary, when $\alpha \geqslant 1/2 + \delta$ it is enough to take a particular term, namely, the maximum term of the sum. If $1/2+ \delta \leqslant \alpha \leqslant 1-\delta$ then it is enough to take $n$ to be the biggest square-free product of the first $k$ primes, which does not exceed $H$. If $\alpha =1$, then for each $p$ we select that prime power $p^m$ for which $(d_k (p^m))^2 p^{-2m\alpha}$ is the largest and then take $n$ to be the product of the first $k$ prime powers $p^m$ which does not exceed $H$  (for details see \cite{art2-key2} or \cite{art2-key17}.) If $\alpha =1+ (1/\log H)$ for instance we may take out from $(d_k(n))^2 n^{-2\alpha}$ the portion $n^{-(2/\log H)}$ (which certainly exceeds $e^{-2}$ for $n \leqslant H$). In \cite{art2-key2} the first of us has shown that even if we take all the terms of the sum we do not get a better result. In fact following the method of \cite{art2-key1} we may show that
$$
\log \left[\begin{matrix}
\max\\
k \geqslant 1
\end{matrix}
\left(
\begin{matrix}
\Sigma\\
n \leqslant x
\end{matrix}
\frac{[d_k(n)]^2}{n^{2\alpha}}
 \right)^{1/2k}
\right] (\log x)^{\alpha -1} (\log \log x)
$$
tends to a positive constant if $1/2 + \delta \leqslant \alpha \leqslant 1-\delta$. These results show the limitations of our method. However out net result are 
\end{remark*}
 
\noindent
{\bfseries Theorem \thnum{3(A)}.\label{art2-thm3A}} \textit{We have, if} $1/2 + \delta \leqslant \alpha \leqslant 1-\delta$,
$$
\begin{matrix}
\max\\
\sigma \geqslant \alpha, \; t \text{ in } I  
\end{matrix}\;
|\zeta (\sigma + it)| > \Exp 
\left(\frac{C(\log H)^{1-\alpha}}{\log \log H} \right).
$$

\noindent
{\bfseries Theorem \thnum{3(B)}.\label{art2-thm3B}} \textit{We have, if} $1 - \dfrac{1}{\log H} \leqslant \alpha \leqslant 1 + \dfrac{1}{\log H}$,
$$
\begin{matrix}
\max\\
\sigma \geqslant \alpha, \; t \text{ in } I
\end{matrix} |\zeta(\sigma + it)| \geqslant e^\gamma (\log \log H - \log \log \log H + O (1)).
$$

\begin{remark}\label{art2-rem1}
H. L. Montgomery \cite{art2-key9} has shown that if $1/2 + \delta \leqslant \alpha \leqslant 1 - \delta$ then $|\zeta(a+ it)|$ exceeds $\Exp [C(\log t)^{1-\alpha}]/(\log \log t)^{\alpha}]$ for a sequence of values of $t$ tending to infinity by a different method. But this method does not enable one to conclude that the maximum of $|\zeta (\alpha + it)|$ as $t$ varies for example, over $[T, 2T]$ exceeds $\Exp [C(\log T)^{1-\alpha}] / (\log \log T)^\alpha]$. The lower bound $\Exp [C(\log T)^{1-\alpha}/(\log \log T)]$ given by our method seems to be the best known till today.
\end{remark}

\begin{remark}\label{art2-rem2}
N. Levinson\pageoriginale \cite{art2-key8} has shown by a different method that $|\zeta(1+it)|$ exceeds $e^\gamma \log \log t + O(1)$ for a sequence of values of $t$ tending to infinity. But, for short intervals like $[T, 2T]$, ours is the only result known.
\end{remark}

\begin{remark}\label{art2-rem3}
Let $1/2 + \delta \leqslant \alpha \leqslant 1 -\delta$. I suspected that if we take $F(s) = (\log \zeta (\alpha + s))^k$ then we might get a better result Theorem \ref{art2-thm3A}. But it was shown by H. L. Montgomery \cite{art2-key10} that if $(\log \zeta(s))^k = \sum\limits^\infty_{n=1} a_k(n) n^{-s}$, then 
$$
\begin{matrix}
\max\\
k \geqslant 1 
\end{matrix}
\left(
\sum\limits_{n \leqslant x} (a_k (n))^2 n^{-2\alpha} \right)^{1/2k}
$$
lies between two constant multiples of $(\log x)^{1-\alpha} (\log \log x)^{-1}$.
\end{remark}

\begin{remark}\label{art2-rem4}
H.L. Montgomery has conjectured \cite{art2-key9} that if $1/2 \leqslant \alpha \leqslant 1 -\delta$ then $|\zeta (\alpha + it)|$ does not exceed $\Exp ([C (\log t)^{1-\alpha}]/[\log \log t]^{\alpha})$
\end{remark}

\section{Further study of the maximum in 1/2 $+ \delta \leqslant \alpha \leqslant 1 -\delta$ by other methods.}\label{art2-sec3}
In the second paper of the series \cite{art2-key12}, the second of us proved that if $1/2 + \delta \leqslant \alpha \leqslant 1-\delta$ and $I$ runs over all intervals, of fixed length $H$, contained in $[T, 2T]$ then 
$$
\log \log \left(\begin{matrix}
\min\\
I
\end{matrix} 
\begin{matrix}
\max\\
t \text{ in } I
\end{matrix}
|\zeta (\alpha + it)|
\right) \sim (1-\alpha) \log \log H,
$$
provided $C < 100 \log \log T \leqslant H \leqslant \Exp [D \log T]/[\log \log T]$) where $C$ is a large positive constant and $D$ a positive constant depending only on $\alpha$. This aspect of the problem has been studied further by us in \cite{art2-key2}. The method is very closely related to a principle which we formulated and employed in \cite{art2-key6}. The main result of \cite{art2-key3} is as follows:


\begin{theorem}\label{art2-thm4}
let $\alpha$ be as above, $E>1$ an arbitrary constant,  $C \leqslant H \leqslant \Exp \left(\dfrac{D \log T}{\log \log T} \right)$ where $C$ is a large positive constant and $D$ an arbitrary positive constant. Then there are $\geqslant TH^{-E}$ disjoint open intervals I (of fixed length $H$) all contained in $[T, 2T]$, such that, 
$$
\frac{(\log H)^{1-\alpha}}{(\log \log H)^\alpha} \ll \max\limits_{t \text{ in } I} |\log \zeta (\alpha + it)| \ll \frac{(\log \log H)^{1-\alpha}}{(\log \log H)^\alpha}.
$$
Here $\log \zeta(s)$ is the analytic continuation in $t \geqslant 2$ along lines parallel to the real axis (and free from zeros of $\zeta(s)$) from $\sigma \geqslant 1$. The Vinogradov symbol $\ll$ means ``less than a positive constant times''.
\end{theorem}

\section{Study of the maximum on $\sigma =1$.}\label{art2-sec4}\pageoriginale 
As a corollary to Theorem \ref{art2-thm4}, we deduced in \cite{art2-key4} the following

\begin{theorem}\label{art2-thm5}
Let $J$ denote the interval I (of Theorem \ref{art2-thm4})  with intervals of length $(\log H)^2$ removed from both extremities. Then 
$$
\begin{matrix}
\max\\
t \text{ in } J 
\end{matrix} |\zeta (1+ it)| \leqslant e^\gamma [\log \log H + \log \log \log H+ O(1)].
$$
Note that {\rm LHS} is $\geqslant e^\gamma (\log \log H-\log \log \log H+ O(1))$ by applying the Corollary to the key theorem. (The conditions for deriving this lower bound from the Corollary to the key theorem are satisfied in the course of the proof of Theorem \ref{art2-thm4}).
\end{theorem}

The key result of \S \ref{art2-sec2} can be used to obtain lower bounds for $\begin{matrix}
\max\\\sigma \geqslant 1, \; t \text{ in } I  
\end{matrix} |\zeta (\sigma + it)| $ and also a similar result (the lower bound gets multiplied by the factor $(6/\pi^2)$ for $|\zeta(\sigma + it)|^{-1}$. But to obtain lower bounds for $\begin{matrix}
\max\\
t \text{ in } I
\end{matrix} |\zeta(1+ it)|$ and for 
$\begin{matrix}
\max\\
t \text{ in } i 
\end{matrix} |\zeta(1+ it)|^{-1}$ we need conditions looking like $100 \log \log \log T \leqslant H \leqslant T$. But by a somewhat complicated application of the key result and other techniques the second of us \cite{art2-key13} proved the following theorem. To state the theorem it is better to introduce some notation. The letter $\theta$ will, as before, denote the least upper bound of the real parts of the zeros of $\zeta(s)$ (we do not know whether $\theta <1$ or not). For $x \geqslant 1$ we define $\log_1 x = \log x$ and for $n \geqslant 2$ we define $\log_n x$ to be $\log(\log_{n-1}x)$; similarly we define for real $x$, $\Exp_1(x) = \Exp (x)$  and for $n\geqslant 2$ we define $\Exp_n(x) = \Exp (\Exp_{n-1} (x))$.

\begin{theorem}\label{art2-thm6}
Consider for open intervals I (for $t$, of length $H \geqslant 100$) contained in $[T, 2T]$ where $T \geqslant T_0$, a large positive constant, the inequality
\begin{equation*}
\begin{matrix}
\max\\
t \text{ in } I
\end{matrix} |\zeta (1+ it)| \geqslant e^\gamma (\log \log H - \log \log \log H-\rho), 
\tag{$\ast$}
\end{equation*}
where $\rho$ is a certain real constant which is effective. Then we have the following four results:
\begin{itemize}
\item[(1)] ($\ast$) holds for all I for which $T \geqslant H \geqslant A_1 \log_4T$

\item[(2)] If $\theta <1$ then ($\ast$) holds for all I for which $T \geqslant H \geqslant A_2 \log_5 T$. 

\item[(3)] Let now $H < A_1 \log_4 T$. Consider a set of disjoint intervals I (of fixed length $H$) for which ($\ast$) is false. Then the number of such intervals I does not exceed $TX^{-1}_1$ where $X_1 = \Exp_4 (\beta H)$ where $\beta$ is a certain positive constant less than $A^{-1}_1$.

\item[(4)] Let now $H< A_2 \log_5 T$. Consider a set of disjoint intervals I (of fixed length $H$)\pageoriginale for which ($\ast$) is false. Then the number of such intervals I does not exceed $TX^{-1}_2$ where $X_2 = \Exp_5 (\beta' H)$ where $\beta'$ is a certain positive constant which is less than $A^{-1}_2$.
\end{itemize}
\end{theorem}

\section{An announcement}\label{art2-sec5}
In this section the length of the interval will not be denoted by $H$. We wish to announce a result \cite{art2-key16} due to the second author which is obtained by quite a different method. 

\begin{theorem}\label{art2-thm7}
Let $\epsilon$ be a constant satisfying $0 < \epsilon <1 $, $T \geqslant T_0 (\epsilon)$, a constant depending only on $\epsilon$, $X = \Exp \left(\dfrac{\log T}{\log \log T} \right)$. If from the intervals $T \leqslant t \leqslant T + e^X$ we exclude certain (boundedly many depending on $\epsilon$) disjoint open intervals I each of length at most $X^{-1}$, then in the remaining portions of the interval, we have,
$$
|\log \zeta (1+ it)| \leqslant \epsilon \log \log T.
$$
Further put $\beta_0 = A(\log T)^{-mu} (\log\log T)^{-2\mu}$ where $\mu = 2/3$ and $A$ is any positive constant. Consider the rectangle $R$ defined by $\sigma \geqslant 1 - \beta_0$, $T \leqslant t \leqslant T + e^X$. Let I denote an open interval for $t$ of length $1/X$ and let $J$ denote the corresponding rectangle $\sigma > 1-\beta_0$, $t$ in $I$. Then with the exception of certain boundedly many (depending on $\epsilon$ and $A$) disjoint rectangles $J$ we have for $s$ in $R$,
$$
|\log \zeta (s)| \leqslant \epsilon \log \log T
$$
where $T \geqslant T_0 (\epsilon, A)$
\end{theorem}

\begin{remark*}
The first result can be proved without assuming the Vinogradov's zero free region. But if we assume the Vinogradov's zero free region, we get a better upper bound for the number of intervals which have to be excluded. However, for the proof of the second part, the Vinogradov zero free region is essential.
\end{remark*}

\begin{thebibliography}{99}
\bibitem{art2-key1} \textsc{R. Balasubramanian} : On the frequency of Titchmarsh's phenomenon for $\zeta(s)$-IV, \textit{Hardy-Ramanujan J.,} Vol. 9(1986), 1-10.

\bibitem{art2-key2} \textsc{R. Balasubramanian}\pageoriginale and \textsc{K. Ramachandra} : On the frequency of Titchmarsh's phenomenon for $\zeta(s)$-III, \textit{Proc. Indian Acad.} Sci., 86 (A) (1977), 341-351.

\bibitem{art2-key3} \textsc{R. Balasubramanian}\pageoriginale and \textsc{K. Ramachandra} : On the frequency of Titchmarsh's phenomenon for $\zeta(s)$-V, \textit{Arkiv f\"or Mathematik} 26(1) (1988), 13-20.

\bibitem{art2-key4} \textsc{R. Balasubramanian}\pageoriginale and \textsc{K. Ramachandra} : On the frequency of Titchmarsh's phenomenon for $\zeta(s)$-VI, (to appear).

\bibitem{art2-key5} \textsc{R. Balasubramanian}\pageoriginale and \textsc{K. Ramachandra} : Progress towards a conjecture on the mean-value of Titchmarsh series-III, \textit{Acta Arith}., XLV (1986), 309-318.

\bibitem{art2-key6} \textsc{R. Balasubramanian}\pageoriginale and \textsc{K. Ramachandra} : On the zeros of a class of generalised Dirichlet series-III, \textit{J. Indian Math. Soc., 41} (1977), 301-315.

\bibitem{art2-key7} \textsc{E. Bombieri} and \textsc{H. Iwaniec} : On the order of $\zeta(1/2+it)$, \textit{Ann. Scoula Norm. Sup. Pisa.} 13 no. 3 (1986), 449-472.

\bibitem{art2-key8} \textsc{N. Levinson} : $\Omega$ theorems for the Riemann zeta-function, \textit{Acta Arith,} XX (1972), 319-332.

\bibitem{art2-key9} \textsc{H. L. Montgomery} : Extreme values of the Riemann zeta-function, \textit{Comment. Math. Helv.,} 52 (1977), 511-518.

\bibitem{art2-key10} \textsc{H. L. Montgomery} : On a question of Ramachandra, \textit{Hardy-Ramanunan J.,} 5 (1982), 31-36.

\bibitem{art2-key11} \textsc{K. Ramachandra} : On the frequency of Titchmarsh's phenomenon for $\zeta(s)$-I, \textit{J. London Math. Soc.,} (2) 8(1974), 683-690.

\bibitem{art2-key12} \textsc{K. Ramachandra} : On the frequency of Titchmarsh's phenomenon for $\zeta(s)$-II, \textit{Acta Math. Acad. Sci. Hungaricae}, Tomus 30 (1-2), (1977), 7-13.

\bibitem{art2-key13}  \textsc{K. Ramachandra} : On the frequency of Titchmarsh's phenomenon for $\zeta(s)$-VII, (to appear).

\bibitem{art2-key14} \textsc{K. Ramachandra} : Progress towards a conjecture on the mean-value of Titchmarsh series-I, \textit{Recent Progress in Analytic Number Theory} (Edited by H. Halberstam and C. Hooley) Vol. I, Academic Press (1981), 303-318.

\bibitem{art2-key15} \textsc{K. Ramachandra} : \textit{A brief summary of some results in the analytic theory of numbers-II Addendum, Number Theory}. Proceedings, Mysore (1981), Edited by K. Alladi, Lecture Notes in Mathematics, 938, Springer Verlag, 106-122.

\bibitem{art2-key16} \textsc{K. Ramachandra} : A remark on $\zeta(1+ it)$, \textit{Hardy-Ramanujan J.,} 10 (1987) (to appear).

\bibitem{art2-key17} \textsc{K. Ramachandra}  and \textsc{A. Sankaranarayanan} : Omega theorems for the Hurwitz zeta-function, (to appear).

\bibitem{art2-key18} \textsc{H. E. Richert} : Zur Absch\"atzung der Riemannschen Zetafunktion in der N\"ahe der Verti\"calen $\sigma =1$, \textit{Math. Ann.,} 169 (1967), 97-101.

\bibitem{art2-key19} \textsc{E. C. Titchmarsh} : The theory of the Riemann zeta-function, Clarendon Press, Oxford (1951).

\bibitem{art2-key20} \textsc{A. Walfisz} : \textit{Weylsche exponential Summen in der neueren Zahlen-theorie}, VEB Deutscher Verlag der Wiss., Berlin (1963) .
\end{thebibliography}

\begin{tabbing}
~*~~ \= \= {\small Institute of Mathematical Sciences}\\
\> \> {\small Madras - 600 113, Tamil Nadu} \\
\> \> {\small India} \\
**~~ \> \> {\small School of Mathematics}\\
\> \> {\small Tata Institute of Fundamental Research}\\
\> \> {\small Homi Bhabha Road} \\
\> \> {\small Bombay-400 005}\\
\> \> {\small India}
\end{tabbing}




