
\chapter{Applications to Stochastic Differential
  Equations}\label{chap2}%%% 2 

\section[Solutions of Stochastic Differential Equations....]{Solutions of Stochastic Differential Equations as Wiener
  Functionals}%2.1  

From\pageoriginale now on, we choose, as our basic abstract Wiener space
$(W,H,\mu)$, the following $r$-dimensional Wiener space
(cf. Ex. \ref{chap1:exam1.1}).  

Let
$$
W=W^r_o = \left\{w \epsilon  C [0,T] \to \mathbb{R}^r), w(0) = 0 \right\}
$$
$\mu = P$, the $r$-dimensional Wiener measure.
$$
H= \left\{ \vphantom{\int\limits_{o}^{T}} h \epsilon  W^r_o ; h =
(h^{\alpha}(t))^r_{\alpha=1},\right. 
$$
$h^\alpha$ absolutely continuous and
$$
\left.\int\limits_{o}^{T} \dot{h}^{\alpha}(S)^2 ds < \infty, \alpha =
1,2 \dots r\right\}.  
$$

We define an inner product in $H$ as follows:
$$
< h,h'>_H = \sum_{\alpha = 1}^r \int\limits_o^T \dot{h}^\alpha (t)
\dot{h}'^\alpha (t) dt, h', h \epsilon  H. 
$$

With this inner product, $H \subset W$ is a Hilbert space. Further
$\overset{\ast}{W} \subset H^* = H \subset W$ is given as follows: 
$$
\overset{\ast}{W} = \left\{\ell \epsilon  H: \ell =
(\ell^\alpha(t))^r_{\alpha=1}, 
\ell^\alpha(t) = \int\limits_o^t \dot{\ell}^{\alpha}(t)ds \right\} 
$$
and $\dot{\ell}^\alpha$ is a right continuous function of bounded
variation on $[0,T]$ such that $\dot{\ell}^\alpha(T) = 0,\alpha =
1,\ldots r\}$. 

If\pageoriginale $\ell \epsilon  \overset{\ast}{W}, w \epsilon  W$, then
$$
\ell(w) = -\sum_{\alpha=1}^r \int\limits_o^T w^\alpha(t) d \dot{\ell}_\alpha (t)
$$
and for $\ell \epsilon  \overset{\ast}{W},h \epsilon  H$,
\begin{align*}
  \ell (h) & = - \sum_{\alpha=1}^r \int\limits_o^T h^\alpha(t) d
  \dot{\ell}_\alpha(t)\\ 
  & =\sum_{\alpha=1}^r \int\limits_o^T \dot{h}^\alpha(t)
  \dot{\ell}_\alpha (t) dt = < h, \ell >_H -. 
\end{align*}

Let $B_t(W^r_o)$ = the completion of the $\sigma$-algebras on
$W^r_o$ generated by $(w^\alpha(s))$, $0 \le s \le t$. 


\medskip
\noindent{\textbf{Stochastic Integrals:}}
 Let $\phi_\alpha (t,w)$ be jointly measurable in $(t,w), B_t$ adapted
 and   
$$
\int\limits_o^T \phi_\alpha (t,w) dt < \infty ~\text{a.s.}
$$

Then it is well known that the stochastic integral
$$
\int\limits_o^t \phi_\alpha (s,w) dW^\alpha_s, (W^\alpha_t (w) =
w^\alpha (t), \alpha = 1,2, \ldots, r) 
$$
is a continuous local martingale.


\medskip
\noindent{\textbf{It\^o process:}}
 A continuous $B_t$-adapted process of the form 
$$
\xi_t = \xi_o + \sum_{\alpha=1}^r \int\limits_{o}^t \phi_\alpha (s,w)
dW^\alpha_s + \int\limits_0^t \phi_o (s,w)ds 
$$
where
\begin{enumerate}[i)]
\item $\phi_\alpha(t,w)$ is $B_t$-adapted, jointly measurable with 
  $$
  \int\limits_o^T \phi^2_\alpha (t,w) dt < \infty ~\text{a.s.}
  $$ 

\item $\phi_o(t,w)$ is $B_t$-adapted, jointly measurable with 
\end{enumerate}
$$
\int\limits_o^T |\phi_0 (s,w)| ds < \infty ~\text{a.s.}
$$\pageoriginale
is called an \text{It\^{o} process}.


\medskip
\noindent{\textbf{Straton ovitch Integral:}}
 Let $\phi_\alpha(t,w)$ be an It\^{o} process. Then $\phi_\alpha$
 is of the form  
$$
\phi_\alpha(t,w)= \phi_\alpha(o,w) + \sum_{\beta = 1}^r
\int\limits_o^t \Xi_{\alpha,\beta} (s,w)dW^\beta_s + \int\limits_o^t
\Xi_{\alpha,o} (s,w)ds. 
$$

Then the \text{Stratonovitch integral} of $\phi_\alpha$ w.r.t
$W^\alpha$, denoted by
$$
\int\limits_o^t \phi_\alpha (s,w) o dW^\alpha_s 
$$
is defined as follows:
$$
\int\limits_o^t \phi_\alpha (s,w ) odW^\alpha_s \triangleq
\int\limits_o^t \phi_\alpha (s,w ) dW^\alpha_s + \frac{1}{2}
\int\limits_o^t \Xi_{\alpha,\alpha}(s,w)ds.
$$


\medskip
\noindent{\textbf{It\^{o} Formula:}}
 Let $\xi_t = (\xi'_t,\ldots, \xi^d_t)$ be a $d$-dimensional It\^{o} process,  
$$
\displaylines{
\text{i.e.,}\hfill \xi^i_t = \xi^i_o + \sum_{\alpha=1}^\gamma
\int\limits_o^t \phi^i_\alpha(s,w) dW^\alpha_s + \int\limits_o^t
\phi^i_o(s,w)ds, 1 \le i \le d.\hfill}  
$$
\begin{enumerate}[1)]
\item Let $f:\mathbb{R}^d \to \mathbb{R}^d$ be a $C^2$ function. Then
  $f(\xi_t)$ is an It\^{o} process we have the It\^{o}
  formula:  
  \begin{align*}
    f(\xi_t) & = f(\xi_o) + \sum_{i=1}^d \sum_{\alpha=1}^r
    \int\limits_o^t \partial_i f(\xi_s) \phi_\alpha^i (s,w)
    dW^\alpha_s\\ 
    & + \sum_{i=1}^d \int\limits_o^t \partial_i f(\xi_s) \phi_o^i (s,w) ds\\ 
    & + \frac{1}{2} \sum_{\alpha=1}^r \sum_{i,j=1}^d \int\limits_o^t
    \partial_{i,j}^2 f(\xi_s) (\phi^\alpha_i \phi^\alpha_j) (s,w) ds 
  \end{align*}

\item Suppose\pageoriginale further that $\phi^i_\alpha (t,w), 1 \le i
  \le d, 1 \le \alpha \le r$ are It\^{o} processes and set  
\end{enumerate}
$$
\eta^i_t = \eta^i_o + \sum_{\alpha=1}^r \int\limits_o^t \partial^i_o
(s,w)o s W^\alpha_s + \int\limits^t_o \phi^i_o (s,w)ds, 1 \le i \le d. 
$$

Then, if $f: \mathbb{R}^d \to \mathbb{R}$ is $C^3$, we have 
\begin{multline*}
  f(\eta_t) - f(\eta_o) = \sum_{i=1}^d \sum_{\alpha=1}^r
  \int\limits_o^t \partial_i f(\eta_s) \phi_\alpha^i (s,w)o
  dW^\alpha_s\\ 
  + \sum_{\alpha=1}^r \int\limits_o^t \partial_i f(\eta_s)
  \phi_o^i (s,w) ds.
\end{multline*}

\medskip
\noindent{\textbf{Stochastic Differential Equations:}}
 Let $\sigma^i_\alpha(x),
b^i(x)$ be functions of $\mathbb{R}^d$ for $i = 1,2,\ldots d, \alpha =
1,\ldots r$ satisfying the following assumptions: 
\begin{enumerate}[i)]
\item $\sigma^i_\alpha, b^i \epsilon  C^\infty (\mathbb{R}^d \to
  \mathbb{R}) ~\forall~ i = 1, \ldots d, \alpha = 1, \ldots r$. 

\item $\forall~ k \epsilon  N, \partial_{i_1}  \partial_{i_2} \cdots
  \partial_{i_k} \sigma^i_\alpha, \partial_{i_1} \dots \partial_{i_k}
  b^i $ 
\end{enumerate}
are bounded on $\mathbb{R}^d$.

Then
\begin{align*}
  |\sigma^i_\alpha(x)| & \le K(1 + |x|), ~\forall~ i = 1, \ldots d, \alpha
  = 1, \ldots r,\\ 
  |b^i(x)| & \le K(1 + |x|), ~\forall~ i = 1, \ldots d.
\end{align*}

Consider the following $SDE$,
\begin{align*}
  dX_t & = \sigma_\alpha (X_t) dW ^\alpha_t + b(X_t) dt,\\
  X_o & = x \epsilon  \mathbb{R}^d \tag{2.1}\label{eq2.1}
\end{align*}
which is equivalent to saying
$$
X^i_t=x^i + \sum_{\alpha=1}^r \int\limits_o^t \sigma^i_\alpha
(X_s)dW^\alpha_s + \int\limits_o^t b^i (X_s) ds, i=1,\ldots, d. 
$$

Then\pageoriginale the following are true: There exists a unique
solution $X_t = X (t,x,w) = X_t^1,\ldots X_t^d$ of (\ref{eq2.1}) such that 
\begin{enumerate}[1)]
\item $ (t,x) \to X(t,x,w)$ is continuous $(a.a.w)$.

\item $\forall~ t \ge 0,x \to X(t,x,w)$ is a diffeomorphism on
  $\mathbb{R}^d (a.a.w)$. 

\item $\forall~ t \ge 0, x \epsilon  \mathbb{R}^d, X(t,x,.)
  \epsilon  L^p ~\forall~ 1 < p < \infty$. 
\end{enumerate}

\setcounter{theorem}{0}
\begin{theorem}\label{chap2:thm2.1}%2.1
  Let $t > 0, x \epsilon  \mathbb{R}^d$ be fixed. Then
  $$
  X^i_t = X^i (t,x,w) \epsilon  \mathbb{D}_\infty,~\forall~ i =
  1,\ldots, d. 
  $$
\end{theorem}

To find an expression for $ < DX^i_t, DX^j_t >_{H'}$ let 
$$
Y_t = ((Y^i_j(t))), Y^i_j(t) = \frac{\partial X^i (t,x,w)} {\partial x^j}.
$$

Let also
$$
(\partial \sigma_\alpha)^i_j = \frac{\partial \sigma_\alpha^j (x)}
{\partial x^j}; (\partial b)^i_j =\frac{\partial b^i} {\partial
  x^j}(x). 
$$

Then it can be shown that $Y_t$ is given by the following $SDE$: 
\begin{align*}
  dY_t & = \partial \sigma_\alpha (X_t).Y_t dW^\alpha_t + \partial
  b(X_t). Y_t dt\\ 
  Y_o & = I \tag{2.2}\label{eq2.2}
\end{align*}
\begin{multline*}
 \text { i. e. } \qquad \qquad Y^i_j (t)  = \delta^i_j + \sum_{\alpha=1}^r
 \sum_{k=1}^d \int\limits_o^t (\partial_k \sigma^i_\alpha) (X_s) Y^k_j
 (t) dW^\alpha_s \\ 
  + \sum_{k=1}^d \int\limits_o^t (\partial_k b^i)(X_s)Y^k_j(s) ds, i,j
  = 1,\ldots, d. 
\end{multline*}

\begin{fact} 
$Y_t \epsilon  L_p \text { i.e.,  } (\sum_{i, j = 1}^d (Y^i_j
  (s))^2)^{1/2} \epsilon  L_p ~\forall~ 1 <  p  <  \infty$. 
\end{fact}

 Also by considering the $SDE$
\begin{align*}
  dZ_t  &=  -Z_t. \partial \sigma_\alpha (X_t)dW^\alpha_s - Z_t [\partial
    b(X_t) - \sum_\alpha (\partial \sigma_\alpha. \partial
    \sigma_\alpha) (X_t)] dt \tag{2.3}\label{eq2.3} \\
  Z_o &= I
\end{align*}
and\pageoriginale using It\^{o}'s formula, we can easily see that
$d (Z_t Y_t) = 0 \Rightarrow Z_t Y_t \equiv I$  
$$ 
\displaylines{
\text { i.e.,}\hfill  Z_t = Y^{-1}_t \text{ exists }, ~\forall~ t.\hfill}
$$

\begin{fact}
  $Y^{-1}_t \epsilon  L_p$
  $$
  \displaylines{
    \text { i.e.,}\hfill \left(\sum_{i,j=1}^d \left((Y^{-1}
    (t))^i_j\right)^2\right)^{1/2} \epsilon  L_p ~\forall~ 1 < p  <
    \infty,\hfill } 
  $$
  since $Z_t \epsilon  L_p$.
\end{fact}


\begin{theorem}\label{chap2:thm2.2}%them 2.2
  For every $t,0 < t < T$ and $i, j = 1,\ldots d$,
  $$
  \displaylines{\hfill
    < DX^i_t, DX^j_t > = \sum_{\alpha=1}^r \int\limits_o^t (Y_t Y_s^{-1}
    \sigma_\alpha (X_s))^i (Y_t Y_s^{-1} \sigma_\alpha (X_s))^j ds \hfill\cr 
    \text{where}\hfill
    (Y_t Y_s^{-1} \sigma_\alpha (X_s))^i = \sum_{k,j} Y^i_k(t)
    (Y^{-1})^k_j(s)\sigma^j_\alpha (X_s).\hfill} 
  $$
\end{theorem}

\begin{remark*}
  The S.D.E (\ref{eq2.1}) is given in the Stratonovitch form as 
    \begin{align*}
      dX_t & = \sigma_\alpha (X_t) o dW^\alpha_t + \tilde{b}(X_t) dt
      \tag*{$(2.1)'$} \\
      X_o & = x 
    \end{align*}
where
$$
\tilde{b}^i(x) = b^i(x) -\frac{1}{2}
      \sum_{k=1}^d \sum_{\alpha=1}^r \partial_k \sigma^i_\alpha (x)
      \sigma^k_\alpha  (x)
$$
  and correspondingly, (\ref{eq2.2}) and (\ref{eq2.3}) are given
  equivalently as  
  \begin{align*}
    dY_t  & = \partial \sigma_\alpha (X_t) Y_t o dW^\alpha_t + \partial
    \tilde{b}(X_t)  dt \tag*{$(2.2)'$}\\
    dZ_t  &=  - Z_t \partial \sigma_\alpha (X_t) o dW^\alpha_t + Z_t
    \partial \tilde{b}(X_t) dt.\tag*{$(2.3)'$}
  \end{align*}
\end{remark*}

For\pageoriginale the proof if theorem \ref{chap2:thm2.1} and theorem
\ref{chap2:thm2.2}, we need the following: 

\setcounter{lem}{0}
\begin{lem}% lemma 1
  Let $X_t$ be the solution of (\ref{eq2.1}) and $a_t = (a^i_t)$ be a
  continuous $B_t$ adapted process. Suppose that $\xi _t = (\xi^i_t)$
  satisfies 
  \begin{align*}
    d \xi_t & = \sum_{\alpha=1}^r \partial \sigma_\alpha (X_t)\xi_t
    dW^\alpha_t + \partial b (X_t) \xi_t dt + a_t dt\\ 
    \xi_o & = 0. \tag{2.4}\label{eq2.4}
  \end{align*}
\end{lem}

Then
$$
\xi_t = \int\limits_o^t Y_t Y^{-1}a_s ds = Y_t \int\limits_o^t
Y^{-1}_s a_s ds,
$$
where $Y_t$ is the solution of (\ref{eq2.2}).

\begin{proof}
It is enough to verify that $\xi_t = \int\limits_o^t  Y_t Y_s^{-1} a_s
ds$ satisfies (\ref{eq2.4}). Now 
\begin{align*}
  d \xi_t & = d (\int\limits_o^t  Y_t Y^{-1} a_s ds)\\
  & = dY_t.\int\limits_o^t  Y^{-1}_s a_s ds + Y_t Y_t^{-1} a_t dt\\
  & = dY_t \int\limits_o^t   Y^{-1}_s a_s ds + a_t dt.\tag*{$\Box$}
\end{align*}

Using (\ref{eq2.2}), we get
\begin{align*}
  d \xi_t & = (\partial \sigma_\alpha(X_t). Y_t dW^\alpha_t + \partial b
  (X_t) Y_t dt) \int\limits_o^t Y_s^{-1} a_s ds + a_t dt\\ 
  & = \partial \sigma_\alpha(X_t) \xi_t dW^\alpha_t + \partial b
  (X_t)\xi_t dt + a_t dt ; 
\end{align*}
hence the lemma is proved.
\end{proof}


\medskip
\noindent{\textbf{Formal Calculations:}}\pageoriginale

By definitions,
$$
DX_t^i[h] = \frac{\partial}{\partial \epsilon} X^i (t,x,w +
\epsilon  h)|_{\epsilon  = o'} h \epsilon  H. 
$$

But
\begin{multline*}
X^i (t,x,w + \epsilon  h) = x + \sum_\alpha \int\limits_o^t
\sigma^i_\alpha (X(s,x,w + \epsilon  h)) d (W^\alpha_s + \epsilon 
h ^\alpha_s)\\ 
+ \int\limits_o^t b^i (X(s,x,w + \epsilon  h)) ds 
\end{multline*}

Hence
\begin{align*}
  DX^i_t[h] & = \sum_{\alpha = 1}^r \sum_{k = 1}^d \int\limits_o^t
  \partial_k \sigma^i_\alpha (X_s) DX^k_s[h] dW^\alpha_s\\ 
  & + \sum_{\alpha = 1}^r \int\limits_o^t  \sigma^i_\alpha (X_s) dh^\alpha_s\\
  & + \sum_{k= 1}^d \int\limits_o^t \partial_k b^i (X_s) DX^k_s[h]  ds.
\end{align*}

This is same as (\ref{eq2.4}) with 
$$
a^i_s = \sum_{\alpha = 1}^r \sigma^i_\alpha (X_s) \dot{h}^\alpha_s.
$$

Hence formally we have
$$
DX^i_t[h] = \sum_{\alpha = 1}^r \int\limits_o^t \left[Y_t Y^{-1}_s
  \sigma_\alpha (X_s)\right]^i \dot{h}^\alpha_s ds. 
$$

Now, let for $i= 1, 2,\ldots d$,
\begin{alignat*}{2}
  \dot{\eta}^i_t, \alpha^{(s)} & = [Y_t Y^{-1}_s \sigma_\alpha (X_s)]^i
  &\qquad &\text{if}~ s \le t \\ 
  & = 0  &\qquad &\text{if}~ s > t.
\end{alignat*}


For fixed $s, 0 \le s \le t \le T, \dot{\eta}^{i, \alpha}_t, (s) $
satisfies the following:
\begin{align*}
  \dot{\eta}^{i, \alpha}_t (s) & = \sum_j \int\limits_s^t \partial_j
  \sigma^i_\alpha (X_u) \dot{\eta}^{j, \alpha}_u {(s)} dW^\alpha_u  \\
& \qquad +
  \sum_j \int\limits_s^t \partial_j b^i (X_u) \dot{\eta}^{j, \alpha}_u
      (s) du + \sigma^i_\alpha (X_s).\tag{2.5}\label{eq2.5} 
\end{align*}\pageoriginale

Note that this is same as (\ref{eq2.2}) with initial condition
$\sigma^i_\alpha (X_s)$. Now 
$$
\displaylines{\hfill 
DX^i_t[h] = < \eta^i_t, h >_H = \sum_\alpha \int\limits_o^T
\dot{\eta}^{i,\alpha}_t (s) \dot{h}^\alpha(s) ds \hfill \cr
\text{where}\hfill
\eta^{i,\alpha}_t (s) = \int\limits_o^s \dot{\eta}^{i,\alpha}_t (u)du
\epsilon \, H.\hfill} 
$$

Hence
$$
< DX^i_t,DX^j_t >_H = \sum_{\alpha=1}^r \int\limits_o^t [Y_t Y^{-1}_s
  \sigma_\alpha (X_s)]^i [Y_t Y^{-1}_s \sigma_\alpha (X_s)]^j ds. 
$$

A rigorous proof is given by using approximating arguments. Let 
$$
\displaylines{\hfill
  \phi_n (s) = \frac{k}{2^n}, \text{ if } \frac{k}{2^n} \le s <
  \frac{k+1}{2^n}, n=1,2 \dots \hfill \cr
  \text{and}\hfill
  \psi_n (s) = \frac{k+1}{2^n}, \text{if} \frac{k}{2^n} < s \le
  \frac{k+1}{2^n}, n= 0,1,2 \dots \hfill}
$$

Using $\phi_n$ and $\psi_n$, we write the corresponding approximating
equations of (\ref{eq2.1}), (\ref{eq2.2}), (\ref{eq2.5}) as  
\begin{align*} 
  dX^{(n)}_t &= \sigma_\alpha \left(X_{\phi_n (t)}^{(n)}\right)dW^\alpha_t +
  b \left(X_{\phi_n (t)}^{(n)}\right)dt \tag*{(2.1)a}\label{eq2.1a} \\
  X_o^{(n)}& =x\\
  dY^{(n)}_t &=  \partial\sigma_\alpha \left(X_{\phi_n (t)}^{(n)}\right)
  Y_{\phi_n (t)}^{(n)} dW^\alpha_t + \partial b
  \left(X_{\phi_n (t)}^{(n)}\right)
  Y_{\phi_n (t)}^{(n)} {dt} \tag*{(2.2)a}\label{eq2.2a}\\ 
  Y_o^{(n)}& = I.\\
  \dot{\eta}^{i,\alpha, (n)}_t (s) & = \sum_{\alpha} \sum_{j}
  \int\limits_{\psi_n(S) \Lambda t}^t \partial_j  \alpha^j_\alpha
  \left(X^{(n)}_{\Phi_n (u)}\right) \dot{\eta^{j, \alpha, (n)}_{\Phi_n
      {(u)}}}  (s) dW^\alpha_u\\ 
  & +  \sum_{j} \int\limits_{\psi_n (S) \Lambda t}^t
  \partial_j  b^i \left(X^{(n)}_{\Phi_n {(u)}}\right) \dot{\eta^{j, \alpha,
      (n)}_{\Phi_n {(u)}}} (s) du +
  \sigma^i_\alpha \left(X^{(n)}_{\phi_n
    {(s)}}\right). \tag*{(2.5)a}\label{eq2.5a}  
\end{align*}\pageoriginale

It is easily seen that \ref{eq2.1a} has a unique solution $X_t^{(n)}
\epsilon  \mathcal{S}$: the space of smooth functionals, and
$\partial X_{t}^{(n)}= Y^{(n)}_t$. 

Further,
$$
DX^{(n)}_t [h]= \sum_\alpha \int\limits_{o}^t \dot{\eta}^{i, \alpha,
  (n)}_{t} (S) \dot{h}^{\alpha}(s) ds. 
$$  

Then the theorem \ref{chap2:thm2.2} follows from the approximating theorem. 

\begin{theorem}\label{chap2:thm2.3}%them 2.3
  Suppose, for $x \epsilon  \mathbb{R}^m$, $A(x)= (A^j_\alpha(x))
  \epsilon  \mathbb{R}^m \otimes \mathbb{R}^r, B(x) = (B^i (x))
  \epsilon  \mathbb{R}^m$ satisfy 
  \begin{align*}
    &|| A(x) || + |B(x)| \le K(1+ |x|),\\
    &|| A(x) - A(y) || +  |B(x)- B(y)| \le K_N| x-y| ~\forall~ |x|, |y|  \le N.
  \end{align*}
 \end{theorem} 
 
 Also,
\begin{enumerate} [(a)]
\item Suppose $\alpha_n (t), \alpha(t)$ be $\mathbb{R}^m$ -valued
  continuous $B_t$ adapted processes such that, for some  $2 \le  p <
  \infty$,  
  \begin{align*}
    & \Sup_n E \left[ \sup_{o \le t \le T} | \alpha_n (t) |^{p+1}\right]< \infty, \\
    &  E \left[ \sup_{o \le t \le T} | \alpha_n (t) - \alpha (t)|^p\right] \to 0
    \text{ as } n \to \infty 
  \end{align*}
  and let, for $i=1, \ldots, n$,
  $$
  \xi^i (t) = \alpha^i (t) +  \sum_{\alpha=1}^{r} \int\limits_{o}^t 
  A^i_\alpha (\xi(s)) dW^\alpha (s) +  \int\limits_{o}^t B^i (\xi
  (s))ds 
  $$
  and 
  \begin{align*}
    \xi^{i, (n)} (t) = \alpha^i_n (t) &+ \sum_{\alpha=1}^{r}
    \int\limits_{o}^t A^i_\alpha( \xi^{(n)} (\Phi_n(s))) dW^\alpha_s
    + \int\limits_{o}^t B^i (\xi^{(n)} ( \Phi_n(s))) ds,
  \end{align*} 
  then\pageoriginale 
  \begin{align*}
    & E \left[ \sup_{o \le s \le T} |  \xi^{(n)} (s) |^p\right] <
    \infty \text{ and }\\ 
    & E \left[ \sup_{o \le s \le T} |  \xi^{(n)} (s)- \xi (s) |^p
      \right] \to 0 \text{ as } n \to \infty. 
  \end{align*} 

\item Suppose $\alpha_{n,\nu}(t), \alpha_\nu (t), t \epsilon  [\nu,
  T]$ are $\mathbb{R}^m$-valued continuous $B_t$- adapted processes
  such that, for some  $2 \le p < \infty$, 
  \begin{align*}
     \sup_n & \sup_{o \le \nu \le T} E \left[ \sup_{\nu \le t \le T} |
      \alpha _{n, \nu}(t) |^{p+1}\right] < \infty,\\ 
    & \sup_{o \le \nu \le T} E \left[ \sup_{\nu \le t \le T} |  \alpha _{n,
        \nu}(t) - \alpha_\nu  (t) | ^p\right] \to \text{ as } n \to \infty. 
 \end{align*}
\end{enumerate} 
 
 Let
 $$
  \xi ^i_\nu (t) = \alpha^i_\nu(t) + \sum_{\alpha=1}^{r}
  \int\limits_{\nu}^{t} A^i_{\alpha}(\xi_\nu(s)) dW^\alpha_s +
  \int\limits_{\nu}^t B^i (\xi_\nu(s)) ds 
 $$
 and 
{\fontsize{10pt}{12pt}\selectfont
 $$
 \xi^{i, (n)}_\nu (t) = \alpha^i_{n, \nu}(t) + \sum_{\alpha =1}^{r}
 \int\limits_{\psi_n(\nu) \Lambda t} A^i_\alpha (\xi _\nu^{(n)}(\Phi_n
 (s)))dW^\alpha_s +  \int\limits_{\psi_n(\nu) \Lambda t} B^i (\xi
 _\nu^{(n)}(\Phi_n (s)))ds. 
 $$}\relax
 
 Then
 $$
\displaylines{\hfill
  E\left[ \sup_{\nu \le s \le T} | \xi_\nu^{(n)} (s)|^P\right] <
  \infty\hfill\cr 
  \text{and}\hfill 
  E\left[ \sup_{\nu \le s \le T} | \xi_\nu^{(n)} (s) - \xi_\nu
    (s)|^p\right] \to 0\hfill } 
 $$
uniformly in $\nu$  as  $n \to \infty$.

Let\pageoriginale $X_t= ( X^i_t)^d_{i=1}$ satisfy (\ref{eq2.1}). Let $\sigma_t =
((\sigma_{ij}(t)))$ where 
$$
\sigma_{ij}(t) = < DX^i_t, DX^j_t >_H.
$$

The problem now is to prove condition \ref{eqA.2}, i.e., 
$$
(\det \sigma_t) ^{-1} \epsilon   L_p ~\forall~ 1 < p < \infty.
$$

Let $Y_t$ satisfy (\ref{eq2.2}). Then $Y_t$ can be considered as an element of
$GL(d, \mathbb{R})$- the group of real non-singular $d \times d$
matrices. Then $(X_t,  Y_t)\in\break  \mathbb{R}^d \times GL(d,
\mathbb{R})$. Let $r_t = (X_t, Y_t)$, which is determine  by (\ref{eq2.1})
and (\ref{eq2.2}). 

\begin{definition}\label{chap2:def2.1}%defini 2.1
  Let $(a^i {(x))^d_{i=1}}$ be smooth functions on $\mathbb{R}^d$ and
  $L=\sum_{i=1}^d$ $a^i (x) \frac{\partial}{\partial x^i}$, the
  corresponding vector field on $\mathbb{R}^d$. Then for  
  $$
  \displaylines{\hfill
  r= (x,e) \epsilon  \mathbb{R}^d \times GL(d, \mathbb{R})\hfill \cr
  \text{we define}\hfill 
  f^i_L (r) \triangleq \sum_{j=1}^{d} (e^{-1})^i_j a^j (x) i=1,2,
  \ldots d\hfill\cr 
  \text{and}\hfill  
  f_L(r) = (f^i_L(r))^d_{i=1}.\hfill }
  $$
\end{definition} 

Let 
\begin{align*}
  \begin{aligned}
    L_\alpha (x) &= \sum^{d}_{i=1} \sigma^i_\alpha (x)
    \frac{\partial}{\partial x^i} \alpha = 1,2,\ldots, r.\\ 
    L_o (x)& = \sum_{i=1}^{d} \tilde{b}_i (x) \frac{\partial}{\partial x^i}\\
    \text{where}\hspace{3cm}  \bar{b}_i(x) &= b^i - \frac{1}{2} \sum_k
    \sum_\alpha \partial_k \sigma^i_\alpha (x) \sigma^k_\alpha(x).
  \end{aligned}
\end{align*}

\setcounter{proposition}{3}
\begin{proposition}\label{chap2:prop2.4}%Prop 2.4
  Let\pageoriginale
  $$
  L=\sum_i a^i (x)\frac{\partial}{\partial x^i}
  $$
  be any smooth vector field on $\mathbb{R}^d$. Then. for $i=1,2,\ldots,d$,
  \begin{align*}
    f^i_L(r_t)-f_L^i(r_0) &=\sum_{\alpha=1}^{r}\int\limits^t_0
    f^i_{[L_\alpha, L]}(r_s) odW^{\alpha}_s+\int\limits_o^t f^i_{[L_o,
      L]} (r_s)ds\\ 
    &=\sum_{\alpha=1}^r \int\limits_o^t
    f^i_{[L_{\alpha},L]} (r_s)dW_s^{\alpha}\\
    & \qquad + \int\limits_o^t f^i_{\left\{[L_o,
      L] +\frac{1}{2}\sum_{\alpha=1}^r \left[L_{\alpha},[L_{\alpha},
        L]\right]\right\}} (r_s)ds, 
  \end{align*}
  where $[L_1,L_2]=L_1L_2-L_2L_1$ is the commutator of $L_1$ and $L_2$.
\end{proposition}

\begin{proof}
  $f_L^i(r_t)=[Y_t^{-1}a(X_t)]^i$ and we know that
  $$
  \displaylines{\hfill
  dY^{-1}_t=-Y_t^{-1}\partial \sigma_{\alpha}(X_t)odW^{\alpha}_t -
  Y^{-1}_{t} \partial \tilde{b}(X_t)dt\hfill\cr 
  \text{and}\hfill
  da(X_t)=\partial a (X_t)\sigma_{\alpha}(X_t)odW_t^{\alpha}+ \partial
  a (X_t)\tilde{b}(X_t)dt\hfill\cr 
  \text{where}\hfill
  \partial a(X_t)=((\frac{\partial a^i}{\partial x^j}(X_t))).\hfill}
  $$
The proof now follows easily from the It\^{o} formula.
\end{proof}

\begin{remark*}%Remk
  $f_{L_{\alpha}}(r_s)=Y_s^{-1}\sigma_{\alpha}(X_s)$. Therefore
  $$ 
  \sigma_t^{ij}=< DX_t^i, DX_t^j>_H  =  \sum_{\alpha=1}^r
  \int\limits_0^t[Y_t f_{L_{\alpha}}(r_s)]^i [Y_t f_{L_\alpha}(r_s)]^j
  ds. 
  $$
\end{remark*}

\begin{proposition}\label{chap2:prop2.5}%Prop 2.5
  Let
  $$
  \hat{\sigma}_t^{ij} (w) = \sum_{\alpha=1}^r \int\limits_0^t
  f^i_{L_{\alpha}}(r_s)f^j_{L_\alpha}(r_s) ds. 
  $$

  Then
  $$
  (\det \sigma_t)^{-1}\epsilon  L_P, ~\forall~ 1<P< \infty \,\text{iff}\, (\det
  \hat{\sigma}_t)^{-1}\epsilon  L_P ~\forall~ 1 < p < \infty. 
  $$\pageoriginale
\end{proposition}

\begin{proof}
  $\sigma_t=Y_t \hat{\sigma}_t Y_t^*$
  implies $\det \sigma_t=(\det Y_t)^2(\det  \hat{\sigma}_t)$.
  
  We know that $|| Y_t ||, || Y_t^{-1} || \epsilon  L_P~ ~\forall~ ~1
  < p < \infty$, where 
  $$
  || \sigma ||= \left(\sum_{i,j}| \sigma_{ij}|^2\right)^{1/2}.
  $$

  Hence, if $\lambda_i^2, i =1,2, \ldots, d$ are the eigenvalues of $Y_tY_t^*$
  then
  $$
  (\det Y_t)^2=\det Y_t Y_t^*=\lambda_1^2 \cdots \lambda_n^2
  $$
  and
  \begin{align*}
    || Y_t ||^2 &=\sum_i <Y_t Y_t^* e_i,e_i >\\
    &=\lambda_1^2+ \cdots +\lambda_n^2
  \end{align*}
  where $(e_i)^d_{i=1}$ is an orthonormal basis in $\mathbb{R}^d$. Therefore
  $$
  (\det ~ Y_t)^2 \leq || Y_t ||^{2n}.
  $$

  Similarly
  $$
  (\det~Y_t^{-1})^2 \leq || Y_t^{-1}||^{2n}.
  $$
  
  Hence the result.
\end{proof}

\section[Existence of moments for a class of Wiener
  Functionals]{Existence of moments for a class of Wiener\hfill\break
  Functionals}%sec 2.2 


\begin{proposition}%Prop 2.6
  Let $\eta>0$ be a random variable on $(\Omega, F, P)$. If,
  $\forall~N=2,3,4,\ldots,\exists $ constants $c_1, c_2, c_3 > 0$
  (independent of $N$) such that 
  $$
  P\left[\eta < \frac{1}{N^{c_1}}\right]=P\left[\eta^{-1}>N^{C_1}\right]
  \leq e^{-c_2N^{C_3}}, 
  $$
  then \quad $E[\eta^{-P}]< \infty, \forall~p > 1$.
\end{proposition}

\begin{proof}
  \begin{align*}
    E \left[\eta^{-P}\right] & \leq 1+\sum_{N=1}^{\infty} E
    \left[\eta^{-P}: N^{C_1} \leq \eta^{-1}\leq (N+1)^{C_{1}}\right]\\ 
    & \leq 1+2^{C_1P}+\sum_{N=2}^{\infty}(N+1)^{C_1p} e^{-C_2 N^{C_3}}\\
    & < \infty.
  \end{align*}\pageoriginale
\end{proof}

\begin{example}\label{chap2:exam2.1}%Exmp 2.1
  Let $0 < \bar{t} \leq T$. Let
  $$
  \eta=\int\limits_0^{\bar{t}}| w(s)|^{\gamma} ds; ~\gamma > 0.
  $$

  Then we will prove that $E[\eta^{-P}]< \infty, \forall~
  1<P<\infty$. To prove this, we need a few lemmas. 
\end{example}


\begin{alphlemma}\label{chap2:alphlemA}%%% A
  Let $P$ be the Wiener measure on $C([o,T]\to \mathbb{R}^r)$. Then,
  $\forall~ \epsilon  > 0, 0<t \leq T \exists~ C_1, C_2> 0$ and
  independent of $\epsilon $ and $t$ such that 
  $$
  P\left[\sup_{0 \leq s \leq t}|w(s)| < \epsilon \right] \leq C_1
  e^{-\dfrac{tc_2}{\epsilon ^2}}. 
  $$
\end{alphlemma}



\begin{proof}
  For $X \epsilon  \mathbb{R}^r, |x|<1$, let
  $$
  u(t, x)=P \left[\max_{0 \leq s \leq t}| w(s)+x | < 1\right].
  $$
\end{proof}

Then it well known that
\begin{align*}
   \frac{\partial u}{\partial t}& =\frac{1}{2} \triangle u 
   ~\text{in}~ \{|x| \leq 1\}\\ 
    u|_{t=0}&=1\\ 
    u|_{|x|=1}&=0.
\end{align*}

Therefore, if $\lambda_n, \phi_n$ are the eigenvalues and
eigenfunctions for the corresponding eigenvalue problem, then 
$$
u(t,x)= \sum_n e^{-\lambda_n t}\phi_n(x) \int_{|y|\leq 1} \phi_n (y) dy.
$$

Also\pageoriginale since $\{w(s)\} \sim \left\{\epsilon  w
\left(\dfrac{s}{\epsilon ^2}\right)\right\}$ for every $\epsilon  > 0$, 
\begin{align*}
  P \left[\sup_{0 \leq s \leq t}| w(s) | < \epsilon \right]
  &=P \left[\sup_{0 \leq s \leq \frac{t}{\epsilon ^2}}| w(s) | < 1\right]\\
  &=u \left(\frac{t}{\epsilon ^2}, 0\right)\sim \phi_1(0) \int\limits_{|Y| \leq
    1}\phi_1(y)dy \times e^{-\frac{\lambda_1^t}{\epsilon ^2}} 
\end{align*}

\begin{alphlemma}\label{chap2:alphlemB}%%% B
  Let
  $$
  \xi(t)= \sum_{\alpha=1}^{r} \int\limits_0^{t} \phi_{\alpha}(s,
  w)dW_s^{\alpha}+\int\limits_0^{t}\psi (s, w)ds.
  $$
  Let
  $$
  \sum_{\alpha=1}^r| \phi_{\alpha}(s, w)|^2 \leq k, | \psi(s, w)| \leq k.
  $$
\end{alphlemma}

Then, $\forall~ a>0 $ and $0 < \epsilon  < \dfrac{a}{2k}, \exists~
c>0$, independent of $a, \epsilon $, and $k$ such that 
$$
\displaylines{\hfill 
  P(\tau_a < \epsilon ) \leq e^{-\frac{ca^2}{k \epsilon }},\hfill\cr
  \text{where}\hfill
  \tau_a= \inf \{t: | \xi (t)| > a\}.\hfill}
$$

\begin{proof}
  We know that we can write
  $$
  \xi(t)=B(A_1(t))+A_2(t)
  $$
  where
  \begin{align*}
    A_1(t) &=\sum_{\alpha=1}^r \int\limits_0^{t} | \phi_{\alpha}(s, w)|^2 ds,\\
    A_2(t) &=\int\limits_0^t \psi (s, w)ds
  \end{align*}
  and $B(t)$ is a 1-dimensional Brownian motion with $B(0)=0$.
\end{proof}

 Hence
 $$
 \{|\xi (t)|>a\}\subset \left\{|B(A_1(t))|> \frac{a}{2}\right\} U
 \left\{|A_2(t)|> \frac{a}{2}\right\}. 
 $$

Further\pageoriginale  $|A_1(t)| \leq kt \,i=1,2$, and if
$$
\sigma_{a/2}^B= \inf \left\{t:|B(t)|> \frac{a}{2}\right\},
$$
then
\begin{align*}
  \left\{|B(A_1(t))|> \frac{a}{2}\right\} & \subset \left\{A_1(t)>
  \sigma^B_{a/2}\right\}\\ 
  &\subset \left\{kt > \sigma^B_{a/2}\right\}\\
  \Rightarrow \tau_a & \geq \frac{a}{2k} \Lambda \sigma_{a/2}^B/k ~\text{a.s.}
\end{align*}

Therefore, if
\begin{align*}
  0 < \epsilon  < \frac{a}{2k}&,\\
  P\left[\tau_a < \epsilon \right] & \leq P\left[\sigma_{a/2}^B< k
    \epsilon \right]\\ 
  &\leq p\left[\max_{0 \leq s \leq k \epsilon }|B(s)| > \frac{a}{2}\right]\\
  & \leq 2P\left[\max_{0 \leq s \leq k \epsilon }B(s)> \frac{a}{2}\right]\\
  &=2 \surd \left(\frac{2}{\pi k \epsilon }\right)
  \int\limits^{\infty}_{a/2}e^{-(x^2/k \epsilon )}dx\\ 
  &\leq e-c.(a^2/k \epsilon).
\end{align*}


\medskip
\noindent{\textbf{Ex. \ref{chap2:exam2.1} (Solution):}}
Let $\bar{t}$ be such $0 < \bar{t} \leq T$ and for
  $N=2,3, \ldots$, define 
  $$
  \sigma_{2/N}(w)=\inf \left\{t: |w(t)| \geq \frac{2}{N}\right\}
  $$
  and
  $$
  \sigma_1^N(w)=\sigma_{2/N}(w) \Lambda \frac{\bar{t}}{2}.
  $$
  
  Let
  $$
  W_1=\left\{w:\sigma_{2/N}(w)< \frac{\bar{t}}{2}\right\},
  $$
  then, by lemma \ref{chap2:alphlemA}, we have $P(w_1^c)\leq
  e^{-c_1N^2}$, for some 
  constant $c_1$ independent of $N$. We denote the shifted path of
  $w(t)$ as 
  $$
  w_s^+(t)=w(t+s).
  $$

Define\pageoriginale
$$
\displaylines{\hfill
  \tau_{1/N}(w)=\inf \left\{t: |w(t)-w(0)| \geq
  \frac{1}{N}\right\}\hfill \cr
  \text{and let}\hfill
  W_2=\left\{W:\tau_{1/N}(w^+_{\sigma_1^N}) \geq
  \frac{\bar{t}}{N^3}\right\}.\hfill }
$$

Note that if $w \epsilon  W_1 \cap W_2$ then
$\sigma_1^N=\sigma_{2/N}$. By strong Markov property of Brownian
motion, we get 
\begin{align*}
  P(W_2^C) &=P\left(\tau_{1/N} < \frac{\bar{t}}{N^3}\right)\\
  & \le e^{-C_{3} N}  \quad (\text{by lemma \ref{chap2:alphlemB}}).
\end{align*}

Define
$$
\sigma_2^N(w)=\sigma_1^N+\tau_{1/N}(w^+_{\sigma_1^N})\Lambda
\frac{\bar{t}}{N^3}. 
$$

From the definition, it follows that on $W_2$,
$$
\sigma_2^N=\sigma_1^N+\frac{\bar{t}}{N^3}.
$$

Clearly, if $t \epsilon  \left[\sigma_1^N, \sigma_2^N\right]$, then
$|w(t)| \leq \dfrac{3}{N}$ and if $w \epsilon  W_1 \cap W_2$, then
$\dfrac{1}{N}\leq |w(t)| \leq \dfrac{3}{N}$. Hence we have. for $w
\epsilon  W_1 \cap W_2$, 
\begin{align*}
  n(w)= \int\limits_0^{\bar{t}}|w(s)|^{\gamma} ds &\geq \int
  \limits_{\sigma_1^N}^{\sigma_2^N}| w(t)|^{\gamma} dt\\ 
  & \geq \frac{\bar{t}}{N^3}. \frac{1}{N^Y}=\frac{\bar{t}}{N^{3+y}}.
\end{align*}

Now
$$
P(W_1^C U W_2^C) \leq e^{-C_4 N}
$$
Hence
$$
P\left(\eta< \frac{\bar{t}}{N^{3+y}}\right)\leq e^{-C_4N}, N=2,3, \ldots
$$
which\pageoriginale gives, by proposition \ref{chap2:prop2.4}, that
$E(\eta^{-p})< \infty$ for every $p>1$.  


\medskip
\noindent{\textbf{Example \ref{chap2:exam2.1}(a):}}
  Let
  $$
  \eta (w)= \int \limits_0^{\bar{t}}e^{- \dfrac{1}{|w(s)|^{\gamma}}}
  ds, 0 < \bar{t} \leq T, \gamma > 0 ; 
  $$
  then $E(\eta^{-p})< \infty$ for all $1 < p < \infty$ when $\gamma <
  2$, and for $\gamma \geq 2$ there exists $p$ such that
  $E[\eta^{-p}]=\infty$. 

\begin{proof}
Exercise.
\end{proof}

\begin{example}%% 2.2
  Let
  $$
  \eta(w)=\int\limits_0^{\bar{t}} \left[\int \limits_0^t|
    w(s)|^{\gamma}dW(s)\right]^2 dt, \text{ for  } 0 <\bar{t} \leq T 
  $$
  fixed, then $E[\eta^{-p}]< \infty$, for every $1 < p < \infty$.
\end{example}

\begin{proof}
  In example \ref{chap2:exam2.1}, we have seen stopping times
  $\sigma_1^N$ and 
  $\sigma_2^N$ satisfying; $0 \leq \sigma_1^N < \sigma_2^N \leq
  \bar{t}, \sigma_2^N-\sigma_1^{N}=\dfrac{\bar{t}}{N^3}$ and 
  $$
  |w(u)| \leq \frac{3}{N}, \text{ if } u \epsilon  \left[\sigma_1^N,
    \sigma_2^N\right]. 
  $$

  Now, let
  \begin{align*}
    W_1 &= \left\{\sigma_2^N-\sigma_1^N = \frac{\bar{t}}{N^3}\right\},\\
    W_2 &= \left\{W: \int \limits_{\sigma_1^N}^{\sigma^N_2}|w(u)|^{2
      \gamma} du > \frac{\bar{t}}{N^{2 \gamma+3}}\right\}. 
  \end{align*}
\end{proof}

By lemma \ref{chap2:alphlemB},
$$
P(W_1^C) \leq e^{-C_1N^{C_2}}
$$
and we have seen that $P(W_2^C) \leq e^{-C_1N^{C_2}}$. Let
$$
\theta(s)= \int\limits_0^s |w(u)|^{2 \gamma} du.
$$

Then\pageoriginale by representation theorem for martingales, there exists
one-dimensional Brownian $B(t)$ such that 
$$
\int\limits_0^t | w(s)|^{\gamma}dW_s=B(\theta(t)).
$$

For $ w \epsilon  W_1 \cap W_2$,
\begin{align*}
  \eta &=\int\limits_0^{\bar{t}}| B(\theta(t))|^2 dt \geq
  \int\limits_{\sigma_1^N}^{\sigma_2^N} | B(\theta(t))|^2 dt\\ 
  &=\int\limits_{\theta(\sigma_1^N)}^{\theta(\sigma_2^N)}| B(s)|^2 d
  \theta^{-1}(s) ~\text{changing the variables}~ \theta(t) \to s\\
  &\begin{tabular}{l|l}
     $= \int\limits_{\theta(\sigma^N_1)}^{\theta (\sigma^N_2)} \dfrac{| B (s)
       |^2}{| w (\theta^{-1} (s)) |^{2_\gamma} ds}$ & $s =
     \int\limits_o^s \dfrac{d (\theta (u))}{| w (u) |^{2_\gamma}}$\\ 
     $\ge \int\limits^{\theta(\sigma_2^N)}_{\theta (\sigma_1^N)} |
     B(s) |^2 \left(\dfrac{N}{3}\right)^{2_\gamma} ds$ & $\theta^{-1} (s) =
     \int\limits_{o}^{\theta^{-1} (s)} \dfrac{d \theta (u)}{|w(u)
       |^{2_\gamma}}$\\ 
     $\ge \left(\dfrac{N}{3}\right)^{2_\gamma} \int\limits^{\theta (\sigma_1^N) +
       \dfrac{\bar{t}}{N^{2_\gamma + 3}}}_{\theta(\sigma_1^N) } |B (s)
     |^2 ds$ & = $\int\limits_o^s \dfrac{du}{| w (\theta^{-1} (u))
       |^{2_\gamma}}$ 
   \end{tabular}\\
  \text{i.e., }\quad \eta & \geq \left(\frac{N}{3}\right)^{2 \gamma}
  \int\limits^{\theta (\sigma_1^N)+ \frac{\bar{t}}{N^{2
  \gamma+3}}}_{\theta (\sigma_1^N)}|B(s)|^2 ds. \tag{2.6}\label{eq2.6} 
\end{align*}

To proceed further, we need the following lemma whose proof will be
given later. 
 
Let $I=[a,b]$ and for $f \epsilon  L^2(I)$ define
$$
\bar{f}=\frac{1}{b-a} \int\limits_I f(x)dx
$$
and
$$
V_I(f)=\frac{1}{b-a}\int\limits_I (f(x)-\bar{f}^2)dx
$$
$V_I$\pageoriginale has following properties:
\begin{enumerate}[(i)]
\item $V_I(f) \geq 0 ~~ \forall~ f ~\epsilon  ~L^2 (I)$

\item $V_I^{1/2}(f+g) \leq V_I^{1/2}(f) + V_I^{1/2}(g)$

\item $V_I(f) \leq \dfrac{1}{b-a} \int\limits_I (f(x) -k)^2 dx$ for
  any constant $k$. 
\end{enumerate}

\begin{alphlemma}\label{chap2:alphlemC}%%% C
  Let $B(t)$ be any one-dimensional Brownian motion on $I=[0,
    a]$. Then the random variable $V_{[0, a]}(B)$ satisfies: 
  $$
  P\left[V_{[0, a]}(B) < \epsilon ^2\right] \leq \sqrt{2}e^{-\dfrac{a}{2^7
      \epsilon ^2}}, \text{  for every  }\epsilon , a > 0. 
  $$
\end{alphlemma}

From (\ref{eq2.6}), using the property (iii) of $V_I$, we get
$$
\eta \geq \left(\frac{N}{3}\right)^{2_\gamma }V_{\left[\theta (\sigma_1^N),
    \theta(\sigma_1^N)+
    \bar{t}/(N^{2_{\gamma}+3})\right]}{(B)\frac{\bar{t}}{N^{2
      _{\gamma}+3}}}.  
$$

Now let 
$$
W_3= \left\{ w:\frac{\bar{t}}{{3^{2_\gamma} N^3}} V_{[\theta
    (\sigma_1^N), \theta(\sigma_1^N)+t/(N^{{2_\gamma}+3})]} (B) >
\frac{\bar{t}}{N^m} \right\} 
$$
Then by lemma \ref{chap2:alphlemC}, we have, for sufficiently large $m$,
\begin{align*}
  P(W_3^C) &\leq e^{-C_3N^{(m-3)-(2 \gamma +3)}}\\
  &\leq e^{-C_3N^{C_4}}.
\end{align*}

Hence on $W_1 \cap W_2 \cap W_3$, $n \geq \dfrac{\bar{t}}{N^m} \geq
\dfrac{1}{N^{C_5}}$. Now 
\begin{align*}
  P((W_1 \cap W_2 \cap W_3)^c) &\leq P(W_1^c)+P(W_2^c)+P(W_3^c)\\
  &\leq e^{-c_6^{N^{C_7}}}.
\end{align*}

Hence by proposition \ref{chap2:prop2.4}, it follows that
$$
E[\eta^{-p}] < \infty, ~\forall~ \quad 1< p < \infty.
$$


\medskip
\noindent{\textbf{Proof of Lemma \ref{chap2:alphlemC}:}} 
  Using\pageoriginale the scaling property of Brownian motion, we have
  $$
  aV_{[\circ, 1]}(B) \sim V_{[\circ, a]}(B).
  $$

Therefore, it is enough to prove that
$$
p\left[V_{[\circ, 1]}(B) < \epsilon ^2\right] \leq \sqrt{2}e^{-1(2^7
  \epsilon ^2)}. 
$$

For $t \epsilon  [\circ, 1]$, we can write
$$
B(t)=t \xi_0 +\surd{2} \sum_{k=1}^{\infty} \left[\xi_k \left\{\frac{\cos (2 \pi
    kt)-1}{2 \pi k}\right\}+\eta_k \frac{\sin 2 \pi kt}{2 \pi k}\right] 
$$
where $\{\xi _k\},\{\eta_k\}$ are $i. i. d. N(\circ, 1) $ random
variables. Therefore 
$$
B(t)-\int\limits_0^1 B(s)ds=\left(t-\frac{1}{2}\right)\xi_0 +\surd 2
\sum_{k=1}^{\infty}\left[\xi_k \frac{\cos 2 \pi kt}{2 \pi k}+\eta_k
  \frac{\sin 2 \pi kt}{2 \pi k}\right]. 
$$

Note that the functions $\left\{t-\frac{1}{2}, \sin 2 \pi kt \right\}$ are
orthogonal to $\left\{\cos 2\pi kt\right\}$ in $L^2[\circ, 1]$. Therefore 
$$
V=V_{[\circ, 1]}(B) \geq \sum_{k=1}^{\infty} \xi^2_k \times
\frac{1}{(2 \pi k)^2}. 
$$

Hence
\begin{align*}
  E(e^{-2z^2V}) & \leq E \left(e^{-2 z^2} \sum_k \xi_k^2/(2 \pi k)^2 \right)\\
  &=\prod_k E\left(e^{-Z^2 \xi_k^2/2 \pi^2 k^2}\right)\\
  & =\prod_k\left(1+ \frac{Z^2}{\pi^2 k^2}\right)^{-1/2}=\surd
  \left(\frac{Z}{\sin h ~z}\right)\\ 
  & \leq \surd{2} e^{-z/4}.
\end{align*}

Therefore
\begin{align*}
  P(V < \epsilon ^2) &\leq e^{2 z^2 \epsilon ^2} E(e^{-2z^2 v})\\
  & \leq \surd{2} e^{2 z^2 \epsilon^2- \frac{Z}{4}}, ~\forall~ z. 
\end{align*}

Taking\pageoriginale $z=\dfrac{1}{16 \epsilon ^2}$, we get
$$
P(V_{[0, 1]}(B)<\epsilon ^2) \leq \surd{2}e^{-1/(2^7 \epsilon ^2)}.
$$

\begin{example}\label{chap2:exam2.3}%%%% 2.3
  Let
$$
  \xi(t)=\xi(0)+\sum_{\alpha=1}^{\gamma}\int\limits_0^t
  \xi_{\alpha}(s)dW_s^{\alpha}+\int\limits_0^t \xi_0(s)ds 
$$
and suppose $\exists$ a sequence of stopping times $\sigma_1^N,
\sigma_2^N$, 
\end{example}

$N=2,3,\ldots$, such that  $0 \leq \sigma_1^N \leq \sigma_2^N \leq
\bar{t}$ and  
\begin{enumerate}[(i)]
\item $\sigma_2^N - \sigma_1^N \leq \dfrac{\bar{t}}{N^3}$.

\item $\sum\limits_{\alpha=1}^\gamma | \xi_{\alpha}(s)|^2 + |\xi_0
  (s)| \leq c_1, ~\forall~ s \epsilon  \left[\sigma_1^N,
  \sigma_2^N\right]$, 

\item $P\left[\sigma_2^N-\sigma_1^N < \dfrac{\bar{t}}{N^3}\right] \leq
  e^{-c_2N^{C_3}}$ 

\item $P\left[\int\limits_{\sigma_1^N}^{\sigma_{2^N}}| \xi (t)|^2 dt
  \leq \dfrac{1}{N^C_4}\right] \leq e^{-c_2N^{c_3}}$ 
\end{enumerate}
where $c_i>0$, $i=1,2,3,4$ are all independent of $N$. Let
$$
\displaylines{\hfill
  \eta(t)=\eta(0)+\int\limits_0^t \xi (s)ds\hfill\cr
  \text{and}
  \hfill\eta=\int\limits_0^{\bar{t}}|\eta(s)|^2 ds (\geq
  \int\limits_{\sigma_1^N}^{\sigma_2^N}| \eta(s)|^2 ds).\hfill} 
$$

Then $\eta^{-1} \epsilon  L_P, ~\forall~ 1<p< \infty$. This follows
from the estimate $\exists~ c_5> 0, c_6>0, c_7>0$ (all independent of
$N$) such that 
$$
P\left[\int\limits_{\sigma_1^N}^{\sigma_2^N}| \eta(t)|^2 dt \leq
  \frac{1}{N^{C_5}}\right] \leq e^{-c_6N^{c_7}}. 
$$

To prove this, we need a few lemmas:

\begin{alphlemma}\label{chap2:alphlemD}%% D
  Let\pageoriginale
  $$
  \xi(t)=\xi_0+\sum_{\alpha=1}^\gamma \int\limits_0^t
  \xi_{\alpha}(s)dW_s^{\alpha}+\int\limits_0^t \xi_0(s) ds. 
  $$
  Let
  $$
  \sup_{t_1 < s \leq t_2} \sum_\alpha | \xi_{\alpha}(s)|^2 + |\xi_0(s)| \leq c.
  $$
  
  Then  $\forall~ 0 < \gamma< \frac{1}{2}, \exists~ c_1> 0, c_2>0$ such that
  $$
  P\left[\sup_{s,t,\epsilon [t_1, t_2]} \frac{|\xi(t)-\xi
      (s)|}{|t-s|^{\gamma}}> N\right] \leq e^{-c_1N^{c_2}}, N=2,3,\ldots 
  $$
\end{alphlemma}

\begin{proof}
  Since we can always write
  $$
  \xi(t)=\xi(0)+B\left(\int\limits_0^t \sum_{\alpha}(s)^2 ds\right)+
  \int\limits_0^t \xi_0(s) ds 
  $$
  where $B(t)$ is a 1-dimensional Wiener process, it is enough to
  prove the Lemma when $\xi(t)=B(t)$. For $w \epsilon  W_0^r$, let 
  $$
  || w ||_{\gamma}= \sup_{s,t \epsilon  [0, T]}
  \frac{|w(t)-w(s)|}{|t-s|^{\gamma}}. 
  $$
\end{proof}

Let
$$
W_{\gamma}=\left\{w \epsilon  W_0^r: || w ||_\gamma < \infty \right\}.
$$

Then $W_\gamma \subset W_0^r$ is a Banach space and if $0 < \gamma <
1/2$, using the Kolmogorov-Prohorov theorem, it can be shown that $P$
can be considered as a probability measure on $W_\gamma$
(cf. Ex. \ref{chap1:exam1.2} with $k(t, s)=t \Lambda s $). Therefore
by Fernique's theorem, 
$$
E(e^{\alpha || w ||^2_\gamma})< \infty
$$
for some $\alpha > 0 \Rightarrow E (e^{|| w ||_{\gamma}) < \infty}$. Therefore
\begin{align*}
  P(||w||_{\gamma} > N) &\leq e^{-N}E[e^{||w||_{\gamma}}]\\
  &\leq e^{-c_1N^{c_2}}
\end{align*}

\begin{alphlemma}\label{chap2:alphlemE}%%% E
  Let\pageoriginale $f(s)$ be continuous on [$a, b$] and let 
  $$
  \displaylines{\hfill 
  \frac{|f(t) -f(s)|}{|t-s|^{1/3}}\leq k \hfill \cr
  \text{and}\hfill  
  \int \limits_{a}^{b}|f(t)|^2 dt > \epsilon ^2 ~\text{where}~
  \epsilon ^3 \leq 2^2 k^3 (b-a)^{5/2}.\hfill} 
  $$ 

  Let 
  $$
  g (t) = g (a) + \int\limits_ a ^t f (s) ds.
  $$
  Then 
  $$
  (b-a) V_{[a, b]}(g) \geq \frac{1}{2^9. 48}
  \frac{\epsilon ^{11}}{k^9 (b-a)^{1 + 9/2}}. 
  $$
\end{alphlemma}

\begin{proof}
  $\exists \quad t_o \epsilon  [a, b]$  such that $| f (t_o) | >
  \dfrac{\epsilon }{(b - a)^{1/2}}$. 
 
  Therefore $| f (s) | \geq | f (t_o)| - |f (t_o) - f (s) | $ implies 
  $$
  | f (s) | \geq \frac{\epsilon }{2(b - a)^{1/2}} ~\text{ if }~ | t_o -
  s | \leq \frac{\epsilon ^3}{k^3 2^3 (b - a)^{3/2}}. 
  $$

  We denote by $I$ the interval of length
  $$
  | I | = \frac{\epsilon ^3}{k^3 2^3 (b - a)^{3/2}}
  $$
  which is contained in $[a, b]$  and is of the form $[t_o, t_o + |I|]$
  or $[t_o -|I|, t_o]$. Such  $I$ exists, since 
  $$
  \frac{\epsilon ^3}{k^3 2^3 (b-a)^{3/2}} \leq \frac{b-a}{2}.
  $$
  
  Note that $f (s)$ has constant sign in $I$. Therefore
  \begin{align*}
    (b-a) V_{[a, b]}(g) &=\int\limits_{a}^{b} (g(s) - \bar{g})^2 ds \\
    & \geq \int\limits_I (g(s) - \bar{g})^2  ds \\
    & \geq \int\limits _I (g (s) - \bar{g}|_I )^2 ds.
  \end{align*}
  
  But\pageoriginale we can always find $t_1 \epsilon  I$ with $\bar{g}| I = g
  (t_1)$. Therefore
  \begin{align*}
    (b - a) V_{[a, b]} (g) &\geq \int\limits _I \left(
    \int\limits_{t_{1}}^{s} f(u) du\right)^2 ds \\ 
    &\geq \frac{ \epsilon ^2}{4(b-a)} \int\limits_I (s - t_1)^2 ds \\
    &\geq \frac{\epsilon  ^2}{4(b-a)} \int\limits_{\alpha}^{\beta} 
    \left(s- \frac{\alpha+\beta}{2}\right)^2 ds~ \text{where}~ I =
    (\alpha, \beta )\\ 
    &= \frac{1}{48} \frac{\epsilon^2}{(b-a)}|I|^3.
  \end{align*}
\end{proof}


\medskip
\noindent{\textbf{Proof of ex. \ref{chap2:exam2.3}:}}
  Let
  \begin{align*}
    W_1&= \left\{ \sigma ^N _2 - \sigma^ N _1 =
    \frac{\bar{t}}{N^3}\right\}.\\ 
    W_2 &= \left\{ \sup_{s, t \epsilon  [ \sigma_1^N, \sigma_2^N ]}
    \frac{| \xi (t) - \xi (s)|}{| t - s| ^{1/3}}\leq N \right\}\\ 
    W_3 &= \left\{ \int\limits_{\sigma_1^N}^{ \sigma_2 ^N}  | \xi (t) |^2
    dt \geq \frac{1}{N^{c_{4}}}\right\}. 
  \end{align*}

  Then by Lemma \ref{chap2:alphlemD} and assumptions (iii) and (iv), we get
  $$
  P\left(w_1^c \cup w_2^c \cup W_3^c \right) \leq e^{-a_{1}N^{a_2}}, a_1>0, a_2>0.
  $$
  
  Hence, if $w \epsilon  W_1 \cap W_2 \cap W_3$, by Lemma
  \ref{chap2:alphlemE}, we 
  can choose $c_5 > 0 $ such that  
  $$
  \left(\sigma_1^N - \sigma_1^N \right) V_{[\sigma_1^N, \sigma_2^N]
  }(\eta ) > \frac{1}{N^{c_{5}}} 
  $$
  and since
  $$
  V_{[ \sigma_1^N, \sigma_2 ^N]} (\eta) \leq \frac{1}{\sigma_2^N
    - \sigma_1^N}\int\limits_{\sigma _1 ^N}^{\sigma_2 ^N} | \eta (t) |^2 dt 
  $$
  we have 
  $$
  P\left[ \int\limits_{\sigma_1^N}^{\sigma^N_2}| \eta (t) |^2 dt \leq
    \frac{1}{N^{c_{5}}}\right] \leq e^{-a_{1}N^{a_{2}}}. 
  $$

\medskip
\noindent{\textbf{Key Lemma:}}
  Let\pageoriginale $\eta (t) = \eta (0) +  \Sigma_{\alpha = 1}^r
  \int\limits_o ^t \eta_ 
  {\alpha} (s) dW_{s}^{\alpha} + \int\limits_{ o }^{t} \eta_{o} (s) ds$ 
  where  $\eta_o (t) $ is also an It\^{o} process given by
  $$
  \eta_{o}(t)=\eta_o (0) + \sum_{ \beta = 1}^{r} \int\limits_{o}^{t}
  \eta_{o \beta} (s) dW_s^{\beta} + \int\limits_o^t \eta_{oo}(s) ds. 
  $$

  Suppose we have sequences of stopping times $\{ \sigma _1 ^N\}, \{
  \sigma_2^N\}$ such that  $0 \leq \sigma_1 ^N < \sigma_2 ^N \leq
  \bar{t}$ for $0 < \bar{t} \leq T, N = 2,3, \ldots $ and satisfying
    \begin{enumerate}[\rm (i)]
  \item $\sigma _2 ^N - \sigma_1 ^N \leq \dfrac{\bar{t}}{N^3}$,

  \item $P \left(\sigma_2 ^N - \sigma _1^N < \dfrac{\bar{t}}{N^3}\right) \leq
    e^{-c_{1}N^{c_{2}}}, \exists $ for some $C_1,  c_2 > 0$ 

  \item $\exists~ c_3 > 0 $ such that for a.a.w
    $$
    | \eta(t) | + \sum_{\alpha = o}^{r} | \eta _{\alpha} (t) | +
    \sum_{\beta=o}^{r}| \eta _{o \beta }(t)| \leq c_3 
    $$
    for every $t \epsilon  \left[ \sigma_1 ^N,  \sigma_2^N\right]$.
  \end{enumerate}

Then for any given $c_4 > o, \exists~ c_5, c_6, c_7 > o$  (which
depend only on $c_1, c_2, c_3, c_4$) such that  
\begin{align*}
  P\left[\int\limits_{\sigma_{1}^{N}}^{\sigma_{2}^{N}} | \eta (t) |^2 dt
    \right. & \left. \leq \frac{1}{N^{c_{5}}}, \sum_{\alpha = o}^{r}
    \int\limits_{\sigma_{1}^{N}}^{\sigma _{2}^{N}} | \eta _{\alpha}
    (t) |^2 dt > \frac{1}{N^{c_{4}}}\right] \\ 
  &\leq e^{-c_{6}N^{c_{7}}}, N = 2, 3, \ldots.
\end{align*}

\begin{proof}
  For simplicity, we take $\bar{t} = 1 $. Let 
  \begin{align*}
    W_1&= \left[\sigma_{2}^{N} - \sigma_{1}^{N}= \frac{1}{N^3}\right]\\
    W_2 &= \left[ \sup_{s, t \epsilon  [ \sigma_{1}^{N},
          \sigma_{2}^{N}]}\frac{| \eta _o (t) - \eta_o (s)|}{|t -s |
        ^{1/3}} \leq N\right] 
  \end{align*}
  then,\pageoriginale by the hypothesis (ii), (iii) and Lemma
  \ref{chap2:alphlemD},
  $\exists$ constants $d_1, d_2 > 0 $ such that   
  \begin{equation*}
    P(W_1^c \cup W_2^c) \leq e^{-d_{1}N^{d_{2}}}. \tag{2.7}\label{eq2.7}
  \end{equation*}

  Now, by representation theorem, on $[\sigma_1^N, \sigma_2^N], \eta
  (t)$ can  be written as  
  \begin{equation*}
    \eta (t) = \eta ( \sigma_1^N ) + B(A(t)) + g(t) \tag{2.8}\label{eq2.8}
  \end{equation*}
  where
  $$
  A(t) = \int\limits_{\sigma_{1}^{N}}^{t}\sum_{\alpha = 1}^{r} | \eta
  _{\alpha }(s) |^2 ds, g (t) = \int\limits_{\sigma_{1}^{N}}^{t}\eta_o (s) ds 
  $$
  and $B(t)$ is one-dimensional Brownian motion with $B(0) = 0$.
\end{proof}

In Ex. \ref{chap2:exam2.3}, we obtained that, for every $a_1 > 0,
\exists~ a_2 > 0 $ such that  
\begin{equation*}
  \left[V_{[\sigma_{1}^{N},  \sigma_{2}^{N}]}  (g) \leq
    \frac{1}{N^{a_{2}}}\right] \subset W_1 ^c \cup W_2 ^c \cup
  \left[\int\limits_{\sigma_{1}^{N}}^{\sigma_{2}^{N}} | \eta_o (t) |^2 dt <
    \frac{1}{2N^{a_{1}}}\right]. \tag{2.9}\label{eq2.9} 
\end{equation*}

Let
$$
W_3 = \left[\sum_{\alpha = o}^{r} \int\limits_{
    \sigma_{1}^{N}}^{\sigma_{2}^{N}}| \eta_{\alpha}(t) |^2 dt \geq
  \frac{1}{N^{c_{4}}}\right].  
$$

Choose $a_3$ such that $a_3 > c_4 + 1$, which implies
$$
\frac{1}{2N^{c_{4}}} > \frac{1}{N^{a_{3}}}, N= 2, 3, \ldots 
$$

Therefore
\begin{align*}
  W_3 &\subset \left[ \int\limits_{\sigma_{1}^{N}}^{\sigma_{2}^{N}} |
    \eta_o (t) |^2 dt \geq \frac{1}{2N^{c_{4}}}\right] \cup \left[A
    \left(\sigma_{2}^{N}\right) \geq \frac{1}{2N^{c_{4}}} \right] \\ 
  &\subset W_{3, 1}\cup W_{3,2} 
\end{align*} 
where
\begin{align*}
  W_{3, 1}&= \left[\int\limits_{\sigma_{1}^{N}}^{\sigma_{2}^{N}} | \eta_o
    (t) |^2 dt > \frac{1}{2N^{c_{4}}}, A\left(\sigma_{2}^{N}\right) <
    \frac{1}{N^{a_{3}}}\right]\\ 
  W_{3, 2}&= \left[A\left(\sigma_{2}^{N}\right)\geq
    \frac{1}{N^{a_{3}}} \right]
\end{align*}\pageoriginale

In (\ref{eq2.9}), taking $a_1 = c_4$, we get, $\exists~ a_2  > 0$ such that  
$$
\left[V_{[\sigma_{1}^{N}, \sigma_{2}^{N}]} (g) \leq \frac{1}{N^{a_{2}}},
  \int\limits_{\sigma_{1}^{N}}^{\sigma_{2}^{N}} | \eta_o (t) |^2 dt >
  \frac{1}{2N^{c_{4}}}\right] \subset W_1^c  \cup W_2 ^c. 
$$

So, in particular,
\begin{equation*}
  W_{3, 1} \cap  \left[V _{[\sigma_{1}^{N}, \sigma_{2}^{N}]} (g) \leq
    \frac{1}{N^{a_{2}}}\right] \subset W_1^c \cup
  W_2^c. \tag{2.10}\label{eq2.10}  
\end{equation*}

Let
$$
 W_4 = \left[ \int\limits_{\sigma_{1}^{N}}^{\sigma_{2}^{N}} | \eta (t) |^2
   dt < \frac{1}{N^{a_{4}}} \right], 
$$
where $a_4$ is some  constant which will be chosen later. Then, for $w
\epsilon  W_4 \cap W_1$, 
$$
  V_{[\sigma_{1}^{N},\sigma_{2}^{N}]}(\eta) \leq
  \frac{1}{\left(\sigma_{2}^{N} -
    \sigma_{1}^{N}\right)} \int\limits_{\sigma_{1}^{N}}^{\sigma_{2}^{N}}|
  \eta (t) |^2 dt \leq \frac{N^3}{N^{a_{4}}} 
$$
i.e.
\begin{equation*}
 V_{[\sigma_{1}^{N},\sigma_{2}^{N}]}( \eta ) \leq \frac{1}{N^{a_{s}}}
 \text{ if }~ a_4 \geq a_5 + 3. \tag{2.11}\label{eq2.11}
\end{equation*}


Let
$$
W_5 = \left[\sup_{0 \leq u \leq  1/(N^{a_{3}})} | B (u) | \leq
  \frac{1}{N^{a_{5}}}\right] 
$$
then, by Lemma \ref{chap2:alphlemA},
\begin{equation*}
  P(W_5^c) \leq d_3 e^{-N}, \text{ if } a_3 > 2a_5 +
  1. \tag{2.12}\label{eq2.12} 
\end{equation*}
 
Now,\pageoriginale for $w \epsilon  W_{3, 1} \cap W_4 \cap W_1 \cap
W_5 $,  by (\ref{eq2.8}), 
\begin{align*}
  V_{[\sigma_{1}^{N},\sigma_{2}^{N}]}^{1/2} (g) & \leq
  V_{\sigma_{1}^{N},\sigma{2}^{N}}^{1/2}( \eta ) + V_{[\sigma_{1}^{N},
      \sigma_{2}^{N}]}^{1/2} (B (A(t)))\\ 
  &\leq \frac{1}{N^{a_{5}/2}} + \frac{1}{N^{a_{5}/2}}\\
  &\quad \text{(by (\ref{eq2.11}) and definition of} W_5 \text{and since, on}\\ 
  & \hspace{3cm}[\sigma_{1}^{N}, \sigma_{2}^{N}], 0 \leq A(t) \leq
  \frac{1}{N^{a_{3}}})\\ 
  &= \frac{2}{N^{a_{5}/2}}.
\end{align*}

Now choose $a_5$ such that $\frac{2}{N^{a_{5}/2}} \leq \frac{1}{N^{a_{2}}}$; then 
$$
V_{[\sigma_{1}^{N}, \sigma_{2}^{N}]}(g) \leq \frac{1}{N^{a_{2}}}.
$$

Hence
$$
W_{3, 1} \cap W_4 \cap W_1 \cap W_5 \subset
\left[V_{[\sigma_{1}^{N},\sigma_{2}^{N}]}(g) \leq \frac{1}{N^{a_{2}}}\right] 
$$
which implies by (\ref{eq2.10}) that 
$$
W_{3, 1 } \cap W_4 \cap W_1 \cap W_5 \subset W_1^c \cup W_2 ^c.
$$

Therefore
$$
W_{3, 1} \cap W_4 \subset W_1^c \cup W_2^c \cup W_5^c.
$$

So choosing $a_3 \geq c_4 + 1, a_3 > 2a_5 + 1, a_5 > 2 (a_2 + 1) $ and
$a_4 \geq a_5 + 3$,  we can  conclude form (\ref{eq2.7}) and
(\ref{eq2.12}) that  
$$
P\left[W_1^c \cup W_2^c \cup   W_5^c\right] \leq e^{-d_{4}N^{d_5}},
~\forall~ N = 2, 3, \ldots. 
$$
for  some constants $d_4 > 0 $ and $d_5 > 0 $ and therefore
\begin{equation*}
  P\left[W_{3, 1} \cap W_4 \right] \leq e^{-d_{4}N^{d_{5}}}, ~\forall~ N
  = 2, 3, \ldots.\tag{2.13} \label{eq2.13} 
\end{equation*}

Next\pageoriginale we  prove that $W_{3, 2} \cap W_4 $ is also
contained  in a set which is exponentially small, i.e.,  
$$
P(W_{3, 2} \cap W_4)  \leq ^{-d_{6}N^{d_{7}}}
$$
for some $d_6 > 0, d_7 > 0$.

 For $  w \epsilon  W_1$, we divide $\left[ \sigma_{1}^{N},
   \sigma_{2}^{N}\right] = \left[\sigma_{1}^{N}, \sigma_{1}^{N} +
   \dfrac{1}{N^3}\right]$ into $N^m$ subintervals of the same length
 viz.  
$$
I_k = \left[\sigma_{1}^{N} + \frac{k}{N^{3 + m}}, \sigma_{1}^{N} +
  \frac{k+1}{N^{3 + m}}\right],  k = 0, 1, \ldots N^m -1. 
$$
 
 Also, we choose $m > a_3$. Then
 \begin{align*}
   \int\limits_{I_{k}} | \eta (t) |^2 dt &= \int\limits_{I_{k}} | \eta
   (\sigma_{1}^{N}) + B(A (t)) + g(t)|^2 dt \tag{2.14}\label{eq2.14}\\ 
   &= \int\limits_{A(I_{k})}| \eta (\sigma_{1}^{N}) + B(s) +
   g(A^{-1}(s)) |^2 dA ^{-1}(s)\\ 
   &\left(\text{where}~ A(I_{k}) = \left[A\left(\sigma_{1}^{N} +
     \frac{k}{N^{3 + m}}\right), A\left(\sigma_{1}^{N} +
     \frac{k+1}{N^{3+m}}\right) \right]\right)\\ 
   &\geq \frac{1}{c} \int\limits_{A(I_{k})}| \eta (\sigma_{1}^{N} ) + B(s) +
   g(A^{-1}(s)) |^2 ds\\
   (\text{since}~ A(t)&= \int\limits_{\sigma_{1}^{N}}^{t} a(s) ds \Rightarrow
   dA^{-1}(s) = \frac{ds}{a (A^{-1}(s))}\\ 
   \text{and}~ a(s) &= \sum_{\alpha =1}^{r} | \eta _{\alpha } (s) |^2 \leq c). 
 \end{align*}

Let 
$$
J_k = \left[ A (\sigma_{1}^{N} + \frac{k}{N^{3+m}}), A(\sigma_{1}^{N} +
  \frac{k}{N^{3+m}}) + \frac{1}{N^{a_{3} + m}}\right]. 
$$

Note that $J_k 's $ are of constant length. Then
\begin{align*}
  W_1 \cap &\left[ | A(I_k)| \geq \frac{1}{N^{a_{3}+m}}\right] \subset 
  W_1 \cap [A (I_k) \supset J_k ] \\
  \subset W_1 \cap& \left[ \int\limits_{I_{k}}| \eta (t) |^2 dt \geq
  \frac{1}{c} \int\limits_{J_{k}} | \eta (\sigma_{1}^{N}) + B (s) +
  g(A^{-1} (s)) |^2 ds \right] \text{ by 2.14}\\ 
  \subset W_1 \cap & \left[\int\limits_{I_{k}} | \eta (t) |^2 dt \geq
    \frac{|J_k|}{c}V_{J_{k}}(B (.) + \tilde{g}) \right]
  ~(\text{where}~ \tilde{g}= g(A^{-1 })) \\ 
  \subset W_1 \cap & \left[ \int_{I_{k}} | \eta (t) |^2 dt \geq \frac{| J _k
    |}{c} \left(V_{j_k}^{1/2}(B)-V_{J_{k}}^{1/2} (
    \tilde{g})\right)^2 \right]. \tag{2.15} \label{eq2.15} 
\end{align*}
 
 Since\pageoriginale
\begin{multline*}
  g= \int\limits_o ^t \eta_o (s) ds ~\text{and}~| \eta_o (s) | \leq c
  \text{ on } \left[ \sigma_{1}^{N}, \sigma_{2}^{N}\right],\\ 
  | \tilde {g}(t) - \tilde{g}(s)| \leq c |A^{-1}(t) - A^{-1}(s)|.
\end{multline*}
 
 Therefore with
 $$
 t_o  = A \left( \sigma_{1}^{N} + \frac{k}{N^{3+m}}\right),
 $$
 \begin{align*}
   V_{J_{k}}(\tilde{g}) &\leq \frac{1}{| J_{k}|} \int\limits_{J_{k}} |
   \tilde{g}(t) - \tilde{g}(t_o) |^2 dt\\ 
   &\leq \frac{c^2}{| J_{k}|} \int\limits_{J_{k}} (A^{-1}(t) - A^{-1} (t_o))^2 ds\\
   &\leq c^2 \left[ A^{-1}\left\{ A\left(\sigma_{1}^{N} +
     \frac{k}{N^{3+m}}\right) + 
     \frac{1}{N^{a_{3}+m}} \right\} - \left(\sigma_{1}^{N} +
     \frac{k}{N^{3+m}}\right)\right]^2\\ 
   &\leq c^2 [\sigma_{1}^{N} + \frac{k+1}{N^{3+m}} - (\sigma_{1}^{N} +
     \frac{k}{N^{3+m}})]2 (\text{ since } J_k \subset A(I_k)) \\
   & = \frac{c^2}{N^{6+2m}}. \tag{2.16}\label{eq2.16}
 \end{align*}

 Hence
 \begin{align*}
   W_1 &\cap \left[J_k^{1/2} (B) > \frac{2c}{N^{3+m}}, | A (I_k) | \geq
     \frac{1}{N^{a_3 +m}} \right]  \tag{2.17}\label{eq2.17}\\ 
   & \subset W_1 \cap \left[ \int_{I_{k}} | (\eta ) |^2 dt \geq \left[c
       \frac{1}{N^{3+m}}\right]^2 \frac{N_{| J_{k}|}}{c}\right]  
   \text{ by 2.15 and 2.16} \\
   & = W_1 \cap \left[ \int\limits_{I_{k}} | \eta (t) ^2 dt \geq
     \frac{c}{N^{6+3 m+a}3}\right]. 
 \end{align*}\pageoriginale
 
 Let
 $$
 W_6 = \bigcap_{k=o}^{N^{m}-1} \left[ V_{J_{k}}^{1/2} (B) \geq
   \frac{2c}{N^{3+m}}\right]. 
 $$

Since
\begin{align*}
  A(\sigma_{2}^{N}) &= \sum_{k=0}^{N^{m}-1} | A (I_k) |, w \epsilon
  W_1 \cap W_{3, 2}\\ 
  &\Rightarrow \exists~  k \ni  | A(I_k)| \geq \frac{1}{N^{a_{3} + m}} \\
  &\Rightarrow W_1  \cap W_{3, 2} \subset \cup_{k=0}^{N^{m}-1} \left\{ | A
  (I_k) | > \frac{1}{N^{a_{3}+m}} \right\}. 
 \end{align*}
 
 Therefore
 \begin{align*}
   W_1 \cap W_6  \cap W_{3, 2} & \subset \bigcup_{k=0}^{N^{m}-1}  \left\{\left[ |
     A (I_k)| > \frac{1}{N^{a_{3}+m}} \right], V_{J_{k}}^{1/2} (B) \geq
   \frac{2c}{N^{3+m}}\right\} \cap W_1\\ 
   & \subset \bigcup _{k=0}^{N^{m}-1} \left[ \int\limits_{I_{k}} | \eta (t) |^2 dt
     \geq \frac{c}{N^{6+3m+a_{3}}} \right] \cap W_1  \text{ by 2.17} \\
   & \subset \left[\int\limits_{\sigma _{1}^{N}}^{{\sigma _{2}^{N}}} | \eta
     (t) |^2 dt \geq \frac{c}{N^{6+3m+a_{3}}}\right]\cap
   W_1. \tag{2.18}\label{eq2.18}  
 \end{align*}
 
 Therefore, if we choose $a_4$ such that 
 $$
 \frac{1}{N^{a_{4}}} < \frac{c}{N^{6+3m+a_{3}}}, ~\forall~ N = 2, 3, \ldots,
 $$
 then (\ref{eq2.18}) implies $W_1 \cap W_6 \cap W_{3, 2} \cap W_4 = \phi$,
 which implies $W_{3, 2}  \cap W_4 \subset W_1 ^c \cup W_6^c$.

\begin{align*}
  P(W_6 ^c) &\leq \sum_{k} P \left[ V_{J_{k}}^{1/2} (B) <
    \frac{2c}{N^{3+m}}\right]\\ 
  &\leq N^m e^{-d_{8} | J_k| \backslash (2c \backslash (N^{3+m}))^2 }
  ~\forall~  k ~(\text{by Lemma (\ref{chap2:alphlemC})})\\ 
  & = N^m e^{-d_{9} N^{6+2m-a_{3}-m}}\\
  &\leq N^m e^{d_{9}N^{6}} ~(\text{since}~ m > a_3 )\\
  &\leq e^{-d_{10}N^{d_{11}}} \tag{2.19}\label{eq2.19}
\end{align*}\pageoriginale
Choosing $c_5 = a_4$, (\ref{eq2.13}) and (\ref{eq2.19}) give us the
required result 

\section{Regularity of Transition Probabilities}%sec 2.3

We are now going to obtain a sufficient condition for (\ref{eqA.2}) to be
satisfied in the case of $X_t$ which is the solution to (\ref{eq2.1}). 

We recall that
\begin{align*}
  L_{\alpha}(x) & = \sum_{i=1}^{d} \sigma_{\alpha}^{i}(x)
  \frac{\partial}{\partial x^{i}}, \alpha = 1, 2 \ldots, r\\ 
  L_{o} (x) & = \sum_{i = 1}^{d} \tilde{b}i (x)
  \frac{\partial}{\partial x ^{i}} 
\end{align*}
where
$$
\tilde{d}^i (x) = b^i (x) - \frac{1}{2}\sum_{k, \alpha } 
\partial_{k}\sigma_{\alpha}^{i}(x) \sigma_{\alpha}^{k}(x). 
$$

Let 
\begin{align*}
  \Sigma_0 & = \left\{ L_1, L_2, \ldots, L_r \right\}\\
  \Sigma_1 & = \left\{ [L_{\alpha}, L]: L \epsilon  \Sigma_o, \alpha =
  0, 1, \ldots, r \right\}\\  
  \cdots & \qquad \cdots \qquad \cdots \qquad \cdots \\
  \Sigma_n & = \left\{ [ L_\alpha, L ]: L \epsilon  \Sigma_{n-1}, \alpha
  = 0, 1,\ldots, r \right\}. 
\end{align*}

Therefore\pageoriginale
$$ 
L \epsilon  \sum_{n}\Rightarrow \exists~  \alpha_o \epsilon  \{1,
2, \ldots r \}, \alpha _i \epsilon  \{0, \ldots r \}, i= 1 \ldots
n 
$$
such that  
$$
L = [ L_{\alpha _{n}} [\ldots[L_{\alpha_{2}}[L _{\alpha_{1}},
        L_{\alpha_{o}}]]\ldots ]. 
$$
Let
\begin{align*}
  &(L_\alpha, L): = [L_ \alpha, L], \alpha = 1, 2 \ldots r\\
  &(L_0, L): = [L_o, L] + \frac{1}{2} \sum_{\beta =1}^{r} [L_{\beta},
    [L_{\beta}, L]]. 
\end{align*}

Then we have
$$
f_L^i (r_t) - f_L^i (r_o)= \sum_{\alpha = 1}^{r} \int\limits_{0}^{t} 
f^i _{(L_{\alpha},L)} (r_s) dW_s^{\alpha} + \int\limits_o^t f^i
_{(L_{0}, L)}(r_s) ds 
$$ 
where $f_L^i, r_t $ etc. are as in proposition 2.3. Let 
\begin{align*}
  \Sigma_{o}'& = \Sigma_o \\
  \cdots & \cdots\\
  \Sigma_n ' & = \{ (L_{\alpha}, L ): L \epsilon  \Sigma_{n - 1}' \} ;
\end{align*}
then
\begin{align*}
  L&\epsilon  \sum_n ' \text{ implies }\\
  L&= (L_{\alpha _{n}}, (L_{\alpha_{n-1}}\cdots (L_{\alpha_{1}},
  L_{\alpha_{o}})) \cdots ) \\ 
  &= L_{\alpha_{o}}, \alpha _1 \cdots \alpha_n
\end{align*}
for some
$$
\alpha_{o} \epsilon  \{ 1,2,\ldots, r\}, \alpha_i \epsilon  \{
0, \ldots, r\}, i = 1, \ldots, n. 
$$

Let
\begin{align*}
  \hat{\Sigma} _m '= {\Sigma}_o' \cup {\Sigma}_1 ' \cup \cdots \cup
      {\Sigma} '_m,\\ 
      \hat{\Sigma}_m = {\Sigma}_o \cup {\Sigma}_1 \cup \cdots \cup
          {\Sigma}_m 
\end{align*}

It\pageoriginale is easy to see that the following two statements are
equivalent: 
\begin{enumerate}[(i)]
\item at $x \epsilon  R^d, \exists~ M $ and $A_1, A_2 \ldots,A_d
  \epsilon  \hat{\Sigma}_{M'} $ such that $A_1 (x), A_2(x) \ldots\break
  A_d (x)$ are linearly independent. 

\item at $x \epsilon  R^d, \exists~ M$ and $A_1, A_2 \ldots, A_d
  \epsilon  \hat{\Sigma}_M$ such that $A_1(x), A_2 (x) \ldots
  A_d(x)$ are linearly independent. 
\end{enumerate}

\setcounter{theorem}{6}
\begin{theorem}\label{chap2:thm2.7}%%%% 2.7
  Suppose for $x \epsilon  \mathbb{R}^d$, $\exists~ M > 0$ and $A_1,
  A_2, \ldots, A_d \epsilon   \hat{\Sigma}_{M'} $ such that  $A_1(x),
  A_2(x), \ldots, A_d (x)$ are independent. Then, for every $ t > 0$, 
  $$
  X_t = (X_1(t, x, w), X_2(t, x, w), \ldots, X_d (t, x, w)),
  $$
  which is the solution of (\ref{eq2.1}), satisfies (\ref{eqA.2}) and hence the
  probability law of $\chi (t, x, w)$ has $C^{\infty}$-density $p(t, x, y)$. 
\end{theorem}

\setcounter{remark}{0}
\begin{remark}%remark 1
  $p(t,x,y)$ is the fundamental solution of 
  \begin{align*}
    &\frac{\partial u}{\partial t} = \left[\frac{1}{2} \sum_{\alpha = 1}^{r}
      L^2_{\alpha} + L_o \right] u\\ 
    & u |_{t = o} = f
  \end{align*}
  i.e.,  \hspace{2cm} $u(t, x)= \int_{\mathbb{R}^{d}}p(t,x,y) f(y) dy$.
\end{remark}

\begin{remark}%remark 2
  The general equation
  $$
  \frac{\partial u}{\partial t}= \left[\frac{1}{2} \sum_{\alpha = 1}^{r}
    L_{\alpha}^{2} + L_o + c (.) \right] u, ~\text{ where }~ c \epsilon  C_b
  ^ \infty ( \mathbb{R}^d) 
  $$
  has also $C^\infty$-fundamental solution and is given by
$$
p (t,x,y) = < \Delta_y(X(t,x,w)), G(w)>
$$
where\pageoriginale
$$
G(w) = e^{\int^t_o c(X(t,x,w)) ds} \epsilon
  \mathbb{D}_{\infty}.
$$
\end{remark}

\begin{remark}%rem3
  The hypothesis in the theorem 2.6 is equivalent to
  the following:  For $x \epsilon  \mathbb{D}^d, \exists~ M> 0$ such
  that   
\begin{equation*}
    \inf_{ \ell \epsilon  S^{d-1}} \sum_{A \epsilon  \hat{\sum}_{M'}}<
    A(x), \ell >^2 > 0 \tag{2.20}\label{eq2.20}
\end{equation*}
where
$$
S^{d-1}= \{l \epsilon  \mathbb{D}^d: |\ell| = 1  \}.
$$
\end{remark}

\setcounter{proofoftheorem}{6}
\begin{proofoftheorem}%pro 2.7
  By (\ref{eq2.20}), $\exists~ \epsilon _o > 0$ and bounded neighbourhood
  $U(x)$ of $x$ in $\mathbb{R}^d,U(I_d)$ in $GL(d,\mathbb{R})$ such
  that  
  \begin{equation*}
    \inf_{ \ell \epsilon  S^{d-1}} \sum_{A \epsilon  \hat{\sum}_{M'}}<
  (e^{-1}A)(y), \ell >^2 \geq\epsilon_o  \tag{2.21}\label{eq2.21} 
  \end{equation*}
  for every $y \epsilon  U(x)$ and $e \epsilon  U(I_d)$. Let $l \epsilon 
  S^{d-1}$ and $A$ be any vector field. Define  
  $$
  f^{(l)}_{A} (r) = < f_A (r), \ell>,
  $$
  (cf. definition \ref{chap2:def2.1}) where $<,>$ is the inner product in
  $\mathbb{R}^d$; then we have the corresponding It\^{o} formula
  as  
  $$
  f^{(\ell)}_{A}(r_t) - f^{(\ell)}_{A}(r_o) = \sum^{r}_{\alpha =1}
  \int\limits^ t_o f^{(\ell)}_{(L_{\alpha},A)}(r_s) dW^{\alpha}_s +
  \int\limits^t_o f^{(\ell)}_{(L_{o},A)}(r_s)  ds. 
  $$
where\pageoriginale $r_t = (Y_t,Y_t), X_t,Y_t$ being the solution of
(\ref{eq2.1}), (\ref{eq2.2}) 
respectively. 
\end{proofoftheorem}

Recall that 
$$
\hat{\mathcal{O}}^{ij}_{t}= \sum^r_{\alpha = 1} \int\limits^t_o
f^i_{L_{\alpha}}(r_s) f^j_{L_{\alpha}} (r_s) ds  
$$
and by proposition \ref{chap2:prop2.5}, to prove the theorem, it is
enough to prove that $(\det
\hat{\Sigma}^{-1}_t \epsilon) \epsilon  L_p$ for $1<p< \infty$. Now  
\begin{align*}
  < \hat{\sigma}_t \ell,\ell> & = \sum^d_{i, j=1}\hat{\Sigma}^{i,j}_t
  \ell^i \ell^j, \ell =(\ell^1, \ell^2, \ldots, \ell^d)\\ 
  &= \sum^r_{\alpha = 1} \int\limits^t_o [ f^{(\ell)}_{L_{\alpha}} (r_s)]^2 ds.
\end{align*}

Let $A \epsilon  \hat{\sum}_{M'}$. Note that $A \epsilon 
\hat{\sum}_{M'}$ implies $\exists~ n$, $0 \leq n \leq M$ and $\alpha_i
\epsilon$  $\{ 0,1,2,\ldots,r \}, 0 \leq i \leq n, \alpha_o \neq 0$,
such that  
$$
A = L_{\alpha_o, \alpha_1, \ldots, \alpha_n}.
$$

Also note that the number of elements in $\hat{\sum}_{M'}$ is 
$$
\sum^{M}_{n=o} r(r+1)^n =k(M) (\text{ say }).
$$

Define the stopping time $\sigma$ by 
$$
\sigma = \inf \{ t: (X_t,Y_t) \notin U (x) \times U(I_d)\}
$$

By lemma \ref{chap2:alphlemB}, for $\bar{t}> 0$, we have 
$$
P\left( \sigma < \frac{\bar{t}}{N3}\right) \leq e^{-c_1 N^3}.
$$

Now in the Key lemma, set for $N= 2,3, \ldots, \sigma^N_1=0$ and 
$$
\sigma^N_2 = \sigma \Lambda \frac{\bar{t}}{N3}.
$$

Then the following are satisfied:
\begin{enumerate}[(i)]
\item \pageoriginale $0 \leq \sigma^N_1 < \sigma^N_2 \leq \bar{t}, \sigma^N_2 -
  \sigma^N_1 \leq \frac{\bar{t}}{N3}$. 
\item $P(\sigma^N_2- \sigma^N_1< \frac{\bar{t}}{N3} )\leq e^{c_1 N^3} $,
\item If we set 
  $$
  C = \sup_{l \epsilon  S^{d-1}} \sup_{r \epsilon  U(x) \times
    U(I_d)} \sum_{A \epsilon  \hat{\Sigma}_{M'+1}}\left[ f^{(l)}_A (r)\right]^2, 
  $$
  then for 
  $$
  t \epsilon  \left[\sigma^N_1, \sigma^N_2\right], \sum_{A \epsilon 
    \hat{\Sigma}_{M'+1}} \left[ f^{(l)}_A (r)\right]^2 \leq C < \infty. 
  $$
  For  
  $$
  w \epsilon  W_1 = \left\{\sigma^N_2 - \sigma^N_1 =
  \frac{\bar{t}}{N3} \right\}, 
  $$
  by choice $U(x) \times U(I_d)$ and (\ref{eq2.21}), we have 
\end{enumerate}

\begin{equation*}
  \inf_{|\ell|=1} \int\limits^{\sigma_2^N}_{\sigma^N_1} \sum_{A
    \epsilon  \hat{\Sigma}_{M'}} [ f^{(\ell)}_A (r_s)]^2 ds \geq
  \epsilon_o \frac{\bar{t}}{N^3} \tag{2.22}\label{eq2.22} 
\end{equation*}

Choose $\gamma > 0$ such that 
$$
\frac{1}{k(M)} \frac{\epsilon _o \bar{t}}{N^3} \geq \frac{1}{N^{\gamma}}.
$$

For $A = L_{\alpha_o, \alpha_1, \ldots, \alpha_n} \epsilon 
\hat{\sum}_{M'}$ and $\ell \epsilon  S^{d-1}$, define  
\begin{multline*}
  W^{A,\ell}_k  =
  \int\limits^{\sigma_2^N}_{\sigma^N_1}\left[f^{(\ell)}L_{\alpha_o, \alpha_1,
      \ldots, \alpha_{k-1}}(r_s)\right]^2 ds < \frac{1}{N^{C_{k-1}}},\\ 
  \sum^r_{\alpha =0}
  \int\limits^{\sigma_2^N}_{\sigma^N_1} \left[f^{(\ell)}L_{\alpha_o, \alpha_1, \ldots
     , \alpha_{k-1}\alpha}(r_s)\right]^2 ds \geq \frac{1}{N^{C_{k}}}, 
  k=1,2,3, \ldots, n, 
\end{multline*}
where\pageoriginale $C_n, C_{n-1}, \ldots C_o$ are obtained applying
Key Lemma successively as follows: 

Let $C_n = \gamma >0$. Then by Key Lemma, $\exists~ C_{n-1}, a_n, b_n$
such that  
$$
P(W^{A,\ell}_n) \leq e^{-a_{n}N^{b_n}}.
$$

Now again by Key Lemma, for given $C_{n-1}, \exists~ C_{n-2}, a_{n-1},
b_{n-1}$ such that  
$$
P(W^{A,\ell}_{n-1}) \leq e^{-a_{n-1}N^{b_{n-1}}}.
$$

And proceeding like this, we see that given $C_{1}, \exists~ C_{o},
a_{1}, b_{1}$ such that  
$$
P(W^{A,\ell}_1) \leq e^{-a_{1}N^{b_1}}.
$$

Hence we see that 
$$
\displaylines{\hfill
  P(W^{A,\ell}_n) \leq e^{-aN^b, k = 1,2, \ldots,n,}\hfill \cr
  \text{where }\hfill 
  a = \min \{ a_i \}_{1 \leq i \leq n}, b= \min \{ b_i \}_{1 \leq i \leq n}.\hfill}
$$

Note that $C_n,C_{n-1}, \ldots C_o$ and $a,b$ are independent of
$\ell$ since they depend only on $\gamma,C$ and $c_1$. Let  
$$
W^{A,\ell}= \bigcup^n_{k=1} W^{A,\ell }_k. \text{ Then } P(W^{A,\ell
}) \leq e^{-a' N^{b'}} 
$$
and 
\begin{equation*}
 P(W(\ell)) \leq e^{-a''N^{b''}} \text{ where } W(\ell)= \bigcup_{A
   \epsilon  \hat{\Sigma}_{M'}} W^{A,\ell}. \tag{2.23}\label{eq2.23} 
\end{equation*}

From\pageoriginale (\ref{eq2.22}), for $w \epsilon  W_1$, we get 
$$
\int\limits^{\sigma_2^N}_{\sigma^N_1}\sum_{A \epsilon 
  \hat{\Sigma}_{M'}} [f^{(l)}_A (r_s)]^2 ds \geq \frac{\epsilon _o}{N^3}
\bar{t} \leq k(M) \frac{1}{N^{\gamma}}. 
$$

Hence $\exists~ A \epsilon  \hat{\Sigma}_{M'}$ such that 
$$
\int\limits^{\sigma_2^N}_{\sigma^N_1}\left[f^{(l)}_A (r_s)\right]^2 ds\geq
\frac{1}{N^{\gamma}}. 
$$

Hence if $A= L_{\alpha_o, \alpha_1, \ldots, \alpha_n}$,
\begin{equation*}
  \sum^r_{\alpha =o}
  \int\limits^{\sigma_2^N}_{\sigma^N_1}\left[f^{(\ell)}_{L_{\alpha_o, \alpha_1,
      \ldots, \alpha_{n -1} \alpha}} (r_s)\right]^2 ds \geq
  \frac{1}{N^{\gamma}}. \tag{2.24}\label{eq2.24} 
\end{equation*}

Now suppose $w \epsilon  W_1 \cap W(l)^c$ which implies $w \notin
W^{A,\ell}_k$ for every $A \epsilon  \hat{\sum}_{M}$ and $k= 1, 2,
\ldots, n$. Then by definition of $W^{A,\ell}_k$ and by (\ref{eq2.24}), it
follows that  
$$
\int\limits^{\sigma_2^N}_{\sigma^N_1} \left[f^{(\ell)}_{L_{\alpha_o, \alpha_1,
    \ldots, \alpha_{n -1} \alpha}} (r_s)\right]^2 ds \geq
\frac{1}{N^{C_{n-1}}} 
 $$
and consequently 
\begin{equation*}
  \sum^r_{\alpha=o}\int\limits^{\sigma_2^N}_{\sigma^N_1}
  \left[f^{(\ell)}_{L_{\alpha_\circ, 
      \alpha_1, \ldots, \alpha_{n -1}, \alpha}} (r_s) \right]^2 ds \geq
  \frac{1}{N^{C_{n-1}}}.  \tag{2.25}\label{eq2.25}
\end{equation*}

And $w \notin W^{A,\ell}_{n-1}$ together with (\ref{eq2.25}) gives 
$$
\int\limits^{\sigma_2^N}_{\sigma^N_1} \left[f^{(\ell)}_{L_{\alpha_o, \alpha_1,
    \ldots, \alpha_{n -2},}} (r_s)\right]^2 ds \geq \frac{1}{N^{C_{n-2}}}. 
$$

Continuing like this, we get 
$$
\int\limits^{\sigma_2^N}_{\sigma^N_1} \left[f^{(\ell)}_{L_{\alpha_o}} (r_s)\right]^2
ds \geq \frac{1}{N^{C_{o}}}. 
$$\pageoriginale

Now, let $\bar{c}=\max \left\{ C_o = C_o (A): A \epsilon  \hat{\sum}_{M'}
\right\}$. Then we have $\sum^r_{\alpha=1}$
 $\int\limits^{\sigma_2^N}_{\sigma^N_1}$ $\left[f^{(\ell)}_{L_{\alpha_o}}
  (r_s)\right]^2 ds \geq \frac{1}{N^{\bar{c}}}$. Hence we have proved
that for $\ell 
\epsilon  s^{d-1}$ and $w \epsilon  W_1 \cap W(\ell)^c, \exists~
\bar{c}> o$ (independent of $\ell$) such that 
\begin{equation*}
  \sum^{r}_{\alpha =1}\int\limits^{\sigma_2^N}_{\sigma^N_1}
  \left[f^{(\ell)}_{L_{\alpha}} (r_s) \right]^2 ds \geq
  \frac{1}{N^{\bar{c}}}. \tag{2.26}\label{eq2.26} 
\end{equation*}

We have
$$
\sigma^{ij}_{\bar{t}} = \sum^{r}_{\alpha =1} \int\limits^{\bar
  {t}}_{o}f^i_{L_\alpha}(r) f^j_{L_\alpha}(r_s) ds.
$$ 

Now let 
$$
q^ij= \sum^{r}_{\alpha =1}
\int\limits^{\sigma^N_2}_{\sigma^N_1}f^i_{L_\alpha}(r_s)f^j_{L_\alpha}(r_s)ds. 
$$ 

Note that 
$$
\sum^{r}_{\alpha
  =1}\int\limits^{\sigma_2^N}_{\sigma^N_1} \left[f^{(\ell)}_{L_{\alpha}}
  (r_s)\right]^2 ds = \sum^d_{i,j=1}q^{ij} \ell^{i} \ell^j= Q(\ell)
\quad (\text{ say}). 
$$

Also, $\det_{\sigma \bar{t}} \geq \det q \geq \lambda^d_1$ where
$\lambda_1 = \inf \limits_{|l|=1} Q(l)$, the smallest eigenvalue of
$q$. Hence to prove that $\sigma^{-1}_t \epsilon  L_p$,it is
sufficient to prove that $\lambda^{-1}_t \epsilon  L_p, ~\forall~ p$.  

By definition of $q^{ij}$, we see that $\exists~ c'$ such that
$|q^{ij}| \leq \frac{c'}{N^3}$. Therefore  
\begin{equation*}
  |Q(\ell)-Q(l')| \leq \frac{c''}{N^3} |\ell
  -\ell'|. \tag{2.27}\label{eq2.27}  
\end{equation*}

Hence $\exists~ l_1,l_2, \ldots l_m$ such that 
$$
\bigcup^m_{k=1} B\left(\ell_k; \frac{N^3}{2c''}_{N^{\bar{c}}}\right) =
S^{d-1}, 
$$
where $B(x,s)$ denotes ball around $x$ with radius $s$.

Also\pageoriginale it can be seen that $m \leq c'''N^{\bar{c}-3)d}$. Then, $\ell
\epsilon  S^{d-1}$ implies $\exists~ \ell_k$ such that $|\ell-\ell_k|
\leq \frac{N^3}{2c''}_N \bar{c}$. Hence by (\ref{eq2.27})
\begin{equation*}
  |Q(l)-Q(l_k) | \leq \frac{1}{2N^{\bar{c}}}. 
\end{equation*}

But for $w \epsilon  W_1 \cap (\cap W(\ell_k)^c), Q(\ell_k) \geq
\frac{1}{2N^{\bar{c}}}$. Hence for
$$
w \epsilon  W_1 \cap (\cap W(\ell_k )^c), Q(\ell) \geq
\frac{1}{2N^{\bar{c}}}. 
$$

So 
$$
\inf_{|\ell|=1} Q(l) \leq \frac{1}{2N^{\bar{c}}} \text{ on } W_1
\left(\bigcap^m_{k=1} W(\ell_k)^c\right) 
$$
i.e.,  \qquad $\lambda_1 \geq \frac{1}{2N^{\bar{c}}} $ on $ W_1
\bigcap \left(\bigcap^m_{k=1} W(l_k)^c\right)$. 

But we have 
$$
P(W^c_1 U W (\ell)) \leq e^{-{\bar{a}}N^{\bar{b}}}
$$
and hence
\begin{align*}
  P \left[W^C_1  \bigcup \left(\bigcup^m_{k=1} W(l_k)\right)\right] &\leq c'''
  N^{(\bar{c}-3)d} e^{-\bar{a}N^{\bar{b}}}.\\
  \text{i.e.,}\hspace{2cm}  P \left[ W^C_1  \bigcup \left(\bigcup^m_{k=1}
    W(l_k)\right)\right] & \leq e^{-\bar{a}N^{\bar{b}_1}}\hspace{3cm}
\end{align*}
which gives the result.

A more general result is given below whose proof is similar to that of
theorem \ref{chap2:thm2.7}. 

\begin{theorem}%the 2.8
  Let\pageoriginale 
  $$
  U_M(x) = \inf_{|l|=1} \sum_{ A \epsilon  \hat{\Sigma}_{M'}} < A(x),
  \ell >^2. 
  $$
Suppose for $x \epsilon  \mathbb{R}^d$, $\exists~ M>0$ and $U(x)$,
neighbourhood of $x$ such that for every $\bar{t}>0$ 
{\fontsize{10pt}{12pt}\selectfont
\begin{align*}
  P & \left[U_M(Xt) < \frac{1}{N} ~\text{for all}~ t \epsilon  [0,
      \bar{t}  \Lambda \tau_{U(x)}] \right]
   = 0 \left(\frac{1}{N^k}\right) \text{ as } N \to \infty \text{ for
     all } k > 0\\
  &\hspace{2cm}(\text{ where } \tau_{U(x)}= \inf \{ t: X_t
   \not\epsilon U(x)\}).  
\end{align*}}\relax
Then the same conclusion of theorem \ref{chap2:thm2.7} holds.
\end{theorem}


\newpage

\begin{center}
\textbf{NOTES ON REFERENCES}
\end{center}

Malliavin\pageoriginale calculus, a stochastic calculus of variation
for Wiener 
functionals, has been introduced by Malliavin \cite{key7}. It has been
applied to regularity problem of heat equations in Malliavin \cite{key8},
Ikeda-Watanabe \cite{key3}, Stroock \cite{key16}, \cite{key17},
\cite{key18}. The main material in 
Chapter \ref{chap2} is an introduction to the recent result of Kusuoka and
Stroock on this line. In Chapter \ref{chap1}, we develop the Malliavin
calculus following the line developed by Shigekawa \cite{key13} and Meyer
\cite{key10}. 

\medskip
\noindent{\textbf{Chapter \ref{chap1}:}}

\begin{description}
\item[1.1.]
\begin{enumerate}
\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{(\theenumi)}
\item For the theory of Gaussian measures on Banach spaces, Fernique's 
  theorem and abstract Wiener spaces, cf Kuo \cite{key5}. 

\renewcommand{\labelenumi}{(\theenumi)}
\item That the support of a Gaussian measure on Banach space is a
  linear space can be found in It\^{o} \cite{key4}. 

\item For the details of Ex. \ref{chap1:exam1.2}, cf. Baxendale \cite{key1}.
\end{enumerate}

\item[1.2.]
\begin{enumerate}
\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{(\theenumi)}
\item An interesting exposition on Ornstein Uhlenbeck
  semigroups and related topics can be found in Meyer \cite{key10}. 

\item The hyper-contractivity of Ornstein Uhlenbeck semigroup 
  (Theorem \ref{chap1:thm1.3}) was obtained by Nelson
  \cite{key11}. Cf. also Simon \cite{key14} and, for an interesting and
  simple probabilistic proof,  Neveu \cite{key12}. 

\item For\pageoriginale the fact stated in Def. \ref{chap1:def1.8}, we
  refer to Kuo \cite{key5}.  
\end{enumerate}

\item[1.3.]
\begin{enumerate}
\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{(\theenumi)}
\item For a general theory of countably normed linear spaces and their
  duals, we refer to Gelfand-Silov \cite{key2}.

\item For Ex. \ref{chap1:exam1.3}, details can be found in
  Ikeda-Watanabe \cite{key3},  Chap.VI, Sections 6 and 8. Cf. also
  Stroock \cite{key19}.  

\item Littlewood-Paley inequalities for a class of symmetric diffusion
  semigroups have been obtained by Meyer \cite{key9} as an application of
  Burkholder's inequalities for martingales, which include the
  inequalities (\ref{eq1.7}) and (\ref{eq1.9}) as special cases. Cf. also Meyer
  \cite{key10}. An analytical approach to Littlewood-\break Paley theory can be
  seen in E.M. Stein \cite{key15}
 
\item $L_p$ multiplier theorem in Step \ref{chap1:step2} was given by
  Meyer. Proof 
  here based on the hyper-contractivity is due to Shigekawa (in an
  unpublished note). 

\item The proof of Theorem 1.9 given here is based on the
  hand-written manuscript of Meyer distributed in the seminars at
  Paris and Kyoto, cf, also Meyer \cite{key10}. 

\item The spaces of Sobolev-type for Wiener functionals were
  introduced by Shigekawa \cite{key13} and Stroock \cite{key16}, cf. also
  \cite{key3}. By using the results of Meyer, they are more naturally and
  simply defined as we did in this lecture. 
\end{enumerate}

\item[1.4.] \begin{enumerate}
\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{(\theenumi)}
\item The\pageoriginale composite of Wiener functionals and Schwartz
  distributions was discussed in \cite{key21} for the purpose of justifying
  what is called  ``Donsker's $\delta$ - functions'', cf. also Kuo
  \cite{key5}, \cite{key6}.   
\end{enumerate}

\item[1.5.]
\begin{enumerate}
\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{(\theenumi)}
\item The result on the regularity of probability laws was first
  obtained by Malliavin \cite{key8}. 
\end{enumerate}
\end{description}

\medskip
\noindent{\textbf{Chapter \ref{chap2}:}}

\begin{description}
\item[2.1.]
\begin{enumerate}[(a)]
\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{(\theenumi)}
\item For the general theory of stochastic calculus; stochastic
  integrals, It\^{o} processes and SDE's we refer to
  Ikeda-Watanabe \cite{key3}, Stroock \cite{key19} and Varadhan
  \cite{key20}.   

\item For the proof of approximation theorem \ref{chap2:thm2.3}, we
  refer to \cite{key3},  chapter V, Lemma 2.1.  
\end{enumerate}

\item[2.2.]
The key lemma was first obtained, in a weaker form, by Malliavin
  \cite{key8}. Cf. also \cite{key3}. The Key lemma in this form is due
  to Kusuoka and Stroock (cf. \cite{key18}) where the idea in
  Ex. \ref{chap2:exam2.3} plays an important role.  
\end{description}

\begin{thebibliography}{99}
\bibitem{key1} {P. Baxendale} :\pageoriginale Gaussian measures on
  function spaces,  Amer. J. Math. 98(4), 891-952, (1976). 

\bibitem{key2} {I.M.Gelfand and G.E. Silov} : Generalized functions, Vol.2,
  Function and generalized function spaces, Academic Press, 1966. 

\bibitem{key3} {N. Ikeda and S. Watanabe} : Stochastic differential
  equations and diffusion processes, North-Holland/Kodansha, 1981. 

\bibitem{key4} {It\^{o}} : The topolgical support of Gauss measure on
  Hilbert space, Nagoya Math. J. Vol.38 (1970), 181-183. 

\bibitem{key5} {H.H.Kuo} : Gaussian measures in Banach spaces,
  Lect. Notes in Math. Vol.463, Springer, 1975. 

\bibitem{key6} {H.H Kuo} : DOnsker's delta function as a generalized
  Brownian functional and its application, to appear in
  Proc. Int. Workshops on Random Fields at Bangalore (1982),
  Lect. Notes in Control and Inf.Sci. 49, Springer, 1983. 

\bibitem{key7} {P. Malliavin} : Stochastic calculus of variation and
  hypoelliptic operators, Proc. Int. Symp. S.D.E. Kyoto, (1976),
  Kinokuniya, 1978, 195-263. 

\bibitem{key8} {P.Malliavin} : $C^k$ - hypoellipticity with degeneracy,
  Stochastic Analysis, Academic Press, 1978, 199-214, 327-340. 

\bibitem{key9} {P.A.Meyer} : D\'emonstration probabiliste de certaines
  inegalit\'es de Lettlewood-Paley Seminaire de Prob. X, Lect. Notes in
  Math. Vol.511, Springer, 1976. 

\bibitem{key10} {P.A. Meyer} :\pageoriginale Notes sur les processus
  d'Ornstein-Unhlenbeck, S\'eminaire de Prob., XVI, Lect. Notes in
  Math. Vol.920, Springer, 1982, 95-133. 

\bibitem{key11} {E. Nelson :} The free Markov field,
  \textit{J.Funot.Anal}. 12 (1973), 211-227. 

\bibitem{key12} {J. Neveu :} Sur $\ell$'esp\'erance conditionnelle par
  rapport a un mouvement brownien, \textit{Ann. Inst. H. Poincar\'e}
  (B) XII, 1976, 105-110.  

\bibitem{key13} {I. Shigekawa :} Derivatives of Wiener functionals and
  absolute continuity of induced measures, \textit{J. Math. Kyoto
    Univ}. 20, 1980, 263-289. 

\bibitem{key14} {B. Simon : } \textit{The $P(\phi)_2$ Euclidean (quantum)
  field theory}, Princeton Univ. Press., 1974. 

\bibitem{key15} {E.M. Stein :} Topics in harmonic analysis, related to
  Littlewood-Paley theory, \textit{Annals of Math. Studies}, 63,
  Princeton Univ. Press, 1970. 

\bibitem{key16} {D.W. Stroock :} The Malliavin calculus and its
  applications to second order parabolic differential operators, I, II,
  \textit{Math. System Theory} 14, 1981, 25-65, 141-171. 

\bibitem{key17} {D.W. Stroock :} The Malliavin calculus and its
  applications, \textit{Lect.Notes in math}. Vol.851, Springer,
  1981,394-432. 

\bibitem{key18} {D.W. Stroock :} Some applications of stochastic calculus
  to partial differential equations, \textit{ Ecole d'ete de
    Probabilite de Saint Flour}, to appear in Lect. Notes in
  Math. 1983. 

\bibitem{key19} {D.W. Stroock :} \textit{Topics in stochastic differential
  equations}, Tata Institute of Fundamental Research, 1982. 

 \bibitem{key20} {S.R.S. Varadhan :}\pageoriginale \textit{Diffusion
   problems and partial differential equations}, Tata Institute of
   Fundamental Research, 1980. 

\bibitem{key21}{S. Watanabe :} Malliavin's calculus in terms of generalized
  Wiener functionals, to appear in \textit{Proc. Int. Workshops on
    Random Fields at Bangalore} (1982), Lect. Notes in Control and
  Inf. Sci. 49, Springer, 1983. 
\end{thebibliography}
