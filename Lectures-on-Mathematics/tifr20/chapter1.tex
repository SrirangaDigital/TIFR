\chapter{Differential Calculus}\label{chap1}

\section{}\label{chap1:sec1}%sec1.1

Let\pageoriginale $k$ be a commutative ring with unit and $A$ a commutative and
associative algebra over $k$ having $1$ as its element. In
Applications, $k$ will usually be the real number field and $A$ the
algebra of differentiable functions on a manifold. 

\begin{defn}\label{chap1:sec1:def1} %definition 1
  A {\em derivation} $X$ is a map $X: A \to A$ such that 
  \begin{enumerate}[\rm i)]
  \item $X \in \Hom_k(A,A)$, and 
  \item $X (ab) = (Xa)b+ a(Xb)$ for every $a,b \in  A$.
  \end{enumerate}
\end{defn}

If no non-zero element in $k$ annihilates $A$, $k$ can be identified
with a subalgebra of $A$ and with this identification we have $Xx=0$
for every $x \in k$. In fact, we have only to take $a=b=1$ in $(ii)$
to get $X_1=0$ and consequently $Xx= xX(1)=0$.  

We shall denote the set of derivations by $C$. Then $C$ is obviously
an $A$-module with the following operations:  
\begin{align*}
  (X +Y) (a) &= Xa +Ya \\
  (aX) (b) & = a(Xb) ~ \text{ for } ~ a, b \in A ~ \text{ and } ~ X,Y \in C.
\end{align*}

We have actually something more: If $X,Y, \in C$, then $[X,Y] \in  C$.

This bracket product has the following properties:
\begin{gather*}
  [X_1 +X_2 , Y] = [X_1, Y] +  [X_2 , Y] \\
  [X,Y] = - [Y,X]\\
  \bigg[ X, [Y,Z] \bigg] + \bigg[Y,[Z,X] \bigg] +  \bigg[ Z, [X,Y]\bigg]
  =0, 
\end{gather*}
for\pageoriginale $X,Y,Z \in C$. The bracket is not bilinear over $A$, but only
over $k$. We have  
\begin{align*}
  [X,aY](b) & = \left\{ X (aY) - (aY) (X) \right\} (b) \\
  &= (Xa) (Yb) + a [X, Y](b)
\end{align*}
so that $[X,aY]= (Xa) Y+ a [X,Y]$ for $X,Y \in C, a \in A$. The skew
commutativity of the bracket gives 
$$
[aX,Y]=- (Ya) X +a [X,Y].
$$

When $A$ is the algebra of differentiable functions on a manifold, $C$
is the space of differentiable vector fields. 

\section{Derivation laws}\label{chap1:sec2}%sec 1.2

\begin{defn}\label{chap1:sec2:def2}%definition 2
  A derivation law in a unitary A-module $M$ is a map $D :  C
  \to Hom_k (M,M)$ such that, if $D_X$ denotes the image of $X \in C$
  under this map, we have 
  \begin{enumerate}[\rm i)]
  \item $D_{X+Y} = D_X +D_Y$
       
    $D_{aX}  = a D_{X}$  for a $\in A, X,Y \in C$.
    
    i.e., \quad $D \in \Hom_A (C, \Hom_k (M,M))$.
  \item $D_X (au) =(Xa) u+a D_X u$\pageoriginale for $a \in  A, u \in M$.
  \end{enumerate} 
\end{defn}

In practice, $M$ will be the module of differentiable sections of a
vector bundle over a manifold $V$. $A$ derivation law enables one thus
to differentiate sections of the bundle in specified directions. 

If we consider $A$ as an A-module, then  $D$ defined by $D_X a = Xa$
is a derivation law in $A$. This  will hereafter be referred to as the
\textit{canonical derivation} in $A$. Moreover, if $V$ is any module
over $k$, we may define on the $A$-module $A  \bigotimes \limits_k V$,
a derivation law by setting $D_X(a \otimes v)= Xa \otimes v$ and
extending by linearity. This shall also be termed the
\textit{canonical derivation} in $A \bigotimes \limits_k V$. 

There exist modules which do not admit any  derivation law. For
instance, let $A$ be the algebra $k[t]$ of polynomial in one variable
$t$ over $k$; then $C$ is easily seen to be the free $A$-module
generated by $P= \partial/ _{\partial t}$. Let $M$  be the
$A$-module $A / \mathfrak{N}$ where $\mathfrak{N}$ is the ideal of
polynomials without constant term. If there were a derivation law is
this module, denoting by $e$ the identity coset of $A/ _\mathfrak{N}$,
we have  
$$
0=  D_p(te) =  (P.t) e + t. D_p e = e,
$$
which is a contradiction.

However, the situation becomes better if we confine overselves to free
$A$-modules. 

\begin{theorem}\label{chap1:sec2:thm1}%theorem 1
  Let $M$ be a free $A$-module, $(e_i)_{i \in I}$ being a basis. Given
  any\pageoriginale system $(\omega_i)_{i \in I}$ of elements in $\Hom_A(C,M)$,
  there exists one and only one derivation law $D$ in $M$ such that
  $D_X e_i = \omega_i (X)$ for every $i \in I$.  
\end{theorem}

Let $u$ be an arbitrary element of $M$. Then $u$ can be  expressed in
the term $u= \sum \lambda_i e_i$. If the conditions  of the theorem have
to be satisfied, we have to define $D_X u = \sum (X \wedge_i) e_i +
\sum \lambda_i \lambda_i (X)$. It is easy to verify that this is a
derivation law. 

We shall now see that the knowledge of one derivation law is enough to
compute all the possible derivation laws. In fact, if $D,D'$ are two
such laws, then $(D_X- D'_X)(au)= a (D_X- D'_X) (u)$. Since $D,D' \in
\Hom_A (C, \Hom_k(M,M))$, it follows that $D-D' \in  \Hom_A(C,
\Hom_A\break (M,M))$. Conversely, if $D$ is a derivation law and $h$ any
element of $\Hom_A(C,\Hom_A$ $(M,M))$, then $D' = D+h$ is a derivation
law as can be easily verified. 

\section{Derivation laws in associated modules}\label{chap1:sec3} %sec 1.3

Given module $M_i$ with derivation laws $D^i$, we proceed to assign in
a canonical way derivation laws to module which are obtained from the
$M_i$ by the usual operations. 

Firstly, if $M$ is the direct sum of the modules $M_i$, then $D_X(m) =
\sum D_X^i(m_i)$ where $m= \Sigma m_i$, gives  a derivation law in
$M$. 

Since $D^i_X$ are k-linear, we may define  $D$ in $M_1 \bigotimes
\limits_k\cdots  \bigotimes \limits_k M_p$ by setting $D_X(u_1,
\otimes \cdots \otimes u_p) = \sum u_1 \otimes \cdots D^i_X u_i
\otimes \cdots u_p$. Now, it is easy to see that this  leaves
invariant the ideal generated by elements of the form 
$$
u_1 \otimes \cdots au_i \otimes \cdots \otimes u_p -u_1 \otimes \cdots
au_j \otimes \cdots \otimes u_p  \text{ with } a \in A.  
$$  

This\pageoriginale therefore induces a k-linear map $D_X$ of $M_1 \bigotimes
\limits_A  \cdots \bigotimes \limits_A M_p$ into itself, where  
$$
D_X(u_1 \otimes \cdots \otimes u_p)= \sum u_1 \otimes \cdots D_X^i u_i
\otimes \cdots \otimes u_p 
$$
where $u_1 \otimes \cdots \otimes u_p \in M_1 \bigotimes \limits_A
\cdots \bigotimes \limits_A M_p$. 

It is easily seen that $D$ is a derivation law.

We will be particularly interested  in the case when $M_1 = M_2 = \cdots
= M_p = M$. In this case, we denote $M_1 \otimes \cdots \otimes M_p$
by $T^p(M)$. Since we have such a law in each $T^p(M)$ (for $T^0
(M)=A$, we take the canonical derivation law) we may define a
derivation law in the  tensor algebra $T^*(M)$ of $M$. If $t,t'$ are
two tensors, we still have  
$$
D_X(t \otimes t') = D_X t \otimes t'  +  t \otimes D_X t'. 
$$

Now let $\mathfrak{N}$  be the ideal generated in $T^* (M)$ by
elements of the form $u \otimes v-  v \otimes u$ with $u, v \in M$. It
follows from the above equality that $D_X \mathfrak{N} \subset
\mathfrak{N}$. Consequently  $D$ induces a derivation law in $T^*(M) /
\mathfrak{N}$, which is the symmetric algebra over $M$. Again, if
$\mathfrak{N}'$ is  the ideal in $T^*(M)$ whose generators are of the
form $u \otimes u, u \in M$, then it is immediate that $D_X
\mathfrak{N}' \subset \mathfrak{N}'$. Thus we obtain a derivation law
in exterior algebra $T^*(M) / _\mathfrak{N'}$ of $M$. 

Let $M,L$ be two $A$-modules with derivation laws  $D^M, D^L$
respectively. We define a derivation  law $D$ in $\Hom_A(L,M)$ by
setting 
$(D_X h) = D^M_X h - h D^L_X$  for every  $h \in \Hom_{A}(L,M)$
and $X \in C$.
\begin{align*}
  \text{In fact} \qquad \qquad D_X (ah) &= D^M_X(ah) - (ah)D^L_X. \\
  D_X(ah)(l) &= D^M_X(ah)(l) - (ah)D^L_X(l) \\
  &=  D^M_X(a.h(l))-a. h (D^L_X(l))\\
  &=(Xa) (h(l)) +a  D^M_L(h(l)) - a.h (D^L_X(l)) \\
  &= \{ (Xa)h \} (l) + (aD_Xh) ~ \text{for every } ~ I \in L.
\end{align*}

In\pageoriginale particular, if $L= M$ with $D^L= D^M$, then we have 
$$
D_Xh =  \left[ D^L_X, h \right] ~ \text{ for every} ~ h \in \Hom_A (L,L). 
$$

Moreover, this leads to a derivation  law in the dual $L^*$ of $L$ by
taking $M =A$ with the canonical derivation law. The corresponding law
is  
$$
(D_Xf) (u) = X(f(u))  - f(D_X^L(u)) ~ \text{ for every } ~ f \in L^* ~
\text{ and } ~ u \in L. 
$$

Now let $L$, $M$ be modules with derivation  laws $D^L$, $D^M$
respectively. We may then define a derivation law in the $A$-module
$\mathscr{F}^p (M,L)$ of multilinear forms on $M$ of degree $p$ with
values in $L$ in the following way:  
$$
(D_X \omega )(u_1, \ldots , u_p) = D^L_X \omega (u_1, \ldots , u_p)-
\sum_{r=1}^p \omega (u_1,  \ldots , D^M_X u_r , \ldots u_p).  
$$

If $\mathscr{U}^p ( M,L)$ is the submodule of $\mathscr{F}^p(M,L)$
consisting of alternate forms , then it is easy to see that $D_\wedge
\mathscr{U}^p (M,L) \subset \mathscr{U}^p (M,L)$. This leads to a
derivation law in the $A$-modules $\mathscr{F}^p(M,A), \mathscr{U}^p
(M,A)$, if we take\pageoriginale $L=A$ with the canonical derivation law. 

Let $M_1, M_2, M_3$ be three modules with a bilinear product $M_1
\times M_2 \to  M_3$, denoted $(u,v) \to uv$. If $D^1, D^2, D^3$ are
the respective derivation  laws, we say that the product is
\textit{compatible} with the derivation laws if  
$$
D^3_X(uv) = (D^1_Xu) v +  u(D^2_X v) ~ \text{ for } ~ X \in C, u \in
M_1 ~ \text{ and } ~ v \in M_2. 
$$

This was the case the we took $M_1 =M_2= M_3 =A$ with the canonical
derivation law and the algebra-product. Again, we seen that the above
condition is satisfied by $M_1 = M_2= M_3 = T^*(M)$ with the
associated derivation laws and the usual multiplication. Moreover, it
will be noted that if $M$ is an $A$-module with derivation law  $D$,
the condition 
$$
D_X(au) = (Xa) u+  a D_X u ~ \text{ for every} ~ a \in A ,u \in M
$$
expresses the fact that the map $A \times M \to  M$ defining the
module structure is compatible with the derivation laws in $A$ and
$M$. If we denote $\mathscr{U}^p(L,M_i)$ by $\mathscr{U}^p_i
(i=1,2,3)$, we may define for $\alpha \in \mathscr{U}^p_1 \beta \in
\mathscr{U}^q_2 , \alpha  \wedge  \beta$ by setting 
$$
(\alpha \wedge \beta) (a_1, \ldots ,a_{p+q}) = \sum \in_\sigma \alpha
(a_{\sigma (1)}, \ldots , a_{\sigma(p)}) \beta(a_{\sigma (p+1)},
\ldots , a_{\sigma(p+q)}) 
$$
where the summation extends over all permutations $\sigma$ of $(1,2 ,
\ldots  , p+q)$ such that $\sigma(1) <  \sigma (2) <\cdots <
\sigma(p)$ and $\sigma(p+1) < \sigma(p+2) < \cdots < \sigma (p+q)$ and
$\in_\sigma$ is its signature. If the derivation laws are compatible
with the product, we have  
$$
D^3_X(\alpha \wedge \beta) = (D^1_X \alpha) \wedge \beta + \alpha
\wedge(D^2_X \beta) ~ \text{ for every } ~ X \in C.  
$$

\section{The Lie derivative}\label{chap1:sec4} %sec 1.4

Let\pageoriginale $V$ be a manifold, $\mathscr{U}$ the algebra of differentiable
functions on $V$ and $\mathscr{C}$ the module of derivations of
$\mathscr{U}$ (viz. differentiable vector fields on $V$. Any
one-parameter group of differentiable automorphisms on $V$ generates a
differentiable vector field on $V$. Conversely,
every differentiable vector field $X$ gives rise to a local
one-parameter group $s(t)$ of local automorphisms of $V$. If $\omega$
is a  $p$-co variant tensor, i.e., if $\omega \in
\mathscr{F}^p(\mathscr{C}, \mathscr{U})$, then we may define
differentiation of $\omega$ with respect to $X$ as follows: 
$$
\theta_X \omega = \lim_{t \to o} \frac{s^*(t) \omega - \omega}{t},
$$
where $s^*(t)$ stands for the $k$-transpose of the differential  map
lifted to $\mathscr{F}^p (\mathscr{C}, \mathscr{U})$. This is known as
the \textit{Lie derivative} of $\omega$ with respect to $X$ and can be
calculated to be  
$$
\theta_X \omega(u_1, \ldots , u_p) = X \omega (u_1 , \ldots  ,u_p) -
\sum_{i=1}^p \omega (u_1, \ldots [X, u_i], \ldots u_p).  
$$

It will be noted if $a \in \mathscr{U}$, then $\theta_{a X} \omega
\neq a (\theta_X \omega)$ if $p > 0$. At a point $\xi \in V$, the Lie
derivative $\theta_X \omega$, unlike the derivation  law, does not
depend only on the value of the vector field $x$ at $\xi$. 

\begin{lem}\label{chap1:sec4:lem1}%lemma 1
  Let $D$ be a derivation  law in the $A$-module $M$ and $\alpha$ a
  multilinear form on $C$ of degree $p$ with values in $M$. Then the
  map $\beta: C^P \to M$ defined by  
  $$
  \beta(Z_1, \ldots , Z_p)= D_X \alpha(Z_1, \ldots , Z_p) -
  \sum_{i=1}^p \alpha (Z_1, \ldots [X, Z_i],  \ldots , Z_p) 
  $$
  is\pageoriginale multilinear.
\end{lem}

\noindent In fact,  $\beta (Z_1, \ldots  Z_i + Z'_i , \dots Z_p) = \beta(Z_1,
\ldots Z_i, \ldots Z_p) + \beta(Z_1, \ldots Z'_i , \ldots Z_p)$ 
and 
\begin{multline*}
  \beta(Z_1, \ldots a Z_i ,\ldots Z_p) = (Xa) \alpha (Z_1, \ldots
  Z_p) +a (D_X \alpha (Z_1, \ldots Z_p)) \\ 
  \qquad - \sum_{j=1}^p a \alpha(Z_1 , \ldots [X,Z_j], \ldots Z_p)-
  \alpha(Z_1,  \ldots (Xa) Z_i , \ldots Z_p) \\ 
  = a \beta (Z_1,\ldots Z_p) ~ \text{ for every } ~ Z_1, \ldots Z_p
  \in C, a \in A.  
\end{multline*}

\begin{defn}\label{chap1:sec4:def3} %definition 3
  The map $X \to \theta_X$ of $C$ into $\Hom_k (\mathscr{F}^p(C,M)
  \mathscr{F}^p (C,M))$ defined by $(\theta_X \alpha)(Z_1,  \ldots ,
  Z_p)= D_X \alpha(Z_1,  \ldots Z_p) -
  \sum^p_{i=1} \alpha(Z_1, \ldots [X,Z_i]$ $\cdots Z_p)$ is called the
      {\em Lie derivation} in the $A$-module $\mathscr{F}^p(C,M)$ and
      $\theta_X \alpha$ is defined to be the {\em Lie derivative} of
      $\alpha$ with respect to $X$. 
\end{defn}

The Lie derivation satisfies the following
\begin{align*}
  \theta_X (\alpha +\beta)  &= \theta_X \alpha + \theta_X \beta \\
  \theta_X (a \alpha ) &= (Xa) \alpha +  a (\theta_X \alpha) \\
  \theta_{X+Y}(\alpha)  &= \theta_X \alpha +  \theta_Y \alpha \\
  \theta_{\lambda X}(\alpha) &= \lambda (\theta_X (\alpha)
\end{align*}
for every $X, Y \in C , \quad \alpha \beta \in \mathscr{F}^p(C,M)$ and
$\lambda \in k$. 

Thus $\theta$ looks very much like a derivation  law, but $\theta_{aX}
\neq a \theta_X$ in\pageoriginale general. From  the definition, it follows that if
$\alpha$ is alternate (\resp symme\-tric), so is $\theta_X \alpha$. 

\section{Lie derivation and exterior product}\label{chap1:sec5} %sec1.5

As in ch.\ref{chap1:sec3}, let $M_1, M_2, M_3$ be $A$-module  with derivations
$D_1, D_2, D_3$ respectively. Let there be given a bilinear product
$M_1 \times M_2 \to M_3$ with reference to which an exterior product
$(\alpha, \beta) \to \alpha \wedge \beta$ of $\mathscr{U}^p
(C,M_1)\times \mathscr{U}^q (C, M_2) \to \mathscr{U}^{p+q} (C, M_3)$
is defined. If the product is compatible with the derivation laws, we
have, on  direct verification, 
\begin{multline*}
\theta_X(\alpha \wedge \beta) = \theta_X \alpha \wedge \beta + \alpha
\wedge \theta_X \beta\\  
\text{ for } ~ \alpha \in \mathscr{U}^p
(C,M_1), \beta \in \mathscr{U}^q(C,M_2) ~ \text{ and } ~ X \in C. 
\end{multline*}

\section{Exterior differentiation}\label{chap1:sec6} %sec1.6

We shall introduce an inner product in the $A$-module
$\mathscr{F}^p(C,M)$. For every $X \in C$, the inner product is the
homomorphism $l_X$ of $\mathscr{F}^p(C,M)$ into
$\mathscr{F}^{p-1}(C,M)$ defined by  
$$
(l_X \alpha ) (Z_, \ldots Z_{p-1}) = \alpha (X, Z_1, \ldots , Z_{p-1})
$$
for every $\alpha \in \mathscr{F}^p (C,M), Z_1, \ldots Z_{p-1} \in
C$. If $\alpha$ is alternate it is obvious that $l_x \alpha$ is also
alternate. When $\alpha$ is of degree $0,l_X \alpha =0$. The inner
product satisfies the following 
\begin{enumerate}
\item $l_{aX}= a l_X$

  $l_{X+Y} = l_X + l_Y, ~ \text{ for } ~ a  \in A, X, Y \in C$.
\item If $\theta_X$ is the Lie derivation,

  $\theta_X l_Y - l_Y \theta_X = l_{[X,Y]}$\pageoriginale for $X, Y, \in C$.
\item If $\alpha$ is alternate, $l_X l_X \alpha = 0$.
\item Let $M_1, M_2, M_3$ be three $A$-modules with a bilinear product
  compatible with their laws $D_1, D_2, D_3$. Then we have, for
  $\alpha \in \mathscr{U}^p$ $(C,M_1), \beta \in  \mathscr{U}^q(C,M_2)$ 
  $$
  l_X (\alpha \wedge \beta) = (l_X \alpha) \wedge \beta +(-1)^p \alpha
  \wedge l_X \beta.  
  $$
  in fact, let $Z_1, \ldots , Z_{p+q-1} \in C$. Then 
\begin{multline*}
  l_X (\alpha \wedge \beta) (Z_1, \ldots , Z_{p+q-1})  = (\alpha \wedge
  \beta) (X,Z_1, \ldots , Z_{p+q-1}) \\
  = \sum_\sigma \in _\sigma \alpha (X,Z_{\sigma (1)}, \ldots ,
  z_{\sigma (p-1)}) \beta(Z_{\sigma (p)} , \dots Z_{\sigma (p+q- 1)})\\
   + \sum_\tau \in _\tau \alpha (X_{\tau (1)},  \ldots  X_{\tau(p)})
  \beta(X,Z_{\tau(p+1)} , \ldots Z_{\tau (p+q-1)})  
\end{multline*}
 where $\sigma$ runs through all permutations of $[1,p+q-1]$ such that
 $\sigma (1) < \cdots < \sigma(p-1)$ and $\sigma(p) < \cdots <
 \sigma(p+q-1)$, while $\tau$ runs through those which satisfy
 $\tau(1) < \cdots  < \tau (p)$ and $\tau(p+1) < \cdots <
 \tau(p+q-1)$. The first sum is equal to $(l_X \alpha) \wedge \beta$
 and the second to $(-1)^p \alpha \wedge (l_X \beta)$. 
\end{enumerate}

\begin{theorem}\label{chap1:sec6:thm2} %theorem 2
  Let $D$  be a derivation law in an $A$-module $M$. Then there exists
  one and only one family of $k$-linear maps $d: \mathscr{U}^p(C,M)
  \to \mathscr{U}^{p+1}(C,M) (p=0,1,2, \ldots)$ such that $\theta (X)
  =  dl_X + l_X d$ for every $X \in C$. 
\end{theorem} 
 
 We call this map the \textit{exterior differentiation} in the module
 of alternate forms on $C$. 
  
 First\pageoriginale of all, assuming  that there exists such a map $d$, we shall
 prove that it is unique. If $d'$ is another such map, we have  
 $$
 (d-d') l_X +l_X (d-d') =0
 $$ 
 
 Hence $l_X(d-d') \alpha = (d' - d) l_X \alpha$ for every $\alpha \in
 \mathscr{U}^p (C,M)$.  We shall prove that $d \alpha= d' \alpha$ for
 every $\alpha \in  \mathscr{U}^p(C,M)$ by induction on $p$. When
 $\alpha$ is of degree $0$, we have $(d' -d)l_x \alpha =0 = l_X (d-d')
 \alpha$. This being true for every $X \in C, d \alpha = d'
 \alpha$. If the theorem were for $p =q-1$, then $(d' -d) l_X \alpha =
 0 = l_X (d-d') \alpha$. Again, since $X$ is arbitrary, $d \alpha =
 d' \alpha$ which proves the uniqueness of the exterior
 differentiation. 
 
 The existence is also proved by induction. Let $\alpha \in
 \mathscr{U}^o (C,M)=M$. Then we wish to define $d_o$ such that $l_X d
 \alpha = (d \alpha)(X) = \theta_X \alpha$ (since $l_X \alpha =0) =
 D_X \alpha$. Hence we can set $(d(\alpha) (X)= D_X \alpha$ for every
 $X \in C$. This is obviously $A$-linear since $D_X$ is A-linear in
 $X$. Let us suppose that $d$ has been defined on $\mathscr{U}^p
 (C,M)$  for $p= 0,1, \ldots (q-1)$ such that the formula is true. We
 shall define $d \alpha$ for $\alpha \in  \mathscr{U}^p(C,M)$ by
 setting  
 $$
 (d \alpha(Z_1, \ldots , Z_{q+1}) = (\theta_{Z_1}\alpha) (Z_2 , \ldots
 Z_{q+1})-  (d l_{Z_1}\alpha) ( Z_2,  \ldots  Z_{q+1}) 
 $$
 
 We have of course to show that the $d \alpha$ thus defined is an
 alternate form. That it is linear in  $Z_2,  \ldots  Z_{q+1}$ follows
 from the induction assumption and the multilinearity of $\theta_{Z_1}
 \alpha$. We shall now prove that it is alternate. That means: 
 $$
 (d \alpha)(Z_1, \ldots , Z_{q+1}) =0  ~\text{ whenever } ~ Z_i = Z_j
 ~ \text{ with } ~ i \neq j.  
 $$
 
 Using\pageoriginale the alternate nature of $\theta_{Z_1} \alpha$ and $d l_{Z_1}
 \alpha$, we see that it suffices to prove that 
\begin{align*}
  (\theta_{Z_1} \alpha )(Z_2, \ldots , Z_{q+1}) & = (d
  l_{Z_1}\alpha)(Z_2, \ldots , Z_{q+1}) ~ \text{ when }  ~ Z_1 = Z_2 \\
  \text{Now} \quad (\theta_{Z_2} \alpha) (Z_2, \ldots , Z_{q+1}) & =(l_{Z_2}
  \theta_{Z_2} \alpha) (Z_3, \ldots  , Z_{q+1}) \\ 
  &= (\theta_{Z_2} l_{Z_2} \alpha) (Z_3, \ldots , Z_{q+1}) ~ \text{ by
  } ~(2)~ of ~Ch. 1.6 \\ 
  &=(d l_{Z_2} l_{Z_2} \alpha + l_{Z_2} d l_{Z_2} \alpha) \,(Z_3, \ldots
  , Z_{q+1}) \\ 
  &=(d l_{Z_2} \alpha) (Z_2, Z_3, \ldots , Z_{q+1}).
 \end{align*} 
 
 Since $(d\alpha)$ is alternate, linearity in $Z_1$ follows from that
 in the other variables and additivity in $Z_1$.  This completes the
 proof of the theorem. 

\begin{remark*}
  If we take $A$ to be the algebra of differentiable functions on a
  manifold $V$, and $M$ to be $A$ itself then the exterior
  differentiation defined above coincides with the usual exterior
  differentiation. 
\end{remark*} 

\section{Explicit formula for exterior differentiation}\label{chap1:sec7} %sec 1.7

\begin{lem}\label{chap1:sec7:lem2} %lemma 2
  The exterior differentiation defined above is given by 
  \begin{multline*}
  (d \alpha) (Z_1,  \ldots , Z_{p+1}) = \sum_{i=1}^{p+1} (-1)^{i+1}
  D_{Z_i} \alpha (Z_1, \ldots Z_i, \ldots Z_{p+1})\\ 
  + \sum_{i <
    j}(-1)^{i+j} \alpha ( [Z_i, Z_j], Z_1, \ldots \hat{Z}_i , \ldots
  \hat{Z}_j , \ldots Z_{p+1}) 
  \end{multline*}
  where\pageoriginale the symbol $\wedge$ over a  letter indicates that the
  corresponding elements is omitted. 
\end{lem} 
 
 If $d$ is defined as above and $\alpha \in \mathscr{U}^p (C,M)$, it
 is easy to see that  
  $$
 (l_{Z_1} d \alpha + d l_{Z_1} \alpha) = \theta_{Z_1} \alpha  ~ \text{
   for every } ~ Z_1 \in C.  
 $$
 
 By the uniqueness of exterior differentiation , we see that the above
 gives the formula for the exterior differentiation. 
  
 We shall use this explicit formula only when the degree of $\alpha
 \le 2$. Then we have the formula: 
\begin{enumerate}
\item $(d \alpha) (X) =  D_X \alpha$ for $\alpha \in \mathscr{U}^0
  (C,M)$, $X \in C$. 
\item $(d \alpha) (X,Y)  = D_X \alpha (Y)- D_Y \alpha (X) - \alpha
  ([X,Y])$ for $\alpha \in \mathscr{U}^1(C,M)$, $X, Y  \in C$.  
\item  $(d \alpha) (X,Y,Z)  = \sum \left\{ D_X \alpha (Y,Z)- \alpha
  ([X,Y],Z) \right\}$ for $\alpha \in \mathscr{U}^2(C,M)$, $X, Y, Z \in C$ 
\end{enumerate} 
where the summation  extends over all cyclic permutations of $(X,Y,Z)$.
 
\section{Exterior differentiation and exterior product}\label{chap1:sec8} %sec 1.8
 
We now investigate the behaviours  of $d$ with regard to the exterior
product. Let $M_1, M_2, M_3$ be three modules with derivation laws
$D_1, D_2, D_3$ and let $M_1 \times M_2 \to M_3$ be a linear product
compatible with the derivation laws. Then we have, for $\alpha \in
\mathscr{U}^p (C,M_1), \beta \in \mathscr{U}^q (C,M_2)$ 
$$
d(\alpha \wedge \beta) = d \alpha \wedge \beta +(-1)^p \alpha \wedge d
\beta.  
$$
 
 Again, we prove this by induction, but this on $p+q$. When
 $p+q=0$, the\pageoriginale above formula just expresses the compatibility of the
 product with the derivation laws. Let us assume the theorem proved
 for $p+q= r-1$. We have 
 $$
 d(\alpha \wedge \beta) (Z_1, \ldots , Z_{p+q+1}) = (l_{Z_1} d (\alpha
 \wedge \beta)) (Z_2, \ldots, Z_{p+q+1}) 
 $$
\begin{align*}
  \text{But},  \quad l_{Z_1} d(\alpha \wedge \beta)  &= \theta_{Z_1} (\alpha
  \wedge \beta)  - d (l_{Z_1} (\alpha \wedge \beta ) ) \\ 
  &= \theta_{Z_1} \alpha \wedge \beta + \alpha \wedge \theta_{Z_1}
  \beta - d (l_{Z_1} \alpha \wedge \beta + (-1)^p \alpha  \wedge
  l_{Z_1} \beta )\\ 
  & \hspace{5cm}\text{ by(3) of Ch. \ref{chap1:sec6}}\\ 
  &= \theta_{Z_1} \alpha \wedge \beta + \alpha \wedge \theta_{Z_1}
  \beta - d l_{Z_1} \alpha \wedge \beta-(-)^{p-1} l_{Z_1} \alpha\\
  & \hspace{2cm}\wedge d \beta -(-1)^P d \alpha \wedge l_{Z_1} \beta -
  \alpha \wedge  d l_{Z_1} \beta \\ 
  & \hspace{4cm}\text{ by induction assumption } \\
  &= l_{Z_1} d \alpha \wedge \beta - (-1)^p d \alpha \wedge
  l_{Z_1}\beta + \alpha \wedge l_{Z_1} d \beta\\ 
  & \hspace{4cm}-(-1)^{p-1} l_{Z_1}
  \alpha \wedge d \beta \\ 
  &= l_{Z_1}(d \alpha \wedge \beta )+ (-1)^p l_{Z_1} (\alpha \wedge d \beta )\\
  &= l_{Z_1}((d \alpha \wedge \beta) + (-1)^p (\alpha \wedge d \beta )) ,
\end{align*} 
 which proves our assertion.

\begin{remark*}
  If we take $M_2= M_3=M$ and $M_1 =A$ with the product $A \times M
  \to M$ defining the module structure, then, by the above formula, we
  obtain 
  \begin{equation*}
    \begin{aligned}
    d (a \alpha ) &= (da) \wedge \alpha + a \wedge d \alpha \\
    & = da \wedge \alpha + a. d \alpha 
    \end{aligned}
    \begin{cases}
      \text{ for} & a \in \mathscr{U}^\circ ( C, A ) = A\\
      \text{ and} & \alpha \in \mathscr{U}^p ( C, M ).
    \end{cases}
  \end{equation*}
\end{remark*} 

\noindent
Thus\pageoriginale the exterior differentiation is not $A$-linear.

\section{The curvature form}\label{chap1:sec9} %section 1.9

It is well-know that the exterior differentiation in the algebra of
differential forms on a manifold satisfies $ dd = 0 $. Let us compute
in our general case value of $ dd \alpha $ for $ \alpha \in
\mathscr{U}^0 (C, M ) = M $. Then one has 
\begin{align*}
  dd \alpha (X,Y) &= D_X ( d \alpha ) (Y) - D_Y (d \alpha ) (X) - ( d
  \alpha ) ( [ X,Y ] ) \\ 
  &= D_X D_Y \alpha - D_Y D_X \alpha - D_{[ X,Y]} \alpha \\
\end{align*}

Let $ K ( X,Y ) = D_X D_Y -D_Y D_X -D_{[X,Y]} $. Then it is obvious
that $ K (X,Y) $ is a $k$-endomorphism of $M$. But, it actually
follows on trivial  verification that it is an $A$- endomorphism. On
the other hand, we have  

\begin{enumerate}[i)]
\item $ K ( X,Y ) = - K ( Y,X ) $
\item $ K ( X + X' ,Y )  = K ( X,Y ) + K ( X',Y )$, and 
\item $ K( a X,Y ) \alpha  = aK ( X,Y ) \alpha$ for every  $\alpha \in M $. 
\end{enumerate}
$i)$ and $ii)$ are trivial and we shall verify only $iii)$.
\begin{align*}
  K ( a X,Y )  &= D_{aX} D_Y -D_Y D_{aX} - D_{[a X,Y]} \\
  &= aD_X D_Y -D_Y ( aD_X ) - D_{a[X,Y]} - ( Ya )X \\
  &= aD_X D_Y - ( Ya ) D_X -a D_Y D_X -a D_{[X,Y]} + ( Ya ) D_X\\
  &= a K( X,Y ).
\end{align*}

We\pageoriginale have therefore proved that $K$ is an alternate form of degree 2 over
$C$ with values in the module $ Hom_A ( M, M ) $. 

\begin{defn}\label{chap1:sec9:def4} %definition 4
  The element $K$ of  $ \mathscr{U}^2 ( C, \Hom_A ( M,M ) ) $ as
  defined above i.e., 
  $$
  K (X,Y) = D_X D_Y -D_Y D_X -_{[ X,Y ]}
  $$
  is called the \textit{ curvature form } of the derivation law $D$.
\end{defn}

\begin{examples*}
  \begin{enumerate}[1)]
  \item Take the  simplest case when $ M = A $, with the canonical
    derivation law. Then 
    $$
    K ( X,Y ) u = XYu - YXu - [ X,Y ] u = 0 
    $$
    i.e., the curvature form is identically zero.
  \item However, there are examples in which  the curvature form is non-zero.
  \end{enumerate}
\end{examples*}

Let $ A = k [ x,y ] $ with $ x,y $ transcendental over $k$. It is easy
to see that $C$ is the free module over $A$ with $ P \left( =
\dfrac{\partial}{\partial x} \right) , Q \left( =
\dfrac{\partial}{\partial y} \right) 
$ as base. 

We take $M$ to be $A$ itself but with a derivation law different from
the canonical one. By Th.\ref{chap1:sec2:thm1}, Ch. 1.2, if we choose $ 1 \in M $
and take $ \omega \in \Hom_A ( C,A ) $, then there exists a derivation
law $D$ such that $ D_X 1 = \omega (X) $. We shall define $\omega$ by
requiring that $ \omega (P) = y $ and $ \omega (Q) = 1 $. Then it
follows that $ D_P (1) = y , D_Q (1) = 1 $. 
\begin{align*}
  K ( P,Q )(1) &= D_P D_Q (1) - D_Q D_P (1) - D_{[ P,Q ]} (1) \\
  &= y - ( Q y ). 1 - y ( D_Q ( 1 )) \\
  &= -1.
\end{align*}

We\pageoriginale now prove two lemmas which give the relation between Lie
derivatives in two directions  and the relation of Lie derivative to
the exterior differentiation in terms of the curvature form.  

\begin{lem}\label{chap1:sec9:lem3} %lemma 3
  $ \theta_X \theta_Y \alpha - \theta_Y \theta_X \alpha = \theta_{[
      X,Y ]}  \alpha + K ( X,Y ) (\alpha)  $ for every  $ \alpha \in
  \mathscr{U}^p$ $( C,M ) $. 
\end{lem}

In fact, when $ \alpha $ is of degree $0$, the formula is just the
definition of the  curvature form. In the general case, this follows
on straight forward  verification.  

\begin{lem}\label{chap1:sec9:lem4} %lemma 4
  $ \theta_X  d \alpha - d \theta_X \alpha = ( l_X K )  \wedge \alpha
  $ for every $ \alpha \in \mathscr{U}^p ( C, M ) $. 
\end{lem}

It will be noted that $ K \in \mathscr{U}^2  ( C, \Hom_A ( M,M )) $
and hence $l_X K$ has values in $ \Hom_A ( M,M ) $. Taking $
M_1 = \Hom_A ( M,M ) $, $ M_2 = M $, $ M_3 = M $ in our standard
notation, one has a bilinear product $ M_1 \times M_2  \to  M_3 $
defined by $ ( h,u ) \to $. The  symbol $\wedge$ used in the
enunciation of the lemma is with reference to this bilinear product.  

\begin{proof}
  As usual, we prove this by induction on $p$, the degree of
  $\alpha$. When $\alpha$ is of  degree $0$, the formula reduces to  
  \begin{align*}
    D_X ( d \alpha (u)) -d \alpha ( \big[ X,u \big ] ) - ( d D_X
    \alpha ) (u) & = ( l_X K \wedge \alpha ) (u) \text{ for } ~  u \in
    C.  \\ 
    \text{i.e.,}\hspace{2cm}   D_X D_u \alpha - D_{[ X,u ]} \alpha -
    D_u D_X \alpha&  = (l_X K \wedge (\alpha) (u)  
  \end{align*}
  which\pageoriginale is but the definition of $K$. Assuming the truth of the  lemma
  for forms of degree $ < p $, we have 
  \begin{align*}
    l_Y \theta_X d \alpha & - l_Y d \theta_X \alpha -l_Y((l_X K)
    \wedge \alpha)\\ 
    &= \theta_X l_Y d \alpha-l_{[ X,Y ]} d  \alpha + d l_Y \theta_X
    \alpha - \theta_Y \theta_X \alpha\\ 
    & \hspace{3cm}- ( l_Y l_X K ) \wedge \alpha +
    ( l_X K ) \wedge ( l_Y \alpha ) \\ 
    &=  - \theta_X d l_Y \alpha + \theta_X \theta_Y \alpha - l_{[ X,Y
    ]} d \alpha + d \theta_X  l_Y \alpha - dl_{[ X,Y ]} \alpha-
    \theta_Y \theta_X \alpha\\ 
    & \hspace{4cm}- ( l_Y l_X K ) \wedge \alpha + ( l_X K
    )\wedge ( l_Y \alpha ) \\  
    &= - \theta_X d l_Y \alpha + d \theta_X l_Y  \alpha + \theta_X
    \theta_Y \alpha -\theta_Y \theta_X \alpha\\ 
    & \hspace{3cm}- \theta_{[ X,Y ]}
    \alpha- ( l_Y l_X K ) \wedge \alpha +  ( l_X K ) \wedge ( l_Y
    \alpha ) \\ 
    &= - \theta_X d l_Y \alpha + d \theta_X l_Y \alpha + ( l_X K )
    \wedge ( l_Y \alpha ) ~ \text{ by lemma \ref{chap1:sec9:lem3}, Ch. 1.9} \\ 
    &= 0 ~ \text{ by induction assumption}.
  \end{align*}
\end{proof}

\begin{remark*}
  The maps $ \theta_X, l_X $, $d$ are of  degrees $ 0, -1, 1 $
  respectively considered as homomorphisms of the graded module $
  \mathscr{U}^* ( C,M ) = \sum \limits_{p} \mathscr{U}^p$ $( C,M )$. If
  $\varphi$ is a map $\mathscr{U}^* ( C,M ) \to \mathscr{U}^* ( C,M )
  $ of degree $p$, and $ \psi $ another of degree $q$, we define the
  commutator $ [ \varphi, \psi  ] = \varphi \psi - (-1)^{pq} \psi
  \varphi  $. We have, in this notation, the following formulae :  

  \begin{tabular}{rlcl}
  i) & $[ \theta_X, l_Y  ] $  $ = l_{[ X,Y ]}$ &&  by (2) of Ch.\ref{chap1:sec6}\\
  ii) & $[ d,l_X ] = \theta_X $ && by  Th. \ref{chap1:sec6:thm2}, Ch. 1.6\\
  iii) & $[ \theta_X, \theta_Y  ]= \theta_{[ X,Y ]} $ & \Bpara{7}{-1}{180}{12}& for derivation
    laws of zero curvature\\ 
  iv) &  $ [ \theta_X , d ]  = 0$ & & by lemma \ref{chap1:sec9:lem3}
  and \ref{chap1:sec9:lem4},  Ch.1.9\\
  v) & $ [ l_X, l_Y ] = 0 $ & & by (3) of Ch.\ref{chap1:sec6}
  \end{tabular}
\end{remark*}

The\pageoriginale operators $ \theta_X $ and $l_X$ have been generalised  ( see [ $
  15 $ ] to the case $ M = A $ by replacing $X$ by an alternate form
$\gamma$ on $C$ with values in $C$. This generalisation has
applications  in the study of variations of complex structures on a
manifold. 

A general formula for $d^2$ is given by 

\begin{lem}\label{chap1:sec9:lem5} %lemma 5
  In our usual notation, $ d^2 \alpha = K \wedge \alpha $.
\end{lem}

The meaning of  $\wedge$ has to be interpreted as in Lemma
\ref{chap1:sec9:lem4}, Ch.1.9 
. The proof is again by induction on the degree of $\alpha$. If
$\alpha$ is of  degree $0, \alpha \in M $ and we have to show that $
dd \alpha ( X,Y )  = K (X,Y) \alpha $.Assuming the lemma verified for
forms of degree $ < p $, we get  
\begin{align*}
  l_X dd \alpha &= \theta_X d \alpha - d l_X d \alpha \\
  &= d \theta_X \alpha + ( l_X K ) \wedge \alpha -d \theta_X \alpha +
  dd l_X \alpha ~\text{ by Lemma \ref{chap1:sec9:lem4}, Ch. 1.9} \\ 
  &= (l_X K) \wedge \alpha  + K \wedge l_X \alpha ~\text{ by induction
    assumption } \\ 
  &= l_X ( K \wedge \alpha ).
\end{align*}

Since  $X$ is arbitrary, $ dd \alpha = K \wedge \alpha $ and the lemma
is proved. 

\begin{lem}\label{chap1:sec9:lem6} %lemma 6
  \begin{align*}
    dK &= 0 \\
    dK ( X,Y,Z ) &= \sum \left \{ ( D_X K ) ( Y,Z )-K ( [ X,Y ], z )
    \right\} \text{ by  (3)  of  Ch. \ref{chap1:sec7}} \\ 
    &= \sum \left\{ D_X K ( Y,Z )-K ( Y,Z ) D_X  - K ( [ X,Y ], Z ) \right\}\\
    &= \sum \left\{ D_X D_Y D_Z  - D_X D_Z D_Y - D_X D_{[ Y,Z ]} - D_Y
    D_Z D_X + \right.\\
    & ~~~\left. D_Z D_Y D_X + D_{[ Y,Z]} D_X -D_{[ X,Y ]} D_Z + D_Z D_{[
        X,Y ]} + D_{[[ X,Y ] Z]}\right\} \\ 
    &=  0 
  \end{align*}
using\pageoriginale Jacobi's identity where the summations  extend
      over cyclic permutations of  $X$, $Y$, $Z$.  
\end{lem}

\section{Relations between different derivation
  laws}\label{chap1:sec10} %sec 1.10 

We shall now investigate the relations between the exterior
differentiations, curvature forms etc. corresponding to two derivation
laws in the same module $M$. It has already been shown (Ch.\ref{chap1:sec2}) 
that  if  $ D,D' $ are two such derivation laws, then there exists $ h
\in \Hom_A ( M,M )) $ such that $ D'_X = D_X + h_X $. We denote the
exterior differential operator, curvature form etc. Corresponding to $
D' $ by $ d', K' $ etc. Then $d'$ is given by $ d '\alpha = d \alpha +
h \wedge \alpha $. ( Here also, the  $Lambda$-sign has to be interpreted as
in lemma \ref{chap1:sec9:lem4}, Ch. 1.9 ). In fact, by definition, it follows that $
\theta'_X \alpha = \theta_X \alpha  + h_X \circ \alpha $. Hence  
$$
d l_X \alpha + h \wedge l_X \alpha  + l_X d \alpha + l_X ( h \wedge
\alpha ) = \theta'_X \alpha.  
$$
From Th. \ref{chap1:sec6:thm2}, Ch. 1.6  on the uniqueness of exterior differentiation, 
our assertion\pageoriginale follows.    

With regard to the curvature form, we have the following  formula:  
$$
K' = K + h \wedge h + dh. 
$$
For
\begin{align*}
 K' (X,Y) &= ( D_X + h_X ) ( D_Y +h_Y ) - ( D_Y + h_Y )(
  D_X + h_Y ) - D_{[ X,Y ]} - h_{[ X,Y ]} \\ 
  &=  K( X,Y ) + h_X h_Y - h_Y h_X + ( D_X h_Y ) - ( D_Y h_Y )- h_{[ X,Y ]} \\
  &= K ( X,Y ) + h_X h_Y - h_Y h_X + dh ( X,Y ) \\
  &= K ( X,Y ) + ( h \wedge h ) ( X,Y ) + dh ( X,Y ).
\end{align*}

The classical notation for $ ( h \wedge h ) $ defined by  $ ( h \wedge
h ) ( X,Y ) = h (X) h (Y) - h (Y) h (X) $ is [ $ h,h $ ]. In that
notation, we have  
$$
K' = K + [ h,h ] + dh. 
$$

\section{Derivation law in \texorpdfstring{$C$}{C}}\label{chap1:sec11} %sec1.11

When $A$ is the algebra of differentiable functions on a manifold $V$,
any derivation law in the $A$-module $C$ of differentiable vector
fields on $V$ is called a \textit{linear connection } on the
manifold. 

Let $A$ be an algebra over $ k, D $ a derivation law in the $A$-
module $C$ of derivations of $A$. Let $ \eta : C \to C $ be the
identity mapping. Then exterior defferential of $\eta$ is given by  
\begin{align*}
  (d \eta) (X,Y) &= D_X \eta (Y) - D_Y \eta (x) - \eta ( [ X,Y ] ) \\
  &= D_X Y - D_Y X - [ X,Y] \text{ for } X,Y \in C.
\end{align*}

The\pageoriginale alternate linear form $ d \eta = T $ is called the \textit{
  torsion form } of the derivation law in $C$. 

Regarding the action of $d$ on $T$, we have the \textit{ Bianchi's
  identity } 

$ (dT) ( X,Y,Z ) = \sum K ( X,Y ) Z $, where the summation extends
over all cyclic permutations of $ ( X,.Y,Z ) $. 

This is immediate from Lemma \ref{chap1:sec9:lem5}, Ch. 1.9 

Let $D$ be a derivation law in $C$. Then we can define a derivation
law in the module of  multilinear forms on $C$ with values  in an $A$-
module $M$ with derivation law $D$. For $ \alpha \in \mathscr{F}^p (
C,M ) $, we define  
$$
( D_X \alpha ) ( Z_1, \ldots, Z_p ) = D_X \alpha ( Z_1, \ldots, Z_p )
- \sum^{p}_{i=1} \alpha ( Z_1, \ldots, D_X Z_i, \ldots, Z_p ).  
$$
Moreover, we define for every $\alpha \in \mathscr{F}^p (C, M)$
{\fontsize{10}{12}\selectfont
$$
( D_X \alpha ) ( Z_1, \ldots, Z_{p+1} ) = D_{Z_1} \alpha ( Z_1,
\ldots, Z_p ) - \sum^{p}_{i=2} \alpha ( Z_2, \ldots, D_{Z_1} Z_i,
\ldots, Z_{p+1}) 
$$}\relax
Obviously $ D \alpha \in \mathscr{F}^{p+1} ( C,M ) $. However, this
operator $D$ does not take  alternate forms into alternate forms. We
therefore set, for $ \alpha \in \mathscr{U}^p ( C,M ) $ 
$$
d' \alpha = \sum^{p+1}_{i=1} (-1)^{i+1} ( D \alpha ) ( Z_i, Z_1,
\ldots, \tilde{Z}_i, \ldots, Z_{p+1} ).  
$$

It is easy to see that $ d' \alpha \in \mathscr{U}^{p+1} ( C,M ) $.

\begin{theorem}\label{chap1:sec11:thm3}%theorem 3
  If the torsion form is zero, then $d'$ and the exterior defferential\pageoriginale
  coincide. 
\end{theorem}

In fact, it is easy to verify that $ l_X d' + d' l_X = \theta_X $ and
the theorem then follows from Th.\ref{chap1:sec6:thm2}, Ch.1.6  

In particular, let $K$ be the curvature form of the derivation law in
$C$; since $ dK = 0 $, we have $ d' K = 0 $. It is easily seen that $
d K = \sum ( D_X K ) ( Y,Z ) $. where the summation extends over
cyclic permutations of $X, Y, Z$. Hence we have the  \textit{ Second
  Bianchi Identity }: 

If  the torsion of the  derivation law in $C$ is  $0$, then $ \sum (
D_X K ) ( Y,Z ) = 0 $ where the summation is over all cyclic
permutations of  $ X,Y,Z $.  

\section{Connections in pseudo-Riemannian manifolds}\label{chap1:sec12} % \sec 1.12 

A differentiable manifold $V$ together with a symmetric bilinear form
is said  to be \textit{Riemannian } if the form is positive definite
at all points. If the above form is only non-degenerate ( not
necessarily positive definite )  at each point, the manifold is
\textit{pseudo-Riemannian.} Such a form defines a natural isomorphism
of the module of  vector fields on $V$ onto its dual. 

Accordingly, in our algebraic set-up, we define a \textit{pseudo
  Riemannian form} on $C$ to be a symmetric bilinear form on $C$ with
values in $A$ such that the induced map $ C \to C^* $ is bijective. 

\begin{theorem}\label{chap1:sec12:thm4} % theorem 4.
  If $g$ is a pseudo-Riemannian form on $C$ then there exists one and
  only one derivation law $D$ on $C$ such that  
  \begin{enumerate}[\rm 1)]
  \item the\pageoriginale torsion form of $D$ is zero,
  \item $ D_X g = 0 $ for every $X$.
  \end{enumerate} 
 
  Explicitly, 1) means that $X g ( Y,Z ) - g ( D_X Y,Z ) - g (
  Y,D_X Z ) = 0$ for every $Y,Z \in C$.  
\end{theorem} 

In fact, by straight forward computation, it can be found that if
there exists one such derivation law $D$, it must satisfy the
equation 
\begin{multline*}
  2 g ( D_X Y,Z ) = Xg ( Y,Z ) -Z g ( Y,X ) + Yg ( Z,X )\\ 
  -g  ( Y,[ X,Z ]) + g ( [ Z,Y ], X )  -g ( Z,[ Y,X ] ).  
\end{multline*}
Since the map $ C \to C^* $ induced from $g$ is bijective, this
equation determines $D$ uniquely and conversely if we define $D$ by
this equation, it can be easily verified that $D$ is a derivative law
in  $C$ and that it satisfies the conditions of the theorem  

\section{Formulae in local coordinates}\label{chap1:sec13}%section 1.13

Finally we translate some of our formulae in the case of a
differentiable manifold in terms  of local coordinates. As far as local
coordinates are concerned, we may restrict ourselves to an open subset
$V$ of $R^n$. Let $ \mathscr{U} $ denote the algebra of differentiable
functions on  $V$ and $ \mathscr{C} $ the $ \mathscr{U} $-module of
vector fields on $V$. Let $ ( x^1,x^2, \ldots^n ) $ be a system of
coordinates. The partial derivatives $ P_i = \dfrac{\partial}{\partial
  x^i} $ have the following properties: 

\begin{enumerate}[1)]
\item $(P_i)_{i=1,2,\ldots n} $ is a base of $ \mathscr{C} $ over $
  \mathscr{U} $.  
\item $ P_i x^j = \delta_{ij} $
\item $[ P_i , P_j] = 0$\pageoriginale for any $ i,j $.
\end{enumerate}

Also $(dx^1, \ldots dx^n)$ form a base for $ \mathscr{C}^* $ over
$ \mathscr{U} $  dual to  $ ( P_i ) $ i.e. $ ( dx^i )$ $(P_j ) =
\delta_{ij} $. Since the $ \mathscr{U} $ -module $ \mathscr{C} $ is
free over $ \mathscr{U} $, all the associated modules such as  $ T^p (
\mathscr{C} ), \mathscr{U} ^p ( \mathscr{C}, \mathscr{U} ) $ are all
free over $ \mathscr{U} $.  Thus $ \mathscr{U}^p ( \mathscr{C},
\mathscr{U})$ has a basis consisting of elements $ dx^{\lambda (1)}
\wedge \cdots \wedge  dx^{\lambda (p) }, \lambda \in S $ where $S$
where $S$ is the set of all maps  $ \lambda :[ 1,p ] \to [ 1,n ] $
such that  $ \lambda (1) < \lambda (2)  < \cdots < \lambda (p) $. If
$M$ is an $ \mathscr{U} $-module, any alternate form $ \in
\mathscr{U}^p ( \mathscr{C},M ) ) $ can be written  in the form $ \sum
\limits_{\lambda \in S} \omega^\lambda \wedge dx  ~ {(1)}_{\wedge dx}
{(2)}_{\wedge \cdots \wedge dx}  \lambda (p) $ with $ \omega^\lambda
\in M $. ( The exterior product is with respect to  the bilinear
product  $ M \times A  \to  M $ defining the structure of $
\mathscr{U} $-module ). 

Let $M$ be a free $ \mathscr{U} $ -module of finite rank with  a
derivation law $D$. Let $ e_\alpha ( \alpha = 1,2, \ldots m )$  be a
base of $M$. We set  
$$
D_{P_i} e_\alpha  = \sum \Gamma^\beta_{i \alpha} e_\beta,
\Gamma^\beta_{i \alpha}  \in \mathscr{U}  
$$

The functions $ \Gamma^\beta_{i \alpha} $ completely determine the
derivation law. Conversely, given $ \Gamma^\beta_{i \alpha} \in
  \mathscr{U}$, we may define, for  
\begin{align*}
  u & = \sum^{m}_{\alpha=1} \rho^\alpha  l_\alpha, \rho^\alpha \in \mathscr{U}. \\
  D_{P_i} u & = \sum_{\alpha} ( p_i \rho^\alpha ) e_\alpha +
  \sum_{\alpha \beta}\rho^\alpha \Gamma^\beta_{i \alpha} e_\beta
\end{align*}
and extend $D$ to the whole of $ \xi $ by linearity. It is easy to see
that is a derivation law. The above becomes in the classical notation\pageoriginale 
$$
D_{P_i} u = \sum_{\alpha} \frac{\partial \rho^\alpha}{\partial x^i}
e_\alpha  + \sum_{\alpha,\beta} \rho^\alpha \Gamma^\beta_{i, \alpha}
e_\beta  
$$
From this we get if $ u \in M $, then 
$$
du = \sum_{i} dx_i \wedge ( D_{P_i} u ) 
$$

Let $ \omega \in \mathscr{U}^p ( C, M ) $. We have seen that 
$$
\omega = \sum_{\lambda \in S} \omega^\lambda \wedge dx ~{}^{(1)} \wedge \cdots
\wedge dx ~{}^{(p)} ~\text{ with }~ \omega^\lambda \in M. 
$$

Using the fact that $ \theta_{P_i}(\alpha \wedge \beta ) =
(\theta_{P_i} \alpha ) \wedge \beta  + \alpha \wedge  ( \theta_{P_i}
\beta ) $, in order to  compute $ \theta_X \omega $, it is enough to
compute $ \theta_{P_i} \omega^\lambda $  and $ \theta_{P_i} dx^j
$. But $ \theta_{P_i} \omega^\lambda = D_{P_i} \omega^\wedge $ which
we have fond out earlier.  On the other hand, 
\begin{align*}
  (\theta_{P_{i}} dx^j (P_k) &= P_i (( dx^j ) (P_k )) - dx^j ([ P_i , P_k ])\\
  &= 0. 
\end{align*}
