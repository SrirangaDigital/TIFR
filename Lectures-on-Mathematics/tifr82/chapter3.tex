\chapter{The Integrals of the Error Terms in Mean Square Formulas}\label{c3}

\section{The Formulas for the Integrated Error Terms}\label{c3:sec3.1}

This\pageoriginale Chapter is in a certain sense a continuation of
Chapter \ref{c2}, where we established explicit formulas for the functions
$E(T)$, $E_\sigma(T)$ defined by \eqref{c2:eq2.1} and
\eqref{c2:eq2.2}, respectively. These functions, which represent the
error terms in mean square formulas, contain much information about
$\zeta(s)$ on the critical line $\re s = 1/2$ and $\re s =
\sigma$. This topic was in part discussed at the end of Chapter \ref{c2}, and
further results may be derived from the asymptotic formulas for 
\begin{equation}
  G(T): = \int\limits_{2}^T (E(t)- \pi)dt\label{c3:eq3.1}
\end{equation}
and 
\begin{equation}
  G_\sigma (T) : = \int\limits_2^T (E_\sigma (t) - B(\sigma)) dt \quad
  \left(\frac{1}{2} < \sigma < \frac{3}{4}\right),\label{c3:eq3.2}
\end{equation}
where
\begin{align}
  B(\sigma) : & = \zeta (2 \sigma -1)\Gamma (2 \sigma-1)
  \int\limits_0^\infty\notag \label{c3:eq3.3}\\ 
  &\quad \left\{\frac{\Gamma (1- \sigma - iu)}{\Gamma
    (\sigma - iu)}+ \frac{\Gamma (1- \sigma + iu)}{\Gamma(\sigma +
    iu)} -2 u^{1-2 \sigma} \sin (\pi
  \sigma)\right\}du \\
  &\quad+ \frac{\pi (1- 2
    \sigma)\zeta (2 - 2 \sigma) (2 \pi)^{2 \sigma-1}}{\Gamma (2
    \sigma) \sin (\pi \sigma)}.\notag
\end{align}

Throughout this chapter it will be assumed that $\sigma$ is fixed and
is restricted to the range $1/2 < \sigma < 3/4$. It may be shown that 
\begin{equation}
  \lim\limits_{\sigma \to 1/2 + 0} B(\sigma)= \pi, \label{c3:eq3.4}
\end{equation}
so that \eqref{c3:eq3.1} may be thought of as the limiting case of
\eqref{c3:eq3.2}, which in view of continuity one certainly expects to
be true. The lower limit of integration in \eqref{c3:eq3.1} and
\eqref{c3:eq3.2} is unimportant, especially in applications. It could
be, of course, taken as zero, but a strictly\pageoriginale positive
lower limit enables one to use asymptotic formulas such as Stirling's
for the gamma-function. Our main results are contained in the
following theorems.

\begin{thm}\label{c3:thm3.1}
  Let $0 < A < A'$ be any two fixed constants such that $AT < N <
  A'T$, $N' = N'(T)= T/(2 \pi) + N/2 - (N^2 /4 + NT/(2 \pi))^{1/2}$,
  and let 
  \begin{align*}
    f(T, n) & = 2 T ar \sinh \sqrt{\frac{\pi n}{2T}}+ \left(2 \pi n T +
    \pi^2 n^2\right)^{1/2} - \frac{\pi}{4},\\
    g(T, n) & = T \log \left( \frac{T}{2 \pi n}\right) - T +
    \frac{\pi}{4}, ar \sinh x = \log \left(x + \sqrt{x^2 +1} \right).
  \end{align*}
  Then if $G(T)$ is defined by \eqref{c3:eq3.1} we have
  \begin{align}
   & G(T)  = 2^{-3/2} \sum_{n \leq N} (-1)^n d(n) n^{-1/2} \left(ar
    \sinh \sqrt{\frac{\pi n}{2T}} \right)^{-2} \left(\frac{T}{2 \pi n}
    + \frac{1}{4}\right)^{-1/4}\label{c3:eq3.5}\\ 
   & \sin (f(T, n))
    - 2 =\sum_{n \leq N'} d(n) n^{-1/2} \left(\log \frac{T}{2 \pi n}
    \right)^{-2} \sin (g(T, n)) + O(T^{1/4}).\notag
  \end{align}
\end{thm}

\begin{thm}\label{c3:thm3.2}
  Let $1/2 < \sigma < 3/4$ be fixed. Then with the above notation and
  $G_0- (T)$ defined by \eqref{c3:eq3.2} we have
  \begin{align}
    & G_\sigma (T)  = 2^{\sigma-2} \left(\frac{\pi}{T}\right)^{\sigma -
      1/2} \sum_{n \leq N} (-1)^{n}\sigma_{1- 2 \sigma} (n)
    n^{\sigma-1}\label{c3:eq3.6}\\ 
    & \left(ar \sinh \sqrt{\frac{\pi n}{2T}}\right)^{-2}
    \left(\frac{T}{2 \pi n} + \frac{1}{4} \right)^{-1/4} \sin (f(T,
    n))\notag\\
    & - 2 \left(\frac{2 \pi}{T}\right)^{\sigma - 1/2} \sum_{n \leq N'}
    \sigma_{1-2 \sigma} (n) n^{\sigma-1} \left(\frac{T}{2 \pi n}
    \right)^{-2} \sin (g(T, n) ) + O (T^{3/4- \sigma}).\notag
  \end{align}
\end{thm}

We remark first that, when $\sigma \to 1/2 + 0$, the expression on the
right-hand side of \eqref{c3:eq3.6} reduces to the corresponding
expression in \eqref{c3:eq3.5}. Since
$$
\frac{\partial f (T, n)}{\partial T} = 2 ar \sinh \sqrt{\frac{\pi
    n}{2T}}, \frac{\partial g(T, n)}{\partial T} = \log
\left(\frac{T}{2 \pi n} \right),
$$
it is seen that formal differentiation of the sine terms in
\eqref{c3:eq3.5} and \eqref{c3:eq3.6} yields the sums in
\eqref{c2:eq2.5} and \eqref{c2:eq2.6}, respectively. This is
natural\pageoriginale to expect, because
$$
\frac{d G(T)}{dT} = E(T) , \quad \frac{dG_\sigma (T)}{dT} = E_\sigma (T).
$$

The formulas \eqref{c3:eq3.5} and \eqref{c3:eq3.6} are of intrinsic
interest, and in Section \eqref{c3:eq3.2} we shall use them to obtain
omega-results for $E(T)$, $E_\sigma (T)$ and $G_\sigma (T)$. Theorem
\ref{c3:thm3.4} brings forth the sharpest $\Omega_{\pm}$- results for
$E(T)$ which correspond to the sharpest known results for $\Delta
(x)$. Mean square estimates for $G(T)$ and $G_\sigma (T)$ are also of
interest, and they will be discussed in Section \ref{c3:sec3.4} .

We shall begin now with the proof of Theorem \ref{c3:thm3.1} and
Theorem \ref{c3:thm3.2}. Details will be given only for Theorem
\ref{c3:thm3.1}, and then it will be indicated what changes are to be
made in proving Theorem \ref{c3:thm3.2}. One applies \eqref{c3:eq3.5}
most often in the case when $N=T$, namely
{\fontsize{10pt}{12pt}\selectfont
\begin{align}
  G(T) & = 2^{-3/2} \sum_{n \leq T} (-1)^n d(n) n^{-1/2} \left(ar
  \sinh \sqrt{\frac{\pi n}{2T}} \right)^{-2} \left(\frac{T}{2 \pi n} +
  \frac{1}{4}\right)^{-1/4}\label{c3:eq3.7}\\ 
  &\quad \sin (f (T, n))
  - 2 \sum_{n \leq c_0 T} d(n) n^{-1/2} \left(\log \frac{T}{2 \pi n}
  \right)^{-2} \sin (g (T, n)) + O (T^{1/2}),\notag
\end{align}}
where
$$
c_0 = \frac{1}{2 \pi} + \frac{1}{2} - \sqrt{\frac{1}{4} + \frac{1}{2 \pi}}.
$$

In proving either \eqref{c3:eq3.5} or \eqref{c3:eq3.7} one would
naturally wish to use Atkinson's formula for $E(T)$, but unfortunately
it contains the error term $O(\log^2 T)$ which is much too large for
this purpose. We shall actually prove \eqref{c3:eq3.7}, and then
indicate how it can be used to yield the slightly more general result
contained in \eqref{c3:eq3.5}. We start from the formulas
\eqref{c2:eq2.18} and \eqref{c2:eq2.19} with $T$ replaced by $t$ and
integrate. We obtain
\begin{align*}
  \int\limits_T^{2T} E(t) dt & = \int\limits_{T}^{2T}
  \int\limits_{-t}^t g(1/2 + i \sigma, 1/2- i \sigma) d \sigma \, dt +
  O(1)\\
  & = \int\limits_T^{2T} (I_1 (t) - I_2 (t) + I_3 (t) - I_4 (t)) dt + O(1),
\end{align*}
where $I_n = I_n(t)$ is as in \eqref{c2:eq2.30} - \eqref{c2:eq2.34},
only with $T$ replaced by\pageoriginale $t$ and $N=T$. To prove
\eqref{c3:eq3.7} i twill suffice to prove
\begin{equation}
  \int\limits_T^{2T} E(t) dt = \pi T + H(2T) - H(T) + K(2T) - K(T) +
  O(T^{1/4}),\label{c3:eq3.8}
\end{equation}
where
\begin{align}
  H(x) : & = 2^{-3/2} \sum_{n \leq x} (-1)^n d(n) n^{-\frac{1}{2}}
  \left(\frac{x}{2 \pi n} + \frac{1}{4} \right)^{-\frac{1}{4}}\label{c3:eq3.9}\\ 
  &\qquad\left(ar \sinh
  \sqrt{\frac{\pi n}{2 x}}\right)^{-2} \sin (f(x, n)),\notag\\
  H(x) : & = -2 \sum_{n \leq c_0 x} d(n) n^{-1/2} \left(\log
  \frac{x}{2 \pi n} \right)^{-2} \sin (g(x, n)),\label{c3:eq3.10}
\end{align}
and then to replace $T$ by $T 2^{-j}$ and sum over $j= 1, 2,
\ldots$ The main term $\pi T$ in \eqref{c3:eq3.8} comes from $I_3
(t)$, while the sums defined by $H$ will appear in the evaluation of
$\displaystyle{\int\limits_{T}^{2T} I_1 (t) dt}$. The integral $I_1$
was evaluated in Section \ref{c2:sec2.5} with an error term
$O(T^{-1/2})$ which, when integrated, is too large for our
purposes. To avoid this difficulty we take advantage of the extra
averaging over $t$ via the following lemma.

\begin{lemma}\label{c3:lem3.1}
  Let $\alpha, \beta, \gamma$, $a, b, k, T$ be real numbers such that
  $\alpha, \beta, \gamma$ are positive and bounded, $\alpha \neq 1$,
  $0 < a < 1/2$, $a < T/(8 \pi k)$, $b \geq T$, $k \geq 1$, $T \geq
  1$, 
  \begin{align*}
    U(t) & = \left( \frac{t}{2 \pi k} + \frac{1}{4}\right)^{1/2}, V(t)
    = 2 ar \sinh \sqrt{\frac{\pi k}{2t}},\\
    L(t) & = \frac{1}{i} (2 k\sqrt{\pi})^{-1} t^{1/2} V^{- \gamma-1}
    (t) U^{-1/2} (t) \left(U(t) - \frac{1}{2}\right)^{-\alpha}
    \left( U (t) + \frac{1}{2}\right)^{-\beta}\\ 
    &\qquad\exp \left\{it V (t)
    + 2 \pi k iU (t) - \pi i k + \frac{\pi i}{4}\right\},
  \end{align*}
  and 
  \begin{align}
    J(T) &= \int\limits_T^{2T} \int\limits_a^b y^{- \alpha} (1+
    y)^{-\beta}  \left(\log \left(1+ \frac{1}{y}
    \right)\right)^{-\gamma}\notag\\ 
    &\qquad \exp \left\{ it \log \left(1+ \frac{1}{y}\right)
    + 2 \pi i ky\right\} dy\, dt.\label{c3:eq3.11}
  \end{align}
\end{lemma}

Then uniformly for $|\alpha -1|\geq \epsilon$, $1 \leq k \leq T + 1$,
we have
\begin{align}
  J(T) &= L(2T) - L(T) + O(a^{1-\alpha})  + O(Tk^{-1} b^{\gamma - \alpha
    - \beta})\notag\\
  &\qquad + O \left(( T/k)^{1/2 (\gamma +1 - \alpha - \beta)}T^{-1/4}
  k^{-5/4}\right). \label{c3:eq3.12}
\end{align}

A\pageoriginale similar result. without $L(2T)- L(T)$, holds for the
corresponding integral with $-k$ in place of $k$.

This result is a modified version of Lemma \ref{c2:lem2.2}, and
likewise also follows from Atkinson's Theorem \ref{c2:thm2.3}. Therein
one takes
$$
f(z) = \frac{t}{2 \pi} \log \frac{1 + z}{z},\quad \Phi (x) = x^{-\alpha}
(1+ x)^{-\beta},\quad F(x) = \frac{t}{1+x}, \mu(x) = \frac{x}{2},
$$
follows the proof of Atkinson's theorem for the inner integral in
\eqref{c3:eq3.11}, and then one integrates over $t$. The contribution
of the integrals $I_{31}$ and $I_{32}$ (see p. 63 of Ivi\'c \cite{Ivic1})
is contained in the $O$-term in \eqref{c3:eq3.12}, since in our case
we find that
$$
I_{31} + I_{32} \ll 
\begin{cases}
  e^{-ck} & \text{if}~ k \geq \log^2 T,\\
  e^{- (tk)^{1/2}} & \text{if}~ k \leq \log^2 T.
\end{cases}
$$ 

Likewise, the error terms
$$
\Phi_a \left(|f'_a + k| + f{''}_a^{1/2}\right)^{-1}, \Phi_b \left(|f'_b
+ k| + f_b''^{1/2}\right)^{-1}
$$
give after integration the terms $O(a^{1- \alpha})$ and
$O(Tk^{-1}b^{\gamma - \alpha - \beta})$ which are present in
\eqref{c3:eq3.12}. The main contribution comes from $I_{32}$, only now
one has to integrate over $t$ for $T \leq t \leq 2T$. This leads to
the same type of integral (the factor $1/i$ is unimportant) at $T$ and
$2T$ respectively. The only change is that $\gamma+1$ appears instead
of $\gamma$, because of the extra factor $\log (1+ 1/y)$ in the
denominator. Hence the main terms will be $L(2T)- L(T)$, and as in
Theorem \ref{c2:thm2.3} the error term is $\Phi_0 \mu_0 F_0^{-3/2}$
with again $\gamma +1$ replacing $\gamma$. This gives the last
$O$-term in \eqref{c3:eq3.12} (see the analogous computation on p 453
of Ivi\'c \cite{Ivic1}), and completes the proof of Lemma
\eqref{c3:eq3.1}.   

Now we write
{\fontsize{10}{12}\selectfont
\begin{align*}
  \int\limits_T^{2T} I_1 (t) dt & = 4 \sum_{n \leq T} d(n)
  \mathop{\lim~\lim}_{\alpha \to 1/2 + 0\, b \to \infty}
  \int\limits_T^{2T}\int\limits_0^b \frac{\sin (t \log (1+1/y))\cos
    (2 \pi ny)}{y^\alpha (1+y)^{1/2} \log (1+ 1/y)} dy \, dt\\
  & = 2 \sum_{n \leq T} d(n) \mathop{\lim~\lim}_{\alpha \to 1/2 + 0 \,
  b \to \infty} \im \\
& \qquad \left\{\int\limits_T^{2T} \int\limits_0^b
  \frac{\exp (it \log (1+ 1/y) + 2 \pi i n y)}{y^\alpha (1+ y)^{1/2}
    \log (1+ 1/y)} dy\, dt \right\} + O(T^{1/4}).
\end{align*}}

The\pageoriginale first equality above holds because the integral defining $I_1 (t)$
converges uniformly at $\infty$ and 0 for $1/2 \leq \alpha \leq 1 -
\epsilon$. The second equality comes from using the case of Lemma
\ref{c3:lem3.1} ``$-k$ inplace of $k$'' for the other two integrals
coming from $\sin (\ldots)$ and $\cos (\ldots)$ in $I_1 (t)$. We
evaluate the double integral above by applying Lemma \ref{c3:lem3.1}
with $\beta = 1/2$, $\gamma=1$, $a \to 0$. Then we let $b \to \infty$
and $\alpha \to 1/2 + 0$. we obtain 
\begin{align}
  &\int\limits_T^{2T} I_1 (t) dt  = H(2T) - H(T) - 2^{-3/2} \sum_{T
    \leq n \leq 2T} (-1)^n d(n) n^{-1/2}\notag\\
  & \left(\frac{2T}{2 \pi n} + \frac{1}{4} \right)^{-1/4} \left(ar
  \sinh \sqrt{\frac{\pi n}{4T}}\right)^{-2} \sin (f (2T, n)) + O
  (T^{1/4})\label{c3:eq3.13}
\end{align}
where $H(x)$ is given by \eqref{c3:eq3.9}.

Hence forth we set for brevity $X= [T]+ \frac{1}{2}$. Note that the
contribution of the integral
$$
I_2 (t) = 4 \Delta (X) \int\limits_0^\infty \frac{\sin (t \log (1+
  1/y))\cos (2 \pi Xy)}{y^{1/2} (1+y)^{1/2} \log (1+ 1/y)}dy
$$ 
to $\displaystyle{\int\limits_{T}^{2T} E(t) dt}$ is estimated again by
  Lemma \ref{c3:lem3.1}. Using the weak estimate $\Delta (X) \ll
  X^{1/3+\epsilon}$ it follows at once that
$$
\int\limits_T^{2T} I_2 (T) dt \ll T^{\epsilon -1/6}.
$$

We now turn to 
\begin{align*}
  I_3 (t) & =- \frac{2}{\pi} \left(\log X + 2 \gamma \right)
  \int\limits_0^\infty \frac{\sin (t \log (1+ 1/y)) \sin (2 \pi
    Xy)}{y^{3/2} (1+y)^{1/2} \log \left(1+ \frac{1}{y} \right)}
  dy\\
  &\quad+ \frac{1}{\pi i} \int\limits_0^\infty \frac{\sin (2 \pi Xy)}{y}
  dy \int\limits_{1/2 - it}^{1/2 + it} \left(1+ \frac{1}{y} \right)^u
  u^{-1}du\\
  & = - \frac{2}{\pi} (\log X + 2 \gamma) I_{31} (t) + \frac{1}{\pi i}
  I_{32} (t),
\end{align*}
say.\pageoriginale We have first
{\fontsize{10}{12}\selectfont
\begin{multline*}
  \int\limits_T^{2T} I_{31} (t) dt = \int\limits_T^{2T} \int\limits_0^{3T}
  \cdots + \int\limits_T^{2T} \int\limits_{3T}^\infty \cdots\\
  = \int\limits_0^{3T} \frac{\left\{\cos (T \log (1+ 1/y)) - \cos (2T
    \log (1+ 1/y)) \right\} \sin (2 \pi Xy)}{y^{3/2} (1+ y)^{1/2}
    \log^2 (1+ 1/y)} dy + O(T^{-1})
\end{multline*}}
on estimating $\int_{3T}^\infty \cdots$ as $O(T^{-2})$ by writing the
sine terms in $I_{31}(t)$ as exponentials, and applying Lemma
\ref{c2:lem2.1}. The remaining integral above is written as 
$$
\int\limits_0^{3T} = \int\limits_{0}^{(2X)^{-1}} +
\int\limits_{(2X)^{-1}}^{3T} = I' + I'',
$$
say. By applying twice the second mean value theorem for integrals it
is seen that the part of $I'$ containing  $\cos (T \log (1+ 1/y))$
equals, for some $0< \eta \leq \xi \leq (2X)^{-1}$,
\begin{align*}
  & 2 \pi X \int\limits_0^\xi \frac{\cos (T \log (1+ 1/y))}{y(1+y)}
  \cdot \frac{y^{1/2} (1+ y)^{1/2}}{\log^2 (1+ 1/y)}dy\\
  &\qquad = 2 \pi x \frac{\xi^{1/2} (1+ \xi)^{1/2}}{\log^2 (1+ 1/\xi)}
  \int\limits_\eta^\xi \frac{\cos (T \log (1+ 1/y))}{y(1+y)}dy\\
  &\qquad - 2 \pi X \frac{\xi^{1/2}(1 + \xi^{1/2})}{\log^2 (1+1/\xi)}
  \left\{- \frac{1}{T} \sin (T \log (1+ 1/y)) \right\} \Bigg|_\eta^\xi
  \ll T^{-1/2},
\end{align*}
since $y^{-1} \sin (2 \pi Xy)$ is a monotonically decreasing function
of $y$ in\break $[0, (2X)^{-1}]$, and $y^{1/2} (1+y)^{1/2} \log^{-2} (1+
1/y)$ is monotonically increasing. The same reasoning applies to the
integral with $\cos (2T \log (1+ 1/y))$, 
and\pageoriginale $I'' \ll T^{-1/2}$ follows on applying Lemma
\ref{c2:lem2.1}. Hence
$$
\int\limits_T^{2T} I_{31} (t) dt \ll T^{-1/2}.
$$ 

Next take $I_{32}(t)$ and write
\begin{align*}
  I_{32}(t) &= \int\limits_0^1 \frac{\sin(2 \pi Xy)}{y} dy
  \int\limits_{1/2- it}^{1/2 + it} (1- 1/y)^u u^{-1} du\\
  &\quad + \int_1^\infty \frac{\sin (2 \pi Xy)}{y} \int\limits_{1/2 -it}^{1/2
  + it} (1+ 1/y)^u u^{-1}du = I'_{32}(t) + I''_{32} (t),
\end{align*}
say. As in the corresponding estimation in the proof of Theorem
\ref{c2:thm2.1} one has $I''_{32} (t) \ll t^{-1} \log t$, which gives
$$
\int\limits_T^{2T} I''_{32} (t) dt \ll \log T.
$$

In $I''_{32}(t)$ we have $o < y \leq 1$, hence by the residue theorem 
$$
\int\limits_{1/2 -it}^{1/2 + it} (1+ 1/y)^u u^{-1} du = 2 \pi i -
\left(\int\limits_{1/2 + it}^{- \infty + it}+ \int\limits_{- \infty -
  it}^{1/2 - it} \right) (1+ 1/y)^u u^{-1} du.
$$

If we use 
$$
\int\limits_0^1 \frac{\sin (2 \pi X y)}{y}dy = \int\limits^{2  \pi
  X}_0 \frac{\sin z}{z} dz = \int\limits_0^\infty - \int^\infty_{2 \pi
X}  = \frac{\pi}{2} + O (T^{-1})
$$
and integrate, we obtain
\begin{align*}
  \int\limits^{2T}_T I'_{32}(t) dt &= \pi^2 iT - \int\limits_{T}^{2T}
  \int\limits_0^1 \frac{\sin (2 \pi X y)}{y} \int\limits_{1/2 +
    it}^{- \infty+ it} (1+ 1/y)^{u}u^{-1} du\, dy\, dt\\
  &\quad - \int^{2T}_T \int\limits_0^1 \frac{\sin(2 \pi Xy)}{y}
  \int\limits_{- \infty - it}^{1/2 - it} (1+ 1/y)^u u^{-1} du\, dy\, dt + O(1).
\end{align*}

Both triple integrals are estimated similarly, each being $\ll
T^{-1/2}$. \break Namely, changing the order of integration and integrating
by parts we\pageoriginale have
{\fontsize{10}{12}\selectfont
\begin{align*}
  & \int\limits_T^{2T} \int\limits_{-\infty + it}^{1/2 + it} (1+ 1/y)^u
  u^{-1} du\, dt = \int\limits_{-\infty}^{1/2} (1 + 1/y)^{\sigma}
  \left\{ \int\limits_T^{2T} (1+ 1/y)^{it} \frac{dt}{\sigma + it}
  \right\} d \sigma\\
  &\qquad = \int\limits_{- \infty}^{1/2} \left(1+ \frac{1}{y} \right)^\sigma
  \Bigg\{\frac{(1+ 1/y)^{2 iT}}{i(\sigma + 2 iT)\log (1/1/y)} - \frac{(1+
    1/y)^{iT}}{i (\sigma + iT) \log (1+ 1/y)}+\\
  &\qquad + \int\limits_T^{2T} \frac{(1+ 1/y)^{it}}{(\sigma + it)^2 \log (1+
    1/y)}dt \Bigg\} d \sigma \ll T^{-1} \int\limits_{- \infty}^{1/2}
  \frac{(1+ 1/y)^\sigma d \sigma}{\log (1+ 1 /y)} \ll T^{-1} y^{- 1/2}
\end{align*}}
for $0 < y \leq 1$, and 
{\fontsize{10}{12}\selectfont
$$ 
T^{-1} \int\limits_0^1 |\sin (2 \pi X y)|y^{-3/2} dy \ll T^{-1}
\int\limits_0^{X^{-1}}  Xy^{-1/2}dy + T^{-1}
\int\limits^\infty_{X^{-1}} y^{- 3/2} dy \ll T^{-1/2}.
$$}

Therefore combining the preceding estimates we have
$$
\int\limits_T^{2T} I_3 (t) dt = \pi T + O(\log T).
$$
Finally, it remains to deal with the contribution of the integral 
$$
I_4 (t) = - i \int\limits_X^\infty \Delta(x) \left(\int\limits_{1/2-
  it}^{1/2 + it}  \frac{\partial h (u, x)}{\partial x}du \right) dx
$$
to $\int\limits_T^{2T} E(t)$, where as in the proof of Theorem
\ref{c2:thm2.1}
\begin{align*}
h(u, x) &= 2 \int\limits_0^\infty y^{-u} (1+ y)^{u-1} \cos (2 \pi x
y)dy\\
&= 2 \int\limits_{0}^\infty w^{-u} (x+ w)^{u-1} \cos (2 \pi w) dw.
\end{align*}

It is easy to see that this integral $h$ is uniformly convergent, and
so we can differentiate under the integral sign to get (after changing
variables again)
$$
\frac{\partial}{\partial x} h (u, x) = \frac{2}{x} (u-1)
\int\limits_0^\infty y^{-u} (1+y)^{u-2} \cos (2 \pi xy) dy.
$$

This\pageoriginale integral is absolutely convergent at both
endpoints, so we insert it in the definition of $I_4 (t)$ to obtain
\begin{align*}
  - \int\limits_T^{2T} I_4 (t) dt
  &= 2 i \int\limits_X^\infty \Delta (x) x^{-1} dx \int_0^\infty y^{-
    1/2} (1+ y)^{-3/2}\\ 
  &\quad \cos (2 \pi xy) dy \int\limits_T^{2T}
  \int\limits_{1/2- it}^{1/2 + it} (u-1) \left(1+ \frac{1}{y}
  \right)^{u- 1/2} du \, dt.
\end{align*}

We can now evaluate explicitly the integrals with respect to $u$ and
$t$. We shall see from subsequent estimates that what remains provides
absolute convergence for the integral in $x$, so that this procedure
is justified. We have
\begin{equation}
  - \int\limits_T^{2T} I_4 (t) dt = 4 \int_X^\infty \Delta (x)
  (x)^{-1} (I (x, T)+ \Gamma (x, T) dx,\label{c3:eq3.14}
\end{equation}
where 
\begin{align*}
  I (x, z): & = \int\limits_0^\infty \frac{- z\sin (z \log (1+ 1/y))
    \cos (2 \pi xy)}{y^{1/2} (1+ y)^{3/2} \log ^2 (1+ 1/y)}dy,\\
  r (x, T): & = \int\limits_0^\infty \frac{\{ \cos (T \log (1+ 1/y)) -
    \cos (2 T \log (1+ 1/y))\} \cos (2 \pi x y)}{y^{1/2} (1+ y)^{3/2}
    \log^2 (1+ 1/y)}\\
  & \hspace{6cm}\left\{\frac{1}{2} +  \frac{2}{\log (1+ 1/y)} \right\}dy.
\end{align*}

Split now 
$$
r(x, T) = \int_0^\infty = \int_0^{3T} + \int\limits_{3T}^\infty = I' + I'',
$$
say. In $I''$ we write
\begin{align*}
&\cos (T \log (1+ 1/y))- \cos (2T \log (1/y))\\
&\qquad = 2 \sin
\left(\frac{3T}{2} \log (1+ 1/y) \right) \sin \left(\frac{T}{2} \log
(1+ 1/y) \right)
\end{align*}
and use the second mean value theorem for integrals. Thus we have, for
some $c > 3T$,
\begin{align*}
  I'' &= \frac{3T^2}{2} \left\{\frac{\sin \left(\frac{3T}{2} \log
    \left(1+ \frac{1}{3T} \right) \right)}{\frac{3T}{2} \log \left(1+
    \frac{1}{3 T} \right)} \cdot \frac{\sin \left(\frac{T}{2} \log
    \left(1+ \frac{1}{3T} \right) \right)}{\frac{T}{2} \log \left(1+
    \frac{1}{3T} \right)} \right\} \times\\
    &\qquad \times \int\limits_{3T}^c \frac{\cos (2 \pi x y)}{y^{1/2} (1+
      y)^{3/2}} \left\{ \frac{1}{2} + \frac{2}{\log (1+ 1/y)}\right\}
    dy \ll Tx^{-1},
\end{align*}
since\pageoriginale the first expression in curly brackets is $O(1)$,
and the above integral is $O(T^{-1} x^{-1})$ on applying Lemma
\ref{c2:lem2.1}. Hence using Theorem \ref{c2:thm2.5} the
Cauchy-Schwarz inequality we obtain
{\fontsize{10pt}{12pt}\selectfont
\begin{equation}
  4 \int\limits_X^\infty \Delta (x) x^{-1} I'' dx \ll
  \left(\int\limits_X^\infty \Delta^2 (x) x^{-2} dx \right)^{1/2}
  \left(\int\limits_{X}^\infty x^{-2} dx\right)^{1/2} \ll
  T^{1/4}.\label{c3:eq3.15} 
\end{equation}}

To evaluate $I'$ we use Lemma \ref{c2:lem2.2} (treating the main terms
as an error term) to get the analogue of \eqref{c3:eq3.15} for
$I'$. the integral $I (x, 2T)- I (x, T)$ is also evaluated by Lemma
\ref{c2:lem2.2} with $\alpha \to 1/2 + 0$, $\beta = 3/2$, $\gamma
=2$. The error terms will be $\ll T^{1/4}$ as in
\eqref{c3:eq3.15}. The main terms will be
{\fontsize{9}{7}\selectfont
$$
\left\{-z (4x)^{-1} \left( \frac{z}{\pi}\right)^{1/2} V^{-2} U^{-1/2}
\left(U- \frac{1}{2} \right)^{-1/2} \left(U + \frac{1}{2}
\right)^{-3/2} \sin \left(zV + 2  \pi x U- \pi x + \frac{\pi}{x}\right)
\right\}\Bigg|_T^{2T}, 
$$}
where
$$
U= \left(\frac{z}{2 \pi x}+ \frac{1}{4} \right)^{1/2},\quad V= 2 ar \sinh
\sqrt{\frac{\pi x}{2z}}.
$$

Thus \eqref{c3:eq3.13} becomes 
{\fontsize{10pt}{12pt}\selectfont
\begin{align}
  - \int\limits_T^{2T}&  I_4 (t) dt = O(T^{1/4}) - \int\limits_Z^\infty
  \Delta (x) x^{-3/2}\notag \label{c3:eq3.16}\\
& \left\{\sqrt{2} z V^{-2} U^{-1/2} \left(U + \frac{1}{2} \right)^{-1}
  \sin \left(zV + 2 \pi x U -\pi x + \frac{\pi}{x}\right)
  \Bigg|_T^{2T}\right\} dx.
\end{align}}

The last integral bears resemblance to the integral for $I_4$ in
Section \ref{c2:sec2.5}. The difference is that instead of $V^{-1}$ we have
$V^{-2}$ and\pageoriginale sine (at $T$ and $2T$) instead of cosine in
\eqref{c3:eq3.16}. This difference is not important at all, and after
using the Voronoi series expansion for $\Delta(x)$ and changing the
variable $x$ to $x^2$ the above integral may be evaluated by Lemma
\ref{c2:lem2.3}. The modification is that, as on p. 454 of Ivi\'c
\cite{Ivic1}, we have $V= 2 ar \sinh (x_0 (\pi /(2T))^{1/2})=
\log\left(\frac{T}{2 \pi n} \right)$; hence if we replace $ar \sinh
\left(x \sqrt{\frac{\pi}{2T}}\right)$ by its square in Lemma \ref{c2:lem2.3} we
obtain in the main term the additional factor $2 \left(\log
\left(\frac{T}{2 \pi n} \right) \right)^{-1}$, the error terms remain
unchanged. With this remark one can proceed exactly as was done in the
evaluation of $I_4$ in the proof of Atkinson's formula, and the
details for this reason may be omitted. We obtain 
\begin{align}
  - \int\limits_T^{2T} I_4 (t) dt & = - 2 \sum_{n < Z} d(n) n^{-1/2}
  \left(\log \frac{z}{2 \pi n} \right)^{-2} \sin (g(z, n))
  \Bigg|_T^{2T} + O(T^{1/4})\notag\\
  &= K(2T) - K(T) - 2 \sum_{N'_2 \leq n \leq N'_1} d(n) n^{-1/2}
  \left(\log \frac{2T}{2 \pi n} \right)^{-2}\notag\\ 
  & \qquad\sin (g (2 T, n)) +
  O(T^{1/4}),\label{c3:eq3.17} 
\end{align}
where as in the proof of Atkinson's formula
$$
Z= N' (z, X) = \frac{z}{2\pi} + \frac{X}{2} - \left(\frac{X^2}{4} +
\frac{Xz}{2 \pi} \right)^{1/2},
$$
$N'_j = N'(2T, jT)$, and $K(x)$ is given by \eqref{c3:eq3.10}.

Thus except for the extra sums in \eqref{c3:eq3.17} and the expression
for $\displaystyle{\int\limits_T^{2T} I_1 (t) dt}$ in
\eqref{c3:eq3.13} we are near the end of the proof of
\eqref{c3:eq3.8}. But the sums in question may be transformed into one
another (plus a small error term) by the method of M. Jutila
\cite{Jutila3}. Indeed, from Jutila's work we obtain (analogously to eq
(15.45) of Ivi\'c \cite{Ivic1})
\begin{align*}
 & -2 \sum_{N'_2 \leq n \leq N'_1} d(n) n^{-1/2} \left(\log \frac{2T}{2
    \pi n}\right)^{-2} \sin (g (2T, n))\\
  & = 2^{-3/2} \sum_{T \leq n \leq 2T} (-1)^n d(n) n^{-1/2}
  \left(\frac{2T}{2 \pi n} + \frac{1}{4} \right)^{-1/4}\\ 
  &\left(ar \sinh
  \sqrt{\frac{\pi n}{4T}}\right)^{-2} \sin (f (2T, n))+ O (\log^2 T),
\end{align*}
the\pageoriginale difference from (15.45) of Ivi\'c \cite{Ivic1} being in
$(\log \ldots )^{-2}$ and \break $(ar \sinh \ldots )^{-2}$, and in $2T$
instead of $T$. Hence collecting all the expressions for
$\int\limits_T^{2T} I_n (t) dt \; (1 \leq n \leq 4)$ we obtain
\eqref{c3:eq3.8}. But applying the same procedure (i.e. (15.45) of
Ivi\'c \cite{Ivic1}) we obtain without difficulty Theorem \ref{c3:thm3.1}
from \eqref{c3:eq3.8}.

We pass now to the proof of Theorem 3.2, basing our discussion on the
method of proof of Theorem \ref{c2:thm2.2}, and supposing $1/2 <
\sigma < 3/4$ throughout the proof. In the notation of
\eqref{c2:eq2.20} we have (with $t$ in place of $T$)
{\fontsize{10pt}{12pt}\selectfont
\begin{align}
  \int\limits_0^t & |\zeta (\sigma + it)|^2 du  = \zeta(2 \sigma)t +
  \zeta (2 \sigma-1) \Gamma (2 \sigma-1)\notag\\ 
  & \int\limits^t
  \left(\frac{\Gamma (1- \sigma - iu)}{\gamma (\sigma - iu)} +
  \frac{\Gamma (1- \sigma + iu)}{\Gamma (\sigma + iu)} \right)du
   - i \int\limits_{\sigma- it}^{\sigma+ it} g(u, 2 \sigma - u)
  du,\label{c3:eq3.18} 
\end{align}}
where $g(u, v)$ is the analytic continuation of the function which is
for $\re u < 0$, $\re (u+v)> 2$ given by 
$$
g(u, v) = 2 \sum_{n=1}^\infty \sigma_{1-u-v} (n) \int\limits_0^\infty
y^{-u} (1+ y)^{-v} \cos (2 \pi ny)dy.
$$

Now we use Stirling's formula for the gamma-function in the from $(s)=
\sigma + it$, $0 \leq \sigma \leq 1$, $t \geq e$
$$
\Gamma (s) = \sqrt{2 \pi} t^{\sigma- 1/2} k(\sigma, t) \exp \left\{-
\frac{\pi}{2} t + i \left(t \log t -t + \frac{\pi}{4} \left(\sigma-
\frac{1}{2}  \right)\right) \right\}
$$ 
with
$$
k(\sigma, t)= 1 + c_1 (\sigma) t^{-1} + \cdots + c_N (\sigma) t^{-N} +
O_N (t^{-N-1})
$$
for any fixed integer $N\geq 1$, where $c_1 (\sigma)= \frac{1}{2} i (\sigma -
\sigma^2 - 1/6)$. Therefore $c_1 (\sigma) = c_1 (1- \sigma)$, and for
$u\geq e$ we obtain 
\begin{align}
  \frac{\Gamma(1- \sigma + iu)}{\Gamma (\sigma + iu)} & = u^{1-2\sigma}
  \exp \left( \frac{i\pi}{2}(1- 2 \sigma)\right) \frac{k(1- \sigma , u)}{k(\sigma,
    u)}\notag\\
  & = u^{1- 2\sigma} \exp \left(\frac{i\pi}{2} (1- 2 \sigma) \right)
  \cdot (1+ m (\sigma, u)),\label{c3:eq3.19}\\
  m(\sigma, u)& = d_2 (\sigma) u^{-2} + \cdots + d_N (\sigma) u^{-N} +
  O_N (u^{-N-1}).\notag 
\end{align}

Thus\pageoriginale
\begin{align*}
  \int_0^t \left(\frac{\Gamma (1- \sigma + iu)}{\Gamma (\sigma + iu)}
  + \frac{\Gamma (1- \sigma - iu)}{\Gamma (\sigma - iu)} \right)du = 
  \int_0^t 2 u^{1- 2\sigma} \cos (\pi \sigma - 1/2 \pi)du\\ 
  + \int\limits_0^t \left\{\frac{\Gamma (1- \sigma - iu)}{\Gamma (\sigma
    -iu)}+ \frac{\Gamma (1- \sigma + iu)}{\Gamma (\sigma + iu)} -
  2u^{1-2\sigma} \cos (\pi \sigma - 1/2 \pi)  \right\} du\\
  = \frac{t^{2-2\sigma}}{1- \sigma} \sin (\pi \sigma)+
    \int\limits_0^\infty  \left\{\frac{\Gamma (1- \sigma-iu)}{\Gamma
      (\sigma- iu)} + \frac{\Gamma (1- \sigma + iu)}{\Gamma (\sigma +
      iu)}  \right\} du + O(t^{- 2 \sigma}),
\end{align*}
where \eqref{c3:eq3.19} was used. Then we have
\begin{align*}
&  \zeta (2 \sigma -1) \Gamma (2 \sigma -1) \int\limits_T^{2T} \int_0^t
  \left(\frac{\Gamma (1- \sigma - iu)}{\Gamma (\sigma - iu)} + \frac{\Gamma
  (1- \sigma + iu)}{\Gamma (\sigma + iu)} \right) du\, dt\\ 
&  = O(T^{1-2\sigma}) + \int\limits_T^{2T} \frac{\zeta (2 \sigma
    -1)\Gamma (2 \sigma-1)}{1-\sigma} \sin (\pi \sigma) t^{2-2\sigma}
  dt + 2 \zeta (2\sigma -1)\\ 
&  \Gamma (2\sigma -1)
  \int\limits_0^\infty \left\{ \re \frac{\Gamma (1- \sigma +
    iu)}{\Gamma (\sigma + iu)}- u^{1-2\sigma} \sin (\pi \sigma )
  \right\} du.
\end{align*}

Taking into accout \eqref{c3:eq3.18} and the definition of $E_\sigma
(T)$ it follows that 
\begin{equation}
  \int\limits_T^{2T} E_\sigma (t) dt = A (\sigma) T- i\int_T^{2T}
  \int\limits_{\sigma- it}^{\sigma + it} g(u, 2 \sigma - u) du \, dt +
  O(T^{1- 2 \sigma}),\label{c3:eq3.20}
\end{equation}
where 
\begin{align}
  A(\sigma) & = \zeta (2 \sigma -1) \Gamma (2 \sigma-1)
  \int\limits_0^\infty\notag 
  \left\{\frac{\Gamma (1-\sigma - iu)}{\Gamma (\sigma -iu)} \right. +\\
&\quad \left.  \frac{\Gamma (1- \sigma + iu)}{\Gamma (\sigma + iu)} - 2u^{1-2
    \sigma} \sin (\pi u) \right\} du.\label{c3:eq3.21}
\end{align}

For $E(T)$ we had an analogous formula, only without a term
corresponding to $A(\sigma)T$. Therefore it seems natural to expect
that 
\begin{equation}
  \lim\limits_{\sigma \to 1/2 + 0} A(\sigma )=0,\label{c3:eq3.22}
\end{equation}
which will indirectly establish \eqref{c3:eq3.4}. We write
\begin{align}
  A(\sigma)  &= \lim\limits_{V \to \infty} \int\limits_0^V 
   \left\{ \zeta (2 \sigma -1) \Gamma (2 \sigma-1)\vphantom{\frac{\Gamma}{\Gamma}}\right.\label{c3:eq3.23}\\ 
   &\quad \left.\left(\frac{\Gamma
    (1- \sigma - iu)}{\Gamma (\sigma - iu)} + \frac{\Gamma (1- \sigma
    + iu)}{\Gamma (\sigma + iu)} - 2u^{1-2 \sigma} \cos (\pi \sigma -
  1/2 \pi \right)\right\} du.\notag
\end{align}

For\pageoriginale a fixed $u$ and $\sigma \to 1/2 +0$ the expression in curly brackets
equals 
{\fontsize{8}{10}\selectfont
\begin{multline*}
  \left(- \frac{1}{2} - \frac{1}{2} \log (2 \pi) (2 \sigma -1) + O ((2
  \sigma-1)^2)\right) \left(\frac{1}{2 \sigma-1} - \gamma + O((2
  \sigma -1)) \right)\times\\
  \times \left\{2- (2\sigma-1) \left(\frac{\Gamma'}{\Gamma} (1/2 -iu)
  + \frac{\Gamma'}{\Gamma} (1/2 + iu) \right)- 2(1+ (1-2\sigma)\log u
  + O ((2 \sigma -1)^2)) \right\},
\end{multline*}}
which tends to 
$$
\frac{1}{2} \left( \frac{\Gamma'}{\Gamma} \left(\frac{1}{2} - iu
\right) + \frac{\Gamma'}{\Gamma} \left(\frac{1}{2} + iu \right)- 2\log
u\right). 
$$

Because of uniform convergence the integral in \eqref{c3:eq3.23} is 
\begin{align}
  & \frac{1}{2} \int\limits_0^V \left(\frac{\Gamma'}{\Gamma} (1/2 -
  iu) + \frac{\Gamma'}{\Gamma}(1/2 - iu) - 2 \log u
  \right)du\label{c3:eq3.24}\\ 
  & = \frac{1}{2i} \log \frac{\Gamma (1/2+ iV)}{\Gamma (1/2- iV)} -
  V\log V + V.\notag
\end{align}

But for $V \geq V_0 > 0$ Stirling's formula gives
\begin{align*}
  \Gamma (1/2 + iV) & = \sqrt{2 \pi} \exp (- 1/2 \pi V + i (V \log V-V))
  \cdot (1+ O(1/V)),\\
  \Gamma (1/2 - iV)& = \sqrt{2 \pi} \exp (- 1/2 \pi .V + i (-V \log V
  + V))\cdot (1+ O(1/v)).
\end{align*}

Therefore
\begin{equation}
  \log \frac{\Gamma (1/2 + iV)}{\Gamma (1/2 - iV)} = 2i (V \log V -V)
  + O(1/V).\label{c3:eq3.25}
\end{equation}

Inserting \eqref{c3:eq3.25} in \eqref{c3:eq3.24} and taking the limit
in \eqref{c3:eq3.23} we obtain \eqref{c3:eq3.22}.

Hence, analogously to the proof of Theorem \ref{c3:thm3.1}, we obtain 
\begin{align}
  \int\limits_T^{2T} (E_\sigma (t) - A(\sigma))dt & = -i
  \int\limits_T^{2T} \int\limits_{\sigma - it}^{\sigma+ it} g(u, 2
  \sigma -u) du\, dt + O(1) \notag\\
  & = -i \int\limits_T^{2T} (G_1 - G_2 + G_3 - G_4) dt + O(1),\label{c3:eq3.26}
\end{align}
where\pageoriginale $G_n$ for $1 \leq n \leq 4$ is given by
\eqref{c2:eq2.45}- \eqref{c2:eq2.48}.

As in the evaluation of $\int\limits_T^{2T} I_1 (t)dt$ in the proof of
Theorem \ref{c3:thm3.2} it will be seen that in the final result the
contribution of $G_1$ will be {\small $2^{\sigma-2} \left(\frac{\pi}{T}
\right)^{\sigma -1/2}\break \sum\limits_{n \leq N} \ldots$} in
\eqref{c3:eq3.6} plus $O(T^{3/4}- \sigma)$, which is the largest
$O$-term appearing in the estimation of various integrals. Using
\eqref{c2:eq2.41},  namely
$$
\Delta_{1- 2 \sigma} (x) \ll x^{1/(4\sigma+1)+\epsilon},
$$
it follows for sufficiently small $\epsilon$ that 
$$
\int\limits_T^{2T} G_2 dt \ll T^{1/ 4 \sigma+!}- 1/2 \epsilon \ll 1.
$$

The contribution of $G_3$ is, however, more involved. We have
\begin{equation}
  - i \int\limits_T^{2T} G_3 dt = \frac{\pi (1- 2 \sigma) \zeta (2- 2
    \sigma)(2 \pi)^{2 \sigma-1}}{\Gamma (2 \sigma) \sin (\pi \sigma)}T
  + O(\log T).\label{c3:eq3.27}
\end{equation}

Since it will be indicated that he contribution of $G_4$ will be
essentially $-2 \left(\frac{2 \pi}{T} \right)^{\sigma - 1/2}
\sum\limits_{n \leq N'}\ldots$ in \eqref{c3:eq3.6}, it follows from
\eqref{c3:eq3.27} that $B(\sigma)$ in \eqref{c3:eq3.2} is indeed given
by \eqref{c3:eq3.3}. In view of \eqref{c3:eq3.21} we may write
$$
B(\sigma) = A(\sigma) + \frac{\pi (1- 2 \sigma)\zeta (2 - 2 \sigma)(2
  \pi)^{2 \sigma-1}}{\Gamma (2 \sigma)\sin (\pi \sigma)},
$$ 
hence taking the limit as $\sigma \to 1/2 + 0$ and using
\eqref{c3:eq3.22} we obtain \eqref{c3:eq3.4}. To obtain
\eqref{c3:eq3.27} we split $(X= N + 1/2)$ the contribution of the
first integral appearing in the definition of $G_3$ as 
{\fontsize{10}{12}\selectfont
\begin{align*}
&  \int\limits_T^{2T} \int\limits_0^{3T} \cdots + \int\limits_T^{2T}
  \int\limits_{3T}^\infty \cdots = - \left(\frac{2i}{\pi} \right)
  \left\{\zeta (2 \sigma)+ \zeta (2 - 2 \sigma)x^{1- 2 \sigma}
  \right\}\\
&  \int\limits_0^{3T} \frac{\sin (2 \pi X y) \left\{\cos (T \log (1+
    1/y)) - \cos (2 T \log (1+ 1/y)) \right\}}{y^{\sigma+1} (1+
    y)^{\sigma} \log^2 (1+ 1/y)} dy  + O(T^{-2\sigma}),
\end{align*}}
analogously\pageoriginale as in the treatment of $I_3 (t)$ in the
proof of Theorem \eqref{c3:eq3.1}. By the same technique the remaining
integral is found to be
$$
\int\limits_0^{3T} = \int\limits_0^{(2x)^{-1}} + \int\limits_{(2
  X)^{-1}}^{3T} = I' + II'' \ll T^{1-2 \sigma} \ll 1.
$$ 

The main term in \eqref{c3:eq3.27} comes from the second integral in
the expression for $G_3$. Integration yields (with $-i$ as a factor) 
{\fontsize{8}{10}\selectfont
\begin{multline*}
  - \frac{i(1- 2 \sigma)}{\pi} \zeta (2 - 2 \sigma)X^{1- 2 \sigma}
  \left\{ \int\limits_T^{2T} \int\limits_0^1 \frac{\sin (2 \pi
    Xy)dy}{y(1+y)^{2 \sigma-1}} \int\limits_{\sigma - it}^{\sigma+ it}
  (u+1- 2 \sigma)^{-1} \left(1 + \frac{1}{y}\right)^u du dt \right.\\
  \left.+\int\limits_T^{2T} \int_1^\infty \frac{\sin(2 \pi Xy)dy}{y (1+
    y)^{2 \sigma-1}} \int\limits_{\sigma - it}^{\sigma + it} (u+1 - 2
  \sigma)^{-1} \left(1+ \frac{1}{y} \right)^u du \, dt \right\}.
\end{multline*}}

The total contribution of the second triple integral above is $\ll
\log T$, after integration by parts, analogously as in the
corresponding part of the proof of Theorem \ref{c2:thm2.1}. To
evaluate the first integral note that the theorem of residues gives,
for $0 < y\leq 1$, 
\begin{align*}
  \int\limits_{\sigma- it}^{\sigma+ it} & (u+1 - 2 \sigma)^{-1} \left(1+
  \frac{1}{y}\right)^u du\\ 
  &= 2 \pi i \left( 1+ \frac{1}{y}\right)^{2\sigma -1}-
  \left(\int\limits_{\sigma+ it}^{- \infty + it}+ \int\limits_{-
    \infty - it}^{\sigma -it} \right) \left(1 + \frac{1}{y} \right)^u
  \frac{du}{u+1 - 2\sigma}\\
  & = 2 \pi i \left(1+ \frac{1}{y} \right)^{2 \sigma-1} + J' + J'',
\end{align*}
say.\pageoriginale Then
\begin{align*}
  & - \frac{i(1 - 2\sigma)}{\pi} \zeta (2 - 2 \sigma)X^{1- 2 \sigma}
  \int\limits_0^1 \frac{\sin(2 \pi Xy)}{y (1+ y)^{2 \sigma-1}} \cdots
  2 \pi i \left(1+ \frac{1}{y}\right)^{2 \sigma-1} dy\\
  & = 2 (1- 2 \sigma) \zeta (2 - 2 \sigma)X^{1- 2\sigma}
  \int\limits_0^1 y^{- 2\sigma} \sin (2 \pi X y)dy\\
  & = 2(1- 2 \sigma)\zeta (2- 2 \sigma)X^{1-2 \sigma}
  \int\limits_0^\infty y^{-2 \sigma} \sin (2 \pi Xy)dy + O(T^{- 2
    \sigma})\\
  & = 2 (1- 2 \sigma) \zeta (2 - 2 \sigma)X^{1- 2\sigma}
  \int\limits_0^\infty X^{2\sigma} (2 \pi)^{2 \sigma} w^{- 2 \sigma}
  \sin w \cdot \frac{dw}{2 \pi X} + O(T^{-2\sigma})\\
  & = 2(2 \pi)^{2 \sigma-1} (1- 2 \sigma) \zeta (2 - 2 \sigma)
  \int\limits_0^\infty w^{- 2 \sigma} \sin W \, dw+ O(T^{-2 \sigma})\\
  & = \frac{\pi (1- 2\sigma) \zeta (2- 2 \sigma)(2 \pi)^{2
      \sigma-1}}{\Gamma (2 \sigma) \sin (\pi \sigma)}+ O(T^{-2 \sigma}),
\end{align*}
where, similarly as in the proof of Theorem \eqref{c2:thm2.2}, we used
$$
\int\limits_0^\infty w^{- 2 \sigma} \sin w\, dw
 = \frac{\pi}{2 \Gamma(2 \sigma)\sin (\pi \sigma)}.
$$

The contribution of $J''$ (similarly for $J'$) is 
\begin{align*}
  \int\limits_T^{2T} & \int\limits_{- \infty - it}^{\sigma-it} \left(1+
  \frac{1}{y} \right)^u \frac{du \, dt}{u+1 - 2\sigma}\\ 
  & =
  \int\limits_{- \infty}^\sigma \left(1+ \frac{1}{y} \right)^v dv
  \left\{\int\limits_T^{2T} \left(1+ \frac{1}{y} \right)^{-it}
  \frac{dt}{v- it + 1- 2 \sigma} \right\} \\
  & = \int\limits_{- \infty}^\sigma \frac{(1+ 1/y)^v}{T\log (1+
    1/y)}dv \ll T^{-1} y^{-\sigma},
\end{align*}
on integrating the middle integral by parts. Then
\begin{align*}
  & T^{-1} \int\limits_0^1 \frac{|\sin (2 \pi Xy)|}{y^{\sigma+1} (1+
    y)^{2 \sigma -1}} dy\\
  & = T^{-1}\left(\int\limits_0^{X^{-1}} \frac{|\sin (2 \pi X
    y)|}{y^{\sigma+1} (1+ y)^{2 \sigma-1}} dy+ \int\limits_{X^{-1}}^1
  \frac{|\sin (2 \pi Xy)|}{y^{\sigma+1} (1+ y)^{2 \sigma-1}}
  dy\right)\\
  & \ll T^{-1} \left(\int\limits_0^{X^{-1}} Xy^{-\sigma} dy +
  \int\limits_{X^{-1}}^\infty y^{- \sigma-1}dy \right) \ll
  T^{\sigma-1} \ll \log T,
\end{align*}
which\pageoriginale proves \eqref{c3:eq3.27}. 

Further with 
$$
c= c(y, \sigma)= (2 \sigma -1) (1+ y)- \sigma - \log^{-1} \left(1+ 
\frac{1}{y} \right) \asymp y (y \to \infty) 
$$
we have
{\fontsize{10}{12}\selectfont
\begin{align*}
  \int\limits_T^{2T} G_4 dt & = 4i \int\limits_X^\infty x^{-1}
  \Delta_{1- 2 \sigma} (x) dx \int\limits_0^\infty y^{- \sigma} (1+
  y)^{- \sigma -1} \log^{-1} \left( 1+ \frac{1}{y}\right) \cos (2 \pi
  x y)\\ 
  &\qquad \int\limits_T^{2T} \left\{ t \cos \left(t \log \left(1+ \frac{1}{y}
  \right)\right) +  c \sin \left(t \log \left(1+ \frac{1}{y} \right)
  \right) \right\}dy\, dt\\
  & = 4i \int\limits_X^\infty x^{-1} \Delta_{1- 2 \sigma} (x) dx
  (I_\sigma (x, 2T)- I_\sigma (x, T) + \Gamma_\sigma (x, T)),
\end{align*}}
where, analogously as in the treatment of $\int_T^{2T} I_4 (t) dt$ in
Theorem \ref{c3:thm3.1}, 
{\fontsize{9pt}{11pt}\selectfont
\begin{align*}
  & I_\sigma (x, z)  = \int\limits_0^\infty \frac{z\sin (z \log
    (1+1/y)) \cos (2 \pi xy)}{y^\sigma (1+ y)^{1+ \sigma} \log^2 (1+
    1/y)} dy, \\
  & r_\sigma (x, T)  =  \int\limits_{0}^\infty \frac{\{ \cos (2T \log
    (1+ 1/y)) - \cos (T \log (1+ 1/y))\} \cos (2 \pi xy)(-c (y,
    \sigma))}{y^{\sigma (1+ y)^{1+ \sigma} \log^2 (1+ 1/y)}} dy. 
\end{align*}}

Then analogously as in the proof of Theorem \ref{c3:thm3.1} we write
$$
r_\sigma (x, T)= \int\limits_0^{3T} + \int\limits_{3T}^\infty = I' + I''
$$
and\pageoriginale show that, for some $c'>3T$,
\begin{align*}
  I'' & \ll T^2 \left| \int\limits_{3T}^{c'} \frac{\cos (2 \pi
    xy)}{y^\sigma (1+ y)^{1+ \sigma}} \left\{\sigma + \frac{2}{\log
      \left(1+ \frac{1}{y}\right)} - (2 \sigma -1)(1+y)
    \right\}dy\right|\\[5pt]
    & \ll T^2 TT^{-\sigma- \sigma -1}x^{-1} = T^{2- 2 \sigma} x^{-1}. 
\end{align*}

Since in mean square $\Delta_{1- 2\sigma}(x)$ is of the order
$x^{3/4}-\sigma$, we find that
\begin{multline*}
  \int\limits_X^\infty I'' x^{-1} \Delta_{1- 2\sigma} (x) dx \ll T^{2-
    2 \sigma} \left(\int\limits_X^\infty \Delta_{1- 2 \sigma}^2 (x)
  x^{-2} dx \right)^{1/2} \left(\int\limits_X^\infty x^{-2} dx
  \right)^{1/2}\\[5pt]
  \ll T^{2-2\sigma} (T^{-1} T^{3/2- 2\sigma})^{1/2}T^{-1/2} = T^{7/4-
    3 \sigma} \leq T^{3/4- \sigma} 
\end{multline*}
for $\sigma \geq 1/2$. Using Lemma \ref{c2:lem2.1} we also obtain $I'
\ll T^{3/4}-\sigma$.

The integral $I_{\sigma}(x, 2T)- I_\sigma(x, T)$ is evaluated by
using Lemma \ref{c2:lem2.3}. The remainder terms will be $\ll
T^{2-2\sigma}(T^{-1/4}x^{-5/4})+ T^{-1}x^{-1/2})$, and their total
  contribution will be (as in the previous case) $\ll
  T^{3/4-\sigma}$. Thus we shall obtain
\begin{multline*}
  i \int\limits_T^{2T} G_4 dt = O(T^{3/4-\sigma})- 2^\sigma
  \pi^{\sigma- 1/2} \int\limits_X^\infty \Delta_{1-2\sigma} (x)
  x^{\sigma-2}\\
  \left\{z^{3/2-\sigma} V^{-2}U^{-1/2} \left(U + \frac{1}{2}
  \right)^{-1} \sin \left(zV + 2 \pi xU- \pi x+
  \frac{\pi}{4}\right)\Bigg|_{z=T}^{2T}  \right\}dx.
\end{multline*}

From this point on the proof is very similar to the corresponding part
of the proof of Theorem \ref{c3:thm3.1}. Instead of the Voronoi
formula \eqref{c2:eq2.23} for $\Delta(x)$ we use the analogue
\eqref{c2:eq2.38} for $\Delta_{1- 2\sigma}(x)$. The main terms will be
the ones appearing in \eqref{c3:eq3.6}, and all the error terms will
be $\ll T^{3/4-\sigma}$. Finally one may derive the transformation
formulae for Dirichlet polynomials for $\sigma_{1- 2 \sigma}(n)$ by
the same technique used by M. Jutila \cite{Jutila3} in deriving the
transformation formulae for\pageoriginale Dirichlet polynomials
containing $d(n)$. In this way the proof of Theorem \ref{c3:thm3.2} is
completed.

\section{Omega-Results}\label{c3:sec3.2}

One of the principal uses of Theorem \ref{c3:thm3.1} and Theorem
\ref{c3:thm3.2} is to provide omega-results for $E(T)$, $E_\sigma(T)$
and $G_\sigma (T)$. We recall the common notation: $f(x) = \Omega
(g(x))$ as $x \to \infty$ means that $f(x) = o (g(x))$ does not hold,
$f(x) = \Omega_+ (g(x))$ means that there exists $C> 0$ and a sequence
$x_n$ tending to infinity such that $f(x_n)> Cg (x_n)$. Analogously,
$f(x) = \Omega_- (g(x))$ means that $f(y_n) < - Cg (y_n)$ for a
sequence $y_n$ tending to infinity, while $f(x) = \Omega_{\pm} (g(x))$
means that both $f(x)= \Omega_+ (g(x))$ and $f(x)= \Omega_- (g(x))$
hold. To obtain omega-results we shall work not directly with Theorem
\ref{c3:thm3.1}, but with a weaker version of it, contained in 

\begin{lemma}\label{c3:lem3.2}
  \begin{align}
    G(T) & = 2^{-1/4} \pi^{-3/4} T^{3/4} \sum_{n=1}^\infty (-1)^n d(n)
    n^{-5/4}\notag\\ 
    & \hspace{2cm}\sin (\sqrt{8 \pi nT}- \frac{\pi}{4})+ O(T^{2/3} \log
    T),\label{c3:eq3.28}\\
    G_\sigma (T) & = 2^{\sigma -3/4}\pi^{\sigma- 5/4}T^{5/4-\sigma}
    \sum_{n=1}^\infty (-1)^n \sigma_{1-2\sigma} (n) n^{\sigma- 7/4}\notag\\
    & \hspace{2cm}\sin \left(\sqrt{8 \pi n T}- \frac{\pi}{4}\right)+
    O\left(T^{1- \frac{2}{3}\sigma}\log T \right).\label{c3:eq3.29}
  \end{align}
\end{lemma}

\begin{proof}
  Both proofs are analogous, so we shall only sketch the proof of
  \eqref{c3:eq3.29}, using Theorem \ref{c3:thm3.2}, Trivially we have
  \begin{multline*}
    T^{1/2-\sigma} \sum_{n \leq N'} \sigma_{1-2 \sigma}(n)
    n^{\sigma-1} \left(\log \frac{T}{2 \pi n} \right)^{-2} \sin (g(T,
    n))\\
    \ll T^{1/2-\sigma}T^{\sigma} \log T = T^{1/2} \log T,
  \end{multline*}
and $\frac{1}{2} < 1 - \frac{2}{3} \sigma$ for $\sigma <
\frac{3}{4}$. Also $\frac{3}{4}- \sigma < 1- \frac{2}{3} \sigma$ and 
\begin{align*}
  & T^{1/2-\sigma} \sum_{T^{1/3} < n \leq N} (-1)^n \sigma_{1-2
    \sigma}(n) n^{\sigma-1} \left(ar \sinh \sqrt{\frac{\pi
      n}{2T}}\right)^{-2} \left(\frac{T}{2 \pi n}+ \frac{1}{4}
  \right)^{-1/4}\\
  & \hspace{9cm}\sin (f(T, n))\\
  & \ll T^{1/2 -\sigma} \sum_{T^{1/3}< n \leq N} d(n) n^{\sigma-1}
  \left(\frac{n}{T} \right)^{-1} \left(\frac{T}{n} \right)^{-1/4} \ll
  T^{5/4-\sigma} \sum_{n > T^{1/3}} d(n) n^{\sigma- 7/4}\\
  & \ll T^{5/4-\sigma}T^{(\sigma- 3/4)/3} \log T = T^{1-
    \frac{2}{3}\sigma} \log T.
\end{align*}
\end{proof}

Further\pageoriginale we have
{\fontsize{8}{10}\selectfont
\begin{align*}
  & 2^{\sigma-2}\pi^{\sigma-1/2}T^{1/2-\sigma} \sum_{n \leq T^{1/3}}
  (-1)^n \sigma_{1-2\sigma}(n) n^{\sigma-1} \left(ar \sinh
  \sqrt{\frac{\pi}{n}{2T}}\right)^{-2} \left(\frac{T}{2 \pi n}+
  \frac{1}{4}\right)^{-1/4} \sin (f(T, n))\\
  & =2^{\sigma-2} \pi^{\sigma -1/2}T^{1/2-\sigma} \sum_{n \leq T^{1/3}}
  (-1)^n \sigma_{1- 2 \sigma}(n) n^{\sigma-1} \left( \left( \frac{\pi
    n}{2T}\right)^{-1} + O \left( \left( \frac{n}{T}\right)^{1/2}
  \right)\right) \left(\frac{T}{2 \pi n} \right)^{-1/4}\\ 
  & \hspace{7cm}\left(1+ O
  \left(\frac{n}{T} \right) \right) \sin (f (T, n))\\
  & = 2^{\sigma-3/4} \pi^{\sigma-5/4} T^{5/4-\sigma} \sum_{n \leq
    T^{1/3}}(-1)^n \sigma_{1-2\sigma}(n) n^{\sigma-1}n^{-1 + 1/4} \sin
  (f(T, n))\\
  &\qquad + O\left( T^{1/2-\sigma} \sum_{n \leq T^{1/3}} d(n) n^{\sigma-1}
  \left(\frac{n}{T} \right)^{3/4} \right) + O \left(T^{1/2 -\sigma}
  \sum_{n \leq T^{1/3}} d(n) n^{\sigma-1} \left(\frac{n}{T}
  \right)^{1/4}\right)\\
  & = 2^{\sigma-3/4} \pi^{\sigma-5/4}T^{5/4-\sigma} \sum_{n \leq
    T^{1/3}} (-1)^n \sigma_{1-2 \sigma} (n) n^{\sigma-7/4} \sin (f(T,
  n)) + O \left(T^{1- \frac{2}{3}\sigma} \log T \right).
\end{align*}}

Finally, for $1\leq n \ll T^{1/3}$, we have by Taylor's formula
$$
f(T, n)= (8 \pi n T)^{1/2} - \frac{\pi}{4} + O\left(n^{3/2}T^{-1/2} \right),
$$
and the total contribution of the error term above will be
\begin{align*}
  & \ll T^{5/4-\sigma} \sum_{n \leq T^{1/3}} d(n) n^{\sigma-
    7/4}n^{3/2}T^{-1/2} = T^{3/4-\sigma} \sum_{n \leq T^{1/3}} d(n)
  n^{\sigma-1/4}\\
  & \ll T^{3/4-\sigma} \log T\cdot T^{(\sigma+ \frac{3}{4})/3}= T^{1-
    \frac{3}{2}\sigma} \log T.  
\end{align*}

Therefore\pageoriginale if we write
$$
\sum_{n \leq T^{1/3}} = \sum_{n=1}^\infty - \sum_{n > T^{1/3}}
$$
and estimate the last sum above trivially, we obtain
\eqref{c3:eq3.29}.

Observe now that $G_\sigma(t)$ is a continuous function of $t$ which
may be written as 
\begin{equation}
  G_\sigma (t)  = 2^{\sigma- 3/4} \pi^{\sigma-
    5/4}t^{5/4-\sigma}g_{\sigma}(t) + O \left(t^{1- \frac{2}{3}\sigma}
  \log t\right),\label{c3:eq3.30}
\end{equation}
where
{\fontsize{10pt}{12pt}\selectfont
\begin{equation}
  g_\sigma (t)  = \sum_{n=1}^\infty h(n) \sin \left(\sqrt{8 \pi n t}-
  \frac{\pi}{4}\right), h(n) = h_\sigma(n) = (-1)^n \sigma_{1-
    2\sigma} (n) n^{\sigma- \frac{7}{4}},\label{c3:eq3.31} 
\end{equation}}
and the series in \eqref{c3:eq3.31} is absolutely convergent for
$\sigma< 3/4$, which is of crucial importance. Namely, we shall first
deduce our omega-results from the following

\begin{lemma}\label{c3:lem3.3}
  If $g_\sigma(t)$ is defined by \eqref{c3:eq3.31}, then there exists
  a constant $C> 0$ such that, uniformly for $1 \ll G \leq T$, 
  \begin{equation}
    \int\limits_T^{T+G} g^2_\sigma(t) dt = CG + O
    (T^{1/2}). \label{c3:eq3.32} 
  \end{equation}
\end{lemma}

\begin{proof}
  By absolute convergence the series in \eqref{c3:eq3.31} may be
  squared and integrated termwise. Therefore the left-hand side of
  \eqref{c3:eq3.32} equals
  \begin{align}
    & \sum_{n=1}^\infty h^2 (n) \int\limits_T^{T+G}\sin^2 \left(\sqrt{8
      \pi n t}- \frac{\pi}{4} \right)dt\label{c3:eq3.33}\\
    &\qquad +O \left\{\sum_{m, n =1; m\neq n}^\infty |h(m) h(n)|\left|
    \int\limits_T^{T+G} \exp \left(i \sqrt{8 \pi nt}(\sqrt{m}\pm
    \sqrt{n})  \right)dt\right|  \right\}\notag
  \end{align}
\end{proof}

The\pageoriginale first integral in \eqref{c3:eq3.33} is 
$$
\frac{1}{2} \int\limits_T^{T+G} \left(1- \cos \left(\sqrt{32 \pi nt} -
\frac{\pi}{2} \right)\right) dt = \frac{1}{2} G + O \left(T^{1/2}
n^{-1/2} \right)
$$
uniformly in $G$ on applying Lemma \ref{c2:lem2.1}. Therefore
{\fontsize{10}{12}\selectfont
\begin{align*}
  \sum_{n=1}^{\infty} h^2 (n) \int\limits_T^{T+G} \sin^2 \left(\sqrt{8
  \pi n t}- \frac{\pi}{4} \right) & = \frac{1}{2} G \sum_{n=1}^\infty
  h^2 (n) + O \left(T^{1/2} \sum_{n=1}^\infty h^2 (n) n^{-1/2}\right)
  \\
  & = \frac{1}{2} G \sum_{n=1}^{\infty} \sigma_{1-2 \sigma}^2 (n) n^{2
  \sigma - 7/2}+ O(T^{1/2})
\end{align*}}
uniformly in $G$, and the last series above is absolutely convergent
and positive.

Also using Lemma \ref{c2:lem2.1} we obtain that the $O$-term
\eqref{c3:eq3.33} is, uniformly in $G$,
\begin{align*}
  & \ll T^{1/2} \sum_{m, n=1; 1 \leq n < m}^\infty m^{\sigma-7/4 +
    \epsilon}n^{\sigma- 7/4+ \epsilon} (m^{1/2}- n^{1/2})^{-1/2}\\
  & \ll T^{1/2} \sum_{n=1}^\infty n^{\sigma- 7/4+ \epsilon} \sum_{n <
    m \leq 2n} \frac{m^{\sigma- 7/4 +\epsilon + 1/2}}{m-n} \\
  & \qquad + T^{1/2} \sum_{n=1}^\infty n^{\sigma- 7/4+ \epsilon} \sum_{m >
    2n} \frac{m^{\sigma-7/4 + \epsilon + 1/2}}{m-n}\\
  & \ll T^{1/2} \sum_{n=1}^\infty n^{2 \sigma - 3 + 2 \epsilon} \log (n+1)
  + T^{1/2} \sum_{n=1}^\infty n^{\sigma- 7/4+ \epsilon} \sum_{m> 2n}
  m^{\sigma+ \epsilon - 9/4}\\
  & \ll T^{1/2} \sum_{n=1}^\infty n^{2 \sigma - 3 + 2 \epsilon} \log (n+1)
  + T^{1/2} \sum_{n=1}^\infty n^{2\sigma - 3 + 2 \epsilon}\ll T^{1/2}
\end{align*}
if $\epsilon > 0$ is sufficiently small, since $\sigma < 3/4$.

It follows from Lemma \ref{c3:lem3.2} that there exist two constants
$B, D> 0$ and a point $t_0 \in [T, T+ DT^{1/2}]$ such that $|g_\sigma
(t_0)|> B$ whenever $T\geq T_0$. However, it is not clear whether
$g_\sigma (t_0)$ is positive\pageoriginale or negative. The following
lemma shows that both positive and negative values of $g_\sigma (t)$
may occur.

\begin{lemma}\label{c3:lem3.4}
  If $g_\sigma (t)$ is given by \eqref{c3:eq3.31}, then there exist two constants
 $B,D > 0$ such that for $ T\geq T_0$ every interval $[T,T +
    DT^{1/2}]$ contains two points $ t_1$, $t_2$ for which 
  \begin{equation}
    g_\sigma (t_1) > B, g_\sigma(t_2) < -B.\label{c3:eq3.34}
  \end{equation}
\end{lemma}

\begin{proof}
  Both inequalities in  \eqref{c3:eq3.34} are proved analogously, so
  the details will be given only for the second one. Suppose that
  $g_\sigma(t) > - \epsilon$ for any given $\epsilon > 0$, and $t \in
  [T, T+ DT^{1/2}]$ for $T \geq  T_0 (\epsilon)$ and arbitrary $D> 0$. If
  $C_1, C_2, \ldots$ denote absolute, positive constants, then for
  $D$ sufficiently large and $G= DT^{1/2}$ we have from
  \eqref{c3:eq3.32}
  $$
  C_1 G \leq \int\limits_T^{T+G} g_\sigma^2 (t) dt = \sum_{k}
  \int\limits_{I_k} g_\sigma^2 (t) dt + \sum_{\ell}
  \int\limits_{J_\ell} g_\sigma^2 (t) dt,
  $$
  where $I'_k$s denote subintervals of $[T, T+ G]$ in which
  $g_\sigma(t) >0$, and the $J'_{\ell}$s subintervals in which
  $g_\sigma(t)< 0$. In each $J_\ell$ we have $g_\sigma^2 (t) <
  \epsilon$, and since
  $$
  |g_\sigma (t)| \leq \sum_{n=1}^\infty |h(n)|= \sum_{n=1}^\infty
  \sigma_{1- 2\sigma}(n) n^{\sigma - 7/4}= C_2,
  $$
  we have
  \begin{align*}
    C_G & \leq C_2 \sum_{k}\int\limits_{I_k} g_\sigma (t) dt + G
    \epsilon^2\\
    & = C_2 \int\limits_T^{T+G} g_\sigma (t) dt + C_2 \sum_{\ell}
    \int\limits_{J_\ell} (- g_\sigma (t)) dt + G \epsilon^2\\
    & \leq C_2 \int\limits_T^{T+G} g_\sigma (t) dt + C_2 G \epsilon +
    G \epsilon^2.
  \end{align*}

But using \eqref{c3:eq3.31} and Lemma \ref{c2:lem2.1} it follows that
\begin{align*}
  \int_{T}^{T+G} g_\sigma (t) dt & = \sum_{n=1}^\infty h(n)
  \int\limits_T^{T+G} \sin \left(\sqrt{8 \pi n t}-
  \frac{\pi}{4}\right) dt\\
  & \ll T^{1/2} \sum_{n=1}^\infty |h(n)|n^{-1/2} = C_3 T^{1/2},
\end{align*}
hence\pageoriginale 
\begin{equation}
  C_1 G \leq C_4 T^{1/2} + C_2 G \epsilon + G\epsilon^2.\label{c3:eq3.35}
\end{equation}

If we take $G= DT^{1/2}$, $D> C_4/C_1$ and $\epsilon$ sufficiently
small, then \eqref{c3:eq3.35} gives a contradiction which proves the
second inequality in \eqref{c3:eq3.34}, and the first one is proved
similarly. 
\end{proof}

Now we turn to \eqref{c3:eq3.30} and observe that $\frac{5}{4} - \sigma
> 1 - \frac{2}{3}\sigma$ for $\frac{1}{2} \leq \sigma <
\frac{3}{4}$. Therefore, by continuity, Lemma \ref{c3:lem3.4} yields
the following proposition ($B, D, t_1, t_2$ are not necessarily the
same as in Lemma \ref{c3:lem3.4}): There exist two positive constants
$B$ and $D$ such that for $T \geq T_0$ every interval $[T, T+
  DT^{1/2}]$ contains two points $t_1, t_2$ for which $G_\sigma (t_1)
> B t_1^{5/4-\sigma}$, $G_\sigma (t_2) 
< - B t_2^{5/4-\sigma}$. By continuity, this also implies that there
is a zero $t_3$ of $G_\sigma(t)$ in $[T, T+ DT^{1/2}]$.

Next consider for $H> 0$
\begin{equation}
  G_\sigma (T+ H) - G_\sigma (T) = \int\limits_T^{T+H} (E_\sigma (t) -
  B(\sigma))dt.\label{c3:eq3.36}
\end{equation}

Let $T$ be a zero of $G_\sigma(T)$, and let $H$ be chosen in such a
way that $G_\sigma (T+ H)> B(T+ H)^{5/4-\sigma}$. By the preceding
discussion we may take $H \leq FT^{1/2}$ with suitable $F> 0$. then
\eqref{c3:eq3.36} gives
$$
B(T + H)^{5/4-\sigma} < \int\limits_T^{T+H} (E_\sigma(t) -
B(\sigma))dt = H(E_\sigma (t_4) - B(\sigma))
$$ 
for some $t_4 \in [T, T+ H]$ by the mean value theorem for
integrals. Therefore 
$$
E_\sigma (t_4) > Ct_4^{3/4-\sigma}
$$
with\pageoriginale a suitable $C>0$, and similarly we obtain
$$
E_\sigma (t_5) < -C t_5^{3/4-\sigma}
$$
with $t_4, t_5 \in [T, T+ FT^{1/2}]$. the foregoing analysis may be
repeated, by virtue of \eqref{c3:eq3.28}, with $G(T)$ in place of
$G_\sigma (T)$ (in \eqref{c3:eq3.31} we shall have $h(n) = (-1)^n d(n)
n^{-5/4}$). In this way we are led to our first omega-result, which is 

\begin{thm}\label{c3:thm3.3}
  There exist constants $B, D> 0$ such that for $T \geq T_0$ every
  interval $[T, T + DT^{1/2}]$ contains points $t_1, t_2, t_3, t_4
  \tau_1, \tau_2, \tau_3, \tau_4$ such that
  \begin{align}
    & E(t_1) > Bt_1^{1/4}, E(t_2) < - Bt_2^{1/4}, G(t_3) > B t_3^{3/4},
    G(t_4)< -Bt_4^{3/4}, \label{c3:eq3.37}\\
    & E_\sigma (\tau_1)  > B \tau_1^{3/4-\sigma}, E_\sigma (\tau_2)< -B
    \tau_2^{3/4-\sigma},\label{c3:eq3.38}\\
    & G_\sigma (\tau_3) > B \tau_3^{5/4-\sigma}, G_\sigma (\tau_4) < -
    B \tau_4^{5/4-\sigma}.\notag
  \end{align}
\end{thm}

Since $G(T)= O(T^{3/4})$, $G_\sigma (T)= O(T^{5/4-\sigma})$ by
\eqref{c3:eq3.28} and \eqref{c3:eq3.29}, this means that we have
proved
\begin{align}
  G(T) = O(T^{3/4}), G(T) & = \Omega_{\pm}(T^{3/4}), G_\sigma (T) = )
  (T^{5/4-\sigma}),\notag \\
   G_\sigma (T) &= \Omega_\pm (T^{5/4-\sigma})\label{c3:eq3.39}
\end{align}
and also
\begin{equation}
  E(T) = \Omega_\pm (T^{1/4}), E_\sigma (T) = \Omega_\pm
  (T^{3/4-\sigma}).\label{c3:eq3.40} 
\end{equation}

Thus \eqref{c3:eq3.39} shows that, up to the values of the numerical
constants involved, we have determined the true order of magnitude of
$G(T)$ and $G_\sigma (T)$. Moreover, not only does Theorem
\ref{c3:thm3.3} provide $\Omega_\pm$-results for the values where
these functions attain large positive and small negative values,
respectively. As mentioned in Section \ref{c2:sec2.6}, the mean square
formulas \eqref{c2:eq2.69} and \eqref{c2:eq2.71} provide weak
omega-results, namely
$$
E(T) = \Omega (T^{1/4}), E_\sigma (T) = \Omega (T^{3/4-\sigma}),
$$
which\pageoriginale are superseded by \eqref{c3:eq3.40}. One can, of
course, try to go further and sharpen \eqref{c3:eq3.40} by using
special properties (arithmetical structure) of the functions $d(n)$
and $\sigma_{1- 2 \sigma}(n)$ appearing in \eqref{c3:eq3.28} and
\eqref{c3:eq3.29}, respectively. As already mentioned in Chapter \ref{c2},
there are several deep analogies between $E(T)$ and $\Delta(x)$. Even
the formula \eqref{c3:eq3.28} has its counterpart in the theory of
$\Delta(x)$, namely
$$
\int\limits_2^T \Delta(t) dt = \frac{T}{4} + \frac{T^{3/4}}{2
  \sqrt{2}\pi^2} \sum_{n=1}^\infty d(n) n^{-5/4} \sin \left(4 \pi \sqrt{n
  T}- \frac{\pi}{4}\right) + O(1),
$$
which is a classical formula of G.F. Voronoi. For $\Delta(x)$ the best
known omega-results are
\begin{equation}
  \Delta(T) = \Omega_+ \left\{(T \log T)^{1/4} (\log \log T)^{1/4(3+
    \log 4)}e^{- C\sqrt{\log \log \log T}} \right\}\label{c3:eq3.41}
\end{equation}
and 
\begin{equation}
  \Delta (T) = \Omega_- \left\{T^{1/4} \exp \left(\frac{D(\log \log
    T)^{1/4}}{(\log \log \log T)^{3/4}} \right) \right\}, \label{c3:eq3.42}
\end{equation}
due to J.L. Hafner \cite{Hafner1} and K. Corr\'adi - I. K\'atai \cite{Corradi and Katai1},
where $C, D > 0$ are absolute constants. The corresponding problems
involving $\Delta_{1- 2 \sigma}(x)$ may be also considered, but it
seems appropriate to make the following remark here. The arithmetical
function $\sigma_{1- 2 \sigma}(n)$, which by \eqref{c2:eq2.37} and
\eqref{c2:eq2.41} has the mean value $\zeta(2 \sigma)$, is much more
regularly distributed than $d(n)$, whose average order is $\log
n$. For this reason sharp omega-results for $\sigma_{1- 2 \sigma}(n)$
are harder to obtain than sharp omega-results for $d(n)$,  since for
the latter one somehow tries to exploit the irregularities of
distribution of $d(n)$. Observe that in \eqref{c3:eq3.28} there is the
factor $(-1)^n$, which is not present in the above Voronoi formula for
$\int\limits_2^{T} \Delta(t) dt$. It was thought by many that the
oscillating factor $(-1)^n$, present already in
Atkinson's\pageoriginale formula \eqref{c2:eq2.5} for $E(T)$, would
hinder the possibility of obtaining sharp $\Omega_{\pm}$-results for
$E(T)$ analogous to \eqref{c3:eq3.41} and \eqref{c3:eq3.42}. The
theorem that follows shows that this is not the case, and that
\eqref{c3:eq3.28} is in fact strong enough to render (when suitable
techniques are applied to it) the analogues of \eqref{c3:eq3.41} and
\eqref{c3:eq3.42}. In the casee of $E_\sigma(T)$ we would have to cope
with the regularity of distribution of $\sigma_{1- 2\sigma}(n)$, and
the presence of the oscillating factor $(-1)^n$. For this reason we
shall content ourselves only with sharp omega-results for $E(T)$,
contained in 

\begin{thm}\label{c3:thm3.4}
  There exist absolute constants $C, D> 0$ such that 
{\fontsize{10pt}{12pt}\selectfont
  \begin{equation}
    E(T) = \Omega_{+} \left\{(T \log T)^{1/4} (\log \log T)^{1/4} (3
    + \log 4) e^{- C\sqrt{\log \log \log T}} \right\}\label{c3:eq3.43}
  \end{equation}}
  and 
  \begin{equation}
    E(T) = \Omega_{-} \left\{T^{1/4} \exp \left(\frac{D(\log \log
      T)^{1/4}}{(\log \log \log T)^{3/4}} \right) \right\}.\label{c3:eq3.44}
  \end{equation}
\end{thm}

These formulas are the exact analogues of \eqref{c3:eq3.41} and
\eqref{c3:eq3.42}. Since the problem of $\Omega_\pm$-results for
$\Delta(x)$ is certainly not more difficult than the corresponding
problem for $E(T)$ (the Voronoi formula for $\Delta(x)$ is simpler and
sharper than Atkinson's formula for $E(T)$ or any of its variants), it
is hard to imagine improvements of \eqref{c3:eq3.43} and
\eqref{c3:eq3.44} which would come from methods not capable of
improving \eqref{c3:eq3.41} and \eqref{c3:eq3.42}. On the other hand,
although \eqref{c3:eq3.43} and \eqref{c3:eq3.44} are such sharper than
just $E(T) = \Omega_\pm (T^{1/4})$, which follows from Theorem
\ref{c3:thm3.3}, one does not obtain in the proof of Theorem
\ref{c3:thm3.4} the localization of points where large positive and
small negative values of $E(T)$ are taken (or to be precise, the
localization will be very poor). Theorem \ref{c3:thm3.3} provides good localization, and thus the omega-results furnished by Theorem \ref{c3:thm3.3} and Theorem \ref{c3:thm3.4} both have their merits and are in a certain sense complementary to one another.

\medskip
\noindent{\textbf{Proof of Theorem 3.4.}}  First\pageoriginale we prove the
$\Omega_+$-result \eqref{c3:eq3.43}.  Let
\begin{equation}
  E^* (t) : = \int\limits_{-1}^1 E_0 (t+u) k_M (u) du, E_0 (t) : = (2
  t)^{-1/2} e(2 \pi t^2),\label{c3:eq3.45}
\end{equation}
 where $E_0$ is introduced because it is more convenient to work
 without square roots in Atkinson's formula. Further let
\begin{equation}
  k_n (u) = K_{1/2\lambda_n} (u) : = \frac{\lambda_n}{2 \pi}
  \left(\frac{\sin (1/2 \lambda_n u)}{1/2 \lambda_n u} \right)^2 \quad
  (\lambda_n = 4 \pi \sqrt{n})
\end{equation}
be the Fej\'er kernel of index $1/2 \lambda_n$, and $M$ is a large
positive integer. Because
$$
k_M (u) > 0, 0 < \int\limits_{-1}^1 k_M (u) du < 1,
$$
\eqref{c3:eq3.43} is a consequence of the following assertion: there
exist absolute, positive constants $A$ and $C$ such that
\begin{equation}
  E^* (t) > A (\log t)^{1/4} (\log \log t)^{1/4(3 + \log 4)} e^{-
    C\sqrt{\log \log \log t}}\label{c3:eq3.47}
\end{equation}
for some arbitrarily large values of $t$. To prove \eqref{c3:eq3.47}
we shall show that, uniformly for $1 \leq M \leq t^{1/2}$, 
{\fontsize{10pt}{12pt}\selectfont
\begin{equation}
  E^* (t) = \sum_{n \leq M} (-1)^n d)n) n^{-3/4} \left(1- \left(
  \frac{n}{M}\right)^{1/2} \right) \cos \left(4 \pi \sqrt{n} t-
  \frac{\pi}{4} \right)  + o(1) \label{c3:eq3.48}
\end{equation}}
and then deduce \eqref{c3:eq3.47} from \eqref{c3:eq3.48}. To this end
let
$$
f(t) : = 2^{-1/2}t^{3/2} \int\limits_2^t (E (2 \pi y^2)- \pi)y\, dy,
$$
so that by \eqref{c3:eq3.28} we obtain
\begin{equation}
  f(t) = \frac{1}{4 \pi} \sum_{n=1}^\infty (-1)^n d(n) n^{-5/4} \sin
  (\lambda_n t - \frac{\pi}{4})+ o(1),\label{c3:eq3.49}
\end{equation}
and by direct computation we find that
\begin{equation}
  E_0 (t) = \frac{d}{dt} f(t) + o(t^{-1/2}).\label{c3:eq3.50}
\end{equation}

Using\pageoriginale \eqref{c3:eq3.50} in \eqref{c3:eq3.45},
integrating by parts, and then using \eqref{c3:eq3.49} we obtain,
uniformly for $1 \leq M \leq t^{1/2}$,
\begin{align*}
  E^* (t) & = - \int\limits_{-1}^1 f(t+u) k'_M (u) du + o(1)\\
  & = - \frac{1}{4 \pi} \sum_{n=1}^\infty (-1)^n d(n) n^{-5/4} \im
  \left\{e^{i (\lambda_n t- \frac{\pi}{4})} \int\limits_{-1}^1 e^{i
    \lambda_n u} k'_M (u) du \right\} + o(1).
\end{align*}

The last integral is readily evaluated as 
$$ 
\int\limits_{-1}^1 e^{i \lambda_n u} k'_M(u) du= 
\begin{cases} 
  - i \lambda_n \left(1- \frac{\lambda_n}{\lambda_n}\right) + o(1) &
  \text{if}~ n \leq M,\\
  o(1) & \text{if}~ n > M,
\end{cases}
$$
and \eqref{c3:eq3.48} follows.

To take advantage of \eqref{c3:eq3.48} we need some facts about sums
involving the divisor function, which reflect the irregularities of
its distribution. This is 

\begin{lemma}\label{c3:lem3.5}
  For each positive constant $C$ and positive integer $K \geq 2$,
  there is a set $P_C \subseteq \{1, 2, \ldots K\}$ such that
  uniformly
  $$
  \sum_{n \notin P_C, n \leq K} d(n) n^{-3/4} \ll C^{-2} K^{1/4} \log K,
  $$
  and if $|P_C|$ denotes the cardinality of $P_C$, then 
  $$
  |P_C| \ll K(\log K)^{1- \log 4} \exp \left(C\sqrt{\log \log K} \right).
  $$
\end{lemma}

\begin{proof}
  First we show that
  \begin{equation}
    \sum_{n \leq x} d(n) (\omega (n)- 2 \log \log x)^2 \ll x \log\, x
    \log\, \log x,\label{c3:eq3.51} 
  \end{equation}
  where as usual $\omega (n)$ denotes the number of distinct prime
  factors of\pageoriginale $n$. To obtain \eqref{c3:eq3.51} note that
  if $p, q$ are primes, then 
  \begin{align*}
    d (np) & = 2d (n) - d \left(\frac{n}{p} \right)\\
    \intertext{and}
    d(n pq) & = 4 d(n) - 2d\left(\frac{n}{p} \right)- 2d
    \left(\frac{n}{q}\right)+ d\left(\frac{n}{pq} \right),
  \end{align*}
  where we put $d(x) =0$ if $x$ is not an integer. Then, for distinct
  primes $p, q$ we obtain
  \begin{align*}
    & \sum_{n \leq x} d(n) \omega^2 (n)= \sum_{pq \leq x, p \neq q}\\
    & \Bigg\{ 4 \sum{n \leq x/pq} d(n) -2 \sum_{n \leq x/p^2 q} d(n) -2
    \sum_{n \leq x/p \, q^2} d(n)\sum_{n \leq x p^2 q^2} d(n)
    \Bigg\}\\ 
    & \hspace{4.8cm}+ \sum_{p \leq x} \Bigg\{
    2 \sum_{n \leq x/p} d(n) - \sum_{n \leq x/p^2} d(n)\Bigg\}\\
    & = 4 \sum_{pq \leq x} \frac{x}{pq} \log \frac{x}{pq} + o(x \log x
    \log \, \log x)\\
    & = 4 x \log x (\log \log x)^2 + o(x \log x \log \, \log x). 
  \end{align*}
\end{proof}

In a similar fashion it may be shown that
$$
\sum_{n \leq x} d(n) \omega(n) = 2 x \log x \log \, \log x+ o(x \log x),
$$
and \eqref{c3:eq3.51} follows. Let now
$$
P_C = \left\{n \leq K: \omega(n) \geq 2 \log log K - C\sqrt{\log \log
  K} \right\}. 
$$

By using $d(n) \geq 2^{\omega(n)}$ it follows that
$$
|P_C| 2^{2 \log \log K- C\sqrt{\log \log K}} \leq \sum_{n \in P_C}
2^{\omega (n)} \leq \sum_{n \leq K} d(n) \ll K\log K,
$$
as asserted. Also, using \eqref{c3:eq3.51} and partial summation we
find that
\begin{align*}
  \sum_{n \notin P_C} d(n) n^{-3/4} & \leq (C^2 \log \log K)^{-1}
  \sum_{n \notin P_C} d(n) n^{- 3/4} (\omega(n) - 2 \log \log K)^2\\
  & \leq (C^2 \log \log K)^{-1} \sum_{n \leq K} d(n) n^{-3/4}
  (\omega(n)- 2 \log \log K)^2\\
  & \ll C^{-2} K^{1/4} \log K.
\end{align*}

Now\pageoriginale let $K = [M/2]$ and let $P_C$ be as in Lemma
\ref{c3:lem3.5} for this $K$ and some $C$ to be chosen later. By
Dirichlet's approximation theorem there exists $t$ satisfying
$$
M^2 \leq t \leq M^2 64^{|P_C|}
$$
and such that for each $m$ in $P_C$ and $n= 2 m$ we have $|t\sqrt{n} -
x_n| \leq \frac{1}{64}$ for some integers $x_n$. For these $n$ and
this $t$ it follows that 
$$
\cos \left(4 \pi t \sqrt{n}- \frac{\pi}{4}\right) \geq \cos
\left(\frac{\pi}{16} + \frac{\pi}{4} \right) > \frac{1}{2}.
$$

Note that each pair $M,t$ constructed in this way satisfies $1 \leq M
\leq t^{1/2}$. For this pair \eqref{c3:eq3.48} gives
{\fontsize{10}{12}\selectfont
\begin{align*}
  E^* (t) & = \left\{ \frac{1}{2} \sum_{\substack{n \leq M, n = 2m\\m
      \in P_C}} - \sum_{\substack{n \notin M, n= 2m\\m \neq P_C}} -
  \sum_{n \leq M, n= 2m+1}\right\} d(n) n^{-3/4} \left(1-
  \left(\frac{n}{m} \right)^{1/2} \right) + o(1)\\
  & = \left\{\frac{1}{2} \sum_{n \leq M} - \frac{3}{2} \sum_{\substack{n
  \leq M, n=2m\\ m \notin P_C}} - \frac{3}{2} \sum_{n \leq M, n=2m+1}
  \right\} d(n) n^{-3/4} \left(1- \left(\frac{n}{m} \right)^{1/2}
  \right)+ o(1).
\end{align*}}

But we have elementarily
$$ 
\sum_{n \leq x, n = 2m} d(n) = \frac{3}{4} x \log x + O (x), \sum_{n \leq
x, n=2m+1} d(n) = \frac{1}{4} x \log x + O (x),
$$
hence by partial summation
\begin{align*}
  \sum_{n \leq M} d(n) n^{-3/4} \left(1- \left(\frac{n}{M} \right)^{1/2}
  \right) & = \frac{8}{3} M^{1/4} \log M + O(M^{1/4})\\
  \intertext{and }
  \sum_{n \leq M, n=2 m+1} d(n) n^{-3/4} \left(1- \left(\frac{n}{M}
  \right)^{1/2} \right) &= \frac{2}{3} M^{1/4} \log M + O(M^{1/4}).
\end{align*}

With\pageoriginale these formulas and Lemma \eqref{c3:eq3.5} we obtain
for this pair $t$, $M$ and $C$ sufficiently large that
\begin{equation}
  E^* (t) \geq \left(\frac{1}{3} + O(C^{-2}) \right) M^{1/4} \log M
  \geq \frac{1}{4} M^{1/4} \log M.\label{c3:eq3.52}
\end{equation}

Note that from $t \leq M^2 64^{|P_C|}$ and the second part of Lemma
\eqref{c3:eq3.5} we obtain
\begin{equation}
  M \gg \log t (\log \log t)^{\log 4-1} \exp \left( -C\sqrt{\log \log
    \log t} \right)\label{c3:eq3.53}
\end{equation}
for some (perhaps different) constant $C > 0$. Combining
\eqref{c3:eq3.52} and \eqref{c3:eq3.53} it is seen that
\eqref{c3:eq3.47} holds, and so \eqref{c3:eq3.43} is proved.

We proceed now to the proof of the $\Omega$-result \eqref{c3:eq3.44},
using again \eqref{c3:eq3.28} as our starting point. First we are
going to prove a weaker $\Omega$-result, namely
\begin{equation}
  \liminf_{T \to \infty} E(T) T^{-1/4} = -
  \infty.\label{c3:eq3.54} 
\end{equation}

This result will be then used in deriving the stronger
$\Omega_-$-result given by \eqref{c3:eq3.44}. To prove
\eqref{c3:eq3.54} it suffices to show that 
\begin{equation}
  \liminf_{T \to \infty} E^*(T)  = -
  \infty,\label{c3:eq3.55}   
\end{equation}
where $E^* (T)$ is defined by \eqref{c3:eq3.45}. Write each $n \leq M$
in \eqref{c3:eq3.48} as $n= \nu^2 q$, where $q$ is the largest
squarefree divisor of $n$. By Kronecker's approximation theorem there
exist arbitrarily large $T$ such that
$$
T\sqrt{q} = 
\begin{cases}
  m_q + \delta_q & \text{if}~ q ~\text{is odd},\\
  \frac{1}{4} + n_q + \delta_q & \text{if}~ q ~\text{is even},
\end{cases}
$$
with some integers $m_q$ and $|\delta_q|< \delta$ for any given
$\delta> 0$. With these\pageoriginale $T$ we conclude that
$$
(-1)^n \cos \left(4 \pi T \sqrt{n} - \frac{\pi}{4}\right) =
-\epsilon_n  \cos \left( \frac{\pi}{4}\right) + O(\sqrt{n} \delta),
$$
where
$$
\epsilon_n = 
\begin{cases}
  -1 & \text{if}~ n \equiv 0 \pmod{4}.\\
  1 & \text{if}~ n \nequiv 0 \pmod{4}.
\end{cases}
$$

We deduce from \eqref{c3:eq3.48} that
{\fontsize{9}{11}\selectfont
\begin{equation}
  \liminf_{T \to \infty} E^* (T) \leq - \cos \left(\frac{\pi}{4}
  \right) \sum_{n \leq M} \epsilon_n d(n) n^{-3/4} \left(1-
  \left(\frac{n}{M} \right)^{1/2} \right)  + O(\delta M^{3/4} \log
  M).\label{c3:eq3.56} 
\end{equation}}

On letting $\delta \to 0$ we obtain \eqref{c3:eq3.55}, since the sum
in \eqref{c3:eq3.56} can be shown elementarily to be unbounded as $M
\to \infty$.

Now we pass to the actual proof of \eqref{c3:eq3.44} by using a
variant of a technique of K.S. Gangadharan \cite{Gangadharan1}. Let $P_x$ be the
set of odd primes $\leq x$, and $Q_x$ the set of squarefree numbers
composed of primes from $P_x$. Let $|P_x|$ be the cardinality of $P_x$
and $M= 2^{|P_x|}$ the cardinality of $Q_x$. Then we have
\begin{equation}
  \frac{x}{\log x} \ll |P_x| \ll \frac{x}{\log x},\quad M\ll \exp
  \left(\frac{cx}{\log x} \right)\label{c3:eq3.57}
\end{equation}
for some $c > 0$, and also that all elements in $Q_x$ do not exceed
$e^{2x}$. 

Now let $S_x$ be the set of numbers defined by 
$$
S_x = \left\{\mu = \sum_{q \in Q_x} r_q \sqrt{q} : r_q \in \{ -1, 0,
1\}; \sum r_q^2 \geq 2 \right\},
$$
and finally
$$
\tilde{\eta} (x) = \inf \left\{|\sqrt{m} + \mu| : m = 1, 2, \ldots; \mu
\in S_x\right\}.
$$

Taking $m= [\sum\sqrt{q}]^2$ it is seen that $|\sqrt{m} - \sum
\sqrt{q}|< 1$, hence $\tilde{\eta} (x) < 1$. Also there are only
finitely many distinct values of $|\sqrt{m} + \mu|$\pageoriginale in
(0,1). Then one has (see Gangadharan \cite{Gangadharan1}):

\begin{lemma}\label{c3:lem3.6}
  If $q(x)=- \log \tilde{\eta}(x)$, then for some $c>0$
  $$
  x \leq q(x) \ll \exp \left(\frac{cx}{\log x} \right). 
  $$
\end{lemma}

Similarly as in the proof of \eqref{c3:eq3.43} we avoid square roots
by introducing the functions
\begin{equation}
  \tilde{E} (t) = \sqrt{2 \pi} \left\{E \left(\frac{t^2}{8 \pi}
  \right)- \pi  \right\}, E_+ (T) = \int\limits_0^T t\tilde{E} (t)
  dt.\label{c3:eq3.58} 
\end{equation}

From \eqref{c3:eq3.28} we have then 
{\fontsize{10pt}{12pt}\selectfont
\begin{equation}
  E_+ (T) = T^{3/2} \sum_{n=1}^\infty (-1)^n d(n) n^{-5/4} \sin
  \left(T\sqrt{n} - \frac{\pi}{4}\right) + O(T^{4/3} \log
  T).\label{c3:eq3.59} 
\end{equation}}

If we could differentiate this series (and the O-term) we could deal
with $E(T)$ directly. This is not possible, but we can use integration
by parts in subsequent integrals that appear to take advantage of
\eqref{c3:eq3.59}.

We let
$$
P(x) = \exp \left(\frac{\alpha x}{\log x} \right)
$$ 
be such that 
\begin{equation}
  P(x) \geq \max (q (x), M^2) \label{c3:eq3.60}
\end{equation}
and define, for a fixed $x$,
\begin{equation}
  \gamma_x = \sup_{u > 0} \left\{\frac{- \sqrt{2 \pi} E (u^2 /(8
    \pi))}{u^{1/2 +1/P(x)}}\right\}.\label{c3:eq3.61}
\end{equation}

Now for $T\to 0+$, $E(T) \sim - T \log T$, so that the expression in
brackets in \eqref{c3:eq3.61} is bounded for small $u$. If this
expression is not bounded for all $u$ then more than \eqref{c3:eq3.44}
would be true. Also, by our earlier $\Omega_-$-result
\eqref{c3:eq3.54} there exists a $u > 0$ for which this expression is
positive. Hence we can conclude that $0 < \gamma_x < \infty$, or, in
other words,
$$
\gamma_x u^{1/2+1/P(x)} + A + \tilde{E} (u) \geq 0
$$
for\pageoriginale all $u>0$, where $A = \sqrt{2} \pi^{3/2}$.

Our next step is to describe the part of the kernel function we use to
isolate certain terms of the ``series'' for $E(u)$, and to point them
in an appropriate direction. Let
$$
V(z) = 2 \cos ^2 \frac{z}{2} = =\frac{e^{iz}+ e^{-iz}}{2} +1
$$
and set
$$
T_x (u) = \prod_{q \in Q_x} V \left(u\sqrt{q} - \frac{5 \pi}{4} \right).
$$

Note that $T_x (u) \geq 0$ for all $u$. Finally, put $\sigma_x =
\exp(- 2P(x))$ and 
\begin{equation}
  J_x : = \sigma_x^{5/2} \int\limits_0^\infty \left(\gamma_x
  u^{1/2+1/P(x)} + A+ \tilde{E} (u) \right) u e^{- \sigma_x u} T_x (u)
  du.\label{c3:eq3.62} 
\end{equation}

From the remarks above we see immediately that $J_x \geq 0$. In the
next two lemmas we provide the tools for an asymptotic expansion for
$J_x$. In the first we cover the first two terms of $J_x$.

\begin{lemma}\label{c3:lem3.7}
  For $\frac{1}{2} < \theta < 2$ and $x \to \infty$ we have 
  $$
  \int\limits_0^\infty u^\theta e^{- \sigma_x u} T_x (u) du =
  \sigma_x^{-1- \theta} \Gamma (1+ \theta) + o (\sigma_x^{-5/2}).
  $$
\end{lemma}

\begin{proof}
  We expand the trigonometric polynomial $T_x (u)$ into exponential
  polynomials as
  $$
  T_x (u) = T_0 + T_1 + \ob{T}_1 + T_2,
  $$
  where 
  $$
  T_0 =1, T_1= \frac{1}{2} e^{1/4 (5 \pi)} \sum_{q \in QW_x} e^{- iu
    \sqrt{q}}, T_2 = \sum_{\mu \in S_x} h_{\mu} e^{-i u \mu},
  $$
  $\ob{T}_1$ is the complex conjugate of $T_1$, and $h_\mu$ are
  constants bounded by $1/4$ in absolute value.
\end{proof}

Note that $T_0$ contributes to the integral exactly the first term, so
that we have to consider the other parts of $T_x$. The part $T_1$
contributes exactly
$$
\frac{1}{2} e^{1/4 (5 \pi)i} \Gamma (1+ \theta) \sum_{q \in Q_x}
(\sigma_x + i \sqrt{q})^{-1-\theta} \ll \sum_{q \in Q_x} q^{- 1/2
  (1+\theta)} \ll M= o \left(\sigma^{-5/2}_{x} \right) 
$$
since\pageoriginale $\theta + 1 > 0$ and \eqref{c3:eq3.60} holds. The contribution
of $\ob{T}_1$ is likewise $o(\sigma_x^{-5/2})$, and $T_2$ provides
the term
\begin{align*}
&  \Gamma (1+ \theta) \sum_{\mu} h_\mu (\sigma_x + iu)^{-1-\theta}. \ll
  3^M \left(\inf\limits_{\mu \in S_x} |\mu|\right)^{-1-\theta} \ll 3^M
  \tilde{\eta} (x)^{-1-\theta}\\  
&\qquad  = \exp \left\{ c\sqrt{P(x)} + P(x) (1+ \theta)\right\} =
  o\left(\sigma_x^{-5/2} \right),
\end{align*}
again by \eqref{c3:eq3.60} and the fact that $1+ \theta < 3$.

In the next lemma we cover the contribution to $J_x$ from
$\tilde{E}(U)$. It is here that we appeal to the identity
\eqref{c3:eq3.59} for $E_+ (T)$.

\begin{lemma}\label{c3:lem3.8}
  For $x \to \infty$ we have
  $$
  \int\limits_0^\infty \tilde{E} (u) u e^{-\sigma_x u} T_x (u) du=
  -\frac{1}{2} \Gamma \left(\frac{5}{2} \right) \sigma_x^{-5/2}
  \sum_{q \in Q_x} d(q) q^{-3/4} + o(\sigma^{-5/2}_x).
  $$
\end{lemma}

\begin{proof}
  Or first step is to integrate by parts to introduce $E_+ (T)$ in the
  integral so that we can use \eqref{c3:eq3.59}. Thus our integral can
  be written as
  $$
  E_+ (u) e^{-\sigma_xu} T_x (u) \Bigg|_0^\infty - \int\limits_0^\infty
  E_+ (u) \frac{d}{du} \left(e^{-\sigma_xu}T_x(u) \right)du.
  $$
  Now since
  $$
  E_+ (u) = 
  \begin{cases}
    O(u^2) & \text{if}~ O \leq u \leq 10,\\
    O(u^{3/2}) & \text{if}~ u \geq 10,
  \end{cases}
  $$
  the integrated terms vanish. In the remaining integral we wish to
  replace $E_+ (u)$ by \eqref{c3:eq3.59}. However, we must be careful
  how we deal with the error term. Write the integral in question as
  \begin{multline*}
  - \int\limits_0^\infty h(u) u^{3/2} \frac{d}{du} \left(e^{-\sigma_x
    u} T_x (u) \right) du + O\left(\int\limits_{10}^\infty u^{4/3}
  \log u \left| \frac{d}{du} (\ldots)\right|du  \right)\\
  + \int\limits_0^{10} h(u) u^{3/2} \frac{d}{du} (\ldots)du +
  O\left(\int_0^{10} u^2 \left|\frac{d}{du} (\ldots ) \right|du
  \right)\\
  = I_1 + O(I_2) + I_3 + O(I_4),
  \end{multline*}
  say,\pageoriginale where $h(u)$ is defined by
  $$
  h(u) = \sum_{n=1}^\infty (-1)^n d(n) n^{-5/4} \sin \left(u \sqrt{n} -
  \frac{\pi}{4}\right). 
  $$
\end{proof}

The integral $I_3$ is bounded by
$$
I'_3 = \int\limits_0^{10} u^{3/2} \left| \frac{d}{du} (\ldots)\right|du,
$$
and this dominates the last integral $I_4$. Hence, we should estimate
$I'_3$ and $I_2$ and calculate $I_1$.

For the two integral estimates, we need a bound on the expression in
absolute values. For this we note that from the definition and from
the decomposition used in the proof of Lemma \ref{c3:lem3.7} we have 
$$
T_x (u) \ll 2^M, T'_x (u) \ll 3^M M e^{cx},
$$
so that
$$
\frac{d}{du} \left(e^{-\sigma_x u} T_x(u) \right) \ll \quad 
e^{- \sigma_x u}4^M.
$$

In $I'_3$ this contributes at most
$$ 
4^M \int\limits_0^{10} u^{-1/2} du \ll e c\sqrt{P(x)} =
O(\sigma_x^{-5/2}). 
$$

In $I_2$ the estimate becomes
$$
4^M \int\limits_{10}^\infty u^{4/3}e^{-\sigma_x u} \log u\, du \ll
e^{\sqrt{P(x)}} \sigma_x^{-7/3-\epsilon} = O(\sigma_x^{-5/2}).
$$

For $I_1$ we expand the expression $\frac{d}{du} (\ldots)$ as
$$
u^{-3/2} \frac{d}{du} (u^{3/2} e^{-\sigma_x u} T_x (u)) - \frac{3}{2}
u^{-1} e^{-\sigma_x u} T_x (u).
$$

The last term contributes to $I_1$ at most (since $h(u)$ is bounded)
$$
2^M \int\limits_0^\infty u^{1/2} e^{-\sigma_x u} du\ll 2^M
\sigma^{-3/2}_x = O(\sigma^{-5/2}_x).
$$

Finally,\pageoriginale we are left to deal with the following:
$$
- \int\limits_0^\infty h(u) \frac{d}{du} \left(u^{3/2} e^{-\sigma_x u}
T_x (u)\right) du.
$$

We replace $h(u)$ by its series definition and integrate term by
term. This is legitimate because of absolute and uniform
convergence. We obtain
\begin{equation}
  - \sum_{n=1}^\infty (-1)^n d(n) n^{-5/4} \im (e^{-1/4 \pi i} I
  (n)),\label{c3:eq3.63} 
\end{equation}
where 
$$
I(n) : = \int\limits_0^\infty e^{iu \sqrt{n}} \frac{d}{du} (u^{3/2}
e^{-\sigma_x u} T_x (u)) du.
$$

In this integral we can reintegrate by parts and expand $T_x(u)$ as we
did in the proof of Lemma \ref{c3:lem3.7} to obtain 
\begin{align*}
  I (n) & = i \sqrt{n} \int\limits_0^\infty e^{iu\sqrt{n}}
  u^{3/2}e^{-\sigma_x u} (T_0 (u) + T_1 (u)+ \ob{T_1 (u)} + T_2
  (u))du\\
  & = I_0 (n) + I_1 (n) + I_1^* (n) + I_2 (n),
\end{align*}
say. The only significant contribution will come from $I_1(n)$, as we
shall see. First we have
$$
I_0 (n) \ll \sqrt{n} |\sigma_x - i \sqrt{n}|^{-5/2} \ll n^{-3/4}.
$$

Second, 
$$
I^* (n) \ll \sqrt{n} \sum_{q \in Q_x} |\sigma_x - i(\sqrt{n}+
\sqrt{q})|^{-5/2} \ll n^{-3/4} M.
$$

Third,
\begin{align*}
  I_2(n) & \ll \sum_{\mu \in S_x} |\sigma_x - i(\sqrt{n}-
  \mu)|^{-5/2}\\[5pt]
  & \ll \begin{cases}
    3^{M}n^{- 3/4} & \text{if}~ n > 2 \max \left\{ |\mu| : \mu \in
    S_x\right\},\\
    3^M \tilde{\eta}(x)^{-5/2} \sqrt{n} & \text{if}~ n \leq 2 \max
    \left\{|\mu|: \mu \in S_x \right\}.
  \end{cases}
\end{align*}

This $\max \{ |\mu|\ldots\}$ is bounded by $M e^{cx}$. Hence all of
these contribute\pageoriginale to our series \eqref{c3:eq3.63} no more
than
$$
3^M \tilde{\eta} (x)^{-5/2}(Me^{cx})^{1/4+\epsilon} = O(\sigma_x^{-5/2}). 
$$
as required. There remains only the contribution of $I_1(n)$. We need
to distinguish two cases. If $n \neq q$ for all $q \in Q_x$, then we
obtain a bound exactly as above for $I_2 (n)$, but with $M$ replacing
the factor $3^M$ which comes from the number of terms in the sum. Now
suppose $n=q$ for some $q$ in $Q_x$. The term in the sum defining
$T_1(u)$ corresponding to this $q$ along contribute exactly
$$
\frac{1}{2}  i \, e^{5 \pi i/4} \Gamma \left(\frac{5}{2} \right)
\sqrt{q} \sigma_x^{-5/2}.
$$

The other terms contribute as in the case $n \neq q$. Combining all
these contributions to \eqref{c3:eq3.63} we see that the lemma is
proved. It should be noted that each $q$ in $Q_x$ is odd so that the
factor $(-1)^q$ in \eqref{c3:eq3.63} is always negative for the
significant terms.

We can now complete the proof of \eqref{c3:eq3.44}. For $J_x$ in
\eqref{c3:eq3.62} we first have $J_x \geq 0$. thus by Lemma
\ref{c3:lem3.7}  and Lemma \ref{c3:lem3.8} we also have, as $x \to
\infty$,
$$
J_x =  \gamma_x \sigma_x^{-1/P(x)} \Gamma \left(\frac{5}{2} +
\frac{1}{P(x)} \right) - \frac{1}{2} \Gamma \left(\frac{5}{2} \right)
\prod_{q \in Q_x} d(q) q^{- 3/4} + o(\gamma_x) + o(1).
$$

Hence if $x$ is sufficiently large we deduce that
\begin{align*}
  \gamma_x & \gg \sum_{q \in Q_x} d(q) q^{- 3/4} \gg \prod_{2 < p \leq x}
  (1+ 2 p^{-3/4})\\
  & = \exp \left(\sum_{2 < p \leq x} \log(1+ 2p^{-3/4}) \right) \gg
  \exp \left(\frac{cx^{1/4}}{\log x} \right).
\end{align*}

In other words, for each sufficiently large $x$ there exists a $u_x$
such that for some absolute constant $A > 0$
\begin{equation}
  -E (u^2_x) u_x^{-1/2} \geq A \exp \left(\frac{\log u_x}{P(x)} +
  \frac{cx^{1/4}}{\log x} \right). \label{c3:eq3.64}
\end{equation}

This implies first that $u_x$ tends to infinity with $x$. If the
second term in the exponential dominates, then it is easy to see on
taking logarithms\pageoriginale and recalling the definition of $P(x)$
that 
$$
\log \log u_x \ll \frac{x}{\log x}.
$$

Hence 
$$
x \gg \log \log u_x \log \log \log u_x,
$$
and since the function $x^{1/4}/\log x$ is increasing for $x \geq
x_0$, we obtain \eqref{c3:eq3.44} from \eqref{c3:eq3.64}. If the first
term in the exponential in \eqref{c3:eq3.64} dominates, then we may
assume
$$
\frac{(\log \log u_x)^{1/4}}{(\log \log \log x)^{3/4}} \gg \frac{\log
  u_x}{P(x)}, 
$$
since otherwise the $\Omega_-$-result holds again. But the last
condition gives again
$$
\log \log u_x \ll \frac{x}{\log x},
$$
so that \eqref{c3:eq3.44} holds in this case as well.

\section{Mean Square Formulas}\label{c3:sec3.3}

The explicit formulas for $G(T)$ and $G_\sigma(T)$, contained in
Theorem \ref{c3:thm3.1} and Theorem \ref{c3:thm3.2}, enable us to
obtain mean square formulas for these functions. The results are given
by

\begin{thm}\label{c3:thm3.5}
  \begin{equation}
    \int\limits_2^{T} G^2 (t) dt = B T^{5/2} + O(T^2), B =
    \frac{\zeta^4 (5/2)}{5 \pi \sqrt{2 \pi} \zeta (5)} =
    0.079320\ldots \label{c3:eq3.65}
  \end{equation}
  and for $1/2 < \sigma < 3/4$ fixed
  \begin{equation}
    \int\limits_{2}^T G_\sigma^2 (t) dt = C(\sigma)T^{7/2-2 \sigma} +
    O(T^{3-2\sigma}) \label{c3:eq3.66}
  \end{equation}]
    with
    \begin{equation}
      C(\sigma) = \frac{4^{\sigma-1} \pi^{2 \sigma-3}\sqrt{2 \pi}}{7-
        4 \sigma} \sum_{n=1}^\infty \sigma^2_{1-2\sigma} (n) n^{2
        \sigma- 7/2}.\label{c3:eq3.67}
    \end{equation}
\end{thm}

\begin{proof}
  Note\pageoriginale that here, as on some previous occasions, the
  asymptotic formula \eqref{c3:eq3.66} for $G_\sigma$ reduces to the
  asymptotic formula for $G$ as $\sigma \to 1/2 +0$. The proofs of
  both \eqref{c3:eq3.65} and \eqref{c3:eq3.66} are analogous. The
  proof of \eqref{c3:eq3.65} is given by Hafner-Ivi\'c \cite{Hafner and Ivic1}, and
  here only \eqref{c3:eq3.66} will be proved. We use Theorem
  \ref{c3:thm3.2} to write
{\fontsize{8}{10}\selectfont
  \begin{align*}
    G_\sigma (t) & = \left\{ 2^{\sigma-2} \left(\frac{\pi}{t}
    \right)^{\sigma-1/2} \sum_{n \leq t} (-1)^n \sigma_{1- 2
      \sigma}(n) n^{\sigma-1} \left( ar \sinh \sqrt{\frac{\pi
        n}{2t}}\right)^{-2} \left(\frac{t}{2 \pi n} + \frac{1}{4}
    \right)^{-1/4} \sin f(t, n)\right\}\\
    &\quad + \left\{ -2 \left(\frac{2 \pi}{t} \right)^{\sigma- \frac{1}{2}}
    \sum_{n \leq c_0 t}\sigma_{1-2 \sigma}(n) n^{\sigma-1} \left(\log
    \frac{t}{2 pi n} \right)^{-2} \sin g (t, n)+
    O(T^{3/4-\sigma})\right\}\\
    & = \sideset{}{_1}\sum (t) + \sideset{}{_2}\sum (t),
  \end{align*}}
  say, and assume $T \leq t\leq 2T$. Then we have
  $$
  \int\limits_T^{2T} G_\sigma^2 (t) dt = \int\limits_T^{2T}
  \sideset{}{_1^2}\sum (t) dt + \int\limits_T^{2T}
  \sideset{}{_2^2}\sum (t) dt + 2 \int\limits_T^{2T}
  \sideset{}{_1}\sum (t) \sideset{}{_2}\sum (t) dt,
  $$
  so that in view of the Cauchy-Schwarz inequality \eqref{c3:eq3.66}
  follows from 
  \begin{equation}
    \int\limits_T^{2T} \sideset{}{_2^2}\sum (t) dt \ll T^{5/2- 2
      \sigma}\label{c3:eq3.68} 
  \end{equation}
  and 
  \begin{equation}
    \int\limits_T^{2T} \sideset{}{_1^2}\sum (t) dt = C(\sigma)
    (2T)^{7/2-2\sigma} - C (\sigma)T^{7/2-2\sigma} +
    O(T^{3-2\sigma})\label{c3:eq3.69}  
  \end{equation}
  on replacing $T$ by $T2^{-j}$ and summing over $j= 1, 2,
  \ldots$. the bound given by \eqref{c3:eq3.68} follows easily by
  squaring and integrating termwise, since the sum in $\sum_2(t)$ is
  essentially a Dirichlet polynomial of length $\ll T$, so its
  contribution to the left-hand side of \eqref{c3:eq3.68} will be $\ll
  T^{1+ \epsilon}$, and the error term $O(T^{3/4-\sigma})$ makes a
  contribution which is $\ll T^{5/2-2\sigma}$. By grouping together
  terms with $m=n$ and $m \neq n$ it is seen that the left-hand side
  of \eqref{c3:eq3.69} equals
  {\fontsize{10}{12}\selectfont
  \begin{align*}
    & 4^{\sigma-2} \pi^{2 \sigma-1} \int\limits_T^{2T} t^{1- 2 \sigma}
    \sum_{n \leq t} \sigma^2_{1- 2 \sigma} (n) n^{2 \sigma-2} \left(ar
    \sinh \sqrt{\frac{\pi n}{2t}}\right)^{-4} \left(\frac{t}{2 \pi n}
    + \frac{1}{4} \right)^{-1/2}\\ 
    & \sin^2 f(t, n) dt
    + 4^{\sigma-2} \pi^{2 \sigma-1} \int\limits_T^{2T} t^{1- 2\sigma}
    \Bigg\{ \sum_{m \neq n \leq t} (-1)^{m+n}\sigma_{1-2 \sigma}(m)
    \sigma_{1-2\sigma} (n) (mn)^{\sigma-1}\\
    &\times \left(\frac{t}{2 \pi m} + \frac{1}{4} \right)^{-1/4}
    \left(\frac{t}{2 \pi n} + \frac{1}{4} \right)^{-1/4} \left(ar
    \sinh \sqrt{\frac{\pi n}{2t}} \right)^{-2} \left(ar \sinh
    \sqrt{\frac{\pi n}{2t}} \right)^{-2}\\ 
    & \hspace{4cm}\sin f(t, m) \sin f(t, n)\Bigg\} dt
     = \sideset{}{'}\sum + \sideset{}{''}\sum,
  \end{align*}}
  say,\pageoriginale and the main terms in \eqref{c3:eq3.69} will come
  from $\sum'$. We have
  $$
  \sideset{}{'}\sum = S_1 + S_2,
  $$
  where
  \begin{align*}
    S_1 & = 4^{\sigma-2} \pi^{2 \sigma-1} \sum_{n \leq T^{1/2}}
    \sigma^2_{1-2 \sigma} (n) n^{2\sigma-2} \int\limits_T^{2T}
    t^{1-2\sigma} \left( \frac{t}{2 \pi n} + \frac{1}{4}
    \right)^{-1/2}\\ 
    & \qquad\left( ar \sinh \sqrt{\frac{\pi n}{2t}} \right)^{-4}
    \sin^2 f(t, n)dt,\\
    S_2 & \ll \sum_{T^{1/2} < n \leq T} d^2 (n) n^{2 \sigma-2} T^{2-
      2\sigma} \left( \frac{T}{n}\right)^{-1/2} \left(\frac{T}{n}
    \right)^2\\
    & = T^{7/2-2\sigma} \sum_{T^{1/2} < n \leq T} d^2 (n) n^{2
      \sigma-7/2} \ll T^{\sigma - 5/4} \log ^3 T \cdot
    T^{7/2-2\sigma}\\
    & = T^{\frac{9}{4} -\sigma} \log^3 T
  \end{align*}
  so that
  $$
  S_2 \ll T^{3-2\sigma},
  $$
  since $9/4- \sigma < 3-2 \sigma$ for $\sigma < 3/4$.


Simplifying $S_1$ by Taylor's formula and using Lemma \ref{c2:lem2.1}
it follows that
{\fontsize{10}{11}\selectfont
\begin{align*}
  S_4 & = 4^{\sigma-2} \pi^{2\sigma-1} \sum_{n \leq T^{1/2}}\sigma^2_{1-
    2\sigma}(n) n^{2 \sigma-2} \int\limits_T^{2T} t^{1- 2 \sigma}
  t^{-1/2} (2 \pi)^{1/2} n^{1/2} \pi^{-2} n^{-2} 4t^2\cdot\\ 
  & \qquad\cdot\frac{1-
    \cos 2f (t, n)}{2} \left(1+ O\left(\left(\frac{n}{T}
  \right)\right)\right)^{1/2} dt\\ 
  & = \sqrt{2 \pi} \frac{4^{\sigma-1}}{2} \pi^{2 \sigma -3} \sum_{n
   \leq T^{1/2}} \sigma^2_{1-2\sigma}(n) n^{2\sigma-7/2}
  \int\limits_T^{2T} t^{5/2-2\sigma} (1- \cos 2f (t, n)) dt\\
  & \qquad+ O\left( \sum_{n \leq T^{1/2}} \sigma_{1-2\sigma}^2 (n)
  n^{2\sigma- 5/2} \int\limits_T^{2T} t^{2- 2 \sigma} dt\right)\\
  & = \frac{1}{2} 4^{\sigma-1} \pi^{2 \sigma-3} (2 \pi)^{1/2} \sum_{n
    \leq T^{1/2}} \sigma^2_{1-2 \sigma} (n) n^{2
    \sigma - 7/2} \int\limits_T^{2T} t^{5/2-2\sigma}dt +
  O(T^{3-2\sigma})\\
  & = C (\sigma) (2T)^{7/2-2\sigma} - C(\sigma)T^{7/2-2\sigma} +
  O(T^{7/2 -2\sigma}T^{\sigma-5/4}\log^4 T+ T^{3-2\sigma})
\end{align*}}
on\pageoriginale writing
$$
\sum_{n \leq T^{1/2}} = \sum^\infty_{n=1} - \sum_{n> T^{1/2}}
$$
and estimating the tails of the series trivially. It remains yet to
consider $\sum''$. By symmetry we have 
{\fontsize{10}{11}
\begin{align*}
&  {\sum}'' \ll \sum_{n < m \leq 2T}  \left|~
  \int\limits_{\max (m, T)}^{2T} \sigma_{1- 2 \sigma}(m) \sigma_{1- 2
    \sigma} (n) (mn) ^{\sigma-1} \times 
  \left(\frac{t}{2 \pi m} + \frac{1}{4} \right)^{-1/4}\right.\\
&  \times\left.\left(\frac{t}{2 \pi n} + \frac{1}{4} \right)^{-1/4}
  \left(ar \sinh 
  \sqrt{\frac{\pi m}{2t}} \right)^{-2} \left(ar \sinh \sqrt{\frac{\pi
      n}{2t}} \right)^{-2} \sin f(t, m) \sin f(t, n)dt \right|.
\end{align*}}

The sine terms yield exponentials of the form $\exp \{if\, (t,
m) \pm ~ if~ (t,\break n)\}$, and the contribution of the terms with
the plus sign is easily seen to be $\ll T^{3-2\sigma}$ by Lemma
\ref{c2:lem2.1}. For the remaining terms with the minus sign put
$$
F(t) : = f(t, m)- f((t, n)
$$
for any fixed $n <m \leq 2T$, so that by the mean value theorem
$$
F' (t) = 2 ar\sinh \sqrt{\frac{\pi n}{2t}} - 2 ar \sinh
\sqrt{\frac{\pi n}{2t}} \asymp T^{-1/2} (m^{1/2} - n^{1/2}).
$$

Again by Lemma \ref{c2:lem2.1}
\begin{align*}
  {\sum}'' & \ll T^{3-2\sigma} \sum_{n < m \leq 2T}
  (mn)^{\epsilon - 5/4+ \sigma-1/2}(m^{1/2} - n^{1/2})^{-1}\\
  & = T^{3-2\sigma} \left(\sum_{n \leq 1/2 m} + \sum_{n > 1/2 m}
  \right) = T^{3-2\sigma}(S_3 + S_4),
\end{align*}
say. Since $1/2 < \sigma < 3/4$ then trivially $S_3 \ll 1$ if
$\epsilon$ is sufficiently\pageoriginale small, and also 
$$
S_4 \ll \sum_{m \leq 2T} m^{2 \epsilon + 2 \sigma - 7/2} \sum_{1/2 m
  <n < m} \frac{m^{1/2}}{m-n} \ll \sum_{m \leq 2T} m^{2 \epsilon + 2
  \sigma -3} \log m \ll 1.
$$

This proves \eqref{c3:eq3.69}, and completes the proof of \eqref{c3:eq3.66}. 
\end{proof}

\section{The Zeros of $E(T)- \pi$}\label{c3:sec3.4}

From Theorem \ref{c3:thm3.3} it follows by continuity that every
interval $[T, T+ D T^{1/2}]$ for $T \geq T_0$ and suitable $D> 0$
contains a zero of $E(t)- \pi$. The same is true, of course, for the
function $E(t)$ itself, but it seems more appropriate to consider the
zeros of $E(t)- \pi$, since by Theorem \ref{c3:thm3.1} $E(t)$ has the
mean value $\pi$. Naturally, one can make the analogous conclusion
also for $E_\sigma(t)- B(\sigma)$, but the numerical calculations of
zeros of $E_\sigma(t)- E(\sigma)$ would be more tedious. Also the
function $E(T)$ seems more important, as the results concerning it
embody usually much information about the behaviour of $\zeta(s)$ opn
the critical line $\sigma = 1/2$, which is one of the main topics of
zeta-function theory.

In [1] the author and H.J.J. te Riele investigated the zeros of
$E(T)- \pi$ both from theoretical and numerical viewpoint. From many
numerical data obtained in that work we just present here a table with
the first 100 zeros of $E(T)-\pi$. Hence forth $t_n$ will denote the
$n^{\rm th}$ distinct zero of $E(T)-\pi$. All the zeros not exceeding 500
000 were found; all were simple and $t_n =499993.656034$ for $n=
42010$ was the largest one. The interested reader will find other
data, as well as the techniques used in computations, in the
aforementioned work of Ive\'c-te Riele.\pageoriginale

\medskip
{\noindent 
\addtolength{\tabcolsep}{-3pt}
\begin{longtable}{|rr|rr|rr|rr|}
  \hline
  $n$ & \multicolumn{1}{c|}{$t_n$} & $n$ & \multicolumn{1}{c|}{$t_n$} &
  $n$ & \multicolumn{1}{c|}{$t_n$} & $n$ & \multicolumn{1}{c|}{$t_n$}\\
  \hline
\endfirsthead
\hline
  $n$ & \multicolumn{1}{c|}{$t_n$} & $n$ & \multicolumn{1}{c|}{$t_n$} &
  $n$ & \multicolumn{1}{c|}{$t_n$} & $n$ & \multicolumn{1}{c|}{$t_n$}\\
  \hline
\endhead
\hline
\endfoot
\endlastfoot
  1 & 1.199593 & 26 & 99.048912 & 51 & 190.809257 & 76& 318.788055\\
  2 & 4.757482 & 27 & 99.900646 & 52 & 192.450016 & 77& 319.913514\\
  3 & 9.117570 & 28 & 101.331134 & 53 & 199.646158 & 78 & 321.209365
  \\
  4 & 13.545429 & 29 &109.007151 & 54& 211.864426& 79& 326.203904\\
  5 & 17.685444 & 30 &116.158343 & 55 &217.647450 &80 &330.978187 \\
  6 & 22.098708 & 31 & 117.477368 & 56 & 224.290283 & 81 & 335.589281\\
  7 & 27.736900 & 32 & 119.182848& 57& 226.323460& 82&339.871410\\
  8 & 31.884578 & 33 & 119.182848& 58& 229.548079& 83&343.370082 \\
  9 & 35.337567 & 34 & 121.514013& 59& 235.172515& 84& 349.890794\\
  10 & 40.500321& 35 & 126.086873& 60& 239.172515 &85 & 354.639224 \\
  11& 45.610584 & 36 & 130.461139& 61& 245.494672& 86& 358.371624\\
  12& 50.514621 & 37 & 136.453527& 62& 256.571746& 87 & 371.554495\\
  13& 51.658642 & 38 & 141.371299 & 63& 362.343301 & 88 & 384.873869 \\
  14& 52.295421 & 39 & 144.418515& 64& 267.822499& 89& 390.001409\\
  15& 54.295421 & 40 & 149.688528 & 65& 280.805140& 90 & 396.118200 \\
  16& 56.819660 & 41 & 154.448617 & 66& 289.701637& 91&399.102390 \\
  17& 63.010778 & 42 & 159.295786& 67& 290.222188& 92& 402.212210 \\
  18& 69.178386 & 43 & 160.333263 &68 &294.912620 &93 &406.737516 \\
  19& 73.799939 & 44 & 160.636660 &69 &297.288651 &94 &408.735190 \\
  20& 76.909522 & 45 & 171.712482& 70& 297.883251& 95& 417.047725 \\
  21& 81.138399 & 46 & 179.509721& 71& 298.880777& 96& 430.962383\\
  22& 85.065530 & 47 & 181.205224& 72& 299.919407& 97& 434.927645\\
  23& 90.665198 & 48 & 182.410680& 73& 308.652004& 98& 439.425963\\
  24& 95.958639 & 49 & 182.899197& 74& 314.683833& 99& 445.648250\\
  25& 97.460878 & 50 & 185.733682&75 & 316.505614& 100& 448.037348\\
  \hline
\end{longtable}}

As already mentioned, from Theorem \ref{c3:thm3.3} it follows that
every interval $[T, T + DT^{1/2}]$ contains a zero of $E(t)-\pi$, hence 
\begin{equation}
  T_{n+1} - t_n \ll t_n^{1/2}.\label{c3:eq3.70}
\end{equation}

On the other hand, the gaps between the consecutive $t_n$'s may be
sometimes quite large. This follows from the inequality
\begin{equation}
  \max_{t_n \leq t \leq t_{n+1}} |E(t) - \pi| \ll (t_{n+1} - t_n)
  \log t_n,\label{c3:eq3.71}
\end{equation}
so if we define
$$
\chi = \inf \left\{ c > 0: t_{n+1} - t_n \ll t_n^c\right\}, \alpha =
\inf \left\{ c \geq 0: E(t) \ll t^c\right\},
$$
then\pageoriginale \eqref{c3:eq3.70} gives $x\leq 1/2$ and \eqref{c3:eq3.71}
gives
\begin{equation}
 x \geq \alpha.\label{c3:eq3.72}
\end{equation}

Since we know from $\Omega$-results on $E(T)$ that $\alpha \geq 1/4$,
it follows that $x \geq 1/4$. There is some numerical evidence
which supports our conjecture that $x = 1/4$, which if true would
be very strong, and is certainly out of reach at present. To prove
\eqref{c3:eq3.71} let
$$
|E (\ob{t}) -  \pi|= \max_{t_n \leq t \leq t_{n+1}} |E(t) - \pi|.
$$

Suppose $E(\ob{t})- \pi > 0$ (the other case is analogous) and use
\eqref{c2:eq2.77}. Then for some $C> 0$, $n \geq n_0$ and $0 \leq
H\leq \frac{1}{2} t_n$,
$$
E(\ob{t}+H)- \pi \geq E(\ob{t}) - \pi - CH \log t_n > 0
$$ 
holds if $0 \leq H \leq (E(\ob{t})-\pi)/ (2C \log t_n)$. Thus $E(t)-
\pi$ has no zeros in $[\ob{t}, \ob{t}+ H]$ with $H= (E(\ob{t})/2C \log
t_n)$. Consequently
$$
(E(\ob{t})- \pi)/(2C \log t_n)= H\leq t_{n+1} - t_n,
$$
and \eqref{c3:eq3.71} follows.

Another important problem is the estimation of $t_n$ as a function of
$n$. Alternatively, one may consider the estimation of the counting
function
$$
K(T) : = \sum_{t_n \leq T}1.
$$

Since $[T, T+ DT^{1/2}]$ contains a $t_n$ for $T \geq T_0$, it follows
that $K(T) \gg T^{1/2}$. Setting $T= t_n$ we have $n= K(t_n) \gg
t_n^{1/2}$, giving 
\begin{equation}
  t_n \ll n^2.\label{c3:eq3.73}
\end{equation}

This upper bound appears to be crude, and we proceed to deduce a lower
bound for $t_n$, which is presumably closer to the true order of
magnitude of $t_n$. Note that $K(T)\ll M(T)$, where $M(T)$ denotes
the\pageoriginale number of zeros in $[0, T]$ of the function
$$
E' (t) = \left|\zeta \left( \frac{1}{2} + it\right)\right|^2 - \log
\left(\frac{t}{2 \pi} 
\right)- 2 \gamma = Z^2 (t) - \log \left(\frac{t}{2 \pi} \right)- 2 \gamma.
$$

Here, as usual, we denote by $Z(t)$ the real-valued function
\begin{align*}
  z(t) & = \chi ^{-1/2}( \frac{1}{2} + it) \zeta (\frac{1}{2} + it),\\
  \intertext{where}
  \chi(s) & = \frac{\zeta(s)}{\zeta(1- s)} = 2^{s} \pi^{s-1} \sin
  \left( \frac{\pi s}{2}\right) \Gamma (1-s).
\end{align*}

Thus $|Z(t)| = |\zeta ({}^{1/2} + it)|$, and the real zeros of $Z(t)$
are precisely the ordinates of the zeros of $\zeta(s)$ on $\re s=
1/2$. But
$$
M(T) = M_1(T) + M_2 (T),
$$
where $M_1(T)$ and $M_2(T)$ denote the number of zeros of 
$$
Z(t) - \left(\log \frac{t}{2 \pi} + 2 \gamma \right)^{1/2},\quad Z(t) +
\left(\log \frac{t}{2 \pi} + 2 \gamma \right)^{1/2}
$$
in $[0, T]$, respectively. Note that $M_j (T) \ll L_j (T)$, where
$L_j(T)$ is the number of zeros of 
$$
Z'(t) + \frac{(-1)^j}{2t \sqrt{\log (t/2 \pi)}}
$$
in $[0, T]$. It was shown by R.J. Anderson \cite{Anderson1} that the number of
zeros of $Z'(t)$ in $[0, T]$ is asymptotic to $\frac{T}{2 \pi} \log
T$, and by the same method it follows that $L_j (T)= O(T \log
T)$. Hence $K(T) \ll T \log T$, and taking $T= t_n$ we obtain
\begin{equation}
  t_n \gg n/\log n.\label{c3:eq3.74}
\end{equation}

In the range for $n$ that was investigated numerically by Ivi\'c- te
Riele \cite{Ivic1}, $t_n$ behaves approximately like $n \log n$, but it
appears quite difficult to prove this.

Another inequality involving the $t_n$'s may be obtained as
follows. Observe that $(T(t)-\pi)$' must vanish at least once in
$(t_n, t_{n+1})$. Hence this interval contains a point $t_0$ such that
$$
0 = E' (t_0) = \left|\zeta \left( \frac{1}{2} + it_0\right)\right|^2- \left(\log \frac{t_0}{2
  \pi} + 2 \gamma \right).
$$

Therefore\pageoriginale it follows that
\begin{equation}
  \max_{t_n \leq t \leq t_{n+1}} \left|\zeta \left(\frac{1}{2} +
  it\right)\right|\geq 
  \left(\log \frac{t_n}{2 \pi} + 2 \gamma \right)^{1/2}.\label{c3:eq3.75}
\end{equation}

This inequality shows that the maximum of $|\zeta ( \frac{1}{2} + it)|$
between consecutive zeros of $E(T)- \pi$ cannot be too small, even if
the gap between such zeros is small. On the other hand, the maximum of
$|\zeta( \frac{1}{2}+ it )|$ can be larger over long intervals, since
R. Balasubramanian \cite{Balasubramanian2} proved
\begin{equation}
  \max_{T \leq t \leq T + H} \left|\zeta \left( \frac{1}{2} +
  it\right)\right| \geq \exp
  \left(\frac{3}{4} \sqrt{\frac{\log H}{\log \log H}}
  \right)\label{c3:eq3.76} 
\end{equation}
in the range $100 \log \log T \leq H \leq T$. Using \eqref{c3:eq3.71}
we may investigate sums of powers of consecutive gaps $t_{n+1}-
t_n$. Namely from Theorem \ref{c2:thm2.4} we have, as $T \to \infty$, 
\begin{equation}
  C_1 T^{3/2} \sim \int\limits_T^{2T} E^2 (t) dt \sim
  \sum_{\substack{T < t_n \leq 2T\\ T^{1/4} \log^{-2} T \leq T_{n+1} -
      t_n }} \int\limits_{t_n}^{t_{n+1}} E^2 (t) dt.\label{c3:eq3.77}
\end{equation}

The contribution of gaps less than $T^{1/4}\log^{-2} T$ is negligible
by\break \eqref{c3:eq3.71} and trivial estimation. From \eqref{c3:eq3.77} we
infer by using \eqref{c3:eq3.71} that
\begin{align*}
  T^{3/2} & \ll \sum_{T < t_n \leq 2T, t_{n+1} - t_n \geq T^{1/4}
    \log^{-2}T} (t_{n+1}- t_n) \left(\max_{t \in[t_n, t_{n+1}]} |E(t) -
  \pi|^2 +1 \right)\\
  & \ll \log^2 T \sum_{T < t_n \leq 2T, t_{n+1} - t_n \geq
    T^{1/4}\log^{-2} T}(t_{n+1}- t_n)^3 + T.
\end{align*}

Replacing $T$ by $T 2^{-j}$ and summing over $j \geq 1$ this gives
\begin{equation}
  T^{3/2} \log^{-2} T \ll \sum_{t_n \leq T} (t_{n+1} -
  t_n)^3. \label{c3:eq3.78} 
\end{equation}

In general, for any fixed $\alpha \geq 1$ and any given $\epsilon > 0$
\begin{equation}
  T^{1/4 (3 + \alpha - \epsilon)} \ll {}_{\epsilon , \alpha} \sum_{t_n
  \leq T} (t_{n+1}- t_n)^{\alpha}. \label{c3:eq3.79}
\end{equation}

This\pageoriginale follows along the same lines as \eqref{c3:eq3.78},
on using
\begin{equation}
  T^{1+ 1/4 a- \epsilon} \ll_{a, \epsilon} \int\limits_2^T |E(t)|^a dt
  \quad (a \geq 0, \epsilon > 0) \label{c3:eq3.80}
\end{equation}
with $a = \alpha-1$. The bound \eqref{c3:eq3.80} for $a> 2$ (without
``$\epsilon$'') follows easily from Theorem \ref{c2:thm2.4} and
H\"older's inequality, and for $o < a < 2$ it follows from 
$$
T^{3/2} \ll \int\limits^T_2 E^{1/2 a} (t) E^{2-1/2a}(t) dt \leq
\left(\int\limits_2^T |E(t)|^2 dt \right)^{1/2} \left(\int\limits_2^T
|E (t)|^{4-a} dt \right)^{1/2}
$$
on using
\begin{equation}
  \int\limits_0^T |E(t)|^A dt \ll T^{1+ 1/4A + \epsilon} \quad \left(0 \leq
  A \leq \frac{35}{4}\right),\label{c3:eq3.81}
\end{equation}
a proof of which is given by the author in Chapter 15 of [1]. It maybe
conjectured that the lower bound in \eqref{c3:eq3.79} is close to the
truth, that is, we expect that
\begin{equation}
  \sum_{t_n \leq T} (t_{n+1}- t_n)^\alpha = T^{1/4(3 + \alpha + o
    (1))} \quad (\alpha \geq 1, T \to \infty),\label{c3:eq3.82}
\end{equation}
but unfortunately at present we cannot prove this for any specific
$\alpha> 1$ (for $\alpha=1$ this is trivial).

If $u_n$ denotes the $n^{\rm th}$ zero of $G(T)$, then by Theorem
\ref{c3:thm3.3} there exist infinitely many $u_n$'s the sequence
$\{u_n\}^\infty_{n=1}$ is unbounded, and moreover
$$
u_{n+1} - u_n \ll u_n^{1/2}.
$$

This bound is actually close to being best possible, since we can
prove without difficulty that
$$
\beta: = \limsup_{n \to \infty} \frac{\log (u_{n+1}- u_n)}{\log u_n} =
\frac{1}{2}. 
$$

This should be contrasted with what we have succeeded in proving for
the sequence $\{ t_n\}_{n=1}^\infty$, namely only
$$
\frac{1}{4} \leq \limsup_{n \to \infty} \frac{\log (t_{n+1}-
  t_n)}{\log t_n} \leq \frac{1}{2}.
$$

To\pageoriginale prove that $\beta = \frac{1}{2}$ it remains to show
that $\beta < \frac{1}{2}$ cannot hold. We have
$$
G(T+H) - G(T)= \int\limits_{T}^{T+H} (E(t)- \pi) dt,
$$
and we choose $T$ (this is possible by Theorem \ref{c3:thm3.3}) such
that $G(T) < - B T^{3/4}$, and $H$ such that $G(T+ H)=0$. Then we have
$O< H \ll T^{\beta+ \epsilon}$, and using the Cauchy-Schwarz
inequality it follows that
$$
T^{3/2} \ll G^2 (T) \ll H \int\limits_T^{T+H} E^2 (t) dt + H^2 \ll H^2
T^{1/2} + HT \log^5 T
$$
by appealing to Theorem \ref{c2:thm2.4}. Hence
$$
T^{3/2} \ll T^{1/2 + 2 \beta + 2 \epsilon} + T^{1+ \beta + \epsilon}
\log^5 T,
$$
which is impossible if $\beta < \frac{1}{2}$ and $\epsilon > 0$ is
sufficiently small. This proves that $\beta = \frac{1}{2}$. The reason
that one can obtain a sharper result for the sequence $\{
u_n\}^\infty_{n=1}$ than for the sequence $\{ t_n\}^\infty_{n=1}$ is
essentially that $G(T)$ is the integral of $E(T)- \pi$, and possesses
the representation \eqref{c3:eq3.28} involving an absolutely
convergent series which is easily manageable. No expression of this
type seems to exist for $E(T)$.

\section{Some Other Results}\label{c3:sec3.5}

In this section we shall investigate some problems concerning $E(T)$
that were not treated before. In particular, we shall consider
integrals of the type
\begin{equation}
  I = I(T, H) = \int\limits_T^{T+H} f(E (t)) |\zeta(1/2+it)|^2
  dt,\label{c3:eq3.83} 
\end{equation}
where $T \geq T_0$, $0\leq H \leq T$, and $f(t)$ is a given function
which is continuous\pageoriginale in $[T, T+ H]$. The method for
evaluating the integral in \eqref{c3:eq3.83} is very simple. Namely,
if $F'=f$, then from the definition of $E(T)$ it follows that 
\begin{align}
  I &= \int\limits_{T}^{T+H} f(E(t)) \left(E' (t)+ \log \frac{t}{2 \pi} + 2
  \gamma\right) dt\label{c3:eq3.84}\\
  & = F(E(T+H)) - F(E(T)) + \int\limits_T^{T+H} f(E(t)) \left(\log
  \frac{t}{2 \pi} + 2 \gamma\right)dt.\notag
\end{align}

Therefore the problem is reduced to a simpler one, namely to the
evaluation of the integral where $|\zeta|^2$ is replaced by
$\log(t/2\pi) + 2 \gamma$. If $T$ and $T+H$ are points at which $E(T)=
E(T+H)$, then \eqref{c3:eq3.84} simplifies even further. As the first
application we prove

\begin{thm}\label{c3:thm3.6}
  With $c= \frac{2}{3} (2\pi)^{-1/2} \zeta^4 \left(\frac{3}{2} \right)
  /\zeta(3)$ we have
{\fontsize{10pt}{12pt}\selectfont
  \begin{align}
    \int\limits_0^T E^2 (t) |\zeta(1/2 + it)|^2 dt  &= c \left(\log
    \frac{T}{2 \pi} + 2 \gamma - \frac{2}{3}\right) T^{3/2} + O(T \log
    ^5 T)\label{c3:eq3.85}
  \end{align}}
and
\begin{align}
    & \int\limits_0^T E^4 (t) |\zeta (1/2 + it)|^2 dt  \ll
    T^{3+\epsilon},\label{c3:eq3.86} \\
    & \int\limits_0^T E^6 (t) |\zeta (1/2 + it)|^2 dt  \ll
    T^{5/2+\epsilon}\label{c3:eq3.87},\\
    & \int\limits_0^T E^8 (t) |\zeta (1/2 + it)|^2 dt  \ll T^{3 +
      \epsilon}.\label{c3:eq3.88} 
  \end{align}
\end{thm}

\begin{proof}
  To prove \eqref{c3:eq3.85} we apply \eqref{c3:eq3.84} with $H =T$,
  $f(t) = t^2$, $F(t) = t^3$. Using the weak bound $E(t) \ll t^{1/3}$
  and the mean square formula \eqref{c2:eq2.100} with the error term
  $O(T \log^4 T)$, it follows that 
  \begin{align*}
    \int\limits_T^{2T} &E^2 (t) |\zeta (1/2 + it )|^2 dt  = O(T) +
    \int\limits_T^{2T} E^2 (t) \left(\log \frac{t}{2 \pi} + 2 \gamma
    \right) dt\\
    & = \left(\int\limits_0^t E^2 (u) du \right) \left(\log \frac{t}{2
      \pi} + 2 \gamma\right) \Bigg|_T^{2T} - \int\limits_T^{2T}
    \left(\int\limits_0^T E^2 (u) du \right) \frac{dt}{t} + o(T)\\
    & = c t^{3/2} \left(\log \frac{t}{2 \pi} + 2 \gamma - \frac{2}{3}
    \right) \Bigg|_T^{2T} + O(T \log^5 T).
  \end{align*}
\end{proof}

Replacing\pageoriginale $T$ by $T 2^{-j}$ and summing over $j= 1,2, \ldots$ we
obtain \eqref{c3:eq3.85}. the remaining estimates
\eqref{c3:eq3.86}-\eqref{c3:eq3.88} are obtained analogously by using
\eqref{c3:eq3.81}. The upper bounds in
\eqref{c3:eq3.86}-\eqref{c3:eq3.88} are close to being best possible,
since
\begin{equation}
  \int\limits_0^T |E (t)|^A |\zeta (1/2 + it)|^2 dt \gg 
  \begin{cases}
    T^{1+ 1/4 A-\epsilon} & (0\leq A < 2),\\
    T^{1+ 1/4 A} \log T & (A \geq 2),
  \end{cases}\label{c3:eq3.89}
\end{equation}
for any fixed $A \geq 0$ and $\epsilon > 0$. For $A \geq 2$ this
follows easily from \eqref{c3:eq3.85} and H\"older's inequality for
integrals, since
\begin{multline*}
  \int\limits_0^T E^2 (t) |\zeta (1/2 + it)|^2 dt = \int\limits_0^T
  E^2 (t) |\zeta|^{4/A} |\zeta|^{2(1-2/A)}dt\\
  \leq \left(\int\limits_0^T |E(t)|^A |\zeta (1/2 + it)|^2 dt
  \right)^{2/A} \left(\int\limits_0^T |\zeta (1/2 + it)|^2dt
  \right)^{1- \frac{2}{A}}.
\end{multline*}

For $O\leq A \leq 2$ we use again \eqref{c3:eq3.85} and H\"older's
inequality to obtain 
{\fontsize{10}{12}\selectfont
\begin{align*}
&  T^{3/2} \log T \ll \int\limits_0^T E^{1/2 A} (t) |\zeta (1/2 +
  it)|E^{2- 1/2 A} (t) |\zeta (1/2 + it)|dt\\
&  \leq \left(\int\limits_0^T |E(t)|^A |\zeta (1/2 + it)|^2 dt
  \right)^{1/2} \left( \int\limits_{0}^T |E(t)|^{8-2A}dt\right)^{1/4}
  \left(\int\limits_0^T |\zeta (1/2 + it)|^4dt \right)^{1/4}.
\end{align*}}

Using \eqref{c3:eq3.81} (with $A$ replaced by $8 - 2A$) and the weak
bound 
$$
\int\limits_0^T |\zeta (1/2 + it)|^4 dt \ll T^{1+ \epsilon} 
$$
we obtain the first part of \eqref{c3:eq3.89}.

Perhaps the most interesting application of our method is the
evaluation of the integral
\begin{equation}
  \int_0^T E(t) |\zeta (1/2 + it)|^2 dt. \label{c3:eq3.90}
\end{equation}

The\pageoriginale function $E(t)$ has the mean value $\pi$ in view of
Theorem \ref{c3:thm3.1}, while $|\zeta (1/2 + it)|^2$ has the average
value $\log t$. Therefore the integral in \eqref{c3:eq3.90}
represents in a certain sense the way that the fluctuations of these
important functions are being superimposed. We shall prove the
following 

\begin{thm}\label{c3:thm3.7}
Let $U(T)$ be defined by
  \begin{equation}
    \int\limits_0^T E(t) |\zeta (1/2 + it)|^2 dt = \pi T\left(\log
    \frac{T}{2 \pi} + 2 \gamma -1 \right)+ U(T),\label{c3:eq3.91}
  \end{equation}
  and let $V(T)$ be defined by 
  \begin{equation}
    \int\limits_0^TU(t) dt = \frac{\zeta^4 (3/2)}{3\sqrt{2 \pi} \zeta
      (3)} T^{3/2} + V(T).\label{c3:eq3.92}
  \end{equation}
  Then 
  \begin{align}
    U(T) & = O(T^{3/4} \log T), U(T) = \Omega_\pm (T^{3/4} \log
    T),\label{c3:eq3.93}\\ 
    V(T) & = O(T^{5/4} \log T), V(T) = \Omega_\pm (T^{5/4} \log
    T)\label{c3:eq3.94}\\
    \intertext{and}
    \int\limits_2^T U^2 (t) dt & = T^{5/2} P_2 (\log T)+ O(T^{9/4+
      \epsilon}),\label{c3:eq3.95}
  \end{align}
  where $P_2 (x)$ is a suitable quadratic function in $x$. 
\end{thm}

\begin{proof}
  We begin the proof by noting that \eqref{c3:eq3.84} gives 
  $$
  \int\limits_2^T E(t) |\zeta (1/2 + it)|^2 dt = \frac{1}{2} E^2 (T) +
  \int\limits_2^T E(t) \left(\log \frac{t}{2 \pi}+ 2 \gamma \right) + O(1).
  $$
  In view of the definition \eqref{c3:eq3.1} of $G(T)$ the integral on
  the right-hand side of this equality becomes
{\fontsize{10pt}{12pt}\selectfont
  \begin{align*}
&    \int\limits_2^T \pi \left(\log \frac{t}{2 \pi} + 2 \gamma
    \right)dt + \int\limits_2^T \left(\log \frac{t}{2 \pi} + 2 \gamma
    \right) dG(t)\\
&    = \pi T \left(\log \frac{T}{2 \pi} + 2 \gamma \right) - \pi
    \int\limits_2^T dt + O(1) + G(T) \left(\log \frac{T}{2 \pi} + 2
    \gamma\right) - \int\limits_2^T G(t) \frac{dt}{t}. 
\end{align*}}

Hence\pageoriginale
$$
U(T) = \frac{1}{2} E^2 (T) + G(T) \left(\log \frac{T}{2 \pi} + 2
\gamma \right) - \int\limits_2^T G(t) \frac{dt}{t} + O(1).
$$

Using Theorem \ref{c3:thm3.1} and Lemma \ref{c2:lem2.1} it follows
that 
\begin{equation}
  \int\limits_2^T G(t) \frac{dt}{t} = O(T^{1/4}). \label{c3:eq3.96}
\end{equation}

This gives at once
\begin{equation}
  U(T) = \frac{1}{2} E^2 (T) + G(T) \left(\log \frac{T}{2 \pi}
  + 2 \gamma \right) + O(T^{1/4}).\label{c3:eq3.97}
\end{equation}

Since $E(T) \ll T^{1/3}$, then using \eqref{c3:eq3.28} and $G(T)=
\Omega_\pm (T^{3/4})$ we obtain \eqref{c3:eq3.93}. Therefore the order
of magnitude of $U(T)$ is precisely determined, and we pass on to the
proof of \eqref{c3:eq3.94} and \eqref{c3:eq3.95}. From
\eqref{c3:eq3.97} we have
\begin{align*}
  \int\limits_{1/2 T}^T U^2 (t) dt &= \int\limits_{1/2 T}^T G^2 (t)
  \left(\log \frac{t}{2 \pi} + 2 \gamma \right)^2 dt+ O\left(\int\limits_{1/2 T}^T (E^4 (t) + T^{1/2})dt \right)\\
&\quad 
  + O \left(\int\limits_{1/2 T}^T |G(t) |(E^2 (t) + T^{1/4}) 
  \log T dt \right).
 \end{align*}

Using \eqref{c3:eq3.81} with $A=4$ it is seen that the contribution of
the first O-term above is $T^{2+\epsilon}$. To estimate the second
O-term we use \eqref{c3:eq3.65} and the Cauchy-Schwarz inequality. We
obtain a contribution which is 
$$
\ll \log T \left\{ \int\limits_{1/2 T}^T G^2 (t) dt
\left(\int\limits_{1/2 T}^{T} E^4 (t) dt + T^{3/2} \right)
\right\}^{1/2} \ll T^{9/4+ \epsilon}
$$

Integration by parts and \eqref{c3:eq3.65} yield $(B = \zeta^4
(5/2)/(5 \pi \sqrt{2 \pi} \zeta (5)))$
\begin{multline*}
  \int\limits_{1/2 T}^T G^2 (t) \left(\log \frac{t}{2 \pi} + 2 \gamma
  \right)^2 dt = (Bt^{5/2} + O(t^{2 + \epsilon})) \left(\log
  \frac{t}{2\pi} + 2 \gamma \right)^2 \Bigg|_{1/2T}^T\\
  - 2 \int\limits{1/2 T}^T (Bt^{3/2} + O(t^{1+ \epsilon})) \left(\log
  \frac{t}{2\pi} + 2 \gamma \right)dt = t^{5/2} P_2 (\log
  t)\Bigg|_{1/2T}^T\\
  + O(T^{2+\epsilon}),
\end{multline*}
where\pageoriginale $P_2(x) = a_0 x^2 + a_1 x+ a_2$ with $a_0$, $a_1$,
$a_2$ effectively computable. This means that we have shown that
$$
\int\limits_{1/2 T}^T U^2 (t) dt = t^{5/2} P_2 (\log t) \Bigg|_{1/2 T}^T
 + O(T^{9/4 +\epsilon}),
$$
so that replacing $T$ by $T2^{-j}$ and summing over $j= 0, 1, 2,
\ldots$ we obtain \eqref{c3:eq3.95}. Probably the error term in
\eqref{c3:eq3.95} could be improved to $O(T^{2+\epsilon})$ (in analogy
with \eqref{c3:eq3.65}), but this appears to be difficult.

Now we shall establish \eqref{c3:eq3.92} with the O-result
\eqref{c3:eq3.94}. Integrating \eqref{c3:eq3.97} with the aid of
Theorem \ref{c2:thm2.4} we have
{\fontsize{10pt}{12pt}\selectfont
\begin{equation}
  \int\limits_{1/2 T}^T U(t) dt = \frac{1}{2} c \left(T^{3/2}- \left(\frac{1}{2}
  \right)^{3/2}\right) + O(T^{5/4})+ \int\limits_{1/2 T}^T G(t) \left(\log
  \frac{t}{2 \pi} + 2\right)dt.\label{c3:eq3.98}
 \end{equation}}

Using Theorem \ref{c3:thm3.1} (with $N=T$) it is seen that the
contribution of the sum $\displaystyle{\sum_{n \leq N'}}$ to the last
integral is $O(T)$, while the contribution of the error term
$O(T^{1/4})$ is trivially $O(T^{5/4} \log T)$. The contribution of the
sum $\displaystyle{\sum_{n \leq N}}$ is, after simplification by
Taylor's formula,
{\fontsize{8}{10}\selectfont
\begin{align*}
  &\int\limits_{1/2 T}^T 2^{-1/4} \pi^{-3/4} t^{3/4} \sum_{n=1}^\infty
  (-1)^n d(n) n^{-5/4} \sin \left(\sqrt{8 \pi nt} -
  \frac{\pi}{4}\right) \left(\log \frac{t}{2\pi} + 2 \gamma \right) dt
  + O(T^{5/4})\\
  & = 2^{-3/4} \pi^{-5/4} \sum_{n=1}^\infty (-1)^{n-1} d(n) n^{- 7/4}
  \int\limits_{1/2 T}^{T} t^{5/4} \left(\log \frac{t}{2 \pi} + 2
  \gamma\right) \frac{d}{dt} \left\{\cos (\sqrt{8 \pi nt} -
  \frac{\pi}{4}) \right\} + O(T^{5/4})\\
  & = 2^{-3/4} \pi^{- 5/4} \sum_{n=1}^\infty (-1)^{n-1} d(n) n^{-7/4}
  \left\{t^{5/4} \left(\log \frac{t}{2 \pi} + 2 \gamma \right) \cos
  \left(\sqrt{8 \pi nt} - \frac{\pi}{4}\right)\right\}\Bigg|_{1/2 T}^T\\
  &\quad -2^{-3/4} \pi^{-5/4} \sum_{n=1}^\infty (-1)^{n-1} d(n) n^{-7/4}
  \int\limits_{1/2 T}^T \left(\frac{5}{4} t^{\frac{1}{4}} \left(\log
  \frac{t}{2\pi} + 2\gamma\right) + t^{\frac{1}{4}} \right)\\
&\quad \cos \left(\sqrt{8
  \pi nt}- \frac{t}{4}\right) dt + O(T^{5/4})\\
  & = 2^{-3/4} \pi^{5/4} \sum_{n=1}^\infty (-1)^{n-1} d(n)n^{-7/4}
  \left\{t^{5/4} \left( \log \frac{t}{2\pi} + 2 \gamma\right) \cos
  \left(\sqrt{8 \pi nt}\right) \right\}\Bigg|_{1/2 T}^T+ O(T^{5/4})
\end{align*}}
if\pageoriginale we use Lemma \ref{c2:lem2.1} to estimate the last
integral above. Inserting this expression in \eqref{c3:eq3.98} we
obtain \eqref{c3:eq3.92} with
\begin{align}
  V(T) & = W(T)+ 2^{-3/4} \pi^{-5/4}T^{5/4} \left(\log \frac{T}{2 \pi} +
  2 \gamma \right)\notag\\ 
  & \qquad\sum_{n=1}^\infty (-1)^{n-1} d(n) n^{-7/4} \cos
  \left(\sqrt{8 \pi n T} - \frac{\pi}{4}\right),\label{c3:eq3.99}
\end{align}
where
\begin{equation}
  W(T)  = O(T^{5/4} \log T).\label{c3:eq3.100}
\end{equation}

This proves the O-result of \eqref{c3:eq3.94}. By the method of Lemma
\ref{c3:lem3.3} and Lemma \ref{c3:lem3.4} it is easily seen that the
series in \eqref{c3:eq3.99} is $\Omega_\pm (1)$, so that the
omega-result of \eqref{c3:eq3.94} follows from a sharpening of
\eqref{c3:eq3.100}, namely
\begin{equation}
  W(T) = O(T^{5/4}). \label{c3:eq3.101}
\end{equation}

To see that \eqref{c3:eq3.101} holds we have to go back to
\eqref{c3:eq3.98} and recall that it is the error term $O(T^{1/4})$
which, after integration in \eqref{c3:eq3.98}, leads to
\eqref{c3:eq3.100} since actually all other error terms will be
$O(T^{5/4})$. Observe that in \eqref{c3:eq3.98} we have in fact a
double integration, since $G(T)$ itself is an integral (the
$\log$-factor is unimportant). By analyzing the proof of Lemma
\ref{c3:lem3.1} it will be seen that instead of the error term $\Phi_0
\mu_0 F_0^{-3/2}$ with $\gamma+1$ replacing $\gamma$ we shall have
$\gamma+2$ replacing $\gamma$ in view of double integration. This
produces in our case the error term $O((T/k)^{1/2(\gamma+2 -\alpha -
  \beta)} T^{-1/4} k^{-5/4})$, which for $\beta = \frac{1}{2}$,
$\gamma=1$, $\alpha \to \frac{1}{2}+ 0$ will eventually give
$O(T^{3/4} \log T)$ and therefore \eqref{c3:eq3.101} holds. This
completes the proof of Theorem \ref{c3:thm3.7}.
\end{proof}

We shall conclude this chapter by establishing some further analogues
between the functions $E(T)$ and $\Delta(x)$. Namely, we shall use the
$\Omega_+$-results \eqref{c3:eq3.43} and \eqref{c3:eq3.41} to derive
omega-results in the mean square for the functions in question. Thus
we write
\begin{align}
  \int\limits_2^T E^2 (t) dt & = cT^{3/2} + F(T)  \;  \left(c= \frac{2}{3}
  (2\pi)^{-1/2} \frac{\zeta^4   (3/2)}{\zeta(3)}\right),\label{c3:eq3.102}\\
  \int\limits_2^T \Delta^2 (t) dt & = dT^{3/2} + H(T) \;  \left(d=
  \frac{\zeta^4 (3/2)}{6 \pi^2 \zeta(3)} \right). \label{c3:eq3.103}
\end{align}

Upper\pageoriginale bound results $F(T) \ll T \log^5 T$ and $H(T)\ll T
\log ^5 T$ 
were given by Theorem \ref{c2:thm2.4} and Theorem \ref{c2:thm2.5},
respectively. Moreover, it was pointed out that in both bounds
$\log^5T$ may be replaced by $\log^4 T$. Now we shall prove
\begin{thm}\label{c3:thm3.8}
  If $F(T)$ and $H(T)$ are defined by \eqref{c3:eq3.102} and
  \eqref{c3:eq3.103}, respectively, then with suitable constants
  $B_1$, $B_2> 0$
{\fontsize{10pt}{12pt}\selectfont
  \begin{align}
    F(T) & = \Omega \left\{T^{3/4}(\log T)^{-1/4} (\log \log T)^{3/4 (3 +
      \log 4)} e^{-B_1\sqrt{\log \log \log T}}
    \right\}\label{c3:eq3.104}
  \end{align}}
and
{\fontsize{10pt}{12pt}\selectfont
\begin{equation}
    H(T)  = \Omega \left\{T^{3/4} (\log T)^{-1/4} (\log \log T)^{3/4
      (3 + \log 4)} e^{-B_2 \sqrt{\log \log \log T}}\right\}.
    \label{c3:eq3.105} 
\end{equation}}
\end{thm}

\begin{proof}
  In Chapter \ref{c2} we proved the inequalities
  \begin{align*}
    E(T) & \leq H^{-1} \int\limits_T^{T+H}E(t) dt + CH \log T \; (O < H
    \leq T, T\geq T_0, C>0)\\
    \intertext{and}
    E(T) & \geq H^{-1} \int\limits_{T-H}^T E(t) dt - CH \log T.
  \end{align*}

  Thus by the Cauchy-Schwarz inequality we have
  \begin{eqnarray*}
    E^2 (T) & \leq  2 H^{-1} \int\limits_T^{T+H} E^2 (t) dt + 2C^2 H^2
    \log^2 T &(E(T) > 0)\\
    \text{and}\quad 
    E^2 (T) & \leq 2H^{-1} \int\limits_{T-H}^T E^2 (t) dt + 2C^2 H^2
    \log^2 T & (E(T)< 0)
  \end{eqnarray*}
  so that in any case for $T \geq T_0$ and a suitable $C_1 > 0$ we
  obtain 
  \begin{equation}
    E^2 (T) \leq 2 H^{-1} \int\limits_{T-H}^{T+H} E^2 (t) dt + C_1 H^2
    \log^2 T.\label{c3:eq3.106}
  \end{equation}

In \eqref{c3:eq3.106} we take $T= T_n$, the sequence of points $T_n\to
\infty$  for which the $\Omega_+$-result \eqref{c3:eq3.43} is
attained. If $C_1, C_2, \ldots$ denote absolute,\pageoriginale
positive constants, then we obtain 
{\fontsize{10}{12}\selectfont
\begin{align*}
  & C_2 H(T \log T)^{1/2} (\log \log T)^{1/2 (3 + \log 4)} \exp \left( -
  C_3 \sqrt{\log \log \log T}\right)\\
  & \leq 2c (T+ H)^{3/2} - 2c (T-H)^{3/2} + 2F(T+H) + 2F (T-H) + C_1 H^3 \log^2
  T\\
  & \leq C_3 HT^{1/2} + 2F (T+H) - 2F (T-H) + C_1 H^3 \log^2 T.
\end{align*}}
\indent
Suppose \eqref{c3:eq3.104} does not hold. Then 
\begin{multline*}
  F(T) \ll K(T, B_1): =\\
T^{3/4} (\log T)^{-1/4} (\log \log T)^{3/4 (3 +
    \log 4)} \exp \left(-B_1 \sqrt{\log \log \log T} \right)
\end{multline*}
for any given $B_1> 0$, where $K(T, B_1)$ is an increasing function of
$T$ for $T\geq T_0 (B_1)$. Now let
$$
H= H(T, B_1)= (K(T, B_1)\log^{-2}T)^{1/3}.
$$

Then we obtain
\begin{multline*}
  C_4 H(T\log T)^{1/2} (\log \log T)^{1/2(3 + \log 4)} \exp \left(-C_3
  \sqrt{\log \log \log T}\right)\\
  \leq C_5 T^{3/4} (\log T)^{-1/4} (\log \log T)^{3/4 (3 + \log 4)}
  \exp \left( -B_1 \sqrt{\log \log \log T}\right),
\end{multline*}
or after simplification
$$
C_4 \exp \left( - \left(\frac{1}{3} B_1 + C_3 \right) \sqrt{\log \log
  \log T}\right) \leq C_5 \exp \left(- B_1 \sqrt{\log \log \log T} \right).
$$

Taking $B_1 = 3 C_3$ the last inequality gives a contradiction if $T
\geq T(C_3)$, which proves \eqref{c3:eq3.104}. One proves
\eqref{c3:eq3.105} analogously, only the proof is even slightly
easier, since in this case one has
\begin{equation}
  \Delta(x) = H^{-1}\int\limits_x^{x+H} \Delta (t) dt + O(H \log x) \; 
  (x^\epsilon \leq H \leq x).\label{c3:eq3.107}
\end{equation}

Namely
\begin{multline*}
  \Delta(x) - H^{-1} \int\limits_x^{x + H} \Delta(t) dt = H^{-1}
  \int\limits_x^{x+H} (\Delta(x) - \Delta(t)) dt\\
  \ll H \log x + H^{-1} \int\limits_x^{x+H} \left(\sum_{x < n \leq x
    +H} d(n) \right) dt \ll H \log x,
\end{multline*}
since\pageoriginale
\begin{equation}
  \sum_{x < n \leq x+H} d(n) \ll H \log x \quad (x^\epsilon \leq H
  \leq x).\label{c3:eq3.108}
\end{equation}
\end{proof}

\bigskip
\begin{center}
  \textbf{\Large Notes For Chapter 3}
\end{center}
\medskip

Theorem \ref{c3:thm3.2} is new, while Theorem \ref{c3:thm3.1} is to be
found in J.L. Hafner - A. Ivi\'c \cite{Hafner and Ivic1}. The motivation for the
study of $G(T)$ is the fact, already exploited by Hafner \cite{Hafner3},
that it is not essential to have a functional equation for the
generating Dirichlet series connected with a number-theoretic error
term, but a Voronoi-type representation for the error term in
question. By this we mean representations such as 
$$
\Delta(T) = \pi^{-1} 2^{-1/2} T^{1/4} \sum_{n \leq T} d(n) n^{-3/4}
\cos \left(4 \pi \sqrt{4 \pi}- \frac{\pi}{4} \right) + O(T^\epsilon),
$$
which follows from Voronoi's classical formula for $\Delta(T)$ (see
\cite{Voronoi1}, \cite{Voronoi2}), and is considerably simpler than Atkinson's
formula for $E(T)$. Indeed, for $E(T)$ it is not clear what the
corresponding Dirichlet series should look like, while for $\Delta
(T)$ it is obviously $\zeta^2 (s)$.

Lemmas \ref{c3:lem3.3} and \ref{c3:lem3.4} are from A. Ivi\'c
\cite{Ivic4}, where a more general result is proved. This enables one to
prove analogous results for error terms corresponding to Dirichlet
series with a functional equation involving multiple
gamma-factors. These error terms, studied extensively in the
fundamental papers of K. Chandrasekharan and R. Narasimhan \cite{Chandrasekharan and  Narasimhan1},
\cite{Chandrasekharan and  Narasimhan2}, \cite{Chandrasekharan and Narasimhan3}, involve functional equations of the form
$$
   \Delta(s) \varphi (s)  = \Delta (r-s) \Psi (r-s),
$$
where
$$
  \varphi (s)  = \sum_{n=1}^\infty f(n) \lambda_n^{-s},\quad \Psi (s) =
  \sum_{n=1}^\infty g(n) \mu_n^{-s},\quad \Delta(s) = \prod_{\nu=1}^N
  \Gamma(\alpha_\nu s+ \beta_\nu),
$$
$\alpha_{\nu}$'s are real, and some natural conditions on $\varphi$
and $\Psi$ are imposed. The class of functions possessing a functional
equation of the above type is large, and much work has been done on
this subject. For this the reader is referred to J.L. Hafner \cite{Hafner2},
where additional references\pageoriginale may be found.

For the method of transforming Dirichlet polynomials with the divisor
function see M. Jutila \cite{Jutila3}, \cite{Jutila6} and his monograph
\cite{Jutila9}. Further applications of this theory are to be found in
M. Jutila \cite{Jutila10}, \cite{Jutila11}, \cite{Jutila12}, \cite{Jutila13}, where among other things, he reproves H. Iwaniec's result \cite{Iwaniec1}
$$
\int\limits_T^{T+G} \left|\zeta \left(\frac{1}{2} +
it\right)\right|^{4} dt \ll T^\epsilon G \;  
\left(T^{2/3} \leq G \leq T\right)
$$
without the use of spectral theory and Kloosterman sums. The above
result will be proved in this text in Chapter \ref{c4} and Chapter \ref{c5}, where
the fourth moment will be extensively discussed.

The first part of Theorem \ref{c3:thm3.3} is contained in A. Ivi\'c
\cite{Ivic4}, while \eqref{c3:eq3.38} is new.

The first $\Omega$-result for $E(T)$, namely $E(T)= \Omega(T^{1/4})$,
was obtained by A. Good \cite{Good3}, and it of course follows also from
the mean value result of D.R. Heath-Brown \cite{Heath-Brown2}, given by
\eqref{c2:eq2.69}. Good's method is based on the use of a smoothed
approximate functional equation for $\zeta (s)$, obtained by the
method of Good \cite{Good1}. This approximate functional equation is
similar in nature to the one that will be used in Chapter \ref{c4} for the
investigation of higher power moments of $|\zeta(\frac{1}{2}+
it)|$. In \cite{Good2} Good obtained an explicit expression for $E(T)$,
similar to the one obtained by R. Balasubramanian \cite{Balasubramanian1}. The use of
the smoothing device, a common tool nowadays in analytic number theory,
makes Good's proof less complicated (his error term is only $0(1)$,
while Balasubramanian had $0(\log ^2 T)$). However, Good's final
formula contains expressions involving the smoothing functions that
are not of a simple nature. Good's method is powerful enough to enable
him in \cite{Good3} to derive an asymptotic formula for
$$
\int\limits_{0}^X (E (T + H) - E(T))^2 dT \qquad (H \ll X^{1/2}),
$$ 
and then to deduce from his result that $E(T) = \Omega (T^{1/4})$.

Theorem \ref{c3:thm3.4} is from Hafner -Ivi\'c \cite{ Hafner and Ivic1}.

Concerning\pageoriginale \eqref{c3:eq3.43} and Lemma \eqref{c3:eq3.5}
(the latter is due to J. L. Hafner \cite{Hafner1}), it should be remarked
that $(3+ \log 4)/4$ is the best possible exponent of $\log \log T$ in
\eqref{c3:eq3.43} that the method allows. This was observed by
S. Srinivasan, who remarked that in the proof one wants to have
$$
\sideset{}{'}\sum_{n \leq x} d(n)\geq (1- \delta) x\log x,
\sideset{}{'}\sum_{n \leq x} 1 \leq x/y 
$$ 
with $y$ as large as possible, where $\sum'$ denotes summation over a
subset of natural numbers. If $\alpha>1$, then by H\"older's
inequality it follows that
\begin{eqnarray*}
  & x \log x & \ll \sideset{}{'}\sum_{n \leq x}d (n) \leq \left(
  \sideset{}{'}\sum_{n \leq x} 1 \right)^{1-1/\alpha} \left(\sum_{n
    \leq x} d^\alpha (n) \right)^{1/\alpha}\\[5pt]
  & & \leq \left(\frac{x}{y} \right)^{1-1/\alpha} \left(x (\log
  x)^{2^\alpha-1}\right)^{1/\alpha},\\[5pt]
  \text{hence} & y & \ll (\log x)^{C(\alpha)},\\[5pt]
  \text{where}& C(\alpha) & = \frac{2^\alpha  -1 -\alpha}{\alpha-1}
  \to \log 4 -1
\end{eqnarray*}
as $\alpha \to 1 + O$. Thus it is only the small factors like $\exp
(C\sqrt{\log \log K})$ in Hafner's Lemma \ref{c3:lem3.5} that can be
possibly improved by this method.

In the proof of Lemma \ref{c3:lem3.5} one encounters sums (see
\eqref{c3:eq3.51}) which are a special case of the sum
$$
\sum_{n \leq x}d_k (n) \omega^m (n),
$$
where $m, k$ are fixed natural numbers. An analytic method is
presented in A. Ivi\'c \cite{Ivic2}, which enables one to evaluate
asymptotically sums of the form $\sum_{n \leq x} f (n)
  g(n)$, where $f(n)$ is a suitable ``small'' multiplicative, and
$g(n)$ a ``small'' additive function. In particular, it is proved
that, if $m, N\geq 1$ and $k \geq 2$ are fixed integers, then there
exist polynomials $P_{k, m, j}(t)$ $(j=1, \ldots , N)$ of degree $m$
in $t$ with computable coefficients such that
\begin{align*}
  \sum_{n \leq x}d_k (n) \omega^m (n) &= x \sum_{j=1}^N P_{k, m , j}
  (\log \log x) \log^{k-j}x\\ 
  &\qquad + O\left(x (\log x)^{k- N-1} (\log \log x)^m\right).
\end{align*}

For\pageoriginale a formulation and proof of Dirichlet's and
Kronecker's approximation theorems the reader is referred to Chapter 9
of Ivi\'c \cite{Ivic1}.

R. Balasubramanian's paper \cite{Balasubramanian2} in which he proves
\eqref{c3:eq3.76} is a continuation of Balasubramanian - Ramachandra
\cite{Balasubramanian and Ramachandra1}, where a weaker version of this result was proved
($\frac{3}{4}$ was replaced by a smaller constant). It turns out that
the limit of the value that  the method can give is only slightly
larger than $\frac{3}{4}$, so that any substantial improvement of
\eqref{c3:eq3.76} will require new ideas.

One can obtain a more precise result than $\chi \geq
\frac{1}{4}$. Namely, from the $\Omega_+$-result \eqref{c3:eq3.43} it
follows that
$$
t_{n+1}- t_{n} > B t^{1/4}_{n} (\log t_n)^{3/4} (\log \log
t_n)^{1/4(3+ \log 4)} \exp \left(-C\sqrt{\log \log \log t_n}\right)
$$  
for infinitely many $n$ with suitable $B, C > O$.

The conjecture \eqref{c3:eq3.82} was made by Ivi\'c- te Riele
\cite{Ivic1}. the numerical data are so far insufficient to make any
reasonable guess about the ``$O(1)$'' in the exponent on the
right-hand side of \eqref{c3:eq3.82}. 

The proof that
$$
\limsup_{n \to \infty} \frac{\log (u_{n+1} - u_n)}{\log u_n} = \frac{1}{2}
$$
is given by the author in \cite{Ivic4}, while Theorem \ref{c3:thm3.6} and
Theorem \ref{c3:thm3.7} are from \cite{Ivic2}. Thus the omega-result
\eqref{c3:eq3.106} answers the question posed in Ch. 15.4 of Ivi\'c
\cite{Ivic1}, and a weaker result of the same type was announced in
Ch. VII of E.C. Titchmarsh \cite{Titchmarsh1}. However, the argument given
therein is not quite correct (only $E(T) = \Omega (T^{1/4})$) is not
enough to give $F(T)= \Omega (T^{3/4}(\log T)^{-1})$. This oversight
was pointed out to me by D.R. Heath-Brown. Both Heath-Brown and
T. Meurman independently pointed out in correspondence how
\eqref{c3:eq3.104} is possible if \eqref{c3:eq3.43} is known. 

The bound \eqref{c3:eq3.107} is a special case of a useful general
result of P. Shiu \cite{Shiu1} on multiplicative functions.

