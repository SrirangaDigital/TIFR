
\chapter{Optimal Control of pd Processes}\label{chap2} %%% chap 2

General\pageoriginale formulations of stochastic control problems have
been studied 
using martingale theory, where the conditions for optimality,
existence of optimality are derived (E1 Karoui \cite{key15}). But this
does not give ways of computing optimal control. Control of Markov
jump processes has been studied using dynamic programming (Pliska
\cite{key21}). In this Chapter, we will be dealing with control theory for
$PD$ processes, following Vermes \cite{key25}. 

Let $Y$ be a compact metric space. Control arises when the system
functions $X, \lambda, Q$ contain a parameter $y ~ \in  ~ Y$
i.e., for $x = (\nu, \xi)$ 
\begin{align*}
  X^yf(x) & = \sum_i b(\nu,\xi,y) \frac{\partial f(\nu,\xi)}{\partial
    \xi_i}\\ 
  Q & = Q(A,x,y).
\end{align*}

A feedback \textit{policy} (or \textit{strategy}) is a function $u :
\mathbb{R}_+ \times ~ E ~ \rightarrow ~ Y$. Let $\mathscr{U}$ denote
the set of all strategies. $u$ is \textit{stationary} if there is no
$t$-dependence, i.e., $u : E ~ \rightarrow ~ Y$. Corresponding to
policy $u$ we get a $PD$ process with characteristics $ X^u,\lambda^u,
Q^u $ given by 
\begin{align*}
  X^u f & = \sum_i ~b(\nu,\xi,u(x)) ~ \frac{\partial f}{\partial
    \xi_i} ~ (x)\\ 
  \lambda^u(x) & = \lambda(x,u(x))\\
  Q^u(A;x) & = Q(A;x,u(x)).
\end{align*}

More conditions on $u$ will be added when required. Then we get a $PD$
process $x_t$ with probability measure $P^u$ determined by $X^u,
\lambda^u, Q^u$. 

Given\pageoriginale a cost function, say, for example,
$$
J_x(u) = E_x^u\left[\int\limits_o^t ~ e^{-\alpha s}~ c(x_s,u_s)ds +
  e^{-\alpha t}\phi(x_t)\right] 
$$
where $E_x^u$ is the expectation w.r.t. $P^u$ starting at $x$ and
$\alpha > 0$. The control problem is to choose $u(.)$ to minimise
$J_x(u)$. The ``usual'' approach to such problems is via ``dynamic
programming''. Let $V(s,x)$ be a function of $(s,x)$. Introduce the
Bellman-Hamilton-Jacobi equation 
\begin{equation}
  \frac{\partial V(s.x)}{\partial s} + \min_{y ~ \in  ~ Y}
       [A^yV(s,x) + c(x,y)] -\alpha ~V(s,x) = 0 \tag{B} 
\end{equation}
where $A^y$ is the generator corresponding to $X^y$, $\lambda(.,y)$,
$Q(.,y)$. 

If $Y$ has one point, then this coincides with the equation for $J_x$
as before. 

\begin{proposition}%proposition 1
  Suppose $(B)$ has a ``nice'' solution (i.e., satisfies boundary
  condition etc.). Then 
  $$
  V(o,x) = \min_{u ~ \in  ~ \mathscr{U}} ~ J_x(u)
  $$
  and the optimal strategy $u^o(s,x)$ satisfies
  $$
  A^{u^o(s,x)}V(s,x) + c(x,u^o(s,x)) = \min_{y ~\in  ~ Y} ~ (A^y ~ v+c).
  $$
\end{proposition}

\begin{proof}
  Same calculations arise as before. Let $x_t$ correspond to an
  arbitrary control policy $u$. Then  
  \begin{multline*}
    d(e^{-\alpha s}V(s,x_s)) = -\alpha e^{-\alpha s}V(s,x_s)ds +
    e^{-\alpha s} \left(\frac{\partial V}{\partial s} + A ^{u}V\right)ds \\
    + e^{-\alpha s}BV~dq \ge -e^{-\alpha s}c(x_s,u(s,x_s))ds +
    e^{-\alpha s}Bu~dq \tag{1}\label{chap2:eq1} 
  \end{multline*}

So\pageoriginale
\begin{align*}
  V(o,x) & \le E_x\left[\int\limits_o^t ~e^{-\alpha s} ~ c(x_s,u_s)ds +
    e^{-\alpha t} ~ \phi (x_t)\right]\\ 
  & = J_x(u).
\end{align*}
Now suppose $u=u^0$, then ``equality'' holds in place of
``inequality'' in (\ref{chap2:eq1}). So 
$$
V(0, x)=J_x(u_0).
$$
So $u^o$ is optimal.
\end{proof}

\medskip
\noindent{\textbf{Objections:}}
\begin{enumerate}
\renewcommand{\labelenumi}{(\theenumi)}
\item There is no general theory under which $(B)$ has solution.

\item $u^o(x)$ constructed as above may fail to be an admissible
  control: to make sense of it, we must be able to solve the ODE 
  $$
  \frac{d}{ds}\xi(s) = b^{u_o}_\nu(\xi_s) = b(\nu,\xi,u^o(s,\xi)).
  $$
\end{enumerate}

There is no guarantee that $u^o$ leads to a ``solvable'' ODE.

So we must redefine ``admissible controls'' so that this is avoided.

\begin{rem}%Remk 1
  In control of diffusion processes, the equation is 
  $$
  dx_t = b(x_t,u(x_t))dt + \sigma(x_t)dW_t.
  $$
\end{rem}

Here we ``handle'' nonsmooth $u$ by using weak solutions.

\begin{rem}%Remk 2
  In deterministic control, one uses open-loop controls depending only
  on time. The equation here is of the form 
  $$
  \dot{x} = b(x_t,u(t)).
  $$
\end{rem}

Then solution is well defined for the measurable $u(.)$.

\medskip
\noindent{\textbf{Special cases:}}\pageoriginale
\begin{enumerate}
\renewcommand{\labelenumi}{(\theenumi)}
\item Control only appears in $Q$. Then the problem reduces to a
  sequential decision problem where a ``decision'' is taken each time
  a jump occurs. (Rosberg, Varaiya and Walrand \cite{key22}).

\item $X=0$. Here Markov jump process with piecewise constant paths
  are considered. Control appears in $\lambda$ and $Q$.

  Then 
  $$
  A^u_f = \lambda (x, u(x))\left(\int\limits_E(f(z)-f(x))Q (dz; x,
  u(x))\right)  
  $$
  is a bounded operator on $B(E)$. Regard $(B)$ as an ODE in Banach
  space $B(E)$. Let $V(s):= V(s,.)$, then
  $$
  \frac{dV}{ds}= g(V(s)) = \min_{y \epsilon Y} (A^y V+ c).
  $$
  So $g$ is a nonlinear function, but it is Lipschitz continuous in $V$
  [Pliska \cite{key21}].

\item Piecewise linear processes (Vermes \cite{key25}).
\end{enumerate}

Here $\xi_t$ is on dimensional and $X=\frac{\partial}{\partial
  \xi}$. Control appears in $\lambda$ and $Q$.

Consider a `stationary' control problem, where the Bellman equation
takes the form
\begin{gather*}
  \min_{y \epsilon Y} (A^y V + c(x, y))=0\\
  V(x) = \Phi (x), \quad x \epsilon E_T.
\end{gather*}

This corresponds to minimising
$$
E_x \left( \int\limits_0^\tau c(x_s, u_s) ds + \Phi (x_\tau)\right),
$$
where $\tau$ is the first hitting time of some target set $E_T$. Then
$$
A^y V(x) = \frac{\partial}{\partial \xi} V(\nu, \xi)+ \lambda(x, y)
\int\limits_E (V(z)- V(x)) Q (dz, x, y).
$$

Suppose\pageoriginale $\nu \epsilon \{ 1, 2, \ldots, n\}$ and 
$$
V(\xi)=
\begin{pmatrix}
  V(l, \xi)\\
  V(N, \xi)
\end{pmatrix}
$$

Then Bellman equation takes the form
$$
\frac{d}{d \xi} V(\xi) = g(V(.)).
$$

This is an ``ordinary'' functional differential equation with 
non-stan\-dard boundary condition. Vermes showed existence of an optimal 
feedback strategy in special cases. 

\medskip
\noindent{\textbf{`Generalised' Dynamic Programming Conditions:}}

Let us consider next optimal control of the deterministic differential
system:
\begin{equation*}
  \dot x_t = f(x_t, t, u_t),  \,t \epsilon[t_o,
    t_l]. \tag{2}\label{chap2:eq2} 
\end{equation*}

Then the control problem is to 
$$
\text{minimize}~ \int\limits_{t_o}^{t_l} \ell (x_t, t, u_t) dt
$$
over ``admissible'' control/trajectory pairs $u_t, x_t$ i.e., pairs of
functions for which
\begin{itemize}
\item[{\rm (i)}] (\ref{chap2:eq2}) is satisfied,

\item[{\rm (ii)}] $x(t_l) = x_l$, $x(t_o)=x_o$ with $x_o, x_l$ given,

\item[{\rm (iii)}] $x_t \epsilon \bar{A}$, $u_t \epsilon \Omega$, where
  $\bar{A}, \Omega$ are compact and $A= \bar{A} \times [t_o, t_l]$.
\end{itemize}
This will be called the \textit{strong problem} $(S)$.

We assume (a) an admissible pair $(x_t, u_t)$ exists, and also we make
a temporary assumption


\medskip

 (b) \qquad 
$\begin{pmatrix}
  f(x, t, \Omega)\\[4pt]
  \ell (x, t, \Omega)
\end{pmatrix}$  \qquad  is convex. \pageoriginale 

This enables ``relaxed controls'' to be avoided. Define
$$
\displaylines{\hfill
\eta(S)= \text{``value'' of } S \hfill \cr
\text{i.e.,} \hfill \inf_{(x_t, u_t)ad}\int \ell dt. \hfill }
$$


\begin{thm} %%% 1
  There exists an optimal admissible pair $(x_t, u_t)$ for the strong
  problem. 
\end{thm}

This is a ``standard'' result in optimal control theory (Vinter and
Lewis \cite{key26}). It depends critically on the convexity assumption
(b). 


\medskip
\noindent{\textbf{A Sufficient Condition for Optimality:}}
 (Standard Dynamic Programming). Suppose $(x_t, u_t)$ is admissible
and $\Phi$ is in $C^1(A)$ such that 
$$
\displaylines{\hfill 
  \Phi_t (t, x) + \max_{u \epsilon \Omega} (\Phi_x (x, t) f(x, t, u) -
  \ell (x, t, u))=0\hfill \cr
  \hfill \Phi (x_l, t_l)\in A \times \Omega\hfill \cr
  \text{and}\hfill  
  \Phi_t (t, x_t) + \Phi (x_t, t) f(x_t, t, u_t)- \ell (x_t, t, u_t)=0
  \quad \text{a.a.t.} \hfill }
$$
then $(x_t, u_t)$ is optimal and $\eta(S)= - \Phi (x_o, t_o)$. The
main result of Vinter and Lewis is as follows.

\begin{thm} %%% 2
  The strong problem has a solution (i.e., there exists an optimal
  pair $(x_t, u_t)$). There exists a sequence $\{ \Phi^i\}$ in
  $C^1(A)$ such that
  \begin{align*}
    &\Phi^i_t + \max_{u \epsilon \Omega} (\Phi_x f - \ell) \leq o, (x,
    t) \epsilon A\\
    & \Phi^i(x_1, t_1) =0
  \end{align*}
  and\pageoriginale $(x_t, u_t)$ is optimal if and only if
  $$
  \displaylines{\hfill 
  \lim\limits_{t \to \infty} H^i (t) =0 ~\text{in}~ L_l [t_o,
    t_1]\hfill \cr
  \text{where}\hfill 
  H^i(t) = \Phi^i_t (x_t, t) + \Phi^i_x (x_t, t) f(x_t, t, u_t) - \ell
  (x_t, t, u_t).\hfill }
  $$
\end{thm}

\medskip
\noindent{\textbf{The Weak Problem}}

For $(x_t, u_t)$ admissible, define $\mu_{x, u} \epsilon C^* (A \times
\Omega)$, the dual of $C(A \times \Omega)$, by
$$
< g, \mu_{x, u}> = \int\limits_{t_o}^{t_l} g(x_t, t, u_t)~ dt
$$
for arbitrary $g \epsilon C(A \times \Omega)$. $\mu_{x, u}$ satisfies
\begin{itemize}
\item[{\rm (i)}] $\mu_{x, u} \epsilon P^+$ (i.e., if $g \geq o$ then
  $<g, \mu_{x,    u} > \geq o$).

\item[{\rm (ii)}] Take $\phi \epsilon C^1 (A)$ and $g(x, t, u)=
  \phi(x, t) +  \phi_x (x,t) f(x, t, u)$ 
\end{itemize}
then
$$
<\phi_t + \phi_x f, \mu_{x, u} > = \phi (x_l, t_l) - \phi (x_o, t_o).
$$
Define
$$
\mu = \{ \mu \epsilon C^* (A \times \Omega): ~\text{(i) and (ii) are
  satisfied} \}.
$$


\begin{proposition}%%% 2
  $\mu$ is weak* compact and convex.
\end{proposition}

\begin{Note}%%% 1
  The cost function for $(x_t, u_t)$ is $< \ell, \mu_{x, u}>$.
\end{Note}

\medskip
\noindent{\textbf{Weak Problem (W):}}\pageoriginale 
Minimise $<\ell, u>$ over $\mu \epsilon \mu$. So
$$
\eta (W) \leq \eta (S).
$$

\begin{thm}%%% 3
  $\eta(S) = \eta (W)$. There exists an optimal $x, u$ for $S$, so
  $\mu_{x, u}$ is optimal for $W$.
\end{thm}

Now we incorporate the constraints on $\mu$ into the cost function in
the following way. Define extended real valued functions $p$, $q$ on
$C^*(A \times \Omega)$ as follows:
$$
p(\mu)= 
\begin{cases}
  < \ell, \mu > & \text{ if }~ |\mu| \leq t_l- t_o, \mu \epsilon P^+\\ 
  + \infty & \text{ otherwise}.
\end{cases}
$$
Let $\mathscr{M}_2= \{\mu \epsilon C^*: ~\text{Condition (ii) is
  satisfied}\}$. Then
$$
q(\mu)=
\begin{cases}
  o & \text{if}~ \mu \epsilon M_2\\
  - \infty & \text{otherwise}.
\end{cases}
$$

\begin{proposition}%%% 3
\begin{tabbing}
 \hspace{3.5cm}\=$p$ \= is $\ell$. s.c. and convex,\\
  \>$q$ \> is u.s.c. and concave,
\end{tabbing}
and 
$$
\eta(W) = \inf_{\mu \epsilon C^*} \{ p (\mu) - q(\mu)\}.
$$
\end{proposition}

The Fenchel dual problem is as follows:
\begin{equation*}
  \max_{\xi \epsilon C(A \times \Omega)} (q^* (\xi) - p^* (\xi)) \tag{D}
\end{equation*}
where $p^*, q^*$ are ``dual'' functionals defined by
\begin{align*}
  p^* (\xi) & = \sup_{\mu \epsilon C^*} < \xi, \mu > - p(\mu).\\
  q^* (\xi) & = \inf_{\mu \epsilon C^*} < \xi, \mu > - q (\mu ).
\end{align*}

\begin{proposition}%%% 4
  $$
  p^* (\xi) = \max_{(x, t, u) \epsilon A \times \Omega} (\xi (t, x, u)
  - \ell (t, x, u))^+ \times (t_l -t_o).
  $$
  where\pageoriginale $a^+ := \max(a, 0)$.
\end{proposition}

\medskip
\noindent{\textbf{Sketch of proof:}}
\begin{align*}
  p^* (\xi) & = \sup_{\substack{|\mu| \leq t_l - t_o\\\mu \epsilon
      P^+}} [< \xi, \mu > - < \ell, \mu > ]\\
  & = \sup_{\substack{|\mu|\leq t_l - t_o\\\mu \epsilon P^+}}[< \xi -
    \ell, \mu > ].
\end{align*}

If $< \xi, \mu > - < \ell, \mu >$ is negative, then the optimum is
zero. If $< \xi, \mu > - < \ell, \mu > \geq o$, then put Dirac measure
$x(t_l- t_o)$ on maximum point to get the result.

\begin{proposition}%%% 5
  $$
  W= \{ \xi \epsilon C: \xi = \phi_t + \phi_x f ~\text{for some}~ \phi
  \epsilon C^l (A)\}.
  $$
  Then
  $$
  \displaylines{\hfill 
  q^* (\xi)= 
  \begin{cases}
    - \infty & \text{if}~ \xi \not\in \bar{W}\\
    \lim\limits_{i} (\phi^i(x_1, t_1) - \phi^i (x_o, t_o)) &
    \text{if}~ \xi \epsilon \bar{W}
  \end{cases}\hfill \cr
  \text{where} \hfill \xi = \lim\limits_{i} \xi^i ~\text{and}~ \xi^i =
  \phi^i_t + \phi^i_x f.\hfill}
  $$
\end{proposition}

\begin{proof}
  For $\xi \epsilon W$, by definition of $q$ and $q^*$, we get $q^*
  (\xi) = \phi (x_1 , t_1) - \phi (x_0, t_o)$.

A similar argument gives the result for $u \epsilon \bar{W}$. For $\xi
\not\in  \bar{W}$, there exists a separating hyperplane, i.e.,
$\bar{\mu} \epsilon C^*$ such that $< \bar{\xi}, \bar{\mu} > \neq 0,
\bar{\xi} \epsilon \bar{W}$ and $< \xi, \bar{\mu} > =0$. If $\mu
\epsilon \mathscr{M}_2$, then $\mu + c \bar{\mu} \epsilon M_2$. So
$$
q^* (\xi) = \inf_{\mu \epsilon M_2} < \xi, \mu > = - \infty.
$$
\end{proof}

Characterizing\pageoriginale the solution of (D):
\begin{align*}
  \eta(D) & = \max_{\xi \epsilon \bar{W}} \left[\vphantom{\max_{\xi
        \epsilon \bar{W}}}  \lim\limits_{i} (\phi^i
    (x_1, t_1) - \phi^i (x_o, t_o))\right.\\ 
    & \left.\quad - \max_{(x, t) \epsilon A \times 
      \Omega} (\xi (t, x, u)- \ell (t, x, u)^+ (t_l, t_o))\right]\\
  & = \sup_{\phi \epsilon C^*} (\phi (x_1, t_1) - \phi (x_o, t_o)-
  \max_{x, t, u} (\phi_t+ \phi_x f- \ell)^+ (t_l-t_o)).
\end{align*}
It is no restriction to assume $\phi (x_1, t_1)=0$. Then Vinter and
Lewis show by an ingenious argument that
$$
\eta (D)= \sup (- \phi (x_o , t_o))
$$
where the supremum over $\phi \epsilon C^l$ such that $\phi (x_1,
t_1)=0$ and $(\phi_t+ \phi_x f- \ell) \leq 0 ~\forall~ (x, t, u)$.

\begin{thm}%%% 4
  $$
  \eta (D) = \eta (W)= \eta (S).
  $$
\end{thm}

\begin{proof}
  This follows from a ``standard'' result in duality theory: $q^*$ is
  finite at some point in its domain where $p^*$ is continuous.
\end{proof}

Proof of the main results now follow easily. The strong problem has a
solution since $\eta(S)= \eta(D)$.
$$
\eta(S)= \lim (- \phi^i (x_o, t_o))
$$
for some sequence of $\phi^i$'s satisfying the ``Bellman
inequality''. The characterization of optimal pairs $(x_t, u_t)$
follows.

\begin{rem}%%% 3
  If\pageoriginale the set
  $$
  \begin{pmatrix}
    f(x, t, \Omega)\\
    \ell (x, t, \Omega)
  \end{pmatrix}
  $$
  is not convex, them the results are still valid but \textit{relaxed
    controls} must be used. 
\end{rem}

A relaxed control $\mu_t$ is a $C^* (\Omega)$-valued function on
$[t_o, t_1]$ such that $\mu_t$ is a probability measure for every $t$
and $t \to \int g(t, u) \mu_t(du)$ is measurable for every continuous
function $g$.


\medskip
\noindent{\textbf{Interpretation:}}
 $x_t$, $\mu_t$ is an admissible pair, whenever 
$$
\displaylines{\hfill
\frac{dx_t}{dt} = \int\limits_\Omega f(x_t, t, u) \mu_t (du);\hfill \cr
\text{the cost is}\hfill
\int\limits_{t_o}^{t_l} \int\limits_\Omega f(x_t, t, u) \mu_t (du) dt.\hfill}
$$

\medskip
\noindent{\textbf{Optimal Control PD Processes (Vermes \cite{key25})}}

In this section, we adopt a slightly modified definition of the PD
process $(x_t)$. It will take values in $E$, a closed subset of
$\mathbb{R}^d$, and we suppose that 
$$
E= E_o U E_\partial U E_T \qquad \text{(disjoint)}
$$
where $E_T$ is a closed set, $E_o$ is an open set and 
$$
E_\partial = (\bar{E}_o - E_o) - E_T.
$$

Let $E'_o$, $E'_\partial$, $E'_T$ be compactification of $E_o$,
$E_\partial$, $E_T$ respectively and $E'$ be the disjoint union of
$E'_o$, $E'_\partial$, and $E'_T$. Then a controlled PD process is
determined by functions
$$
\displaylines{\hfill
  f : E'_o \times Y \to \mathbb{R}^d;\hfill\cr
  \hfill\lambda  : E'_o \times Y \to \mathbb{R}_+,\hfill \cr
  \text{and}\hfill 
  Q: (E'_o U E') \times Y \to m_1 (E_o) \hfill}
$$
where\pageoriginale $m_l(E_o)$ is the set of probability measures on
$E_o$ and $Y$ is a compact (control) space. Function $f$ gives the
deterministic motion by 
$$
\dot{x}_t = f(x_t, y_t).
$$

We assume $f$ satisfies a Lipschitz condition in $x$.

\noindent
\textbf{Admissible Controls:} Feed back controls $u(t)= u(x_t)$ are
not the\break ``right'' class of controls because the equation $x=f(x,
u(x))$ only has a unique solution under strict conditions on
$u(.)$. Let
\begin{align*}
  \alpha_t & =~\text{last jump time before}~ t.\\
  n(t) & = x_{\alpha (t)}\\
  z(t) & = t- \alpha(t).
\end{align*}

Then $n(t)$, $z(t)$ determine $x_t$; in fact, for fixed $y\epsilon Y$, 
$$
\displaylines{\hfill x_t= X_{n(t), z(t)}\hfill \cr
\text{where}\hfill X_{n, z} = n + \int\limits_o^z f(X_{n,s}, y)ds.\hfill}
$$

Then admissible controls are $Y$-valued measurable functions\break $u(n(t), 
z(t))$. By Caratheodory's theorem, the equation
$$
X_{n, z} = n+ \int\limits_o^z f(X_{n, s}, u(n, s)) ds
$$
has\pageoriginale a unique solution, and PD process is well defined
for such $u$. We will consider the three component process $(x_t, z_t,
n_t)$ for notational convenience. 

\medskip
\noindent{\textbf{Relaxed controls}}
 are functions $\mu: E \times \mathbb{R}_+
\to m_1 (Y)$ such that $(n, z)\to \int \phi (n, z, y) \mu (dy; n, z)$
is a measurable function for $(n, z)$ for all continuous
$\phi$. Corresponding to $\mu$, define
\begin{align*}
  f^\mu (x, n, z) & = \int f(x, y) \mu (dy, n, z)\\
  \lambda^\mu (x, n, z) & = \int \lambda (x, y) \mu (dy; n, z)\\
  Q^\mu (A, x, n, z) & = \int Q(A, x, y) \mu (dy, n, z).
\end{align*}

Then we construct a PD process $(x_t, n_t, z_t)$ corresponding to
$f^\mu$, $\lambda^\mu$, $Q^\mu$ in the usual way.

The \textit{strong problem} is to minimise $J_{\hat{x}_o}(\mu)$ over
admissible relaxed controls $\mu$, where $\hat{x}_o= (x, x, o)$, and 
\begin{multline*}
  J_{\hat{x}_o}(\mu) = E^\mu_{x_o} \left(\int\limits_o^\tau
  \int\limits_Y \ell_o (x_t, y)  \mu (dy; n_t, z_t) dt \right.\\
  \left. + \sum\limits_{\left\{ t: x_{t-} \epsilon E_\partial \right\}} \int
  \ell_o (x_{t-}, y) \mu (dy; n_{t-}, z_{t-})+ \ell_T (x_\tau)\right).  
\end{multline*}
Here $\tau$ is the first hitting time of set $E_T$.

\medskip
\noindent{\textbf{Main Results:}}

\begin{thm}%%% 5
  There exists an optimal (relaxed) control.
\end{thm}

\begin{thm}%%% 6
  The value function $\psi (x)= \sup \phi (x, x, o)$ where the
  supremum is over all functions $\phi \epsilon C^1(E)$ such that 
  \begin{align*}
    \phi_z &(x, n, z)  + \min_{y \epsilon Y}
    \left(\vphantom{\int}\nabla_x \phi (x, n, z) 
    f(x, y) + \lambda(x, y)\right.\\ 
     & \left. \left(\int \phi ( \xi, \xi, o) Q (d \xi, x, y)
    - \phi (x, n, z)\right) + \ell_o (x, y) \right) ~(x, n, z) \epsilon
    \tilde{E}_o \tag{3}\label{chap2:eq3}\\
    & \geq 0\\
    \phi & (x, n, z) \leq \min_{y \epsilon Y} \left\{ \int \phi (\xi,
    \xi, o) Q (d \xi, y, x) + \ell_o (x, y)\right\} (x, n, z) \epsilon
    \tilde{E}_\partial \tag{4}\label{chap2:eq4}\\
    \phi & (x, n, z) \leq \ell_T (x), \quad x \epsilon E_T
    \tag{5}\label{chap2:eq5} 
  \end{align*}
and\pageoriginale $\tilde{E}$ is the space of triplets $(x, n, z)$.
\end{thm}

\begin{thm}%%% 7
  There exists a sequence $\phi^k$ satisfying (\ref{chap2:eq3}),
  (\ref{chap2:eq4}), (\ref{chap2:eq5}) above such
  that $\mu^o$ is optimal if and only if 
  \begin{align*}
    \phi^k  (x, n, z) & + \int\limits_Y \left\{\nabla_x \phi^k (x, n,
    z) f(x, y) + \lambda (x, y)\right\}\\ 
    & \quad \left[ \int \phi^k (\xi, \xi,0)
      \vphantom{\int}\times Q (d \xi, x, y) - \phi^k (x, n,
      z)\right]\\ 
    & \hspace{2cm}+ \ell_o (x, y) \mu^o (dy, n, z) 
    \to o ~\text{in}~ L_l (Q^o_o). \tag{6}\label{chap2:eq6}\\
    & \int\limits_Y \left\{ \int\limits_{E_o} \phi^k (\xi, \xi, o) Q
    (d \xi, x, y) + \ell_o(x, y)\right\}\mu^o (dy,n, z)\\
    & \hspace{2cm}- \phi^k (x, n, z) \to 0 ~\text{in}~ L_l (Q^o_\partial)
    \tag{7}\label{chap2:eq7}\\
    \phi^k (x, n, z) &- \ell_T (x) \to 0 ~\text{in}~ L_1
    (Q^o_T).\tag{8}\label{chap2:eq8} 
  \end{align*}
The measures $Q^o_o$, $Q^o_\partial$ and $Q^o_T$ are defined as
follows. 

Denote $\tilde{x}_t= (x_t, n_t, z_t)$. For $A \epsilon
\tilde{E}_o$,
$$
Q^o_o (A)= \tilde{E}^{\mu_o}_{\hat{x}_o} \int\limits^\tau_o \psi_A
(\tilde{x}_t) dt
$$ 
which\pageoriginale is a measure on $\tilde{E}_o$ and is called
potential measure of $\tilde{x}_t$. 
$$
Q^o_\partial (A)= \tilde{E}^{\mu_o}_{\hat{x}_o} \sum\limits_{t \leq
  \tau} \psi_A (\tilde{x}_{t-})
$$
where $A \in  \tilde{E}_\partial$.
$$
Q^o_T (A)= \tilde{P}^{\mu_o}_{\hat{x}_o}  [\tilde{x}_T \in  A]
$$
for $A \in  \tilde{E}_T$.
\end{thm}

Comparing with deterministic case, the necessary and sufficient
condition there was that $(x_t, \mu_t)$ is optimal if and only if 
$$
\phi^i_t (x_t, t) + \int \left\{\phi^i_x (x_t, t) f(x_t, t, u)- \ell
(x_t, t, u)\right\}\mu_t (du) \to o ~\text{in}~ L_l (t_0, t_1).
$$

The ``probability measure'' corresponding to $\mu_t$ is Dirac measure
on $x(.)$ and $Q^o_o (A)$ is the time spent by $x(.)$ in $A$. Thus the
conditions stated are a direct generalization of the deterministic
ones. 

\begin{rem}%%% 4
  Note that if we define
  $$
  Q^o_o(A) = E_{\tilde{x}} \int^\tau_o \psi_A (\tilde{x}_s) ds
  $$
  then for any positive measurable function $g$,
  $$
  \displaylines{\hfill 
  E_{\tilde{x}} \int^\tau_og(\tilde{x}_s) ds =
  \int\limits_{\tilde{E}_o} g(\xi) Q^o_o (d \xi);\hfill \cr
  \text{for, if} \hfill 
  g (\tilde{x})= \sum_{i}c_i \psi_{A_i} (\tilde{x})\hfill }
  $$
then\pageoriginale 
\begin{align*}
  E_{\tilde{x}} \int\limits_{o}^{\tau} g(\tilde{x}_s) ds&= \sum_{i}
  c_i E_x \int\limits_{0}^{\tau} \psi_{A_i} (\tilde{x}_s) ds\\ 
  &=\sum\limits_{i} c_i Q^\circ_\circ(A_i)\\ 
  &= \int\limits_{E_o} g(\xi)~ Q(d \xi).
\end{align*}
The general case follows by monotone convergence.
\end{rem}

\begin{rem}%rem 5
The $Q^\circ_i$ are ``potentials of additive functionals'' $\ell_t$ is an
\textit{additive functional} if $\ell \ge o$ and\footnote{$\theta_t$
  is the shift operator on the space of right continuous 
  functions: $(\theta_t w)_s= \omega_{t+s}$}
 
$$
\ell_{t+s}= \ell_t+\ell_s o \theta_t
$$
$t, p^*_t, I_{(t \ge \tau)}$ are some example of additive functionals.
\end{rem}

The potential of an additive functional is an operator 
$$
U_\ell g(\tilde{x}) = E_{\tilde{x}} \int\limits_{o}^\tau g(\tilde{x}_s)d \ell_s.
$$

Here $Q^o_O,Q^o_\partial, Q^o_T$ correspond precisely to this with
$\ell_t=t, p^*_t, I_{(t>T)}$ respectively. 


\medskip
\noindent{\textbf{The Weak Problem:}} 

The deterministic weak problem involved the fact that
$$
\phi(x_1, t_1)- \phi(x_o, t_o) = \int\limits_{t_o}^{t_1} ( \phi_t + \phi_xf)ds
$$
for any $\phi~ \in  ~C^1$. The stochastic equivalent of this is
Dynkin's formula. To get this in the appropriate form, \textit{define
  operators} $A^y, B^y$ as follows. 
\begin{align*}
  A^y \phi (x, n,z)&= \phi_z(x,n,z) + \triangledown_x \phi (x,n,z)f(x,y)\\
  & \hspace{1cm}+ \lambda(x,y) \int\limits_{\tilde{E}_O} (\phi( \xi, \xi,o)  -
  \phi(x,n,z)) Q (d \xi, x,y)\\
  \text{and}\quad  
  B^y \phi(x,n,z)&= \int\limits_{E_\partial} \phi(\xi, \xi,o)Q(d \xi,
  x,y) - \phi(x,n,z)
\end{align*}
for\pageoriginale $(x,n,z) \in  \tilde{E}_\partial$. Then the Dynkin formula
on the interval $(o, \tau)$ is  
\begin{align*}
  \tilde{E}^\mu_{\hat{x}} \phi(x_\tau, n_\tau, z_\tau) & - \phi(\hat{x})\\
  &={E}^\mu_{\hat{x}} \left[ \int\limits_{o}^\tau \int\limits_{Y} A^y
    \phi(x_t, n_t, z_t) \mu (dy; n_t, z_t) dt\right.\\
    & \left.\quad + \int\limits_{o}^\tau
    \int\limits_{Y} B^y \phi (x_t, n_t, z_t) \mu (dy, z_t,n_t)dp^*_t\right] \\
  &= \int\limits_{\tilde{E}_o} \int\limits_{Y} A^y \phi (x,n,z) \mu (dy;
  n,z)Q^\mu_o (dx,dn,dz)\\ 
  & \quad +  \int\limits_{\tilde{E}_d} \int\limits_{Y}
  B^y \phi (x,n,z) \mu (dy; x,z)Q^\mu_o (dx,dn,dz) 
\end{align*}
Now
$$
\tilde{E}^\mu_{\hat{x}} \phi(x_\tau, n_\tau, z_\tau)=
\int\limits_{\tilde{E}_T} \phi (x,n,z) Q^\mu _T(dx,dn,dz). 
$$
So we can express the Dynkin formula as follows:
$$
\displaylines{\hfill
  \phi(\hat{x}_o)=  \int\limits_{\tilde{E} \times Y} L \phi(\tilde{x}, y)
  M^\mu (d \tilde{x}, dy) \hfill \cr 
  \text{where}\hfill
  L \phi(x,n,z,y)= \psi_{\tilde{E}_T} \phi (x,n,z)
  + \psi_{\hat{E}_o} A^y \phi (x,n,z)+  \psi_{\tilde{E}_\partial}
  B^Y(x,n,z). \hfill }
$$
\begin{multline*}
  M^\mu \left(S_1 \times S_2\right)= Q^\mu_T \left(S_1 \bigcap
  \tilde{E}_T\right)
  +\int\limits_{ S_1  \bigcap \tilde{E}_o} \int\limits_{S_2} \mu
  (dy;n,z)Q^\mu_o (dx,dn,dz)\\ +  \int\limits_{S_1 \bigcap
    \tilde{E}_\partial} \int\limits_{S_2} \mu (dy;n,z)Q^\mu_\partial
  (dx,dn,dz). 
\end{multline*}

The\pageoriginale cost for the relaxed control $\mu$ is 
$$
J_{\hat{x}_o} (\mu) = \int\limits_{E \times Y} \ell (\tilde{x},
y)M^\mu(d \tilde{x}, dy). 
$$

The following supplementary assumption is required. 
$$
\inf_{u \in  u} J_{\hat{x}_o} (\mu) = \inf\limits_{\mu
  \in  u_o} J_{\hat{x}_o} (\mu) 
$$
for some $c>o$ and $u$ is the set of relaxed controls,
$$
u_c= \left\{\mu \in  u: \mu \in  [\tau+ p^*_\tau] \le c\right\}
$$
with this assumption the weak problem is to minimize
$\int\limits_{\bar{E} \times Y}{\ell dM}$ over measures $M \in 
m_{1+c}(\tilde{E} \times Y)$  (where $m_a$ is the set positive
measures of total mass less than or equal to a) such that 
\begin{enumerate}
\item $M = M_o +  M_\partial + M_T$

  where
  \vskip -1.4cm 
  \begin{align*}
    &M_T~ \in ~ m_1~ (\tilde{E}_T).\\
    &M_\partial~ \in ~ m(\tilde{E}_\partial ~\times~ Y)\\
    &M_O~ \in  ~m(\tilde{E}_o ~\times ~Y).
  \end{align*}

\item $\phi(\hat{x}_o)  = \int L \phi dM, \phi \in  C^1 (\tilde{E})$.
\end{enumerate} 
 
 From\pageoriginale this point on, the development follows the Vinter-Lewis
 arguments closely. We reformulate the weak problem as a convex
 optimization problem by incorporating the constrains in the cost
 function and obtain the characterization of optimality by studying
 the dual problem. The reader is referred to Vermes \cite{key25} for
 the  details.  
 
 \begin{rem}%rema 6
   The optimality condition involves the measures $Q^o_O,
   Q^o_\partial, Q^o_T$ corresponding to $\mu^o$. These can be
   computed from the following system of equations. 
 \begin{align*}
   & A^{\mu^o}h(\tilde{x})+ \psi_{\Gamma \bigcap E_o} = 0, \tilde{x}
     \in  \tilde{E}_O\\ 
   & B^{\mu^o}h(\tilde{x})+ \psi_{\Gamma \bigcap \tilde{E}_\partial} = 0,
     \tilde{x} \in  \tilde{E}_\partial\\ 
   & h(\tilde{x})+ \psi_{\Gamma \bigcap \tilde{E}_T}
     \tilde{(x)}, \tilde{x} \in  \tilde{E}_T.\\ 
 \end{align*} 
 \end{rem}

 Then 
 $$
 Q^o(\Gamma) = h(\hat{x}_o).
 $$

\setcounter{exam}{0} 
\begin{exam}%exam 1
   If $\Gamma \subset \tilde{E}_o$, then Dynkin's formula says
   \begin{align*}
     h (\hat{x}_o) &= E^{\mu^o}_{\hat{x}_O} \int\limits_{O}^\tau
     \psi_\Gamma(\tilde{x}_s) ds\\ 
     &= Q^o_O(\Gamma).
   \end{align*}
\end{exam} 
 
 The results outlined above are the first general results on optimal
 control of $PD$ processes. Obviously much work remains to be done;
 natural next steps would be to determine necessary conditions for
 optimality of Pontrjagin type; to develop computational methods; and
 to study optimal stopping and ``impulse control'' for $PD$
 processes. For some related work, see van der Duyn Schouton \cite{key29},
 Yushkevich \cite{key30} and Rishel \cite{key31}.  
 


