
\chapter[Differential equations concerning ....]{Differential equations concerning angular characters of
  positive quadratic forms}%cha 17 


The\pageoriginale notion of angular characters was first introduced by
Hecke in the study of algebraic number fields. These are functions $u$
defined on the non zero elements of a give algebraic number field $K$
such that   
\begin{enumerate}
\item $u (\alpha) = u (r \alpha \varepsilon)$ for rational numbers $r
  \neq 0$ and units $\in$ of $K$ 

\item For a given $\alpha \in K$, $\alpha \neq 0$, the set of values $u
  (\alpha)$ (for the different $u's$) and the norm $N_\alpha$ of
  $\alpha$ determine the principal ideal ($\alpha$) of $\alpha$ 
\end{enumerate}

It is possible to realise the angular characters $u$ ($\alpha$) with
the variable $\alpha$ as solution of a certain eigen value problem and
this enables us to carry out certain explicit analytic computations
with $u(\alpha)$. Analogous considerations can be developed for
positive quadratic forms. Here we ask for functions $u (y)$ defined on
the space of positive matrices $y = y^{(n)}$ which are invariant
relative to the transformations $y \rightarrow r y[u]$ where $r$ is a
positive real number and $u$, an unimodular matrix, such that the
determinant $|y|$ and the set of all values $u(y)$ for a given $y$
determine uniquely the class  of matrices $y[u]$ which are equivalent
with $y$. It can be expected that suitable functions $u(y)$ appear
again as solutions of an eigen value problem. The use of such angular
characters will be particularly felt in determining a set of Dirichlet
series equivalent with a give modular form of degree $n$ in analogy with a
theory of Hecke. A satisfactory treatment of the theory of
angular\pageoriginale characters for positive quadratic forms has so
far been possible only in the case $n=2$. We now make our above
statements precise.  

Consider a space of $n$ real coordinates $y_\nu > 0, \nu = 1.2 \ldots
n$, and the linear differential operators $\Omega$ in this space, 
\begin{equation*}
\Omega = \sum C_{{\nu_1}{\nu_1}} \ldots \nu_n \frac{\partial
  ^{\nu_1}}{\partial y^{\nu_2}_2} \ldots \frac{\partial
  ^{\nu_n}}{\partial y^{\nu_n}_n} \tag{350}\label{eq350} 
\end{equation*}

We shall denote by $\psi$ the set of all such operators
$\Omega$ which are invariant relative to the group of mappings
$$
\mathscr{Y}_\nu \rightarrow \mathscr{Y}^*_\nu  = a_\nu y_\nu , \nu =
1, 2 \ldots n 
$$
where there $a_\nu '\mathscr{S}$ are arbitrary positive real
numbers. Given any algebraic number field $K-$ for simplicity we
assume $K$ to be totally real - we can associate with $K$ a space of
$n$ real coordinates as follows. Let the dimension of $K$ over the
field of rationals be $n$, and for $\alpha \in K$, let $\alpha^{(1)} ,
\alpha^{(2)}, \ldots \alpha^{(n)} $ denote the conjugates of
$\alpha$. We then set $\mathscr{Y}_\nu = |\alpha^{(\nu)}| , \nu = 1, 2
\ldots n , |\alpha^{(\nu)}|$  denoting the absolute value of
$\alpha^{(\nu)}$. 

The angular characters of $K$ are functions \; $u (\alpha) = u
(\alpha^{(1)}, \ldots \alpha^{(\nu)})$ of $n$ real variables which
depend only on the absolute values\break $|\alpha^{(1)}| , |\alpha^{(2)}|,
\ldots |\alpha^{(n)}|$ of the variables, and which satisfy the
following conditions:- 
\begin{enumerate}
\item $u$ is an eigen function of every differential operator $\Omega
  \in \mathscr{P}$ 

\item $u$ is invariant relative to the mappings $\mathscr{Y}_\nu
  \rightarrow r \mathscr{Y}_\nu$ where $r$ is an arbitrary positive
  real number. 

\item $u$ is invariant relative to the unit group of $K$ 
\end{enumerate}

We\pageoriginale shall look into these defining properties of $u$ a
little more 
closely. Clearly all the operators $\mathscr{Y}_\nu
\dfrac{\partial}{\partial y_\nu}, \nu = 1,2 \ldots n$ lie in
$\psi$, and it is easily seen that these operators actually
generate $\psi$, meaning that any operator in $\psi$ is
a polynomial of the type  
$$
\sigma_{\nu_1 \nu_2 .. \nu_n} a_{\nu_1 \nu_2 \ldots \nu_n}
(\mathscr{Y}_1 \frac{\partial}{\partial y_1})^{\nu_1} \ldots
(\mathscr{Y}_n \frac{\partial}{\partial y_n})^{\nu_n} 
$$
with constant coefficient $a_{\nu_1 \nu_2 \ldots \nu_n}$. Then the
first condition on $u$ reduces to the requirement that $u$ is an eigen
function of each $ \mathscr{Y}_\nu \dfrac{\partial}{\partial y_\nu} ,
\nu = 1,2 \ldots n$, in other words that  
$$
(\mathscr{Y}_\nu \frac{\partial}{\partial y_\nu} +  \lambda_\nu) u =
0, \nu = 1,2 \ldots n 
$$
with appropriate $\lambda_\nu 's$. Hence we conclude that  
\begin{equation*}
u = C \prod^n_{\nu = 1} \mathscr{Y}^{- \lambda_\nu}_\nu \tag{351}\label{eq351} 
\end{equation*}

The second condition on $u$ requires that $u$ is homogeneous of degree
$0$ in $Y_1 , Y_2, \ldots Y_n$ and then  
\begin{equation*}
\sum^n_{\nu = 1} y_\nu \frac{\partial}{\partial Y_\nu} u = 0
\tag{352}\label{eq352}  
\end{equation*}
form which it follows that $\sum^n_{\nu = 1} \lambda_\nu = 0$ 

We now come to the last condition on $u$. It is well known that any
unit of $K$ is a power product of $n-1$ fundamental units $
\mathscr{E}_1 , \mathscr{E}_2 \ldots \mathscr{E}_{n-1}$ multiplied by
a certain root of unity. Hence the last condition only amounts to
requiring that $u$ is invariant under the mappings \break $Y_\nu \rightarrow
Y_\nu |\mathscr{E}^{(\nu)}_{\mu}|, \mu = 1,2 \ldots n - 1$. Then  
\begin{align*}
\prod^n_{\nu = s} (y_\nu |\mathscr{E}^{(\nu)}_{\mu}|)^{\lambda_\nu} &
= \prod^n_{\nu = s} y^{- \lambda_\nu}_{\nu} \text{ so that} \\ 
\prod^n_{\nu = 1}| \mathscr{E}^{(\nu)}_{K}| ^{-\lambda_\nu} & = 1, \mu
= 1,2, \ldots n -1  
\end{align*}

Together\pageoriginale with (\ref{eq352}) this can be written as  
\begin{align*}
\sum^n_{\nu = 1} \lambda_\nu & = 0 \\ 
\sum^n_{\nu = 1} \lambda_\nu \log | \varepsilon^{(n)}_{\mu}| & = 2
\mathfrak{K}_\mu \pi i \big \} i \mu = 1,2, \ldots n -1 
\end{align*}

For a given set of integers $\mathfrak{K}_\mu$ these $n$ equations
define uniquely the $n$ eigen values $\lambda_1 , \lambda_2 \ldots
\lambda_n$ and hence also $u$ by (\ref{eq351}). Varying systems of
$\mathfrak{K}'s$ determine the different $u 's$. 

We now generalise these considerations for positive quadratic forms or
what is the same for positive matrices. Here $\psi$ will stand
for the set of all linear differential operators $\Omega$ on the space
of positive matrices $Y^{(n)}$ which are invariant relative to the
group of mappings $T \rightarrow Y [R], R$ being an arbitrary non
singular matrix. As in the earlier case we can show that the operators
$\sigma (Y \dfrac{\partial}{\partial Y})^\mathfrak{K} \in \psi,
\mathfrak{K} = 1,2 \ldots n$ and they generate $\psi$ where as
usual, $\dfrac{\partial}{\partial y} = (e_{\mu
  ,\nu}\dfrac{\partial}{\partial y_{\mu, \nu}})$. Let $Y^* = Y [R], R$
non singular. For an arbitrary function $f(y)$ we have for the
total differential,  
$$
df = \sigma (d y \frac{\partial}{\partial y} f) = \sigma( d y^*
\frac{\partial}{\partial y^*}f) 
$$

Also $d y^* = (dy) [R]$ so that
$$
 \sigma (d y \frac{\partial}{\partial y} f) = df =  \sigma (d y^*
 \frac{\partial}{\partial y^*} f) =  \sigma (d y  R
 \frac{\partial}{\partial y^*} fR') 
$$
and consequently,
$$
\frac{\partial}{\partial y} =  R \frac{\partial}{\partial y^*} R'
\frac{\partial}{\partial y^*} = \frac{\partial}{\partial y} [R^{-1}] 
$$

Then 
\begin{equation*}
( Y^* \frac{\partial}{\partial y^*})^* R' (Y \frac{\partial}{\partial
    y})^R R^{-1}, \mathfrak{K} = 1,2,\ldots n, \tag{353}\label{eq353}  
\end{equation*}
and\pageoriginale
\begin{equation*}
\sigma (Y^* \frac{\partial}{\partial y^*})^\mathfrak{K} = \sigma (Y
\frac{\partial}{\partial y})^{\mathfrak{K}} \tag{354}\label{eq354}  
\end{equation*}

This proves that $\sigma ( Y \dfrac{\partial}{\partial y})^\mathfrak{K}
\in \psi, \mathfrak{K} = 1,2 \ldots n$. Consider now any
operator $\Omega \in \psi$. As a linear operator it is of the
form 
$$
\Omega = \Omega (y , \frac{\partial}{\partial y}) = \sum_{R_1} C_{R_1}
(y) \prod^n_{\mu , \nu = 1} \frac{\partial^{\mu \nu}}{\partial y^{s
    \mu \nu}_{\mu \nu}} \varrho_{\mu \nu \geq 0}\text{integral}, 
$$
and $R_1 = (\varrho_{\mu \nu}) = R'_1$.

Since $\Omega$ is invariant relative to the mapping $Y \rightarrow y^*
= y [R], R$ nonsingular, we have  
\begin{equation*}
\Omega (Y[R], \frac{\partial}{\partial y} [R^{-1}]) = \Omega (y,
\frac{\partial}{\partial y}), |R| \neq 0 \tag{355}\label{eq355}  
\end{equation*}

Let $Y_0$ by an arbitrary point an let $V$ be such that $Y_0 [V] =
E$. Let $u$ be an arbitrary orthogonal matrix ($u' u = E$) and set $R
= V u$. Then 
\begin{equation*}
Y_0 [R] = (Y_o[V]) [u] = E .\tag{356}\label{eq356}
\end{equation*}

Let $f(y)$ be an arbitrary function and define 
\begin{equation*}
g (y) = \Omega (y \frac{\partial}{\partial y}) f (y) \tag{357}\label{eq357}
\end{equation*}

With $Y^* = y[V]$ we have $\dfrac{\partial}{\partial y^*} =
\dfrac{\partial}{\partial y} [V^{-1}]$ so that  
$$
\frac{\partial}{\partial y} [R^{-1}] = (\frac{\partial}{\partial
  y}[V^{-1}]) [u] = \frac{\partial}{\partial y^*} [u] 
$$

Then from (\ref{eq355}), (\ref{eq356}) and (\ref{eq357}) we have 
\begin{align*}
g (y_0) & = \{ \Omega (y_0 , \frac{\partial}{\partial y})  f (y) \}_{y
  = y_o} \\ 
& = \{ \Omega (E, \frac{\partial}{\partial y^*} [u]) f (y^* [V^{-1}])
\}_{y^* = E} \tag{358}\label{eq358} 
\end{align*}\pageoriginale

Since this is true for all orthogonal matrices $u$ we conclude that
the right side of (\ref{eq358}) is independent of $u$, in other words,  
$$
\Omega (E , \frac{\partial}{\partial y^*}[u]) = \Omega (E ,
\frac{\partial}{\partial y^*}), 
$$
or equivalently,
\begin{equation*}
\Omega (E, \frac{\partial}{\partial y} [u]) = \Omega (E,
\frac{\partial}{\partial y}) \tag{359}\label{eq359} 
\end{equation*}

Since the ring generated by the differential operators
$\dfrac{\partial}{\partial y_{\mu \nu}}$ is isomorphic with the
polynomial ring generated by $Y_{\mu \nu}$ under the isomorphism
$Y_{\mu \nu} \leftrightarrow e_{\mu \nu} \dfrac{\partial}{\partial
  y_{\mu \nu}}$, the truth of (\ref{eq359}) for every orthogonal matrix $u$
is equivalent with the relation 
$$
\omega (E, Y[u]) = \omega [E,y]
$$
for these $u's$. In particular, choosing $u$ such that $Y[u] =
\Lambda = (\delta _{\mu \nu}, )$ we shall have 
\begin{equation*}
\Omega(E, \Lambda) = \Omega (E, Y) \tag{360}\label{eq360}
\end{equation*}

The left side is a symmetric function of the $\lambda_\nu ' s , \nu =
1,2 \ldots n$ in fact symmetric polynomial in the $\lambda _\nu 's$ so
that it is a polynomial of the `power sums' $\sum^n_{\nu = 1}
\lambda^\mathfrak{K}_\nu = \sigma (\Lambda)^{\mathfrak{K}}), \mathfrak{K}
= 1,2 \ldots$. Thus $\Omega (E , y) = \Omega (E, \Lambda) =
P(G(\Lambda) \ldots \sigma (\Lambda)^n) $, a polynomial with constant
coefficients. Since $u$ is orthogonal and $y[u] = \Lambda$ we have
$\sigma (\Lambda) = \sigma (y [u]) = \sigma(y)$, and then  
\begin{equation*}
\Omega(E, Y) = P(\sigma (y), \sigma(y)^2 , \ldots \sigma(y)^n),
\tag{361}\label{eq361} 
\end{equation*}\pageoriginale
where $P$ is a polynomial with constant coefficients. 

Then form (\ref{eq358}),
\begin{align*}
g(y_0) & = \{ \Omega (E , \frac{\partial}{\partial y^*) f(y^*
  [V^{-1}]}\}_{y^* = E} \\ 
& = \{ P (\sigma (\frac{\partial}{\partial y^*)},
\sigma(\frac{\partial}{\partial y^*})^2 ,\ldots
\sigma(\frac{\partial}{\partial y^*})^n s (y^* [V^{-1}] \} _{y^* =E} 
\end{align*}

Comparing the two operators $\sigma (y^* \dfrac{\partial}{\partial
  y^*})^{\mathfrak{K}}$ and $\sigma (\dfrac{\partial}{\partial
  y^*})^\mathfrak{K}$, and in \break particular their highest degree terms at
the point $y^* = E$, we can write 
\begin{gather*}
g(y_0) = \{ P(\sigma(y^* \frac{\partial}{\partial y^*}), \ldots
\sigma(y^* \frac{\partial}{\partial y^*})^n f (y^* [V^{-1}] \}_{y^* =
  E} \\ 
+ \{ \Omega^* (y^* \frac{\partial}{\partial y^*}) f (y^* [V^{-1}])
\}_{y^*- E} 
\end{gather*}
where the degree of $\Omega^*$ in $\dfrac{\partial}{\partial y^*}$ is
smaller than that of $\Omega$ in $\dfrac{\partial}{\partial y^*}$. Due
to the invariance of the operators $\sigma(Y \dfrac{\partial}{\partial
  y})^{\mathfrak{K}}$ for the mappings $y \rightarrow Y^*$, the above
gives  
\begin{gather*}
g(y_0) = \{ P(\sigma(y \frac{\partial}{\partial y}), \ldots \sigma(y
\frac{\partial}{\partial y})^n f (y [V] \}_{y = y_0} \\ 
+ \{ \Omega_1 (y \frac{\partial}{\partial y}) f (y) \}_{y = y_0} 
\end{gather*}
with $\Omega_1$ having the same degree in $\dfrac{\partial}{\partial
  y}$ as $\Omega^*$ in $\dfrac{\partial}{\partial y^*}$ and since
$y_0$ is  arbitrary by choice, 
$$
g(Y) = P(\sigma(y \frac{\partial}{\partial y}), \ldots \sigma(y
\frac{\partial}{\partial y})^n f (y) + \Omega_1 (y
\frac{\partial}{\partial y}) f (y). 
$$

Since\pageoriginale $g(y) = \Omega (y , \dfrac{\partial}{\partial y})
f(y)$ and the above is true for every function $f(y)$ it is immediate
that   
$$
\Omega (y , \frac{\partial}{\partial y}) = P(\sigma
(y\frac{\partial}{\partial y}), \sigma (y \frac{\partial}{\partial
  y})^2 \ldots \sigma(y \frac{\partial}{\partial y})^n) _+\Omega_1 (y
\frac{\partial}{\partial y}) 
$$
where the degree of $\Omega_1$ in $\dfrac{\partial}{\partial y}$ is
less than that $\Omega$ in $\dfrac{\partial}{\partial y})$ and $P$ is
a polynomial with constant coefficients. By resorting to induction on
the degree of $\Omega$ in $\dfrac{\partial}{\partial y}$ we conclude
that  $\Omega (\dfrac{\partial}{\partial y})$ is a polynomial in
\; $\sigma(y \dfrac{\partial}{\partial y})^\mathfrak{K}$, \; $\mathscr{R} = 1,2
\ldots n$, and this was what we set out to prove. 

We now define the angular characters as functions $u(y)$ which satisfy
the following requirements. 
\begin{enumerate}[(1)]
\item $u$ is an eigen function of each operator $\Omega \in
  \psi$ 

\item $u$ is homogeneous of degree $o$ in $y$, in other words, $u (r
  y) = u (y)$ for every real $r > 0$, 

\item $u$ is invariant relative to the group of mappings $y
  \rightarrow y [u]$ where $u$ is an arbitrary unimodular matrix. 

\item $u$ is square integrable over a fundamental domain of the group
  of mappings $y \to y [u]$, $u$ unimodular, in the determinant surface
  $|y| = 1$ with a certain invariant volume element $d \vartheta_1$.  
\end{enumerate}

Let us examine the consequences of these defining properties of
$u$. Since we have shown that $\psi$ is generated by the
elements $\sigma (y \dfrac{\partial}{\partial y})^\mathfrak{K},
\mathfrak{K} = 1,2 \ldots n$, the first condition on $u$ can be
replaced by a system of differential equations 
\begin{equation*}
(\sigma (y \frac{\partial}{\partial y})^\mathfrak{K} +
  \eta_\mathfrak{K}) u(y) = 0 k= 1,2 \ldots n \tag{362}\label{eq362} 
\end{equation*}

The second\pageoriginale condition is then nothing else but the
requirement that 
$\eta_1 = 0$. The third condition means that $u$ is a kind of
automorphic function, and it is a pertinent question as to the
existence of non-trivial solutions of (\ref{eq362}) which satisfy the second
and third condition above. We shall subsequently show that such non
trivial solutions $u$ always exist. But these special functions $u$
fail to be angular characters in that they do not need the fourth
requirement.	 

The equation in (\ref{eq362}) corresponding to $\mathfrak{K} = 2$ is of
particular interest, as in this case $\sigma(y
\dfrac{\partial}{\partial y})^\mathfrak{K} = \sigma (y
\dfrac{\partial}{\partial y})^2$ can be proved to be the
\textit{Laplace Beltrami} operator of the space $y > 0$, considered as
a Riemannian space relative to the metric  
\begin{equation*}
d r^s = \sigma (y^{-1} d y)^2 \tag{363}\label{eq363}
\end{equation*}

We prove this as follows. The Laplace - Beltrami operator is invariant
relative to the transformations $y \rightarrow y[R]$, $R$
non-singular which are movements of the space $y > 0$, and the
operator $\sigma (y \dfrac{\partial}{\partial y})^2$ is also invariant
relative to these transformations as is seen from (\ref{eq354}). In view of the
transitivity of the group of movements then, it suffices to show that
the two operators are equal at the special point $\gamma = E$. At this
point we choose the coordinate system 
\begin{equation*}
x = (- y + E)(y + E)^{-1} \tag{364}\label{eq364}
\end{equation*}

The substitution $y \rightarrow x$ is a $1-1$ mapping of the space $y >
0$ onto the space $E - x'x > 0, x' = x$, and a simple computation
shows that 
\begin{equation*}
ds^2 = 4 \sigma ((E - x x')^{-1} dx )^2 \tag{365}\label{eq365}
\end{equation*}\pageoriginale

It is then immediate that our coordinate system at $E$ is a geodesic
one.  Clearly the point $y = E$ corresponds to $x = 0$. By means of
the relations  
\begin{align*}
\frac{\partial}{\partial y} & = - \frac{1}{2}(E + x) ((E + x)
\frac{\partial}{\partial x})' \tag{366}\label{eq366} \\ 
\frac{\partial}{\partial x}x & = \frac{n+1}{2} E + (x
\frac{\partial}{\partial x})' \\ 
\frac{\partial}{\partial x}(x \frac{\partial}{\partial x}) & = (x
\frac{\partial}{\partial x} \frac{\partial}{\partial x})' +
\frac{1}{2} \frac{\partial}{\partial x} + \frac{1}{2}
\sigma(\frac{\partial}{\partial x})E 
\end{align*}
which are easily proved, we obtain that at $x = 0$
$$
(y \frac{\partial}{\partial y})^2 = \frac{1}{4}\bigg\{ 
\frac{\partial}{\partial x} \frac{\partial}{\partial x} + \frac{1}{2} 
\frac{\partial}{\partial x} + \frac{1}{2} \sigma
\frac{\partial}{\partial x} E - \frac{n+1}{2} \frac{\partial}{\partial
  x} \bigg\}, 
$$
and then 
\begin{align*}
\sigma(y \frac{\partial}{\partial y})^2 & = \frac{1}{4}
\sigma{\frac{\partial}{\partial x}})^2 = \sum_{\mu, \nu} e^{2}_{\mu
  \nu} \frac{\partial^2}{\partial x^2_{\mu \nu}} \\ 
= & \frac{1}{4} \sum_{\nu} \frac{\partial^2}{\partial x^2_{\mu \nu}} +
\frac{1}{8} \sum_{\mu < \nu} \frac{\partial^2}{\partial x^2_{\mu
    \nu}}. 
\end{align*}

On the other hand, at $x = 0$, we have
$$
ds^2 = 4 \sigma(d x)^2 = 4 \sum_\nu dx^2_{\nu \nu} + 8 \sum_{\mu <
  \nu} dx^2_{\mu \nu} 
$$
and we can then conclude from (\ref{eq290}) that $\sigma (y
\dfrac{\partial}{\partial y})^2$ is identical with the Laplace -
Beltrami operator at $x = 0$ and hence also at any other point.  

We are also interested in the determinant surface $|y| = 1$ and we can
introduce the Laplace - Beltrami operator $\Delta_1$ in this
surface. We wish to determine\pageoriginale the relationship between
$\Delta$ and $\Delta_1$. We first observe that in (\ref{eq363}).  
\begin{equation*}
dr^2 = d^z \log  |y| \tag{367}\label{eq367}
\end{equation*}
\begin{align*}
For, -d^2 log |y| & = -d (d \log |y|) = -d (\frac{1}{|y|} d|y|) \\
& = d (\frac{1}{|y|}, \sigma (\frac{\partial}{\partial y} |y|) = -d
(\sigma (d y y^{-1})) \\ 
& = -d (\sigma ( y dy^{-1})) = \sigma ((dy ^{-1}) dy) \\
& = -  \sigma (- y^{-1} dy y^{-1 dy}) = \sigma (y^{-1} dy)^z \\
& = ds^2
\end{align*}

The relationship between $\Delta$ and $\Delta_1$ is now provided by
the following general lemma, viz. 

\setcounter{lem}{24}
\begin{lem}\label{chap17:lem25}%lem 25
 Let $R$ be a domain in the space if $n$ real
  coordinates \break $y_1 , y_2 , \ldots y_n$, and $x = x (y_1, y_2 ,
\ldots y_n)$,  a positive homogeneous function on $\mathfrak{K}$  of
  degree \; $\mathfrak{K} > 0$.  Denote by $M$  the surface
  defined by \break $x (y_1, y_2 , \ldots y_n) = 1$. Let $R$, $M$ be
  considered as Riemann space relative to the metric $ds^2 = d^2
\varphi$ where $\varphi =  -  \log x$, and let $\Delta, \Delta _1$
  denote the Laplace Beltromi operator in $R$ and $M$ 
  respectively. If $h_1 = h_1 (y_1, y_2 , \ldots y_n)$ is an
  arbitrary function in $M$ and 
$$ 
h = h_1( \dfrac{y_1}{n \sqrt{x}} ,
\dfrac{y_2}{\mathfrak{K}\sqrt{x}}, \ldots
\dfrac{y_n}{\mathfrak{K}\sqrt{x}}) 
$$
 the homogeneous\pageoriginale function of degree 0 in $R$ which
 extends $h_1$ then  we have   
\begin{equation*}
\Delta_1 h_1 = \Delta h \tag{368}\label{eq368}
\end{equation*}
\end{lem}

\begin{proof}
We chose in $R$ a special coding system $ (x_1, x_2 , \ldots x_n)$
as follows. Let $y_\mu = \psi_\mu (x_1, x_2 , \ldots x_{n-1})
(1 \le \mu \le n)$ be a parametric representation of the surface $M$
so that in particular, rank $(\dfrac{\partial \varphi_{\mu}}{\partial
  x_{\nu}}) = n-1$. Then the equations 
\begin{equation*}
y_\mu = y_\mu (x_1, x_2 , \ldots x_{n-1}) x_n , i \le \mu \le n
\tag{369}\label{eq369} 
\end{equation*}
define the desired coordinate system $(x_1, x_2 , \ldots x_n)$. To
prove our assertion we need only show that the square matrix
$(\dfrac{\partial \varphi_\mu}{\partial x_\nu})$ has the rank $n$
Since $\dfrac{\partial \varphi_\mu}{\partial x_\nu} = \dfrac{\partial
  \varphi_\mu}{\partial x_\nu} \times_n$ for $\nu < n$ and
$\dfrac{\partial \varphi_\mu}{\partial x_\nu} = \varphi \mu, \varphi =
1,2 \ldots n$, it suffices to show that the homogeneous linear
equations  
\begin{equation*}
\sum^{n-1}_{\nu = 1} \xi_\nu \frac{\partial \varphi_\mu}{\partial
  x_\nu} \times n + \xi_n \varphi_\mu = 0 1 \le \mu \le n
\tag{370}\label{eq370}  
\end{equation*}
admit of only the trivial solution. Since $x (\varphi_1 , \varphi_2
\ldots \varphi_n ) = 1$ identically in $x_1 , x_2, \ldots x_{n-1}$, we
have  
\begin{equation*}
\sum^n_{\mu = 1} \frac{\partial X}{\partial \varphi_\nu} (\varphi)
\frac{\partial \varphi_\mu}{\partial x_\nu}= 0, 1 \le \nu < n
\tag{371}\label{eq371}   
\end{equation*}
\end{proof}

Besides, 
\begin{equation*}
\sum^n_{\mu = 1} \frac{\partial \lambda}{\partial \varphi_\nu}
(\varphi)  \varphi_{\mu} = \mathfrak{K} \lambda (\varphi) > 0
\tag{372}\label{eq372}    
\end{equation*}
by a standard result on homogeneous functions. Multiplying both sides  
of (\ref{eq371})\pageoriginale by $\xi x n $ and of (\ref{eq372}) by
$\xi$ and adding, we obtain  
in view of (\ref{eq370}) that $\xi \mathfrak{K} \lambda (\varphi)> o$ whence
it follows that $\xi_n = o$ Since we know that rank $(\dfrac{\partial
  \varphi_\mu}{\partial x_\nu}) = n - 1, ^{\mu = 1, 2, \ldots n}_{\nu
  = 1, 2, \ldots n - 1,}$ we conclude from (\ref{eq370}) that $\xi _o = o $
for all $\nu = 1, 2, \ldots n$. We have now shown that (\ref{eq369}) gives a
parametric representation of the whole space $R$ in terms of that in
$| v |$. Let us compute fundamental metric form $ds^2$ in this
special coordinate system. We have 
\begin{align*}
ds^2  = d^2 \varphi & = d(\sum^{n}_{\nu = 1} \frac{\partial
  \varphi}{\partial x _\nu} d x _\nu ) = \sum^{n}_{\mu, \nu = 1}
\frac{\partial^2 \varphi}{\partial x_\mu} \partial ^{dx_\mu}_{x_\nu} d
x_\nu \\ 
& = \sum_{\mu, \nu} d x_\mu dx _\nu \tag{373}\label{eq373}   
\end{align*}
with \; $g_{\mu \nu} = \dfrac{\partial^z \varphi}{\partial
  x_\mu}_{\partial x_\nu} (1 \le \mu, \nu \le n) $ 

Also 
\begin{align*}
\frac{\partial \varphi}{\partial x_\nu}  = \frac{\partial (- \log
  \chi}{\partial x_\nu} & = - \frac{1}{\chi} \frac{\partial (\chi
  (y)}{\partial x _\nu} = - \frac{1}{2} \sum^n_{\mu = 1}
\frac{\partial \chi (y)}{\partial y_\mu} \frac{\partial
  y_\mu}{\partial x_\nu}\\ 
& = - \frac{1}{\chi} \sum^n_{\mu = 1} \frac{\partial \chi
  (y)}{\partial y_\mu} \frac{\partial \varphi_\mu}{\partial x_\nu} x_n
\tag{374}\label{eq374}   
\end{align*}

Since $\chi$ is homogeneous of degree $\mathfrak{K}$ in $y_1, y_2,
\ldots y_n, \dfrac{\partial \chi}{\partial y _\mu}$ is homogeneous of
degree $\mathfrak{K} - 1$ in $y_1, y_2, \ldots y_n $ Also, all the
$y's$ are linear functions in $\chi_n$ and it then follows from
(\ref{eq374}) that $\dfrac{\partial \varphi}{\partial x_\nu}$ is a
homogeneous function of degree $o$ in $x_n$ for $\nu < n$. In other
words, for $\nu < n$, $\dfrac {\partial \varphi}{\partial \chi_\nu}$ is
independent of $x_n$ and consequently 
\begin{equation*}
g_{n \nu} = g_{\nu n} = o \tag {375}\label{eq375}  
\end{equation*}
for these values of $\nu$.

Also,\pageoriginale 
\begin{align*}
\frac{\partial \varphi}{\partial x_n} & = - \frac{1}{\chi} \sum^n_{\mu
  = 1} \frac{\partial \chi (y)}{\partial y_\mu} \frac{\partial
  y_\mu}{\partial x_n}\\ 
& = - \frac{1}{2} \sum_{\mu} \frac{\partial \chi_{(y)}}{\partial
  y_\mu} \frac{y_\mu}{x_n} = -\frac{- \mathfrak{K}}{x_n} 
\end{align*}
so that
\begin{equation*}
g_{n n }= \frac{\partial^2 \varphi}{\partial x^2} =
\frac{\mathfrak{K}}{x^2_n}. \tag{376}\label{eq376}   
\end{equation*}

Then from (\ref{eq373}), $d s^2$ is given by
\begin{equation*}
ds^2 = \sum^{n - 1}_{\mu, \nu = 1} g_{\mu \nu} dx _\mu dx _\nu +
\frac{\mathfrak{K}}{x^2_n} d x^2_n. \tag{377}\label{eq377}   
\end{equation*}

On $N$ of course we have $x_n = 1$ so that $ d x_n = o$, and then 
\begin{equation*}
ds^2 = \sum^{n - 1}_{\mu , \nu = 1} g_{\mu \nu} dx_\mu dx_\nu
\tag{378}\label{eq378}    
\end{equation*}
gives the metric form.

Let $(g^{\mu \nu})$ $(\mu, \nu < n)$ denote the inverse of the matrix
$(g_{\mu \nu})$ and let $g$ denote the determinant of $(g_{\mu
  \nu})$. Since $\dfrac{\partial \varphi}{\partial x_\nu}$ is
independent of $x_n$ for $\nu < n$ it follows that $g_{\mu \nu} (\mu,
\nu < n)$ and consequently $g$ are independent of $x_n$. Then by the
definition of $\triangle$, using (\ref{eq375}) and (\ref{eq376}), we have 
\begin{align*}
\triangle & = \frac{1}{\sqrt{g g}_nn} \sum^{n}_{\mu, \nu = 1}
\frac{\partial}{\partial x_\mu} (\sqrt{gg}_{nn} g^{\mu \nu}
\frac{\partial}{\partial x_\nu}) \frac{1}{\sqrt {gg}_{nn}}
\frac{\partial}{\partial x _ n} \sqrt{gg}_{nn}
\frac{x^2_n}{\mathfrak{K}} \frac{\partial}{\partial x_n}\\ 
& = \frac{1}{\sqrt {g}} \sum^{n - 1}_{\mu, \nu = 1}
\frac{\partial}{\partial x_\mu} (\sqrt{g} g^{\mu \nu }
\frac{\partial}{\partial x_\nu}) + \frac{1}{\mathfrak{K}} x_n
\frac{\partial}{\partial x_n} \chi_n \frac{\partial}{\partial x_n}\\ 
& = \triangle_1 + \frac{1}{\mathfrak{K}} (x _n \frac{\partial}{\partial
  x_n})^2 \tag{379}\label{eq379}   
\end{align*}

Since\pageoriginale $h (y_1, y_2, \ldots y_n) = h_1 \left(
\dfrac{y_1}{\sqrt[\mathfrak{K}] {\chi}},  \ldots
\dfrac{y_n}{\sqrt[\mathfrak{K}] {\chi}} \right ) $ by assumption and  
\begin{equation*}
\sqrt[\mathfrak{K}] {\chi} = \sqrt[\mathfrak{K}] {\chi (\varphi. x_n)} =
x_n \sqrt[\mathfrak{K}] {\chi (\varphi)}  = x_n \tag{380}\label{eq380}   
\end{equation*}
in an obvious notation, we obtain
$$
h(y_1, y_2, \ldots y_n) = h_1 (\varphi_1, \varphi_2 \cdots \varphi_n)
$$
and $\dfrac{\partial h}{\partial x_n} = \dfrac{\partial h_1}{\partial
  x_n} = o$. It now follows from (\ref{eq379}) that $\triangle h =
\triangle_1 h_1$ and Lemma \ref{chap17:lem25} is proved. Finally we
remark that if 
$d \vartheta, d \vartheta_1$ denote the invariant volume elements of
$R$ and $H$ relative to the metrics (\ref{eq377}) and (\ref{eq378}) respectively,
then   
\begin{align*}
d \vartheta & = \sqrt{gg}_{nn} \prod^n_{\nu = 1} d x_\nu =
\frac{\sqrt{\mathfrak{K}}}{x_n} \sqrt {g} \prod^n_{\nu = 1} dx_\nu,\\ 
d \vartheta_1 & = \sqrt{g} \prod_{\nu = 1}^{n - 1} d x _\nu
\end{align*}
so that $d \vartheta $ and $d \vartheta_1$ are connected by the relation,
\begin{equation*}
d \vartheta = \sqrt{\mathfrak{K}} x^{-1}_n d x _n d \vartheta_1
\tag{381}\label{eq381}    
\end{equation*}

We now interpret (\ref{eq368}) and (\ref{eq381}) in the particular space $y >
o$. In view of (\ref{eq367}) we can state 

\begin{lem}\label{chap17:lem26}%%%% 26
 Let $\triangle$ denote the Laplace-Beltrami operator of the 
  space $y > o$ relative to the metric $d s^2 = \sigma (y^{-1} d y)^2$
  and $\triangle_1$ the Laplace-Beltrami operator of the determinant
  surface $| y |  = 1$ relative to the induced metric. If $h_1 (y)$ is
  an arbitrary function on this surface and $h (y)$ the homogeneous
  function of degree $0$ on the whole space $y > 0$ defined
  by\pageoriginale $h (Y) = h_1 (| Y|^{1/n} Y)$ then we have
  $\triangle h = \triangle_1 h_1$. 
\end{lem}

This is how (\ref{eq368}) reads in the space $y > 0$. We now take up
(\ref{eq381}). The fundamental metric in the space of real matrices $y =
y^{(n)}$ was given by $d s^2 = \sigma (y^{-1} dy )^2$, and the $L - 1$
transformations of this space onto itself which leave the metric
invariant are given by $y \to y^* = y[R]$ with an arbitrary real non
singular matrix $R$. From (\ref{eq138}) we know that  
$$
\frac{\partial (y^*}{\partial (y)} = | R |^{n + 1} = | y ^* |^{\frac{n
    + 1}{2}} | y | ^{- \frac{n + 1}{2}} 
$$ 
and then then \; $| y | ^{- \dfrac{n + 1}{2}} [ d y]$ \; is left
invariant by the transformations $y \to y^*$. It follows that the
invariant volume element $d \vartheta$ in this case is given by 
$$
d \vartheta = \sqrt {C} | y |^{- \frac{n + 1}{2}} [d y]
$$
with an arbitrary constant $C$. We fix $C$ by requiring $ d \vartheta$
in the standard form, viz. $d \vartheta = \sqrt{g} \pi_{p \le \nu} dy
_{\mu \nu}$ in the usual notation. Then $g = c | y |^{(n + 1)}$ and in
particular at $y = E$ we have $g = C$. But at this point 
$$
d s^2 = \sigma (d y )^2 = \sum^n_{\mu = 1} dy^2 _{\mu \mu} +  2
\sum_{\mu < \nu} dy^2_{\mu \nu} 
$$
so that the matrix $(g_{r s})$ whose determinant is $g$ is diagonal
with $\eta$ of the diagonal elements $1$ and the rest $\dfrac{\eta (n
  - 1}{2}$ as 2. Thus, at $Y = E$, $g = z^{n (n - 1)/2}$ and this is
then the value for $c$ Thus 
\begin{equation*}
d \vartheta = 2^{n(n-1)/4} | y |^{- \frac{n+1}{2}} [ dy ]
\tag{382}\label{eq382}     
 \end{equation*} 
 
 From (\ref{eq381}) we have $\chi^{-1}_{n} d x _n d \vartheta_1 =
 \dfrac{1}{\sqrt{\mathfrak{K}}} d \vartheta$ where $\chi_n$ is given by
 (\ref{eq380}), viz. $\chi_n = \sqrt[\mathfrak{K}]{\chi (y)}$. In the present
 case, $\chi (y) = | y |$ and $\mathfrak{K} = n$ so that $x_n = n 
 \sqrt{| y |} = y$ (say), and then from (\ref{eq381})  and (\ref{eq382}), 
 \begin{equation*}
y^{-1} d y d \vartheta_1 = \frac{1}{\sqrt{n}} 2^{n(n - 1)/4} | y
|^{-\frac{n + 1}{2}} [ d y ] = \frac{1}{\sqrt{n}} d
\vartheta. \tag{383}\label{eq383} 
 \end{equation*}\pageoriginale 
 
 We can now compute the volume of the fundamental domain of the
 unimodular group acting on the determinant surface $| y | = 1$. If
 $\mathfrak{K}$ denotes the space of all reduced matrices, this volume
 is given by $V_n = \int\limits_{y_1 \in \mathfrak{K}} d
 \vartheta_1$. Now 
 \begin{align*}
V_n \Lambda (\frac{n (n + 1}{2} & = \int\limits^{\infty}_{o} e^{- y}
y^{\frac{n (n + 1}{2} - 1} dy \int\limits_{\substack{y _1 \in
    \mathfrak{K}\\ | y _1 | = 1}} d \vartheta_1 \\ 
& = \int\limits_{y \in \mathfrak{K}} e^{\sqrt[n]{| y |}} | y
|^{\frac{n+1}{2}} y^{-1} dy d \vartheta_1\\ 
& = \frac{1}{\sqrt{n}} 2^{n(n-1)/4} \int\limits_{y \in \mathfrak{K}}
e^{- \sqrt[n]{| y |}} [d y]. 
 \end{align*} 
 
 The last integral has already been explicitly computed in (\ref{eq149}) and
 putting it in, we have 
 \begin{equation*}
V_n = \frac{n + 1}{2} \sqrt{n} 2^{n (n-1)/4} \vartheta_n \tag{384}\label{eq384}
 \end{equation*} 
 
 In particular we have shown that the volume of the fundamental domain
 is finite. We can therefore state that if $u (y)$ is homogeneous of
 degree 0, is invariant relative to the modular group and satisfies
 the equations (\ref{eq362}) and if further $\mathcal{U}$ is bounded in the
 fundamental domain, then $\mathcal{U}$ is square integrable and is
 hence an angular character. 
 
 We\pageoriginale return now to the question of existence of solutions
 of (\ref{eq362})  and examine how far they meet the other three
 requirements for an  angular character. We first observe that if $U
 (y)$ is a solution of  (\ref{eq362}) with the set of eigen values
 $\lambda_1, \lambda_2, \ldots  \lambda_n$, then $\mathcal{U}$ is a
 homogeneous function of degree  $-\lambda_1$ so that $| Y
 |^{\lambda_1|n} \mathcal{U}(y)$  is  homogeneous of degree 0. We show
 presently that for every solution  $\mathcal{U} (y) $ of
 (\ref{eq362}), $| Y |^s \mathcal{U} (y)$ (for an  arbitrary complex
 constant $s$) is also a solution with certain eigen 
 values $\lambda^*_1, \lambda_2^*, \ldots \lambda^*_n$ depending on
 $s$ and then in particular $| y |^{\lambda_1| n} \mathcal{U} (y)$
 will be a solution of (\ref{eq362}) with $\lambda^*_1 = o$. In other words,
 given any $\mathcal{U} (y)$ which satisfies the first condition for
 an angular character, we can determine one which, besides the first,
 fulfills the second condition too. 
 
 That $| Y |^s \mathcal{U} (y)$ is a solution of (\ref{eq362}) is an
 immediate consequence of the following operator identity, 
 \begin{equation*} 
(Y \frac{\partial}{\partial y} )^\mathfrak{K} |y |^s =
   \sum^{\mathfrak{K}}_{\nu = 0} s^\nu \big( ^{\mathfrak{K}}_{\nu} \big)
   | y |^s (y \frac{\partial}{\partial y})^{\mathfrak{K} - \nu}
   \tag{385}\label{eq385} 
 \end{equation*} 
 where we remark that $| Y |$ is to be treated as an operator. For
 $\mathfrak{K} = 1$ it is directly verified that 
 $$
 (y \frac{\partial}{\partial y} | y |^s = | y |^s y
 \frac{\partial}{\partial y} + s | y |^s E, 
 $$
 and then (\ref{eq385}) is proved by induction on $\mathfrak{K}$. One also
 obtains the analogous identity 
 \begin{equation*}
\big( (y \frac{\partial}{\partial y})' \big)^\mathfrak{K} | y |^s =
\sum^{\mathfrak{K}}_{\nu = 0} s^\nu \big(^\mathfrak{K}_\nu \big) | y |^s
\big( (y \frac{\partial}{\partial y})' \big)^{\mathfrak{K} - \nu}
\tag{386}\label{eq386} 
 \end{equation*} 
 and this we need later.

We now\pageoriginale show that (\ref{eq362}) has non trivial solutions
which are invariant relative to the unimodular substitutions $y \to y
[\mathcal{U}]$. We decompose $y, \dfrac{\partial}{\partial y}$ as   
$$
y =  
\begin{pmatrix}
y_1 & y_3 \\
y_3 & y_2
\end{pmatrix},
\quad \frac{\partial}{\partial y} =
\begin{pmatrix}
\frac{\partial}{\partial y_1} & \frac{1}{2} \frac{\partial}{\partial y_3}\\
\frac{1}{2} \frac{\partial}{\partial y_3} & \frac{\partial}{\partial y_2}
\end{pmatrix}
$$
with $y_1 = y_1^r, o < r < n$, and prove by induction on $\mathfrak{K}$
that  
\begin{equation*}
\big( y \frac{\partial}{\partial y} \big)^{\mathfrak{K}} |y _1|^{- s} =
(-1)^\mathfrak{K} s \big (s - \frac{n - r}{2} \big)^{\mathfrak{K} - 1} |
y_1 |^{- s} 
\begin{pmatrix} 
E & o\\ 
y'_3 y^{-1}_1 &  o 
\end{pmatrix}. \tag{387}\label{eq387} 
\end{equation*}

Indeed,
\begin{align*} 
\big ( y \frac{\partial}{\partial y} \big) | y_1 |^{-s} & = - s | y_1
|^{- s - 1} y \frac{\partial}{\partial y} | y_1 |\\ 
& = -s | y_1 |^{-s - 1} y \begin{pmatrix} |y_1 | y_1^{-1} & o\\ o &
  o \end{pmatrix}\\ 
& = - s |y_1 |^{-s} \begin{pmatrix} E & o \\ y'_3 Y^{-1}_1 &
  o \end{pmatrix} 
\end{align*}
and then we have only to assume (\ref{eq387}) for a particular value of
$\mathfrak{K} \ge 1$ and prove it for the next higher value. 

Now 
\begin{equation*}
(y \frac{\partial}{\partial y})^{\mathfrak{K}+1} |y_1|^{-s} =
  (-1)^{\mathfrak{K}} s (s - \frac{n-r}{2})^{\mathfrak{K}-1} y
  \frac{\partial}{\partial y} |y_1|^{-s} \begin{pmatrix} \in & 0
    \\ y'_3 y^{-1}_1 & 0 \end{pmatrix} \tag{388}\label{eq388} 
\end{equation*}
by the induction assumption. Also,
$$
\frac{\partial}{\partial y} | y_1 |^{-s} \begin{pmatrix} E & o \\ y'_3
  y^{-1}_1 & o \end{pmatrix} = \begin{pmatrix}
  \frac{\partial}{\partial y_1} & \frac{1}{2} \frac{\partial}{\partial
    y_3} \\ \frac{1}{2} \frac{\partial }{\partial y_3}, &
  \frac{\partial}{\partial y_2} \end{pmatrix} \begin{pmatrix} | y_1
  |^{-s} E & o \\ |y_1 |^{-s} y'_3 y&^{-1}_1 & o \end{pmatrix}  
=
$$
\begin{align*}
& = 
\begin{pmatrix}
- s |y_1 |^{-s} y_1^{-1} + \frac{1}{2} | y_1 |^{-s}
(\frac{\partial}{\partial y_3} y'_3) y_1^{-1} & o\\ 
o & o
\end{pmatrix}\\
& = |y _1 |^{-s}
\begin{pmatrix}
- s y_1^{-1} + \frac{1}{2} (n - r ) E y^{-1}_1 & o\\
o & o
\end{pmatrix}\\
& = - (s - \frac{n - r}{2} ) |y _1|^{-s} \begin{pmatrix} y_1^{-1} & o
  \\ o & o \end{pmatrix}. 
\end{align*}\pageoriginale

Putting this in (\ref{eq388}) we have 
\begin{align*}
(y \frac{\partial}{\partial y})^{\mathfrak{K} + 1} | y_1 |^{-s} & =
  (-1)^{\mathfrak{K}+1} s (s - \frac{n - r}{2})^\mathfrak{K} | y _1
  |^{-s} |y_2 |^{-s} y \begin{pmatrix} y^{-1}_{1} & o \\ o &
    o \end{pmatrix}\\ 
& = (-1)^{\mathfrak{K} + 1} s (s - \frac{n - r}{2})^\mathfrak{K} | y
  _1|^{-s} \begin{pmatrix} E, & o \\ y'_3 y_1^{-1} & o \end{pmatrix} 
\end{align*}
and the proof of (\ref{eq387}) is now complete.

It follows from (\ref{eq387}) that
\begin{equation*}
\left \{  \sigma (y \frac{\partial}{\partial y})^\mathfrak{K} +
\lambda_\mathfrak{K} \right\} |y_1|^{-s } = o, \lambda_\mathfrak{K} = r
s (\frac{n -r}{2} - s)^{\mathfrak{K} - 1} ; \mathfrak{K} \ge
1. \tag{389}\label{eq389} 
\end{equation*}

In other words we have shown that $| y_1 |^{-s}$ is a solution of
(\ref{eq362}) belonging to the set of eigen values. 
\begin{equation*}
\eta_\mathfrak{K} = r s (\frac{n -r}{2} - s )^{\mathfrak{K} -1},
\mathfrak{K} = 1, 2, \ldots n. \tag{390}\label{eq390} 
\end{equation*}

But itself $| y_1 |^{-s}$ is not invariant relative to the unimodular
substitutions; in fact if $\mathcal{U} = (Q R)$ is any unimodular
matrix with $Q = Q^{(n, r)}$, then  due\pageoriginale to a
transformation $y \to y 
[\mathcal{U}]$ of $y$, $y_1 = y \left [ ^{E^(r)}_o\right]$ goes over
into $(y [\mathcal{U}] \left[^{E^(r)}_o\right] = y [Q]$, and $|y_2
|^{-s}$ goes into $| y [Q]|^{-s}$. However it is easily seen from
(\ref{eq389}) that $| y [Q] |^{-s}$ also satisfies the same equation with
the same set of eigen values and then  
\begin{equation*}
\mathscr{E}(y, s)  = \sum_Q | y [Q] |^{-s} \tag{391}\label{eq391}
\end{equation*}
where $Q$ runs through a complete representative system of the classes
$\{Q^{n, r}\}$ of primitive matrices is again a solution of (\ref{eq362})
belonging to the above system of eigen values (\ref{eq390}). Of course, we
have $\mathscr{E} (y [\mathcal{U}], s ) = \mathscr{E}(y, s)$ for any
unimodular matrix $\mathcal{U}$; in other words $\mathscr{E} (y, s)$
is a solution of (\ref{eq362}), which is invariant relative to the
unimodular transformations. 

The function $\mathscr{E}(y, s)$ is a generalisation of the usual
Epstein's zeta function. It follows from (\ref{eq387}) that  
$$
\left\{ (y \frac{\partial}{\partial y})^2 + (s - \frac{n - r}{2}) (y
\frac{\partial}{\partial y}) \right\} | y_1 |^{-s} = o 
$$
and hence we can conclude that
\begin{equation*}
\left\{ (y \frac{\partial}{\partial y})^2 + (s - \frac{n - r}{2}) (y
\frac{\partial}{\partial y}) \right\} \mathscr{E} (y, s) = o
\tag{392}\label{eq392}  
\end{equation*}

It is possible to characterise $\mathscr{E} (y, s)$ as a solution of
(\ref{eq392}), whose Fourier coefficients (in a certain sense) have
specified properties. 

Finally we prove that for every solution $\mathcal{U}(y)$ of (\ref{eq362}),
$\mathcal{U}^* (Y) = \mathcal{U} (Y^{-1})$ also satisfies a
differential equation of the same kind,  
$$
\left \{ \sigma (y \frac{\partial}{\partial y})^\mathfrak{K} +
\lambda^*_\mathfrak{K} \right\} \mathcal{U}^* (y) = o, \mathfrak{K} = 1,
2, \ldots n, 
$$
where $\lambda^*_\mathfrak{K}, \mathfrak{K} = 1, 2, \ldots n$ are
uniquely determined by the eigen value s\pageoriginale $\lambda_1,
\lambda_2, \ldots \lambda_n$ of $\mathcal{U}$. We need a few operator
identities as preliminaries. Let $y \dfrac{\partial}{\partial y} =
\triangle = (\omega_{\mu \nu})$. We prove first that   
\begin{equation*}
\omega_{\mu \nu} \omega_{x \lambda} = \omega_{\mu \lambda} \omega_{\mu
  \nu} + \frac{1}{2} \delta_{\nu \mu} - \frac{1}{2} \delta_{\lambda
  \mu} \omega_{\mu \nu} \tag{393}\label{eq393} 
\end{equation*}

Since $e_{\mu \nu} \dfrac{\partial y_{x \lambda}}{\partial y_{\mu
    \nu}} = \dfrac{1}{2} (\delta_{\mu \nu, x \lambda} + \delta_{\mu,
  \nu, \lambda \nu}), \delta_{\mu \nu, x \lambda} = \delta_{\mu x  }
\delta_{\nu \lambda}$ 

We have
\begin{align*}
\omega_{\mu \nu } \omega_{x \lambda} & = \big( \sum^n_{\rho = 1}
y_{\mu \rho} e_{\rho \nu} \frac{\partial}{\partial y_{\rho \nu}} \big
) \big( \sum^n_{\sigma = 1} y_{x \sigma} e_{\sigma \lambda}
\frac{\partial}{\partial } y_{\sigma \lambda} \big) \\
& = \sum^{n}_{\rho, \sigma = 1} y_{\mu \rho} e_{\rho \nu}
\frac{\partial}{\partial y_{\rho \nu}} y_{x \sigma} e_{\sigma \lambda}
\frac{\partial}{\partial y _{\sigma \lambda}}\\ 
& = \sum^n_{\rho, \sigma = 1} y_{\mu \rho} y_{x \sigma} e_{\rho \nu}
\frac{\partial}{\partial y_{\sigma \lambda}} \frac{1}{2}
\sum^{n}_{\rho, \sigma = 1} y_{\mu \rho} y_{\mu \rho} (\delta_{\rho
  \nu, x \sigma} + \delta_{\rho \nu, \sigma}) e_{\sigma \lambda}
\frac{\partial}{\partial y_{\sigma \lambda}}\\ 
& = \sum^n_{\rho, \sigma = 1} y_{x \sigma} e_{\sigma \lambda}
\frac{\partial}{\partial} y_{\sigma \lambda} y_{\mu \rho} e_{\rho \nu}
\frac{\partial}{\partial} y_{\rho \nu} \frac{1}{2} \sum^{n}_{\rho,
  \sigma = 1} y_{\mu \rho} (\delta_{\rho, \nu x \sigma} + \delta_{\rho
  \nu, \sigma x}) \\
& \qquad \qquad e_{\sigma \lambda} \frac{\partial}{\partial
  y_{\sigma \lambda}} - \frac{1}{2} \sum^{n}_{\rho, \sigma = 1} y_{x
  \sigma} (\delta_{\sigma \lambda, \mu \rho }+ \delta_{\sigma \lambda,
  \rho \mu} e_{\rho \nu } \frac{\partial}{\partial} y _{\rho \nu} \\ 
& = \omega_{x \lambda} \omega_{\mu \nu} + \frac{1}{2} y_{\mu x} e_{\nu
  \lambda} e_{\nu \lambda} \frac{\partial}{\partial y_{\nu \lambda}} +
\frac{1}{2} \delta_{\nu \lambda} \omega_{\mu \nu } \\
& \hspace{3cm} + \frac{1}{2} y_{x
  \mu} e_{\lambda \nu} \frac{\partial}{\partial y_{\lambda \nu}} -
\frac{1}{2} \delta_{\lambda \mu} \omega_{x \nu}\\ 
& = \omega_{x \lambda} \omega _{\mu \nu} t \frac{1}{2} \delta_{\nu x}
\omega_{\mu \lambda} - \frac{1}{2} \delta_{\lambda \mu} \omega_{\mu
  \nu}, 
\end{align*}\pageoriginale
and (\ref{eq393}) is established.

We use (\ref{eq393}) to show that for any operator matrix  $A =
(\alpha_{\mu \nu})$, 
\begin{align*}
\sigma (\triangle^\mathfrak{K} A) & = \sum_{\nu \nu_2 \cdots
  \nu_{\mathfrak{K}+1}} \omega_{\nu_2 \nu_3} \cdots \omega_{\nu_{g - 1}
  \nu_g} \omega_{\nu_1 \nu_2} \omega_{\nu_g \nu_{g+1}} \cdots
\omega_{\nu_\mathfrak{K}\nu_{\mathfrak{K}+1}}
\alpha_{\nu_{\mathfrak{K}+1} \nu_1}\\ 
& \qquad \qquad - \frac{1}{2} \sigma (\Lambda^{g-2})
(\Lambda^{\mathfrak{K}+g+1} A) + \frac{n }{2} \sigma
(\Lambda^{\mathfrak{K}-1}A) \tag{394}\label{eq394}  
\end{align*}

The proof is by induction on $j$. For $j= 2$ (\ref{eq394}) is obviously
true. Assume then $j \ge 2$. By means of (\ref{eq393}), the induction
assumption  gives that 
\begin{align*}
\sigma (\Lambda^{\mathfrak{K}} A) & = \sum_{\nu_1, nu_2 \cdots
  \nu_{\mathfrak{K}+1}} \omega_{\nu_1 \nu_2 \cdots}
\omega_{\nu_\mathfrak{K} \nu_{\mathfrak{K}+1}}
\alpha_{\nu_{\mathfrak{K}+1}\nu_1}\\ 
& = \sum_{\nu_1, \nu_2, \ldots \nu_{\mathfrak{K}+1}} \omega_{\nu_2
  \nu_3} \cdots \omega_{\nu_g \nu_{g + 1}} \omega_{\nu_1,\nu_2}
\omega_{\nu_{g+1} \nu_{g+2} } \cdots \omega_{\nu_\mathfrak{K}
  \nu_{\mathfrak{K}+1}} \alpha_{\nu_{\mathfrak{K}+1} \nu_1}\\ 
& \qquad + \frac{1}{2}\sum_{\nu_1, \nu_2, \ldots \nu_{\mathfrak{K}+1}}
\omega_{\nu_2 \nu_3} \cdots \omega_{\nu_{g+1} \nu_g }  \delta_{nu_2
  \nu_g} \omega_{\nu_1 \nu_{g+1}} \omega_{\nu_{g+1}}\\
& \hspace{4.5cm}
\omega_{\nu_{g+1}\nu_{g+2}} \cdots \omega_{\nu_\mathfrak{K}
  \nu_{\mathfrak{K}+1}} \alpha_{\nu_{\mathfrak{K}+1}\nu_1}\\ 
& \qquad -\frac{1}{2} \sum_{\nu_1, \nu_2, \ldots \nu_{\mathfrak{K}+1}}
\omega_{\nu_2 \nu_3} \cdots \omega_{\nu_{g-1} \nu_{g + 1}\nu_1}
\omega_{\nu_g \nu_2} \\
& \hspace{4.5cm} \omega_{\nu_{g+1} \nu_{g+2}} \cdots \omega
_{\nu_\mathfrak{K} \nu_{\mathfrak{K}+1}}  \alpha_{{\mathfrak{K}+1}
  \nu_1} \\ 
& \qquad  - \frac{1}{2} \sigma (\Lambda^{g-2}) \sigma
(\Lambda^{\mathfrak{K}-g+1} A) + \frac{n}{2} \sigma
(\Lambda^{\mathfrak{K}-1} \Lambda)\\ 
& = \sum_{\nu_1, \nu_2, \ldots \nu_{\mathfrak{K}+1}} \omega_{\nu_2
  \nu_3} \cdots \omega_{\nu_g \nu_{g+1} }  \omega_{\nu_1 \nu_2 }
\omega_{\nu_{g+1} \nu_{g+2}} \cdots
\omega_{\nu_\mathfrak{K}\nu_{\mathfrak{K}+1}}
\alpha_{\nu_{\mathfrak{K}+1} \nu_1}\\ 
& \qquad - \frac{1}{2} \sigma (\Lambda^{g-1}
\sigma(\Lambda^{\mathfrak{K}-g} \Lambda) + \frac{n}{2} \sigma
(\Lambda^{\mathfrak{K}-1} A)  
\end{align*}
and this\pageoriginale proves (\ref{eq394}). Putting $j = k
+ 1$ in 
(\ref{eq394}) we obtain that   
\begin{align*}
\sigma (\Lambda^\mathfrak{K} A) & = \sum_{\nu_1, \nu_2, \ldots
  \nu_{\mathfrak{K}+1}} \omega_{\nu_2 \nu_3} \cdots
\omega_{\nu_\mathfrak{K} \nu_{\mathfrak{K}+1}} \omega_{\nu_1 \nu_2}
\alpha_{\nu_{\mathfrak{K}+1} \nu_1}\\
& \hspace{3cm} \frac{1}{2} \sigma
(\Lambda^{\mathfrak{K}-1} ) \sigma (A) + \frac{n}{2} \sigma
(\Lambda^{\mathfrak{K}-1} A)\\ 
& = \sigma (\Lambda^{\mathfrak{K}-1} (\Lambda' A')) - \frac{1}{2}
\sigma (\Lambda^{\mathfrak{K}-1}) \sigma (A) + \frac{n}{2} \sigma
(\Lambda^{\mathfrak{K}-1} A). 
\end{align*}

Choosing for $A$ the special operator matrix $\big( (\Lambda')^\ell
\big)' $ this yields,  
\begin{align*}
\sigma (\Lambda^\mathfrak{K} \big( (\Lambda')^\ell \big)' & = \sigma
(\Lambda^{\mathfrak{K}-1} \big( (\Lambda')^{\ell+1})' \big) \\
& \qquad -
\frac{1}{2} \sigma (\Lambda^{\mathfrak{K}-1}) \sigma (\Lambda')^\ell
\frac{n}{2} \sigma (\Lambda^{\mathfrak{K}-1} \big( (\Lambda')^\ell
\big)' \tag{395}\label{eq395} 
\end{align*}

As a consequence of (\ref{eq395}) we can conclude by induction on
$\mathfrak{K}$ that  
\begin{equation*}
\sigma (\Lambda^\mathfrak{K} = \sigma (\Lambda')^\mathfrak{K} +
\sum_{\substack{\nu_1 \nu_2 \cdots \nu_r \\ \nu_1 + \cdots + \nu_r <
    \mathfrak{K}}} e^\mathfrak{K}_{\nu_1 \nu_2 .. \nu_r}
\sigma(\Lambda')^{\nu_s} \sigma(\Lambda')^{\nu_2} \cdots \sigma
(\Lambda')^{\nu_r} \tag{396}\label{eq396} 
\end{equation*}

Inverting this system of equations one also has 
\begin{equation*}
\sigma (\Lambda')^\mathfrak{K} = \sigma (\Lambda^\mathfrak{K}) +
\sum_{\substack{\nu_1 \nu_2 \cdots \nu_n \\ \nu_1 + \cdots + \nu_r <
    \mathfrak{K}}} d^\mathfrak{K}_{\nu_1 \nu_2 .. \nu_n} \sigma
(\Lambda)^{\nu_1} \sigma(\Lambda)^{\nu_2} \cdots
\sigma(\Lambda)^{\nu_r} \tag{397}\label{eq397} 
\end{equation*}
with\pageoriginale certain constant coefficients $d_{\nu_1 \nu_2
  \ldots \nu_r}^k$.  

Let\label{p.279} now $y^* = y^{-1}$ and $\mathcal{U}^* (y) = \mathcal{U} (y
^*)$. Then $dy^* = - y^{-1} d y y^{-1}$, and for any function
$\varphi$ we have  
$$
d \varphi = \sigma (dy \frac{\partial}{\partial y} \varphi) = \sigma
(d y^* \frac{\partial}{\partial y^*} \varphi ) = - \sigma (dy y^{-1}
(\frac{\partial}{\partial y^ *} \psi ) y^{-1}) 
$$
and consequently
$$
\frac{\partial}{\partial y} \varphi = - y^{-1}
(\frac{\partial}{\partial y^*} \varphi ) y^{-1}, \text { on } y
\frac{\partial}{\partial y} = - (y^* \frac{\partial}{\partial y^*})'. 
$$

Replacing $y$ by $y*$ in (\ref{eq397}) we can state now that 
{\fontsize{10pt}{12pt}\selectfont
\begin{align*}
& \sigma(y \frac{\partial}{\partial y})^\mathfrak{K} \mathcal{U}^* (y)
  = (-1)^\mathfrak{K} \sigma \big ( (y^* \frac{\partial}{\partial y^*})
  \big)^\mathfrak{K} \mathcal{U} (y^*)\\ 
& = (-1)^\mathfrak{K} \left \{ \sigma (\chi^* \frac{\partial}{\partial
    y^*})^\mathfrak{K}+ \sum_{\substack {\nu_1 \nu_2 \cdots \nu_r
      \\ \nu_1 + \nu_r < \mathfrak{K}}}d^\mathfrak{K}_{\nu_1 \nu_2
    \cdots \nu_r} \sigma (y^* \frac{\partial}{\partial y^*} )^{\nu_1}
  \cdots \sigma(y^* \frac{\partial}{\partial y^*})^{\nu_r} \right \}
  \mathcal{U} (y^*)\\ 
& = (-1)^\mathfrak{K} \left\{ - \lambda_{\mathfrak{K}} + \sum_{\substack
    {\nu_1 \nu_21 \cdots \nu_r \\ \nu_1 + \cdots + \nu_r <
      \mathfrak{K}}} (-1)^r d^\mathfrak{K}_{\nu_1 \nu_2 \cdots \nu_r}
  \lambda_{\nu_1} \lambda_{\nu_2} \cdots \lambda_{\nu_r} \right\}
  \mathcal{U} (y^*)\\ 
& = - \lambda^*_\mathfrak{K} \mathcal{U}^* (y) 
\end{align*}}\relax
with
\begin{equation*}
\lambda^*_\mathfrak{K} (-1)^\mathfrak{K} \left\{ \sum_{\substack{\nu_1
    \nu_2 \cdots \nu_r \\ \nu_1 + \cdots + \nu_r < \mathfrak{K}}}
(-1)^r d^\mathfrak{K}_{\nu_1 \nu_2 \cdots \nu_n } \lambda_{\nu_1}
\lambda_{\nu_2} \cdots \lambda_{\nu_r} \right\} \tag{398}\label{eq398} 
\end{equation*}

A detailed calculation shows that 
\begin{align*}
\sigma (\Lambda') & = \sigma (\Lambda), \sigma (\Lambda')^2 = \sigma
(\Lambda)^2\\ 
\sigma (\Lambda')^3 & = \sigma (\Lambda)^3 - \frac{n}{2} \sigma
(\Lambda)^2 + \frac{1}{2} (\sigma (\Lambda))^2,\\ 
\sigma (\Lambda')^4 & = \sigma (\Lambda)^4 - n \sigma (\Lambda)^3 +
\frac{1}{2} \sigma (\Lambda) \sigma (\Lambda)^2 + \frac{1}{2} \\
& \qquad \qquad + \frac{1}{2} \sigma (\Lambda)^2 \sigma (\Lambda) \frac
     {n^2}{4} \sigma (\Lambda)^2 - \frac{n}{4} (\sigma
     (\Lambda))^2  
\end{align*}\pageoriginale 
and it follows then that 
\begin{align*}
\lambda^*_1 & = \lambda_1, \lambda^*_2, \lambda^*_3 = - \lambda_3 +
\frac{n}{2} \lambda_2 + \frac{1}{2} \lambda^2_1,\\ 
\lambda^*_4 & = \lambda_4 - n \lambda_3 - \lambda_1 \lambda_2 +
\frac{n^2}{4} \lambda_2 + \frac{n}{4} \lambda^2_1. 
\end{align*}

It would be of interest to determine the cases when we shall have
$\lambda^*_\nu = \lambda_\nu$ for each $\nu$. 

When all is said and done, the question remains still open whether
angular characters according to our definition actually exist. We only
know that  if we are given one angular character we can obtain others
from it; for instance, if $\mathcal{U} (y)$ is angular character then
so  is $\mathcal{U}^* (y) = \mathcal{U} (y^{-1})$. For $n > 2$ the
existence question is still a problem. For $n=2$ however, the angular
characters are completely determined and they are just solutions of
the wave equations relative to the modular group. 

Let us introduce the operators $H_\mathfrak{K}$ by
\begin{equation*}
H_\mathfrak{K} = \frac{1}{2} (\sigma (y \frac{\partial}{\partial
  y})^\mathfrak{K} + \sigma \big ( ( y \frac{\partial}{\partial y } i
)^\mathfrak{K} \big) \tag{399}\label{eq399}  
\end{equation*}
and\pageoriginale observe in view of (\ref{eq397}) that  
$$
H_\mathfrak{K} = \sigma (y \frac{\partial}{\partial y})^\mathfrak{K} +
\frac{1}{2} \sum_{\substack{\nu_1 \nu_2 \cdots \nu_r \\ \nu_1 + \cdots
    + \nu_r < \mathfrak{K}}} d_{\nu_1 \nu_2 \cdots \nu_r} \sigma (y
\frac{\partial}{\partial y})^{\nu_1} \cdots \sigma (y
\frac{\partial}{\partial y})^{\nu_r} 
$$
for $\mathfrak{K} = 1, 2 \cdots n$.

It is easily seen that by means of these $n$ equations, $\sigma (y
\dfrac{\partial}{\partial y} )^\mathfrak{K} , \mathfrak{K} =
1. 2. \cdots n$ can be expressed in terms of the $H_\mathfrak{K}' s$. 

It follows therefore that $H_\mathfrak{K}, \mathfrak{K} = 1. 2 \cdots n$
also generate the space of invariant (linear) differential operators
as $\sigma (y \dfrac{\partial}{\partial y})^{\mathfrak{K}} -
\mathfrak{K} = 1.2 \cdots n$ do. The angular characters $\mathcal{U}
(y)$ are then eigen functions of these operators $H_\mathfrak{K},
\mathfrak{K} = 1.2 \cdots n$, and in place of (\ref{eq362}) we have an
equivalent system of differential equations for $\mathcal{U} (y)$,
viz.  
\begin{equation*}
(H_\mathfrak{K} + \mu_{\mathfrak{K}} \mathcal{U} (y) = o, \mathfrak{K} =
  1.2, \ldots n \tag{400}\label{eq400} 
\end{equation*}
with certain eigen values $\mu_{\mathfrak{K}} (\mathfrak{K} = 1.2 \cdots
n)$ which are uniquely determined by the eigen values
$\lambda_{\mathfrak{K}}$ of $\mathcal{U} (y)$ and conversely. We shall
give an interesting integral formula (\ref{eq407}) involving these
operators. 


First we have to generalise the method of partial integration. Let $A
= (a_{\mu \nu})$, $B = (\ell _{\mu \nu})$ be arbitrary matrices whose
elements are all functions of the elements of $y$ We know that $d
\vartheta = 2^{n (n-1)/4} |y|^{-\dfrac{n+1}{2}} [dy]$ is the volume
element in the space of matrices $y > o$, invariant relative to the
transformations $y \to y [R]$, $| R | \neq 0$. Let 
$$
\omega_{\mu \nu} = \pm \prod_{\rho, \sigma \neq \mu, \nu} dy_{\rho \sigma},
$$ 
the ambiguous sign being determined by the requirement that 
\begin{align*}
dy_{\mu \nu} \omega_{\mu \nu} & = [dY] \text{and let}\\
\Omega & =2 ^{n (n-1)/4} |Y| ^{-\frac{n+1}{2}} Y (e_{\mu \nu}
\omega_{\mu \nu}),  
\end{align*}\pageoriginale
a matrix of differential forms of degree $\frac{n (n+1)}{2}-1$. We 
wish to prove that  
\begin{equation*}
\int\limits_\mathcal{G} B \{Y \frac{\partial} {\partial Y} A \} d \vartheta =
-\int\limits_\mathcal{G} \{ Y (\frac{\partial}{ \partial Y})' B'\}' A d
\vartheta + \int\limits_{\ell \mathcal{G}} B \Omega A \tag{401}\label{eq401} 
\end{equation*}
where $\mathcal{G}$ denotes a compact domain with a given orientation
and $bg$ is its boundary, assumed to be piece wise
smooth. Now  
\begin{align*}
& B (y \frac{\partial} {\partial Y} A) + ( ( Y \frac{\partial}
  {\partial Y})'B')A =\\ 
& = (\sum_{\rho \sigma \tau}) \ell_{\mu \rho} y_{\rho \sigma}
  e_{\sigma \tau} (\frac{\partial}{\partial y}_{\sigma \tau} a_{\tau
    \nu})) + (\sum_{\rho \sigma \tau} e_{\rho \tau } (\frac{\partial}
  {\partial Y}_{\rho \tau } \ell _{\mu \sigma }) a_{\tau \nu})\\ 
& = (\sum_{\rho \sigma \tau} y _{\rho \sigma} e _{\rho \sigma \tau}
  (\ell _{\mu \sigma} \frac{\partial} {\partial Y}_{\rho\tau} a_{\tau
    \nu } + a_{\tau \nu} \frac{\partial} {\partial Y}_{\rho \tau} \ell
  _{\mu \sigma})) \tag{402}\label{eq402} 
\end{align*}

Also
\begin{align*}
d (B \Omega A) & = d (B 2 ^{n(n+1)}/4) |Y|^{- \frac{n+1}{2}} Y (e_{\mu
  \nu \omega_{\mu \nu}})A)\\ 
& = 2 ^{n (n+1)/4} d (\sum_{\rho \sigma \tau} \ell_{\mu \nu} |Y|
^{-\frac{n+1} {2}} y_{\rho \sigma} r_{\sigma \tau \omega_{\sigma \tau}
  a_{\mu \nu}})\\ 
& = 2^{n (n+1)/4} (\sum_{\rho \sigma \tau} e_{\sigma \tau }
\frac{\partial} {\partial y}_{\sigma \tau} |Y| ^{- \frac{n+1} {2}
}y_{\rho \sigma}) \omega_{\sigma \tau}) \\ 
&= 2^{n (n+1)/4} (\sum_{\rho \sigma \tau} e_{\sigma \tau }
\frac{\partial} {\partial y}_{\sigma \tau} ( \ell _{\mu \rho} a_{\tau
  \nu} |Y| ^{- \frac{n+1} {2} }y_{\rho \sigma}) \omega_{\sigma \tau})
     [dY] \\
& = (\sum_{\rho \sigma \tau} y_{\rho \sigma} e_{\sigma \tau}
     \frac{\partial}{\partial y _{\sigma \tau}} (\ell_{\mu \rho}
     a_{\tau \nu} )d \vartheta +  \\
& \qquad + 2^{n (n-1)/4} (\sum_{\rho \sigma\tau} e_{\sigma \tau} \ell_{\mu
       \rho} a_{\tau \nu} \frac{\partial}{\partial y}_{\sigma \tau} (
     |Y| ^{-\frac{n+1}{2}y_{\rho \sigma}}) [dy] \tag{403}\label{eq403} 
\end{align*}\pageoriginale

We shall show that $\sum_\sigma e_{\sigma \tau}
\dfrac{\partial}{\partial y}_{\sigma \tau} ( |Y|
^{-\dfrac{n+1}{2}y_{\rho \sigma}})=0$, and then the last term on the
right side of (\ref{eq403}) vanishes. Let $Y_{\mu \nu}$ denoted the
algebraic minors of the elements of $Y$ so that $|Y|Y^{-1} = (Y_{\mu
  \nu})$ 

Then
\begin{align*} 
& \sum_\sigma e_{\sigma \tau}  \frac{\partial}{\partial y}_{\sigma
    \tau}( |Y| ^{-\frac{n+1}{2}y_{\rho \sigma}}) = \\ 
& =\frac{n+1}{2} |Y|^{-\frac{n+1}{2}} \sum_\sigma Y _{\sigma \tau}
  y_{\rho \sigma} + \sum_\sigma |Y|^{-\frac{n+1}{2}} \delta _{\rho
    \tau} e_{\sigma \tau} \\ 
& = \frac{n+1}{2} |Y|^{-\frac{n+1}{2}} \delta_{\rho\tau} +
  \frac{n+1}{2} |Y| ^{\frac{n+1}{2}} \delta_{\rho\tau} = 0 
\end{align*}
as desired. (\ref{eq403}) now reduces, in view of (\ref{eq402}), to
\begin{align*}
d (B \Omega A) & = (\sum_{\rho \sigma \tau} y_{\rho \sigma} e_{\rho
  \sigma} \frac{\partial} {\partial}_{\sigma \tau} (\ell_{\mu \rho} a
_{\tau \nu})) d \vartheta \\ 
& =(B (Y \frac{\partial}{\partial Y} A) + (( Y
\frac{\partial}{\partial Y})' B',A) d \vartheta 
\end{align*}
and then, applying Stoke's formula by which 
$$
\int\limits_\mathcal{G} d \omega = \int\limits_{ \ell \mathcal{G}} \omega 
$$
for an arbitrary exterior differential from, $\omega$ we have 
$$
\int\limits_\mathcal{G} B (Y \frac{\partial} {\partial Y} A) d
\vartheta = -\int\limits_\mathcal{G}((Y \frac{\partial} {\partial
  Y})'B)'A d \vartheta + \int\limits_{\ell \mathcal{G}} B \Omega A. 
$$

More\pageoriginale generally we can show that 
\begin{align*}
\int\limits_{\mathscr{G}}\bigg\{  (y \frac{\partial }{\partial
  y})^\mathfrak{K} A ' \bigg\} d \vartheta & = (-1) ^\mathfrak{K}
\int\limits_{\mathscr{G}}\bigg\{  (y \frac{\partial }{\partial
  y})')^\mathfrak{K} B' \bigg\}  A d \vartheta 
+ \sum_{ \vartheta = 0}^
           {{\mathfrak{K} - 1}} (- 1)^\nu\\
& \qquad  \int\limits_{\ell
             \mathscr{G}}\bigg\{  ((y \frac{\partial }{\partial
             y})^\nu  B' \bigg\} \Omega \bigg\{ Y(\frac{\partial
           }{\partial y})^{ \mathfrak{K} - 1 - \nu}\bigg\}
           \tag{404}\label{eq404}  
\end{align*}

For $\mathfrak{K} = 1$, (\ref{eq404}) reduces to (\ref{eq401}) proved
above and then (\ref{eq404}) is established by restoring to
introduction on $\mathfrak{K}$   

Setting $A = \varphi E$ and $B = \psi E$  in (\ref{eq404}) where $\varphi$
and $\psi$ are arbitrary functions, and taking the trace of both
sides, we obtain that  
\begin{align*}
\int\limits_{ \mathscr{G}} \psi \sigma (y \frac{\partial}{\partial
  y})^{\mathfrak{K}} \varphi d \vartheta & = (-1)^{\mathfrak{K} }
=\int\limits_{ \mathscr{G}} \psi \sigma (y \frac{\partial}{\partial
  y})')^{\mathfrak{K}}  \psi d \vartheta + \sum^{\mathfrak{K}=1}_{ \nu =
  0}( -1)^\nu \\
& \qquad \int\limits_{\ell \mathscr{G} } \sigma \bigg\{ ((y
\frac{\partial }{\partial})^\nu )\bigg\}\Omega \bigg\{  (y
\frac{\partial}{\partial y})^{\mathfrak{K} - 1 -\nu} \varphi \bigg\}
\tag{405}\label{eq405} 
\end{align*}

Interchanging $\varphi$ and $\psi$ and replacing $\nu $ by
$\mathfrak{K} - 1-\nu $ in (\ref{eq405}) we obtain by transposition that  
\begin{align*}
\int\limits_{ \mathscr{G}} \psi \sigma ((y \frac{\partial}{\partial
  y})')^{\mathfrak{K}} \psi d \vartheta & = (-1)^{\mathfrak{K} }
=\int\limits_{ \mathscr{G}} \psi \sigma (y \frac{\partial}{\partial
  y})^{\mathfrak{K}} \psi d \vartheta + \sum^{\mathfrak{K}}_{ \nu = 0}(
-1)^\nu \\
& \qquad \int\limits_{\ell \mathscr{G} } \sigma \bigg\{ (y
\frac{\partial }{\partial})^\nu \bigg\}\Omega \bigg\{  ((y
\frac{\partial}{\partial y})')^{\mathfrak{K} - 1 -\nu}\bigg\}  \varphi
\tag{406}\label{eq406} 
\end{align*}

It follows by addition, from (\ref{eq405}) and (\ref{eq406}) that 
\begin{align*}
\int\limits_{\mathscr{G}} \psi H_\mathfrak{K} \psi d \vartheta  & =
(-1)^\mathfrak{K} \int\limits_{ \mathscr{G}} \varphi H_\mathfrak{K} \psi
d \vartheta +\frac{1}{2} \sum_{\nu = 0}^{ \mathfrak{K} - 1}(-1)^\nu\\
& \qquad \int\limits_{\ell \mathscr{G}} \sigma \bigg\{ (( y \frac{\partial
}{\partial y})' )^\nu \psi \bigg\} \Omega \bigg\{
(y\frac{\partial}{\partial y})^{ \mathfrak{K}- 1 - \nu } \varphi
\bigg\}  + \frac{1}{2} \Sigma^{\mathfrak{K}-1}_{ \nu = 0}(-1)^\nu\\
& \qquad 
\int\limits_{\ell G} \sigma \bigg\{ (\frac{\partial}{\partial y})^\nu
\psi \bigg\}' \Omega \bigg\{ (( y \frac{\partial }{\partial y})' )^{
  \mathfrak{K} - 1- \nu }\varphi \bigg\} \tag{407}\label{eq407} 
\end{align*}\pageoriginale
where $H_{\mathfrak{K}}$ is defined in (\ref{eq399}).

By means of the formula (\ref{eq407}) one can prove the orthogonal relations
for angular characters. For we require a special representation for
the scalar product of the angular characters given below. Let $u$,
$\tilde{u}$, be two angular characters and introduce the scalar product
$(u, \tilde{u})$  by  
\begin{equation*}
(u , \tilde{u}) = \int\limits_{\substack y_i \in \mathfrak{K}\\  |y_1|
    = 1} u(r_1) \tilde{u}(y_1) d\vartheta_1 \tag{408}\label{eq408} 
\end{equation*}
Then, 
\begin{align*}
(u , \tilde{u})  & = \int\limits_{\substack{ y_1 \in \mathfrak{K} \\ |
      y_1 | = 1 }} u (y_1) \tilde{u} (y_1) d \vartheta_1 \int\limits^e
  _1 y^{ -1} dy, y = |y|^{ 1/n} \\ 
& = \int\limits_{\substack {y \in \mathfrak{K} \\ i \leq |y| \leq e^n}}
  u (y) \tilde {u}y^{-1} dy d\vartheta_1\\ 
& = \int\limits_{\substack {y \in \mathfrak{K} \\ i \leq |y| \leq e^n}}
  u (y) \tilde {u }(y)  d\vartheta
\end{align*}

We now take for $\mathscr{G}$ in (\ref{eq407}) the domain $\{ y \in
\mathfrak{K} , 1, |y| \leq e^n \}$ .  

This domain is not compact and this presents some difficulty. We have
to approximate this by compact domains $\mathscr{G} i = 1 , 2 ,
\ldots$, apply (\ref{eq407}) to each\pageoriginale $\mathscr{G}_i$ and
resort to a limiting process. Of course all this needs justification.   

A detailed account of some of the results quoted in this section one
finds in the following references. 
\begin{description}
\item[1. E. Hecke,] Eine neue Art von Zetafunktionen und ihre
  Beziehungen Zur Verteilung der Primzahlen, math.Zeit. 1 (1918),
  357-376. 

\item[2. W. Roelcke,] \"Uber die Wellengleichung bei
  Grenzkreisgruppen erster Art, Act. Math (in print). 
\end{description}

