\chapter[The Symplectic group of degree \texorpdfstring{$n$}{n} ....]{The Symplectic group of degree \texorpdfstring{$n$}{n} considered as a Group of
  mappings}% chapter 2 

Let $Z$\pageoriginale be a point of the manifold $\mathscr{Y}$ defined
by $Z = Z'$, $Y > 0   (Z = X + iY)$ and $\mathcal{M}$, a symplectic
matrix: $\mathcal{M} = \begin{pmatrix}A & B \\ C & D \end{pmatrix} \in
S$. We prove that the transformation  
\begin{equation*}
Z \rightarrow \mathcal{M} \langle Z \rangle = (AZ + B) (CZ + D)^{-1}
\tag{23}\label{eq23} 
\end{equation*}
is a $1 -1$ mapping of $\mathscr{Y}$ onto itself. For brevity, we put
$$
P = AZ + B,   Q = CZ + D
$$

In view of (9) we obtain
\begin{align*}
\frac{1}{2i} (P'\bar{Q} - Q'\bar{P}) & = \frac{1}{2i}\big( (Z'A' + B')
(C\bar{Z} + D) - (Z'C' + D') (A\bar{Z} + B)\big) \\ 
& = \frac{1}{2i} (Z' - \bar{Z}) = \frac{1}{2i} (Z - \bar{Z}) = Y > O
\end{align*}

Also the matrix $CZ + D$ is non-singular so that the above mapping is
well defined. For, if $\mathfrak{z}$ be any $n$-rowed complex column
which satisfies the equation $Q   \mathfrak{z} = 0$, then $\bar{Q}
\bar{\mathfrak{z}} = 0$ and $\mathfrak{z}'   Q' = 0$ so that  
$$
\mathfrak{z}'   Y   \bar{\mathfrak{z}} = \frac{1}{2i} (\mathfrak{z}'
P'   \bar{Q}   \bar{\mathfrak{z}} - \mathfrak{z}'   Q' \bar{P}
\bar{\mathfrak{z}}) = 0. \qquad \text{ But } Y > 0. 
$$
Hence it follows that $\mathfrak{z} = 0$ and this in turn implies that
$Q$ is non-singular. 

Let then $Z_1 = PQ^{-1}$. In view of (9) It follows that 
$$
P'Q = (Z'A' + B') (CZ + D) = (Z'C' + D')(AZ + B) = Q'P
$$
in other words, $Z_1$ is a symmetric matrix.

Further 
\begin{align*}
Y_1 & = \frac{1}{2i} (Z_1 - \bar{Z}_1) = \frac{1}{2i} (Z'_1 -
\bar{Z}_1) = \frac{1}{2i}(Q^{'-1} P' - \bar{P}\bar{Q}^{-1})\\ 
& = \frac{1}{2i} Q'^{-1}(P'\bar{Q} - Q'\bar{P})\bar{Q}'^{-1} = Q'^{-1}
Y \bar{Q}^{-1} > 0 \tag{24}\label{eq24}  
\end{align*}

Thus it follows that $Z_1 \in \mathscr{Y}$; in other words, the
transformation (\ref{eq23}) takes $\mathscr{Y}$ into $\mathscr{Y}$. 

A simple computation shows that $\mathcal{M}_1\mathcal{M}_2 \langle Z
\rangle = \mathcal{M}_1 
\langle \mathcal{M}_2 \langle Z \rangle \rangle$, $\mathcal{M}_i \in
S$. Since\pageoriginale 
$\mathcal{S}$ is a group implies that the mapping $ Z \to \mathcal{M}
< Z>$ is 
actually onto and that this mapping has an inverse.   

We showed that $| C Z + D| \neq o$ for any $\begin{pmatrix} A & B \\ C
  & D \\ \end{pmatrix} \varepsilon \mathcal{S}$. Specialising $A,D$ to
be 0, and $B, -C$ to be $E$, the above implies that, for $ Z
\varepsilon \mathscr{Y}$ 
\begin{equation*}
|Z| \neq 0 \tag{25}\label{eq25} 
\end{equation*}

Now for every $ Z \in \mathscr{Y}$, $Z + iE$ also lies in
$\mathscr{Y}$ so that we conclude that 
\begin{equation*}
|Z + i E| \neq o, Z \in \mathscr{Y} \tag*{$(25)'$}\label{eq25'}  
\end{equation*}

We can then introduce the mapping 
$$
W = T < Z > \qquad \text{ with } T = \begin{pmatrix} E & -iE\\ E &
  iE \end{pmatrix} i.e \;\; W = (Z - iE) (Z + iE)^{-1} 
$$

Let $\mathfrak{K}$ be the domain onto which $\mathscr{Y}$ in mapped by
$T$. Then 
\begin{align*}
W-iE & = (Z -iE) (Z + iE)^{-1} -E\\
& = \{ (Z+iE) - (Z-iE)\} (Z+iE)^{-1} = -2i (Z+iE)^{-1}
\end{align*}
so that $|W-iE| \neq 0$  Also $W(Z+iE) = Z-iE $ i.e $i(E+W) = (E-W)Z$
so that $Z = i(E-W)^{-1} (E+W)$. This in particular implies that the
correspondence between $\mathscr{Y}$ and $\mathfrak{K}$ is $1-1$. Also
is it easily seen that the relations $Z = Z'$ and $ W = W'$ are
equivalent. Now 
\begin{align*}
& E - W \bar{W} = E-(Z+iE)^{-1} (Z-iE) (\bar{Z}+iE) (\bar{Z}-iE)^{-1}\\
& = (Z+iE)^{-1} \{ (Z+iE) (\bar{Z}-iE) - (Z+iE) (\bar{Z}+iE)\}
  (\bar{Z}-iE)^{-1}\\ 
& = Zi(Z+iE)^{-1} (\bar{Z}-Z) (\bar{Z}-iE)^{-1}\\
& = 4 (Z+iE)^{-1} Y (\bar{Z}-iE)^{-1} > 0
\end{align*}

Hence $\mathfrak{z}' (E - W' \bar{W}) \bar{\mathfrak{z}}$ is a
hermitian form for any complex column $\mathfrak{z}$. Thus $W = T < Z
>$ satisfies the relations. 
\begin{equation*}
W = W', E - W \bar{W} > o \tag{26}\label{eq26} 
\end{equation*}

We\pageoriginale claim that these relations characterise the elements of
$\mathfrak{K}$. For, if $W$ is any matrix satisfying relations (\ref{eq26}),
then the matrix $E-W$ is non-singular, since the relation $(E-W)
\mathfrak{z} =0$ for any complex column $\mathfrak{z}$ implies along
with (\ref{eq26}) that $\mathfrak{z}' W = \mathfrak{z}'$ and
$\bar{W} \bar{\mathfrak{z}} =  \bar{\mathfrak{z}}$ so that
$\mathfrak{z}' (E - W  \bar{W})  \bar{\mathfrak{z}} = 0$ and
consequently $\mathfrak{z} = 0$. Hence the matrix $Z =i(E -W)^{-1} (
E+W )$ is well defined, and precisely  as in the earlier case it can
be shown that $Z \in \mathfrak{H}$ and that $W = T <z>$. This allows
us to conclude that
the domain $\mathfrak{K}$ is characterised by the relations (\ref{eq26}),
viz. $W=W' E -W\bar{W} > 0$ for any $W \in \mathfrak{K}$. This
domain is one of the four main types of $E$. Cartan's irreducible
bounded symmetric domains. We may remark in this connection that the
domain $\mathscr{Y}$ is called the \textit{generalized upper half
  plane} and the domain $\mathfrak{K}$, the \textit{generalised unit
  circle.}  

We have seen that the symplectic substitutions (\ref{eq24}) form a group of
$1-1$ mappings of $\mathscr{Y}$ onto itself. By means of the
transformation $W = T < Z >$ which is a $1-1$ map of $\mathscr{Y}$ onto
$\mathfrak{K}$, the above group can be transformed into a group of
$1-1$ mappings of $\mathfrak{K}$ onto itself. In fact, which
corresponds to the mapping $Z \to \mathcal{M} < Z >$ of $\mathscr{Y}$
will be 
given by $W \to \mathcal{M}_1 < W >$ where $\mathcal{M} <T^{-1} < W >>
= T^{-1} <\mathcal{M}_1 < W 
>>$. In other words $\mathcal{M}_1 < W > = T \mathcal{M} T^{-1} < W >$
(each of the above 
groups will be shown to be full group of analytic homeomorphisms of
the respective domain). Thus to the symplectic matrix $\mathcal{M}$
corresponds 
the matrix $\mathcal{M}_1 = TMT^{-1}$ and to the group $\mathcal{S}$
corresponds the group $S_1 = TST^{-1}$. Using (6) which
characterises the elements of $\mathcal{S}$ we shall obtain a
characterisation of the elements of $\mathcal{S}_l$. $\mathcal{M}
\in S$ is characterised by $\mathcal{M} = \bar{\mathcal{M}}$, $\mathcal{M}' I
\mathcal{M} = I,I \begin{pmatrix}  0 & E 
  \\ -E & 0\end{pmatrix}$  With $\mathcal{M} = T^{-1} \mathcal{M}_1 T$
  the above give   
\begin{equation*}
\left. 
\begin{aligned}
\mathcal{M}_1' T'^{-1} I T^{-1} \mathcal{M}_1 & = T'^{-1} I T^{-1}\\
\mathcal{M}_1'T'^{-1} I \bar{T}^{-1} \bar{\mathcal{M}}_1& = T'^{-1} I
\bar{T}^{-1} 
 \end{aligned} 
 \right \}.
 \end{equation*}\pageoriginale
  
 By a simple computation we find that 
 \begin{equation*}
T^{-1} = \frac{1}{2i} \begin{pmatrix}  iE & iE \\ -E & E \end{pmatrix}
, - T'^{-1} I T^{-1} = \frac{i}{2} I, T'^{-1} I \bar{T}^{-1} =
\frac{i}{2} H \tag{27}\label{eq27}  
 \end{equation*} 
 where
 $$
 H =   
\begin{pmatrix} 
E & 0 \\ 
0 &-E
\end{pmatrix} 
 $$
 
 Thus $\mathcal{M}_1$ can be characterised by 
 $$
 \mathcal{M}_1' I \mathcal{M}_1 = I ,   \mathcal{M}'_1 H
 \bar{\mathcal{M}}, = H  
 $$
 
 We can replace the second relation, in view of the first, by 
 $$
 I \mathcal{M}_1^{-1} I^{-1} H \bar{\mathcal{M}}_1 = H \quad \text{or}
 \quad I^{-1} H  \bar{\mathcal{M}}_1 = \mathcal{M}_1 
 I^{-1} H. 
 $$
 
 With $K = I^{-1} H = \begin{pmatrix}  0 & E \\ E& 0\end{pmatrix}$ we
   obtain finally the relations 
 \begin{equation*}
\mathcal{M}_1' I \mathcal{M}_1 = I,K \bar{\mathcal{M}}_1 =
\mathcal{M}_1 k \tag{28}\label{eq28}  
 \end{equation*} 
 
 The decomposition $\mathcal{M}_1 = \begin{pmatrix}  A_1 & B_1 \\ C_1 & 
   D_1\end{pmatrix}$ leads to the relations 
 \begin{equation*}
B_1 = \bar{C}_1, D_1 = \bar{A}_1, A'_1 \bar{A}_I -C_1' \bar{C}_1 = E,
A'_1 C_1 = C'_1 A_1 \tag{29}\label{eq29}  
 \end{equation*}
 
 The relations (\ref{eq28}) and (\ref{eq29}) are clearly equivalent. 
 
 We now show that the domains $\mathscr{Y}$ and $\mathfrak{K}$ are
 homogeneous, in other words, that the groups $\mathcal{S}$ and
 $\mathcal{S}_1$ are transitive in their respective domains. It
 clearly suffices to prove for one, say $\mathfrak{K}$, and this in
 turn only requires the determination of a substitution  $\mathcal{M}_1$ which
 takes the point 0 to any assigned point $W \in
 \mathfrak{K}$. If $\mathcal{M}_1 = \begin{pmatrix}  A_1 & B_1 \\ C_1 &
   D_1\end{pmatrix}$, the relation $W = \mathcal{M}_1 < 0 >$ implies that $W =
   B_1 D_1^{-1}$ i.e $B_1 = W D_1$. Then in view of (\ref{eq29}) we should have
   $C_1 = W \bar{D}_1$, $ A_1 = \bar{D}_1$ and $\bar{D}_1 D_1 - \bar{D}_1
   \bar{W} W D_1 = E$. Consequently $\bar{D}'_1 (E - \bar{W}'W) D_1 =
   E$ or $D_1 \bar{D}_1 = (E - \bar{W}' W)^{-1}$. The last
   equation is certainly solvable for $D_1$ as $E -\bar{W}'W$ is
   positive Hermitian. If $D_1$ is obtained as any solution of the
   above equation,\pageoriginale then the earlier equations define
   $A_1$, $B_1$ and    $C_1$ and the matrix $\mathcal{M}_1
   = \begin{pmatrix} A_1 & B_1\\ C_1 &      D_1\end{pmatrix}$ will
     have the desired properties.     

 We proceed to establish a result we promised earlier, viz that the
 group of symplectic substitutions is the full group of analytic
 mapping of the domain $\mathscr{Y}$ onto itself. 
 
 By an \textit{analytic mapping} $Z \to Z^\times$ of $\mathscr{Y}$
 onto itself, we mean a mapping with the following properties  
 \begin{enumerate} [i)] 
\item it is topological, 

\item $Z^\ast_{\mu \nu} = Z^\ast_{\mu \nu} (Z)$ is a regular
  function of the independent elements $Z_{\mu \nu} (\mu \le \nu)$
 for $\mu \nu = 1,2 \dots \eta$ 

\item $Z_{\mu \nu} = Z_{\mu \nu} (Z^\ast)$ is a regular
  function of the independent variables $Z^\ast_{\mu \nu} (\mu \le
  \nu)$ of $Z^\ast$ for $\mu \nu = 1,2 \dots \eta$. 
 \end{enumerate} 
 
 Then every symplectic substitution $Z \to Z^\ast = \mathcal{M} < Z > $ is
 clearly and analytic mapping of $\mathscr{Y}$. We prove the converse
 in the following  


  \begin{thm}\label{chap2:thm1}%the 1
 Every analytic mapping of $\mathscr{Y}$ onto itself is a
  symplectic substitution 
 \end{thm} 
 
 In view of the $1-1$ correspondence between $\mathscr{Y}$ and
 $\mathfrak{K}$ by means of the transformation $Z \to T < Z >$, the
 above will imply a similar result of the domain $\mathfrak{K}$- in
 fact, it suffices to prove the corresponding  result for
 $\mathfrak{K}$ to infer Theorem \ref{chap2:thm1}. Since the group
 $\mathcal{S}_1$ 
 is transitive with regard to $\mathfrak{K}$ we may even assume that
 the given analytic mapping   
 \begin{equation*}
W_o \to W^*_o \tag{30}\label{eq30} 
  \end{equation*} 
  where $W_o = (\omega_{\mu \nu})$ of $\mathfrak{K}$ has 0 as a
  fixed point. Let $W = tW_o$ where $t$ is a complex variable and let
  the characteristic roots of the hermitian matrix $W'_0 \bar{W}$ be
  $r_1, r_2 \dots r_n$ where $o < r_1 \le r_2 \le \dots \le r_n$.  


  It is well known that there exists a unitary matrix $u$ such that 
$$
\mathfrak{A}'W'_o \bar{W}_o \bar{\mathfrak{A}} = \begin{pmatrix}  r_1
  & & 0 \\ &  r_{2_{..}}  & \\ 0 &  & r_n\end{pmatrix} 
$$\pageoriginale  

  We then have
$$
\mathfrak{A}' (E -W \bar{W}) \bar{\mathfrak{A}} = E - t
\bar{t} \begin{pmatrix}  r_1 &  & 0 & \\ & r_2 & & \\ & &  r_n \\ 0 &
  & & \end{pmatrix} >0 
$$
if and only if $t \bar{t} r_n < 1$. But for $t = 1$ $W =W_o$ and we know
that $E -W'_o \bar{W}_o$. Hence $r_n < 1$.It is now immediate that if
$|t| \le 1$ then $E-W'\bar{W} > o$ and consequently $W \in
\mathfrak{K}$. Then to each point $W=t$ $W_o$ with $|t| \le 1$ there
corresponds an image point $W^* \in \mathfrak{K}$. The mapping
$: t \to (t w_o)^* = W^*$ is regular function of the single variable
$t$ in $t \bar{t} r_n < 1$, meaning each element of $W^*$ is a regular
function of $t$, so that there exists a power series expansion for the
elements of $W^*$ in the form  
\begin{equation*}
W^* = \sum_{\mathfrak{K} = 1}^\infty t^\mathfrak{K}
W^*_{\mathfrak{K}} \tag{31}\label{eq31}  
\end{equation*}
which converges for $t \bar{t} r_n < 1$ and, a fortiori for, $|t| \leq
1 1$ where $W^*_\mathfrak{K}$ for each $\mathfrak{K}$ is a matrix
whose elements are functions (polynomials) of the elements of $W_o$
alone. One the other hand, the elements of $W^*$ are regular functions
of the variables $t \omega _{\mu \nu}$ so that they may be developed
into a power series in $t \omega _{\mu \nu}$ (about the origin)
converging for sufficiently small values of the variables. But the
$\omega_{\mu \nu}$ occurring in $W_o \in \mathfrak{K}$ can all be
shown to be uniformly bounded so that we need only restrict $|t|$ to
be small while the $\omega _{\mu \nu}'s$ may be arbitrary in
their domain. Since a power series expansion (for the elements 0
$W^*$) is unique, it follows that (\ref{eq31})  again is the desired power
series and that $t^{\mathfrak{K}}W^*_{\mathfrak{K}}$ is precisely the
aggregate\pageoriginale of all terms $\mathfrak{K}$ in
it. Consequently, the series   
\begin{equation*}
W^*_o = \sum_{\mathfrak{K} = 1}^\infty W^*_\mathfrak{K} \tag{32}\label{eq32}  
\end{equation*}
obtained from (\ref{eq31}) by specialising $t$, converges everywhere in
$\mathfrak{K}$ if we do not spilt up the polynomials which are
elements of $W^*_\mathfrak{K}$ into their single terms. Since $E -W^*
\bar{W}^* > 0$ for $t \bar{t} = 1$,we obtain by integration over the
circle $t\bar{t} = 1$ that  
\begin{equation*}
\frac{1}{2 \pi i} \int\limits_{t \bar{t} =1} (E -W^* \bar{W}^*) \frac{dt}{t}
> 0 \tag{33}\label{eq33}   
\end{equation*}
where by $\int A dt$ with any matrix $ A = (a_{\mu \nu} (t))$ we mean
the matrix\break $(\int a_{\mu \nu} dt)$. Substituting for $W^*$ the series
(\ref{eq31}) which converges uniformly for $| t | \le 1$, termwise
integration yields  
\begin{equation*}
E -\sum_{\mathfrak{K} = 1}^\infty W^*_\mathfrak{K}
\bar{W^*_\mathfrak{K}} > 0 \tag{34}\label{eq34}   
\end{equation*}
the rest of the terms all vanishing. In particular we have
\begin{equation*}
E -W^*_1 \bar{W}^*_1 > 0 \tag{35}\label{eq35}  
\end{equation*}

The elements of $W^*_{\mathfrak{K}}$ are homogeneous polynomials of
degree $\mathfrak{K}$ in $\omega _{\mu \nu} (\mu \le \nu)$ so that the
$n (n+1) /2$ elements of $W^*_1 = (W^{(1)}{^*}_{\mu \nu})$ are
liner functions of the independent elements $\omega_{\mu \nu} (\mu \le
\nu)$. Let $D$ be the determinant of this linear transformation. Since
$W^*_1$ is the linear part of the power series (\ref{eq32}), the functional
determinant of the $n(n+1)/2$ independent elements of $W^*_o$ with
respect to the variables $\omega_{\mu \nu} (\mu \le \nu)$ at the point
$W_o = 0$ is also $D$. As the mapping $W_o \to W^*_o$ is invertible it
follows that $D \neq 0$. Also if we replace the mapping $W_o \to W_o^*$
by its inverse, the determinant change into $D^{-1}$ so that we can,
without loss of generality,assume that $D \bar{D} \ge 1$.   

Consider now the liner mapping $\varphi : W_o \to W^*_1$. Let
$\mathfrak{K}_1$ the image of $\mathfrak{K}$ by $\varphi$. We denote
by $\vartheta(\mathfrak{K}_1)$ the Euclidean volumes of $\mathfrak{K}$
and $\mathfrak{K}_1$, the real and imaginary parts of
$\omega_{\mu \nu}$ being the rectangular cartesian coordinates. Then
we have $\vartheta(\mathfrak{K}_1) = D \bar{D} \vartheta
(\mathfrak{K}) \ge \vartheta (\mathfrak{K})$.  But $\mathfrak{K}_1
\subset \mathfrak{K}$ so that $\vartheta(\mathfrak{K}_1) \le \vartheta
(\mathfrak{K})$. Hence it follows that\pageoriginale
$\vartheta(\mathfrak{K}) = 
\vartheta (\mathfrak{K}_1)$ and $D \bar{D} = 1$. We are going
to conclude from this that $\mathfrak{K} = \mathfrak{K}_1$. Our
argument is as follows. Let $ \mathfrak{K}^\ast$ = Exterior
$\mathfrak{K}= (\bar{\mathfrak{K}})^c$ and $\mathfrak{K}^*_1 =$
Ext  $\mathfrak{K}_1 = (\bar{\mathfrak{K}})^c$  the superscript $`c'$
denoting complements, and the bars denoting the closures. Since
$\mathfrak{K}_1 \subset \mathfrak{K}$ and $\vartheta (\mathfrak{K}_1)
= \vartheta (\mathfrak{K})$ it is immediate that $\vartheta$(Interior
$(\mathfrak{K} - \mathfrak{K}_1) = 0$) and consequently. 

Int $(\mathfrak{K}-\mathfrak{K}_i) = 0$ (void). A point of
$\mathfrak{K}$ is then either a point of $\mathfrak{K}_1$ or a limit
point of $\mathfrak{K}_1$ and so $\bar{\mathfrak{K}} =
\bar{\mathfrak{K}}_1$. We need only show then that the boundary  $Bd
\mathfrak{K} = Bd \mathfrak{K}_1$. Being a linear map, $\varphi$ is a
topological map in the large so that if it maps $\mathfrak{K}$ onto
$\mathfrak{K}_1$ then it maps $Bd \mathfrak{K}$ onto $Bd
\mathfrak{K}_1$, Ext. $\mathfrak{K}$ onto Ext. $\mathfrak{K}_1$, and
$Bd.$ (Ext. $\mathfrak{K}_1$) onto $Bd.$ (Ext $\mathfrak{K}_1$). Thus 
\begin{align*}
Bd .\mathfrak{K}_1 & = \varphi (Bd.\mathfrak{K})  = \varphi (Bd.
\mathfrak{K}^*) = Bd. \mathfrak{K}^*_1 = Bd. (\mathfrak{K}_1)^c\\ 
& = Bd .(\bar{\mathfrak{K}})^c = Bd. \mathfrak{K}^* = Bd. \mathfrak{K}.
\end{align*}

We have incidentally shown that $\varphi$ maps $Bd .\mathfrak{K}$ onto
itself. 

We prove in Lemma \ref{chap2:lem2} that any complex symmetric matrix can be
represented in the form $W_o = u' \mathcal{P}
u$, $u$-unitary and $\mathcal{P}$, a diagonal
matrix with diagonal elements  $p_1 , p_2 \dots
p_n$ where $p^2_2 ,\nu - 1,2 \dots n$ are the
characteristic roots of $W_o \bar{W}_o$. Then $E -W_o \bar{W}_o =
u' \bigg(E-\begin{pmatrix}  2 & 0 \\ p_\nu & \\ 0 &
&\end{pmatrix}\bigg) \bar{u} $ so that $W_o \in
\mathfrak{K}$ if and only if $p^2_\nu <1$, $\nu = 1,2 \dots n$. The boundary
points of $\mathfrak{K}$ are therefore precisely those for which $p^2_\nu
\le 1$, $\nu = 1,2 \ldots n$, the equality holding for at least one
$\nu$. Since $\varphi (Bd. \mathfrak{K}) = Bd .\mathfrak{K}$ it is
immediate that $|E - W^*_1 \bar{W}^*_1| = 0$ for $W_0 \in
Bd. \mathfrak{K}$. In other words, $|E - W^\ast_1 \bar{W}^\ast_1|$
considered a polynomial in
$p_\nu$, $\nu = 1,2,\dots n $ vanishes if $p^2_\nu =
1$ for some $\nu$. Hence it is divisible by $\prod\limits_{\nu = 1}^n
(1 - p^2_\nu)$. Considering the degree of $|E - W^*_1
\bar{W}^*_1|$ in the $p_i's$ we have $|E- W^*_1
\bar{W}^*_1| = c \prod\limits_{\nu=1}^n (1- p^2_\nu)$,\pageoriginale $c-a$
constant. The choice of $P$ as 0 leads to the determination of $c$
to be 1. Hence 
\begin{equation*}
|E- W^*_1 \bar{W}^*_1| = \prod\limits_{\nu=1}^n (1 - p^2_\nu) = |E W_o
\bar{W}_o| \tag{36}\label{eq36}   
\end{equation*}

Replacing $W_o$ in (\ref{eq36}) by $\dfrac{1}{\sqrt{\lambda}} W_o$, in view
of the linearity of $\varphi: W_o \to W^*_1$ we obtain 
$$
|\lambda E W_o \bar{W}_o| = |\lambda E - W^*_1 \bar{W}^*_1 | 
$$
identically in $\lambda$ and therefore that $W_o \bar{W}_0$ and $W_1^*
\bar{W}^*_1$ have the same characteristic roots. Lemma \ref{chap2:lem2} (proved
below) will then imply that  
\begin{equation*}
W^*_1 = u' W_o u \tag{37}\label{eq37}  
 \end{equation*} 
 for some unitary matrix $u$. We stop here to prove

\setcounter{lem}{1}
 \begin{lem}\label{chap2:lem2} %lem 2
Every complex symmetric matrix $W_o$ admits a representation of
  the kind $W_o = u' P u$ with $u'u = E$, $P =\begin{pmatrix}
  p_1 & &  0 \\ & p_{2_{\ddots}}  & \\ 0 & &
   p_n\end{pmatrix}$  $p_\nu ^2$  being the
    characteristic roots of $W_o \bar{W}_o$. 
 \end{lem} 

 \begin{proof}
 $W_o \bar{W}_o$ being hermitian, there exists a unitary matrix $u_1$
   such that $W_o \bar{W}_o = u'_1 \mathcal{P}^2 \bar{u}$. Then $F =
   u'^{-1}_1 W_o u^{-1}_1$ is symmetric and satisfies the relation $F
   \bar{F} = P^2$. Writing $F =F_1 + iF_2$ ($F_\nu$ being real), it
   follows that $F_1 F_2 - F_2 F_1 = 0$. Hence  by a well know result,
   an orthogonal matrix $Q$ can be found which transform $F_1$ and
   $F_2$ simultaneously into diagonal matrices $Q' F_1 Q$ and $Q' F_2
   Q$. Then $R = Q' F Q$ is also diagonal. If $r_\nu$, $\nu = 1,2, \dots
   n$ be the diagonal elements of $R$ the relation $R \bar{R}= Q' P^2
   Q$ implies that $r_\nu \bar{r}_\nu (\nu =1,2, \dots n)$ are identical
   with $P^2_\nu (\nu = 1,2,\dots \eta)$. Then we can find a unitary
   matrix $u_2$ such that $R=u'_2 p u_2$. Now $W_o = u'_1 F u_1 = u'_1
   Q'^{-1} R Q^{-1} u_1 = u'_1 Q'^{-1} u'_2 p u_2 Q^{-1}
   u_1$. Taking\pageoriginale    $u =u'_1 Q^{-1} u'_2$ we obtain $W_o
   = u' P u$. Clearly $u$ is a    unitary matrix.   
 \end{proof} 
 
 We revert now to the proof of the main theorem. From (\ref{eq34}), we have
 \begin{equation*}
E - W^*_1 \bar{W}^*_1 - W^*_{\mathfrak{K}} \bar{W}^*_{\mathfrak{K}} >
0 \tag{38}\label{eq38}   
 \end{equation*}
 for $\mathfrak{K} = 2,3,\ldots$, and any $W_o$. Choosing in
 particular $W_o = u c^{is}$ with $o < u < 1$ and $s =s'= \bar{s}$ we
 get from (\ref{eq37}) that 
 \begin{equation*}
W^*_1 \bar{W}^*_1 = u u' e^{is} u u \bar{u}' e^{-is} \bar{u} = u^2
e^{is}  e^{-is} = u^2 E
\end{equation*}
But $W_o \bar{W}_o = u^2 E$ and form (\ref{eq38})
 $$
(1-u^2) E W^*_{\mathfrak{K}} - \bar{W}^*_\mathfrak{K} > O \text{ for }
 \mathfrak{K} >1, o < u < 1. 
 $$
 
 Letting $u \to 1$ this gives $W^*_{\mathfrak{K}} = 0$ for $\mathfrak{K}
 > 1$, $W_o e^{is}$, $S=S'\bar{S}$ 
 
 Since the elements of $W^*_{\mathfrak{K}}$ are analytic functions of the
 elements of $S$ and they vanish for real values of these elements, it
 follows that they vanish for complex $S$ too. Since the mapping $S
 \to W_o = e^{is}$ maps a neighborhood of $0$ onto a neighborhood of
 $E$ so that $W^*_{\mathfrak{K}} = 0$ in a neighborhood of $E$,  so that
 $W^* _{\mathfrak{K}} =0$ in a neighborhood of for $\mathfrak{K} > 1$,
 we conclude that $W^*_\mathfrak{K}=0$ identically for $\mathfrak{K} >
 1$, and $W^*_o = \sum W^*_\mathfrak{K} =W^*_1 $. Thus the mapping $W_o
 \to W^\ast_0 = W^*_1$ is linear. If now we show that in (\ref{eq37}) the
 matrix $u$ does not depend on $W_o$, then $W ^*_1 = u' W_o u =
 \mathcal{M}_1 <W_o>$ where 
 $\mathcal{M}_1 = \begin{pmatrix} u' & 0\\0 & u^{-1}\end{pmatrix} \in
 S_1$ and our theorem would have been proved. We proceed to establish
 this. 
 
 Let
 \begin{equation*}
W^*_1 = W^*_1 (W_o) = \sum_{\mu \leq \gamma} \omega _{\mu \nu} A_{\mu \nu} 
\tag{39}\label{eq39} 
 \end{equation*} 
 and introduce
 \begin{equation*}
W_1 = W_1 (W_o) = \sum_{\mu \leq \gamma} \omega _{\mu \nu} \bar{A}_{\mu \nu}
\tag{40}\label{eq40} 
 \end{equation*} 
 where\pageoriginale $A_{\mu \nu}$ are constant matrices. Then
 $\bar{W}^*_1 = W_1 
 (\bar{W}_o)$ and $W^*_1 \bar{W}^*_1 = u' W_o \bar{W}_o \bar{u} = E
 W_o \bar{W}_o=E $ Hence $W^*_1 (W_o) W_1 (W^{-1}_o) = E$ for $W_o$
 such that $W_o \bar{W}_o = E$. In particular then, this is true for
 $W_o = e^{is}$ where $S=S' = \bar{S}$ Since $W_1 $ and $W^*_1$ depend
 analytically upon their arguments, this relation holds for complex
 symmetric $S$ too, that is to say identically in $W_o$, by an earlier
 argument.   
 
 For convenience, we shall usually write $W_2$ instead of $W_{\nu\nu}$
 and $A_\nu$ instead of $A_{\nu \nu}$.  
 
 Let
 $$
 W_{oo} \begin{pmatrix} \omega_1 & & o \\ & \omega_2 & & \\ o & & 
   \omega_n\end{pmatrix} W_{o1} = W_o - W_{oo}. 
 $$
 
 Employing the Taylor Series Expansion in the neighborhood of\break $W_{o1} =
 0$ we find 
 \begin{align*}
W^{-1}_o & = (W_{oo} + W_{o1})^{-1} = W_{oo}^{-1} (E + W_{o1}
W_{oo}^{-1})^{-1}\\ 
& = W_{oo}^{-1} - W_{oo}^{-1} W_{o1} W_{oo}^{-1} + \cdots
 \end{align*} 

 Using the linearity of $W_1$ and $W^*_1$ we therefore get
 \begin{align*}
E &= W^*_1 (W_o) W_1 (W_o^{-1})\\
& = (W^*_1 (W_{oo}) + W^*_1 (W_{01})) (W_1 (W_{oo}^{-1}) - W_1
(W^{-1}_{oo} W_{o1} W_{oo}^{-1}) + \cdots) 
 \end{align*} 
 
 Comparing the terms of degree 0 and 1 we obtain
 \begin{align*}
& W^*_1 (W_{oo}) W_1 (W_{oo}^{-1}) = E \tag{41}\label{eq41} \\
 & W^*_1 (W_{oo}) W_1 (W_{oo}^{-1} W_{o1} W^{-1}_{oo}) = W^*_1
   (W_{o1}) W_{11} (W^{-1}_{oo}) \tag{42}\label{eq42}  
 \end{align*}
 
 The first equation means
$ \sum ^n _{\mu,\nu = 1} \omega _\mu \omega ^{-1}_\nu A_\mu
 \bar{A}_\nu = E$ identically in $\omega_\nu$,\break $\nu = 1,2\dots n$ 
 
 This leads to 
 \begin{equation*}
A_\mu \bar{A}_\nu = 0, \mu \neq \nu \tag{43}\label{eq43} 
 \end{equation*} 

 Let the\pageoriginale `$u$' which enters in (\ref{eq37})
 corresponding to $W_{o1} = 0$ be  denoted by $u_o$  
 
 From (\ref{eq37}) and (\ref{eq39}) we get 
 $$
 \sum_{\nu =1}^n \omega_\nu A_\nu = u'_o W_{oo} u_o 
 $$
 
 From this, in view of (\ref{eq43}) we infer that 
 $$
 \sum_{\nu=1}^n \omega_\nu \bar{\omega}_\nu A_\nu \bar{A}_\nu = u'_o
 W_{oo} \bar{W}_{oo} \bar{u}_o \text{ and  consequently} 
 $$ 
 $$
 |\lambda E -\sum^n_{\nu=1} \omega_\nu \bar{\omega}_\nu A_\nu
 \bar{A}_\nu | = | \lambda E -W_o \bar{W}_{oo}| 
 $$
 identically in $\lambda$. Choosing $\omega_\nu = 1$ and $\omega_\nu = 0$
 for $\mu \neq \nu$ the above gives  
 $$ 
 |\lambda E - A_\nu \bar{A}_\nu| = \bigg|\lambda E- \begin{pmatrix}  o
  & & o \\  & 1 & \\ o & & o\end{pmatrix}\bigg| 
 $$
 so that the characteristic roots of $A_\nu \bar{A}_\nu$ are $1,0,0
 \dots 0 $. In virtue of Lemma \ref{chap2:lem2}, we can assert the
 existence of a unitary matrix $\nu$ such that 
 $$
 A_1 = \nu' \begin{pmatrix} 1 &  & o \\ &  o& & \\ & & o & \\o & && 
   o \end{pmatrix} \nu 
 $$
 
 Without loss of generality we can assume $\nu = E$, as in the
 alternative case, we need only consider the mapping $\bar{\nu} W_o^*
 \bar{\nu}$ instead $W_o^*$.   Then $A_\nu \bar{A}_\nu = A_\nu A_1 =
 0$ for $\nu > 1$ by (\ref{eq43}) which means that for $\nu > 1$  
 $$
 A_\nu = \begin{pmatrix}  o & o \\ o & B^{(n.1)}_\nu\end{pmatrix} 
 $$
 
 Successive application of this argument shows that we may assume
 $$
 A_\nu \begin{pmatrix} o & & & & \\ & o & & & \\ & & 1 & \\ & & &
   o\\ & & & & o\end{pmatrix} (\nu = 1,2 \dots n) 
 $$
 
 Then we\pageoriginale shall have $\sum_{\nu=1}^n A_\nu = E$ and 
 \begin{align*}
W^*_1 (W_{oo}) &=\sum^n_{\nu=1} \omega_\nu A_\nu = W_{oo} & and \\
W^*_1 (W_{oo}) &=\sum^n_{\nu=1} \omega_\nu A_\nu = W_{oo}   
 \end{align*} 
 
 From (\ref{eq44}) we then conclude that 
 $$
 W^*_1 (W_{o1}) = W_{oo} W_1 (W_{oo}^{-1} W_{o1} W_{oo}^{-1}) W_{oo}  
 $$
 \begin{align*}
\text{Now}\quad  \qquad  & W^*_1 (W_{o1}) = \sum_{\mu < \nu}
\omega_{\mu \nu} A_{\mu 
  \nu} \qquad \qquad \tag{44}\label{eq44}  \\
\text{and } \qquad \quad & W_{oo} W_1 (W_{oo}^{-1} W_o W_{oo}^{-1})
W_o = \sum_{\mu 
  \nu} \frac{\omega _{\mu \nu}}{\omega_\mu \omega_\nu} W_{oo}
\bar{A}_{\mu \nu}  W_{oo} \tag{45}\label{eq45}  
 \end{align*}
 
 A comparison of (\ref{eq44}) and (\ref{eq45}) yields
 \begin{align*}
A_{\mu \nu} & = \frac{1}{\omega_\mu \omega_\nu} W_{oo} \bar{A}_{\mu
  \nu} W_{oo}\\ 
\text{or }  \hspace{2cm} \omega_\mu \omega_\nu A_{\mu \nu} & = W_{oo}
\bar{A}_{\mu \nu} W_{oo}   \qquad (\mu < \nu). \hspace{2cm}
 \end{align*}
  
 Since this holds identically in $W_{oo}$, setting $W_{oo} =E$, this
 in particular implies that $A_{\mu \nu} = \bar{A}_{\mu \nu}$ i.e
 $A_{\mu \nu}$ is real, and further $A_{\mu \nu} = a_{\mu\nu} (e_{\mu
   \nu} + e_{\nu \mu})$ with real $a_{\mu \nu}$,where $e_{\mu \nu}$
 denotes the matrix with $1$ at the $(\mu, \nu th)$ place and $0$ else
 where. Since $A_\mu \begin{pmatrix}  o & & \\ & 1 & \\ & &
   0\end{pmatrix}$ we have in particular $a_{\nu \nu} = \frac{1}{2}$. 
 
\setcounter{pageoriginal}{27}
 Now $W^*_1 = \sum_{\mu \le \nu} \omega_{\mu \nu} A_{\mu \nu} =
 (a^*_{\mu \nu} \omega _{\mu \nu})$ with real $a^*_{\mu \nu}$ and $a^*
 _{\mu \nu}=1$. In view of (\ref{eq37}), the expression $|W^*_1||W_o|^{-1}$
 has a constant absolute value. On the other hand it is a rational
 function of $\omega_{\mu \nu}$. Consequently it is a constant. Since
 the product $\omega_1 \omega_2 \dots \omega_n$ appears in both the
 determinants with the factor 1, it is immediate that $|W^*_1| =
 |W_o|$. Since the matrix $(\pm \delta_{\mu \nu})$ is unitary, we can
 assume that $a^*_{1 \nu} \geq 0$ for $\nu > 1$.\pageoriginale The
 term $(\omega_1 
 \omega_\mu \omega_\nu)^{-1} \omega \omega_{1 \mu} \omega_{\mu \nu}$
 has in $|W^\ast_1|$ the coefficient $2 a^\ast_{\mu \nu}(1 < \mu <
 \nu)$ and in $|W_0|$, the coefficient 2. Hence 
 $a^*_{\mu \nu} = 1 ( 1 < \mu < \nu)$.  Also the term $(\omega_1
 \omega_\nu)^{-1} \omega \omega^2_{1 \nu}$ has in $|W^*_1|$ the
 coefficient, $-a{^{*{2}}}_{1 \nu}$ and in $|W_o|$, the coefficient
 $-1$. Hence $a^*_{1 \nu}=1$ for $\nu = \ge 1$. We already know that
 $a^*_{\nu \nu} = 1$. Thus we conclude that $W^*_1 = (\omega_{\mu
   \nu}) = W_o$. In other words we have shown that with the aid of
 appropriate symplectic transformations, any analytic map $W_o \to
 W^*_o$ of $\mathscr{Y}$ onto $\mathscr{Y}$ can be reduce to
 the identity  map so that the analytic map we started with must
 itself be symplectic. This completes the proof of theorem
 \ref{chap2:thm1}.  
 
