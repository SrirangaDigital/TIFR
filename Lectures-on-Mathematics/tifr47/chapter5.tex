
 \chapter{Number fields}\label{chap5}
 

 \section{Statement of results}\label{chap5:sec5.1}\pageoriginale
 
 Let $G$ be a semi-simple and simply connected classical group defined
 over a number field $K$. 

 \setcounter{thm}{0}
 \begin{thm}\label{chap5:thm1}
The canonical map $i : H^1(K,G) \to \prod \limits_{V \in \infty}
H^1(K_v,G)$ is bijective 
 \end{thm} 
 
 \begin{thma}\label{chap5:thm1a}
The mapping $i$ above is injective
 \end{thma} 

  \begin{thma}\label{chap5:thm1b}
The mapping $i$ above is surjective; this is true even for connected
semisimple groups but not necessarily simply connected. 
 \end{thma} 
 
 \noindent
 Theorems~1\ref{chap5:thm1a} and 1\ref{chap5:thm1b}~b) together imply
 theorem~\ref{chap5:thm1}.

  
 Let $G/K$ be a semisimple and connected classical group; let $p:\tilde{G} \to
 G$ be the universal covering with kernel $F$. The exact sequence 
 $$
 1 \longrightarrow F \longrightarrow \tilde{G} \longrightarrow  G
 \longrightarrow  1 
 $$
 defines a map $\delta : H^1(K,G) \to H^2 (K,F)$.
 
 \begin{thm}\label{chap5:thm2}
 The map $\delta$ defined above is surjective.
 
 In theorem~\ref{chap5:thm1} we any replace $\prod\limits_{v \in  \infty}$ by
 $\prod\limits_{v}$, since $H^1(K_v,G)=1$ for $v \notin \infty$ by
 theorem \ref{chap4:thm1} of chapter \ref{chap4}. The injectivity of
 the map $H^1(K,G) \to 
 \prod\limits_v H^1(K_v,G)$ is known as the Hasse principle for $H^1$
 of $G$. Harder $[H]$ has proved theorem~\ref{chap5:thm1} for any
 simply connected 
 semi-simple group $G/K$ not containing any factor of type
 $E_\infty$. If $G$ is semi-simple and connected and if $\P :
 \tilde{G} \to G $ be its simply connected covering with kernel $F$
 then Hasse-Principle for $H^1$ of $G$ is equivalent to the Hasse
 Principle for $H^2$ of $F$. The proof of this makes use of a simple
 lemma in diagram chasing which we shall state without proof for
 future reference. 
 \end{thm}

 \setcounter{lem}{0}
 \begin{lem}\label{chap5:sec5.1:lem1}%lemma 1
Let\pageoriginale $A_1$, $A_2$, $A_3$, $A_4$, $B_1$, $B_2$, $B_3$,
$B_4$ be sets with distinguished elements and suppose we have a
commutative diagram with exact rows  
\[
\xymatrix{
A_1 \ar[r] \ar[d]_{f_1} & A_2 \ar[r]\ar[d]_{f_2} & A_3 \ar[r]
\ar[d]_{f_3} & A_4 \ar[d]_{f_4}\\
B_1 \ar[r] & B_2 \ar[r] & B_3 \ar[r] & B_4 
} 
\]

Let $f_1$ be surjective, $f_2$ injective and $f_4$ has trivial kernel
then $f_3$ has trivial kernel. 
 \end{lem} 
 
 For the present assume theorem~\ref{chap5:thm1}, \ref{chap5:thm2}; if
 Hasse-principle for $H^1$ of 
 $G$ is valid then in the diagram below $\beta$ is injective; 
 \[
\xymatrix{
H^1 (K,\tilde{G}) \ar[r] \ar[d]_\alpha & H^1 (K,G) \ar[r] \ar[d]_\beta & H^2
(K,F) \ar[d]_\gamma \ar[r] & 1 \\
\prod H^1 (K_v, \tilde{G}) \ar[r] & \prod H^1 (K_v, G) \ar[r] & \prod
H^1 (K_v, F)
}
\]
 The top row is exact by theorem~\ref{chap5:thm2}; $\alpha$ is
 surjective by theorem~\ref{chap5:thm1}. 
 Clearly the bottom row is exact. Hence by lemma $1$, $\gamma$ has
 trivial kernel; $i.e$. Hasse-Principle for $H^2$ of $F$
 holds. Conversely suppose Hasse-Principle for $H^2$ of $F$ holds; the
 diagram below is commutative with exact rows  
{\fontsize{10}{12}\selectfont
\[
\xymatrix{
H^1 (K,F) \ar[r] \ar[d]_\alpha & H^1 (K, \tilde{G}) \ar[r]
\ar[d]_\beta & H^1 (K,G) \ar[r] \ar[d]_\gamma & H^2 (K,F)
\ar[d]_{\eta}\\
\prod\limits_{v\in \infty} H^1 (K_v, F) \ar[r] &
\prod\limits_{v\in\infty} H^1 (K_v, \tilde{G}) \ar[r] & \prod H^1
(K_v, G) \ar[r] & \prod H^2 (K_v, F) 
}
\]}
where\pageoriginale $\infty$ denotes the set of archimedean places; in
view of theorem~\ref{chap5:thm1},  $\beta$ is bijective; by assumption
$\eta$ is 
injective; also $\alpha$ can be shown to be surjective; hence by lemma
1, $\gamma$ has trivial kernel, by a twisting argument which we have
used several times it follows that $\gamma$ is injective
i.e. Hasse-Principle for $H^1$ of $G$ holds.  

The first step in the proof of theorem~\ref{chap5:thm1} is reduction
to the case of 
absolutely almost simple groups which we shall now carry out; $G$ is a
finite product of $K$-almost simple groups say $G = \prod G_i$; since
$H^1(K,G) \cong H^1 (K,G_i)$, $H^1(K_v,G)\cong \prod H^1(K_v,G_i)$, for
the proof of theorem~\ref{chap5:thm1} it is enough to consider
$K$-almost simple 
groups. So suppose $G$ is $K$-almost simple. By \S~\ref{chap2:sec2.2} \eqref{c2:eq1} 
we know 
that $G= \prod\limits^{r}_{i=1} H_i$ where $H_i's$ are
$\bar{K}$-almost simple groups and that $g_{\bar{K}/K}$ acts on the
set of the $H_i's$ by permuting them; moreover this action is
transitive; hence if $h$ denotes the isotropy group of $H=H_1$ in
$g=g_{\bar{K}/K}$ we have $G=\prod\limits_{s \in g/h}{}^s H$; let $L$
be the fixed field of $h$ and let $M$ be any finite Galois extension
of $K$ containing $L$. For any $K$-algebra $A$ we denote by $G_A$ the
set of $A$-valued points of $G$ i.e. if $G= \Spec B$ then
$G_A = \Hom (\Spec A ,\Spec B) = \Hom_{K-alg}(B,A)$. Consider the
diagram below  
\[
\xymatrix@C=1.4cm{
H^1 (g_{m/K}, G_M) \ar[r]^{f_1} \ar[d]_{\alpha} & H^1 (g_{M/K},
G_{M\otimes_K K_v}) \ar[d]_{\beta}\\
H^1 (g_{M/L}, H_M) \ar[r]_{g_1} & H^1 (g_{M/L} , H_{M\otimes_K K_v})
}
\]
 where \pageoriginale $\alpha$, $\beta$ are the isomorphisms given by
 lemma~\ref{chap1:lem1} of \S~\ref{chap1:sec1.3}; $f_1$, $g_1$
 are the natural  homomorphisms 
 obtained from the canonical mappings $G_M \to G_{M \otimes_K K_v}$
 and $H_M \to H_{M \otimes_K K_v}$; now $M \otimes_K K_v \cong \oplus
 M_{\bar{v}}$  where $\bar{v}$ runs through all places of $M$
 extending $v$ and 
 $g_{M/K}$ permutes the components $M_{\bar{v}}$ transitively, the
 isotropy group of one particular $M_{\bar{v}}$ being its
 decomposition group $g_{M_{\bar{v/}}K_v}$. By lemma~\ref{chap1:lem1} of
 \ref{chap1:sec1.3}, $H^1(g_{M/K}, G_{M \otimes K_v})\cong H^1(g_{M_{\bar{v}}/K_v},
 G_{M_{\bar{v}}}$ and with this identification, $f_1$ becomes the
 canonical map $H^1(g_{M/K}, G_M) \to H^1(g_{M_{\bar{v}}/K_v},
 G_{M_{\bar{v}}})$. Similarly $M \otimes K_v \cong M \otimes_L(L
 \otimes_K K_v) \cong \underset{w/v}\oplus M \otimes_L L_w \cong
 \underset{w/v}\oplus \underset{\bar{w}/w}\oplus M_{\bar{w}}$, and so  
 $$
H^1(g_{M/L}, H_{M \otimes_{K} K_v}) \cong
 \prod_{w/v}H^1(g_{M/L},H_{M \otimes_{L} L_w)} \cong
 \prod_{w/v}H^1(g_{M_{\bar{w}/L_w}}, H_{M_{\bar{w}}}),
$$
 where for each $w$, $\bar{w}$ is an extension of $w$ to $M$. Therefore
 the Hasse Principle for $H^1$ of $G$ will follow if we can prove the
 same for $H$; hence for the proof of theorem~\ref{chap5:thm1} we can restrict
 ourselves to absolutely almost simple and simply connected classical
 groups.  
 
 Before proceeding with the proofs of theorems~\ref{chap5:thm1} and
 \ref{chap5:thm2} we shall 
 discuss the types of involutory algebras $(A,I)$ over $K$. If $I$ is
 of the first kind, $ A \cong A^o$, so $A$ is of order 2 in the
 Brauer group and therefore $A$ is either a matrix algebra over $K$ or
 a matrix ring over a quaternion division algebra $(cf.~De~,e.g.)$.  
  In the case of $\mathscr{P}$-adic field we saw (\S~\ref{chap4:sec4.1},
 proposition~\ref{chap4:prop1}) that the only division algebra with
 involution of 
 the second kind and with centre $L$ is the field $L$ itself. But in
 the case of number fields the situation is different. In fact we
 shall prove the following   
 
\setcounter{proposition}{0}
 \begin{proposition}%pro 1
There\pageoriginale exists a division algebra over $K$ of any given
degree $m$ with an involution of the second kind.  
 \end{proposition}
 
 \begin{proof}
Choose extensions $L/F$ and $M/K$ such that i) $[L:K]=2$ ii) $M/K$ is
cyclic of degree $m$ iii) $L$ and $M$ are linearly disjoint over
$K$. Such a choice is always possible. Then $ML/L$ is again a cyclic
extension and if $\sigma$ is a generator of $g_{ML/L}$ then $\sigma/M$
is a generator of $g_{M/K}$. We shall construct $A$ as a crossed
product $A=(ML/L, \sigma,a)$  where  $a \in L^*$ to be suitably chosen;
this is by definition a left free module over $ML$ with basis
$1=u^o$, $u^1,\ldots,u^{m-1}$ and the multiplication rules are given by  
\begin{align*}
ux & = \sigma_x \cdot u \text{ for } x \in ML \\
u^i,u^j & = u^{i+j} \text{ if } i+j<m,\\
u^i. u^j & = au^{i+j-m} \text{ if } i+j\ge m.\\
\end{align*}
  \end{proof}  
  $A$ is a simple algebra with centre $L$; we then require $a^I=a^{-1}$
  and define $I : A \to A$ as follows: $I|M$ is the identity, $I|L$ is
  the non-trivial $K$-automorphism of $L$ and $u^I=u^{-1}$; if $x=\sum
  x_i u^i$ is any element of $A$ with $x_i \in ML$ we define $x^I =
  \sum u^{-i}x^I_i$; with this definition for any $x \in ML$,
  $(\sigma_x)^I = {}^\sigma(x^I)$; using this it follows that $I$ is an
  involution; clearly $I$ is of the second kind. We seek an additional
  condition on a to make $A$ into a division algebra. $a^I=a^{-1}$ is
  equivalent to $N_{L/K} a=1$ which by Hilbert's theorem 90 implies
  $a=b^I/b$ for some $b \in L$. We have only to choose $b$ properly. By
  Frobenius theorem we can choose a prime divisor $\mathfrak{p}$ in
  $K$ with the properties $i$) if $\mathfrak{p}$ is any prime divisor
  of $M$\pageoriginale dividing $\mathfrak{P}$ then $[M_\mathfrak{p} :
    K_\mathfrak{P}]=m$ and $M_{\mathfrak{p}}/ K_{\mathfrak{P}}$ is
  unramified; ii) $\mathfrak{p}$ splits into two distinct prime
  divisors $\mathscr{G}_1$ and $\mathscr{G}_2$ in $L$. Next choose $b
  \in L$ such that $b \in \mathscr{G}$ but $b \notin \mathscr{G}^2_1$,
  $b \notin \mathscr{G}_2$ and $b$ integral at $\mathscr{G}_2$. We
  claim  that with this choice of $a$, $A$ is a division algebra. For
  $ML/L$ is unramified at $\mathscr{G}_2$ and for $\sigma$ one can
  take the Frobenius automorphism; we shall calculate the
  $\mathscr{G}_2$-invariant of $(ML/L, \sigma,a)$; $ord_{\mathscr{G}_2}
  a=1$ by the choice of $b$ in $a=b^I/b$; hence the $\mathscr{G}_2$
  -invariant will be $\dfrac{1}{m}$ since the local degree of $ML/L$
  at $\mathscr{G}_2$ is $m$ by our choice of $\mathfrak{P}$. Hence
  $(ML/L, \sigma,a)$ has order $m$ in the Brauer group. Now the index
  of an algebra being a multiple of the exponent the index of $(ML/L,
  \sigma, a)$ is $m$, so that it is a division algebra.  

By \S \S \ref{chap2:sec2.4} and \ref{chap2:sec2.6}, the
absolutely almost simple simply 
connected classical groups are classified as follows: 

Type ${}^1A_n$: Norm-one-group of simple algebras ``${}^2A_n$: Groups
belonging to this type are $G= \bigg\{x \in A /Nx =1, xx^{I}=1
\bigg\}$ where $A$ is simple $K$-algebra with involution $I$ of the
second kind, the centre $L$ of $A$ being a quadratic extension of
$K$. 

\noindent
Type $C_n$: Symplectic groups of the special unitary groups of
hermitian forms over quaternion algebras; 

\noindent
Types $B_n$, $D_n$: Spin groups of quadratic forms

Spin groups of skew hermitian forms over quaternion algebras.

\section{Proof of theorem 2}\label{chap5:sec5.2}

The\pageoriginale ideal of the proof can be explained as follows:
\begin{enumerate} 
\item Prove that an element in $H^2(K,F)$ is trivial locally at all
  places outside a finite set $S$ of places of $K$. 

\item Construct a torus $\tilde{T} \subset \tilde{G}$ containing $F$
  such that $H^2 (K_v, \tilde{T})= \{1\}$ for $v \in S$ and such that
  the Hasse principle for $H^2$ of $\tilde{T}$ holds. 
\end{enumerate}

Assuming 1) and 2) have been achieved we have a commutative
diagram with exact rows: 
\[
\xymatrix{
1\ar[r] & F \ar[r] \ar[d] & \tilde{T} \ar[r] \ar[d] & T \ar[r] \ar[d]
& 1 \\
1 \ar[r] & F \ar[r] & \tilde{G} \ar[r] & G \ar[r] & 1
}
\]
$T$ is the quotient of $ \tilde{T}$ by $F$ and the vertical maps are
the natural ones. This gives on passing to cohomology a commutative
diagram in which the top row is exact: 
\[
\xymatrix{
H^1 (K,T) \ar[r]^{\delta_2} \ar[d]_{F} & H^2 (K,F) \ar[r]^{h}
\ar[d]^{\text{identity}} & H^2 (K, \tilde{T})\\
H^1(K,G) \ar[r]^1_{\delta_1} & H^2(K,F)
}
\]
 Given a 2-cohomology class $a= (a_s) \in H^2(K,F)$ construct the
 set $S$ of places as in 1) and $\tilde{T}$ as in 2). By 1) and
 2) $h(a)$ is locally trivial at all places; since the Hesse principle
 for $H^2$ of $\tilde{T}$ holds by construction $h(a)$ must be
 trivial; hence $a$ is in the image of $\delta_2$ and hence of
 $\delta_1$. This proves the theorem  provided we can ensure steps
 1) and 2). 
 
\begin{step}%%% 1
 Let\pageoriginale $(a_s) \in H^2(K,F)$ be given; we have $H^2(K,F)=
 \xrightarrow[L]{\lim} H^2(g_{L/K},\break F_L)$ where $L$ runs through the set of
 finite Galois extensions of $K$; by choosing $L$ big enough assume
 that $(a_s)$ comes from $H^2(g_{L/K}, F_L)$ and that $F_L=
 F_{\bar{K}}$; this being possible by the finiteness of $F$. We define
 $S$ to be the set consisting of archimedean places and all those
 places $v$ of $K$ which are ramified in $L/K$; we shall show that
 this $S$ satisfies our requirements; let $v \notin S$ and suppose $w$
 is an extension of $v$ to $L$; let $l,k$ be the residue fields of
 $L_w$ and $K_v$ respectively; since $v$ is unramified in $L/K$,
 $g_{\ell/k} \cong g_{L_w/K_v}$ and we have an isomorphism $H^2(g_{L_w
   /K_v}, F_{\bar{k}}) \cong H^2(g_{1/k}, F_{\bar{k}})$. Since the
 cohomological dimension of the 
 finite field $k$ is one (\cite{keyS2}, II \S~3) we have $H^2
 (g_{\bar{k}/k}, F_{\bar{K}})=0$; hence there exists a finite extension
 say $l'$ of $k$ containing $l$ such that the inflation map 
 $$
 H^2 (g_{l/k}, F_{\bar{k}}) \longrightarrow H^2 (g_{{l'}/k}, F_{\bar{k}})
 $$
 is zero. We can find a finite Galois extension say $L'_w$ of $K_v$
 containing $L_w$ and unramified at $v$ with residue field isomorphic
 to $l'$; we then have $H^2(G_{l'/k},F) \cong H^2(g_{L'_w/K_v}, F)$ and
 the inflation map $H^2(g_{L_{v'}/K_v}, F) \longrightarrow H^1(g_{L'_w
   /K_v}, F)$ is zero, so $a=0$. This completes the proof of step
 1). 
\end{step}

\begin{step}%%% 2
To any given $v \in S$ we construct a maximal
 torus $\tilde{T}_v \subset \tilde{G}$ containing $F$ and defined over
 $K_v$ such that $H^2(K_v,\tilde{T}_v) = \{1\}$; by \S~\ref{chap4:sec4.2}, 
lemma~\ref{chap4:lem1}, this is possible for every non-archimedean $v \in S$; 
 moreover\pageoriginale we 
 can assume that $S$ contains at least one non-archimedean place $v$
 and remark that for this $v$ by the construction of \S~\ref{chap4:sec4.2}, 
lemma~\ref{chap4:lem1}, there is no non-trivial homomorphism of $G_m$ into
$\tilde{T}_v$ 
 over $K_v$. For archimedean $v$, the same lemma~\ref{chap4:lem1} holds, but we
 omit the proof. By an approximation argument, we can then find a
 torus $\tilde{T}$ defined over $K$ such that $\tilde{T} \cong
 \tilde{T}_v$ over $K_v$ for every $v \in S$. Hence $H^2(K_v,
 \tilde{T}) =(1)$ and $\tilde{T}$ evidently contains $F$. We have only
 to establish the Hasse Principle for $H^2$ of $\tilde{T}$. Suppose
 $(a_s)\in H^2(K, \tilde{T})$ has trivial image in $H^2(K_{v},
 \tilde{T})$ for all places $v$ of $K$; given $v$ we can find a finite
 Galois extension $L/K$ which splits $\tilde{T}$ such that $(a_{s})$
 comes from an element of $H^2(g_{L/K}; \tilde{T}_L)$ and that the
 image of $(a_s)$ under the map $H^2(g_{L/K}, \tilde{T}_L) \to
H^2 (g_{L\bar{v}/K_v}, \tilde{T}_{L\bar{v}})$ is zero; here $\bar{v}$
 denotes some extension of $v$ to $L$; this follows from the
 expression of $H^2()$ as inductive limit. Since any cohomology class
 of $H^2(g_{L/K}, \tilde{T})$ is trivial locally for all but a finite
 number of places (this follows from the results of chapter~\ref{chap3}, in
 particular theorem~\ref{chap3:thm1} and the isomorphism (5))  we can
 assume that 
 the extension $L$ has been so chosen that the image of $(a_s)\in
 H^2(g_{L/K} \tilde{T})$ under the map $H^2(g_{L/K}, \tilde{T})
 \rightarrow H^2(g_{L_{\bar{v}}/K_v}, \tilde{T})$ is zero for all
$v$. \S~\ref{chap3:sec3.2} theorem~\ref{chap3:thm7} then implies
 $(a_s)$ is trivial.  
\end{step}

 This proves theorem \ref{chap5:thm2}.
 

 \section{Proof of theorem~1b}\label{chap5:sec5.3}
 
 We have to prove that if $G$ is semi-simple and connected then the
 mapping $H^1(K,G) \rightarrow \prod\limits_{v} H^1 (K_v, G)$ is
 surjective; on the right hand side we have only to consider real
 infinite places since 
 for complex\pageoriginale places $H^1(K_v,G)= \{1\}$. Hence assume
 $K_v \cong 
 \mathbb{R}$, then by  definition $H^1(K_v, G)=H^1(Z_2, G_c)$ where
 $\mathbb{C}$ denotes the field of complex numbers. Let $(a_s) \in
 H^1(Z_2, G_{\mathbb{C}})$ be given; if $Z_2= \{ e,s\}$ we have $1=
 a_e= a_{s^2}= a_s \cdot {}^sa_s$ i.e. ${}^sa_s = a^{-1}_s$; by the general
 theory of algebraic group we can write $a_s = a'_s. a''_s$ where
 $a'_s$ is semisimple, $a''_s$ is unipotent and $a'_s$ and $a''_s$
 commute; moreover this representation is unique. Since $s_{a_s}=
 s_{a'_s} s_{a''_s}$ we have $a^{-1}_s = {^sa'_s}. {^s a''_s}$; but
 $a^{-1}_s = a'^{-1}_s. a''^{-1}_s$ so that $a'^{-1}_s. a''^{-1}_s =
 {^sa'_s}.{^s a''_s}$; by uniqueness this implies $^sa''_s =
 a''^{-1}_s$ i.e. $ a''_s$ defines a 1-cocycle. The algebraic
 subgroup generated by $a''_s$ is isomorphic to the additive group
 $G_a$; but since the additive group is cohomologically trivial, the
 cocycle $a''_s$ splits; hence for the proof of the theorem we can
 assume without loss of generality that $a_s$ is semi-simple; but any
 semi-simple elements of $G$ is contained in a maximal torus. So any
 element in $\prod\limits_{v \in \infty} H^1(K_v,G)$ is contained in
 the image of $\prod\limits_{v \in \infty} H^1(K_v, T_v)$ for
 suitably chosen maximal tori $T_v$ of $G$ over $K_v$. Now by an
 approximation argument, we construct a maximal torus $T$ of $G$ over
 $K$ which is conjugate to $T_v$ by an element of $G_{K_v}$. Then
 $H^1(K_v, T_v)$ can be replaced by $H^1(K_v,T)$ and 
 theorem~\ref{chap5:thm1} b, 
 follows from the corollary to theorem~\ref{chap3:thm6b} b), 
\S~\ref{chap3:sec3.3} and the 
 commutativity of the diagram 
\[
\xymatrix{
H^1 (K,T) \ar[r] \ar[d] & \prod\limits_{v\in \infty} H^1 (K_v, T)
\ar[d]\\
H^1(K,G) \ar[r] & \prod\limits_{v\in\infty} H^1 (K_v,G)
}
\]
  
\section{Proof of theorem~1a, 
for type ${}^1 A_n$}\label{chap5:sec5.4}  
  
  The\pageoriginale classical group of this type is $G = \bigg\{ u \in
  A \bigg/ Nu=1 
  \bigg\}$ where $A$ is a simple algebra with centre $K$ and $N$
  stands for the reduced norm. The exact sequence of algebraic groups 
    $$
  1 \rightarrow G \rightarrow A^* \xrightarrow{N} G_m 
  $$ 
  gives rise to a commutative diagram with exact rows:
\[
\xymatrix{
A^{\ast}_K  \ar[r]^N \ar[d] & K^\ast\ar[r] \ar[d] & H^1 (K,G) \ar[r]
\ar[d] & H^1 (K,A^{\ast}) = \{1\}\\
\prod\limits_{v\in\infty} A^\ast_{K_v} \ar[r]^N &
\prod\limits_{v\in\infty} K^\ast_v \ar[r] & \prod\limits_{v\in\infty}
H^1 (K_v, G) \ar[r] & \prod\limits_{v\in\infty} H^1 (K_v, A^\ast) = \{1\}
}
\]  
    $H^1(K,A^*) = \{1\}$ and $H^1(K_v, A^*)= \{1\}$ by \S~\ref{chap1:sec1.7}, 
Example~\ref{chap1:exam1}. By the usual twisting argument injectivity
of $H^1(K,G) 
\rightarrow \prod\limits_{v \in \infty}H^1(K_v,G)$ is equivalent to
kernel being trivial for all twisted groups. By diagram chasing we are
reduced to proving the following. 
    
\begin{prop*}{\em (Norm theorem for simple algebras).}
 If an element  $x$ of $K^*$ is the reduced norm of an element in
 $A_{K_v}$ for all places $v$ of $K$ then it is the reduced norm of an
 element in $A$.   
 \end{prop*}        
 
 We shall give Eichler's proof $[E_1]$ with slight
 modifications. First we shall introduce some terminology; the
 principal polynomial of an elements $a$ in a central simple algebra
 $A$ is by definition the characteristic polynomial of $a \otimes 1$ in
 an isomorphism $A \otimes_KL \cong M_n (L)$ where $L$ is a splitting
 field of $A$. This polynomial has coefficients in $K$ and is
 independent of the splitting of the splitting field $L$ and the
 chosen\pageoriginale isomorphism  $A \otimes_KL \cong M_n(L)$. An
 element $a \in A$ is said to be a regular element if its principle
 polynomial is separable. 
 
 The proof of the proposition depends on the following lemmas:
 
\begin{lemb}\label{chap5:lema} 
Let $K$ be an infinite field and $A$ a simple algebra with centre
$K$. If $x \in K$ is the reduced norm of an element $z \in A$ then one
can find a regular element $\bar{z} \in A$ whose reduced norm is $x$.  
\end{lemb}
   
\begin{proof}
Since $A_{\bar{K}}$ is a matrix algebra over $\bar{K}$ we can find a
regular diagonal matrix $y$ with determinant $x$. $N(zy^{-1})=1$,
which implies $y=z[a_1, b_1] \cdots [a_r, b_r]$ where $[a_1,
b_1],\ldots,[a_r,b_r]$ are certain commutators in $A_{\bar{K}}$; let
$e_1, \ldots , e_M$ be a basis of $A/K$ where $M=[A:K]=n^2$. Let
$\alpha_1^{(i)}, \ldots , \alpha^{(i)}_M$, $\beta^{(j)}_1, \ldots ,
\beta^{(j)}_M$, $i,j$ taking the values $1,2, \ldots ,r$ independently
be a set of independent variables. Write $x_i= \sum\limits_{t=1}^M
\alpha^{(i)}_t e_t$, $y_j= \sum\limits_{t=1}^M \beta^{(j)}_t
e_t$. Consider the generic element $z[x_1, y_1]M[x_r, y_r]$ of
$A_{\bar{K}}$. The discriminant of its characteristic polynomial is
not identically zero since for the choice $x_i=a_i$, $y_j=b_j$ the above
generic element specializes to the regular element $y$. This
discriminant can be written as $P/Q$ where $P$ and $Q$ are polynomials
in the variables $\alpha^{(i)}_t$, $\beta^{(j)}_{t'}$ and by what we
said above $P,Q$ are not identically zero. Since $K$ is infinite we
can specialize $\alpha^{(i)}_t$, $\beta^{(j)}_{t'}$ to elements of $K$
for which $P \neq 0$ and $Q \neq 0$; if $x_i$  specializes to $x'_i$
and $y_j$ to $y'_j$ under this specialisation of $\alpha^{(i)}_t$,
$\beta^{(j)}_{t'}$ then $z[x'_1, y'_1] \cdots [x'_r, y'_r]$ is a
regular element of $A$ with reduced norm equal to that of $z$, i.e. its
reduced norm is $x$. This proves the lemma. 
\end{proof}


\begin{lemb}\label{chap5:lemb} 
Let\pageoriginale $A/K$ be a simple algebra of degree $n^2$ over its 
centre $K,K$ 
being any field; then $A$ contains an element with principal
polynomial equal to a given separable polynomial $f(X)$ of degree $n$
if and only if for every irreducible factor $g(X)$ of $f(X)$ the
algebra $A\otimes_K K[X]/g(X)$ splits.  
\end{lemb}

If $f$ is irreducible, this is standard. The proof for the general
case is similar to the usual one $(cf. [K_1])$.  

\begin{lemb}\label{chap5:lemc} 
Let $K$ be a number field and $f(X)\in K[X]$ a separable
polynomial; let $A$ be a simple algebra with centre $K$; then $A$
contains an element with principal polynomial $f(X)$ if and only if
$AK_v$ contains an element with principal polynomial equal to
$f(X)$ for every place $v$ of $K$. 
 \end{lemb}
  
 \begin{proof}
We shall make use of lemma~\ref{chap5:lemb}); let $g(X)$ be an irreducible factor
of $f(X)$ and suppose $L=K[X]/g(X)$; let $g(X)=g_1(X)g_2(X) \cdots
g_r(X)$ be the decomposition of $g$ into irreducible factors over
$K_v$; then we have  
$$
(A \otimes_K L) \otimes_KK_v \cong \oplus A \otimes_K K_v[X]/g_i(X)
\cong \oplus A_{K_v}\otimes_{K_v} K_v[X]/g_i(X) 
$$

\noindent
By assumption and lemma~\ref{chap5:lemb}), $A_{K_v}\otimes_{K_v} K_v[X]/g_i (X)$ is
a matrix algebra over $K_v[X]/g_i(X)$ so that $(A \otimes_KL)
 \otimes_KK_v$ is a direct sum of matrix algebras. Also $L
\otimes_KK_v \cong \oplus_{w/v} L_w$, the direct sum extended over all
the extensions of $v$ to $w$; hence 
 $A \otimes_K L \otimes_K K_v \cong \oplus_{w/v} A \otimes_KL_w \cong
\oplus_w (A \otimes_KL) \otimes_L L_w= \oplus_w A_L \otimes L_w$ say
where $A_L=A \otimes_KL$. From the splitting criterion for simple
algebras over number\pageoriginale fields it follows that $A \otimes_KL$ is a
matrix algebra. Since $g(X)$ is any irreducible factor of $f(X)$ by
lemma~\ref{chap5:lemb}) it follows that $A$ contains an element with principal
polynomial equal to $f(X)$. This proves the lemma. 
 \end{proof}


 \begin{proofofproposition}\label{chap5:prfprop1}%\pro 1
By lemma~\ref{chap5:lema}) we can find regular elements $z_v$ of $A_{K_v}$ such
that $x=Nz_v$ for every place $v$ of $K$. Let $f_v(X)=X_n - \cdots +
\cdots + (-1)^nx$ be the principal polynomial of $z_v$. Let $T$ denote
the set of places $v$ of $K$ for which $A_{K_v}$ is not a matrix
algebra over $K_v$; then $T$ is a finite set. Construct the polynomial
$f(X)=X^n - \cdots + \cdots (-1)^n x$ with the constant term $x$ such
that its coefficients approximate those of $f_v(X)$ for $v \in T$. If
the approximation is close enough $f(X)$ will be separable and
$K_v[X]/f(X) \cong K_v[X]/f_v(X)$ for $v \in T;$ this can be proved by
Newton's method of approximating roots of polynomial; here one has to
use the fact that the $f_v(X)'s$ are separable polynomials; we
therefore assume $K_v[X]/f(X) \cong K_v[X]/f_v(X)$ for $v \in T$. Now
since $f_v(X)$ is the principal polynomial of $z$ in $A_{K_v}$ there is an
isomorphism of $K_v[X]/f_v(X)$ into $A_{K_v}$ and from $K_v[X]/f(X)
\cong K_V[X]/f_v(X)$ we conclude that there exists an isomorphism of
$K_v[X]/f(X)$ into $A_{K_v}$ for $v \in T$. Hence there exists an
elements an element in $A_{K_v}$ whose principal polynomial is equal
to $f(X)$; this  is true fro every $v \in T$. If $v \notin T$ then by the
definition of $T, A_{K_v}$ is a matrix algebra so that there always
exists a matrix in $A_{K_v}$ with characteristic polynomial
$f(X)$. Hence the conditions of lemma~\ref{chap5:lemc}) are satisfied and we
conclude that $f(X)$ is\pageoriginale the principal polynomial of some
element $z$ 
of $A$; but then  $Nz =x$ so that $x$ is needed the reduced norm of
the element $z$ of $A$. This proves the proposition and so 
theorem~\ref{chap5:thm1}a) is proved for groups of type $^1A_n$.   
\end{proofofproposition} 

\section[Proof of theorem 1a for type...]{Proof of theorem 1a for type ${}^2A_n$; reductions
  (Landherr's theorem)}\label{chap5:sec5.5}

 The classical group in this case is $G=\bigg\{x \in A /xx^{I}=1,Nx=1
 \bigg\}$ where $A$ is a simple $K$-algebra with involution $I$ of the
 second kind the centre 
  $L$ of $A$ being a quadratic extension of $K$. Consider the map
  $\eta : x \rightarrow (xx^{I}, Nx)$ of $G$ into $A^* \times L^*$,
  the latter being considered as an algebraic variety over $K$ as
  explained in \S~\ref{chap3:sec3.1} Example~1
  $y=xx^{I}$ and $z=Nx$ satisfy 
  the relations $y^I=y$ and $Ny=zz^{I}$, define $H=\bigg\{ (y,z)\in
  A^* \times L^* \bigg / y^I=y, Ny=zz^{I}\bigg\}$; this $H$ is not an
  algebraic group; but it becomes a homogeneous space for $A^*$ under
  the operation given by $x:(y,z) \rightarrow(xyx^{I}, zNx)$. The
  sequence $1 \rightarrow G \rightarrow A^{*} \rightarrow H
  \rightarrow 1$ is then an exact sequence and we get the following
  commutative diagram: 
{\fontsize{9}{11}\selectfont
\[
\xymatrix@C=1.3cm{
A^\ast_K \ar[r]^{\eta}\ar[d] & H_K \ar[r]^{\delta}\ar[d] & H^1 (K,G)
\ar[r] \ar[d]_{\mathfrak{h}} & H^1 (K, A^\ast) = \{1\}\\
\prod A^\ast_{K_v} \ar[r]^\eta & \prod H_{K_v} \ar[r]^{\delta} & \prod
H^1 (K_v, G) \ar[r] & \prod H^1 (K_v, A^\ast) = \{1\}
}
\]}
 The mapping $\delta's$ are surjective since by 
\S~\ref{chap1:sec1.7} Example~\ref{chap1:exam1} 
 $H^1(K,A^*)= \{1\}$ and $H^1(K_v, A^*) = \{1\}$ for every place $v$ of
 $K$. As in the previous paragraph we see that the kernel of $h$ is
 trivial if and only if every element $b \in H_K$ which is in
 $\eta(A^*_{K_v})$ for all $v$ actually is in $\eta(A^*_K)$. So we
 have to prove the       
 
\setcounter{proposition}{0}
\begin{proposition}\label{chap5:prop1}%pro 1
Let\pageoriginale $y \in A^*_K$, $z \in L^*_K=L^*$ be such that $y^1=y$ and
$N_y=zz^I$; suppose the equations $y=xx^I$, $z = Nx$, $x \in A^*$ are
solvable locally at all places $v$ of $K$ i.e. with $x=x_v \in
A^*_{K_v}$; then they can be solved globally in $K$, i.e. with $x \in
A^*_K$. For the proof of this proposition we shall first carry out
several reductions. 
\end{proposition}

\begin{reduction}\label{chap5:red1}
Write $z=Nx_v$, $x_v \in A^*_{K_v}; i)$ if $v$ extends uniquely to a place
$w$ of $L$ then $A_{K_v}= A \otimes _K K_v \cong B$ where $B$ is a
simple algebra over $L_w$; this is because $A \otimes_K K_v$ is a
direct sum of simple algebras and since its center $L \otimes_K K_v$
is a field, there is only one simple component; moreover, we have
$A_{K_v} \cong A \otimes_L L_w$. ii) On the other hand if $v$ extends to
two different places $w_1,w_2$ of $L$ then $A_{K_v} \cong A_1 \oplus
A_2$ where $A_1$ and $A_2$ are simple algebras over $L_{w_1}$ and $L_{w_2}$
respectively; this is because in this case $L \otimes _K K_v \cong
L_{w_1} \oplus L_{w_2}$ and since $A_{K_v}\cong A \otimes _L (L
\otimes _K K_v)$ we have $A_{K_v}\cong A_1 \oplus A_2$ where $A_1=A
\otimes _L L_{w_1}$  and $A_2=A \otimes _L L_{w_1}$. In the first case
$z$ is the reduce norm of an element of $A \otimes_L L_w$. while in
the second case $z$ is a reduced norm from both $A_1$ and $A_2$. Hence
$z$  is local 
norm of the algebra $A/L$ at all places of $L$; by the norm theorem
for simple algebras (\S~\ref{chap5:sec5.4})  we conclude that
$z=Nt$ where $t \in 
A^*_K$. Replace $(y,z)$ by $(t^{-1}yt^{-I},zNt^{-1})$. The components
$t^{-1}yt^{-I}$ and $zNt^{-1}$ satisfy the same condition as $(y,z)$;
if the proposition is true for the pair $(t^{-1}yt^{-I},zNt^{-1})$
then it is true also for the pair $(y,z)$; now $zNt^{-1}=1$ by the
choice of $t$; hence we are reduce to proving the proposition in the
case when $z=1$.   
\end{reduction}

\begin{reduction}\label{chap5:red2}
To carry out this reduction we need the following.
\end{reduction}

\setcounter{lem}{0}
\begin{lem}\label{chap5:lem1}%lemm 1
If\pageoriginale $y \in A^*_K$ is such that $y^I =y,Ny=1$ and if the equation
$y=xx^I, x \in A^*$ is solvable locally at all places then it is
solvable globally. To start with assume this lemma. The element $y$ of
proposition~\ref{chap5:prop1} after reduction~1) satisfies all the conditions of
lemma~\ref{chap5:lem1}. Let $x \in A$ be a solution of $y=xx^I$ assured by 
lemma~\ref{chap5:lem1}. Replace $(y,z)$ in the proposition by $(x^{-1}yx^{-1},
zNx^{-1})$. This shows that for the proof of the Proposition~\ref{chap5:prop1} we
can assume without loss of generality that $y=1$; but  we can no
longer assume $z=1$. 
\end{lem}

We shall now prove lemma~\ref{chap5:lem1}. Let us start by explaining our notation
to be used in this paragraph. The dimension $[A:L]$ is denoted by the
integer $n^2$. If $v$ is any place of $K$ then two cases occurs i)
$L_{K_v} \cong L_{w_1} \oplus L_{w_2}$ if $v$ extends to two different
places $w_1$ and $w_2$ in $L$. ii) $L_{K_v}$ is a field if $v$ extends
uniquely to a
place $w$ of $L$; in this case $L_{K_v} \cong L_w$. In case i)
$A_{K_v}\cong A_1 \oplus A_2$ where $A_1 \cong A \otimes_L L_{w_1}$
and $A_2 \cong A \otimes_L L_{w_2}$; the action of $I$ is to
interchange the component. In case ii) $A_{K_v} \cong A \otimes_L
L_{w}$  is simple algebra with center $L_w$. If $u$ is an element of
$A_{K_v}$ we denote its components in case i)
 by $u^{(1)}$  and
$u^{(2)}$; in case ii) $u$ considered as an element of $A
\underset{L}\otimes L_w$ is denoted by $u^{(1)}$; the two uses of the
symbol $u^{(1)}$ corresponding to the different cases will be
evident from the context and will not lead to any confusion. In case
i) $N$ stands for the reduced norm of $A_{K_v}$, i.e if
$u=(u^{(1)},u^{(2)})\in A_{K_v}$ then $Nu=(N_1u^{(1)},N_2u^{(2)})$
where $N_1$, $N_2$ are the reduced norm mapping of the simple algebras
$A_1$ and $A_2$ respectively; in case ii) $N$ shall
denote\pageoriginale the 
reduced norm of the simple algebra $A \otimes_L L_w$. By an order in a
simple algebra $A/K$ we mean a subring of $A$ which is finitely
generated as a module over the ring of integers of $K$ and such that
it generates $A$ as a $K$-vector space. The algebra $A_{K_v}$ being
finite dimensional over the complete field $K_v$ it is a normed
algebra and that all its norm inducing $v$-topology on $K_v$ are
equivalent; when we talk of approximation of elements in $A_{K_v}$ we
mean this in the sense of the norm topology on $A_{K_v}$. If
$\mathscr{O}$ is an order in $A$ its completion at the place $v$ is
denote by $\mathscr{O}_v$. We shall state without proof two sublemmas
which we shall use; the first one is a special case of a more general
theorem of Hasee:   


\begin{sublema}\label{chap5:sublema}
(Norm theorem for quadratic extensions).
 If $L/K$ is a quadratic extension of the number field $K$ then an
 element of $K$ is a norm from $L$ to $K$ if and only if it is locally a
 norm at all places of 
  $K$. 
\end{sublema}

\begin{sublema}\label{chap5:sublemb}
(Strong approximation theorem for simple algebras, cf \cite{keyE2},
\cite{keyK1}). Let $G$ be the norm one group of the simple algebra $A$
  with center $K$, a number field, and $\mathscr{O}$ an order in $A$;
  let $S \supseteq \infty$ be a finite set of places of $K$. Suppose given a
  place $v_o \in S$  such that $A_{v_o}$ is not a division algebra,
  and element $a_v \in G_{K_v}$; then there exists $x \in G_K$ such that
  $x \cong a_v$ in the $v$-topology for $v \in S$, $v \neq v_o$ and $x
  \in \mathscr{O}_v$ for $v \notin S$. 
\end{sublema}

\setcounter{proofoflem}{0}
\begin{proofoflem}\label{chap5:proofoflem1}%%% 1
  The idea of the proof can be explained thus: Replace $y$ by the
element $t_J t^{I}$ where $t \in A^*_K$ and $Nt=1$; choose $t$ in such
a way that $K(tyt^{I})$ becomes a separable algebra of maximal
degree;\pageoriginale 
and then seek a solution of $tyt^I=xx^{I}$ with $x \in L(tyt^I)$. If
the latter is possible then clearly the lemma will be proved. The
actual construction of $t$ will be the last step of the proof. In two
preliminary steps we shall assume that $K(tyt^I)$ is a separable
algebra of maximal degree, and investigate conditions for solvability
of $tyt^I=xx^I$. In step 1) we show, by means of the quadratic norm
theorem, that solvability is assured, once we know the solvability
with $x \in L(tyt^I) \otimes K_v$ for every place $v$ of $K$. step
2) is preparatory to step 3) in which we derive several
sufficient conditions for the local solvability at $v$. In the final
step 4) we construct $t$ by means of the approximation theorem in
such a way that for every place $v$ at least one of these conditions
is satisfied. Clearly the proof of the lemma will then be complete. 
\end{proofoflem}

As outlined above we shall assume that $K(tyt^I)$ is a
separable algebra of maximal degree. Since $I$ is identity on
$K(tyt^I)$ and  not the identity on $L(tyt^I)$, the latter is
the direct sum of the spaces of symmetric elements and
antisymmetric elements; if $L=K(\sqrt {d})$ then $K(tyt^I)$ is
the space of symmetric elements while $\sqrt{d}K(tyt^I)$ is
the space of antisymmetric elements; hence 
$$
L(tyt^I) \cong
K(tyt^I) \oplus \sqrt{d}K (tyt^I) \cong (K \oplus \sqrt{d}K)
\otimes K(tyt^I)\cong L \otimes K(tyt^I).
$$
Since $K(tyt^I)$ is
a commutative separable algebra it is the direct sum of
separable extension fields $K_i(i=1,2, \ldots r)$ of $K$. If
$K_1$ is one such component then $L \otimes_K K_1$ being an
algebra of degree two over $K_1$ must be either a quadratic
extension of $K_1$ or a direct sum of two algebras isomorphic
to $K_1$; in the former case  
$I$ is\pageoriginale the nontrivial $K_1$-automorphic of $L \otimes
K_1$ while in the latter case $I$ interchanges the components of any
element of $K_1 \oplus K_1$. Accordingly let $K_1, \ldots,K_s$ be those
field among $K_i(i=1,2,\ldots r)$ for which $L \otimes_K K_j$ is a
quadratic extension of $K_j(j=1,2,\ldots,s)$. Then we have $L(tyt^I)\cong (L
\otimes K_1 \oplus  \cdots \oplus L \otimes K_s)\oplus (K_{s+1}\oplus
K_{s+1}) \oplus \cdots \oplus (K_r \oplus K_r)$. Let  $x=(x_1,
\ldots,x_s,x_{s+1},x'_{s+1}, \ldots ,x_r,x'_r)$ be any element of
$L(tyt^I)$; $x^I=(x^I_1, \ldots ,x^I_s, x'_{s+1},x_{s+1}, \ldots
,x'_r,x_r)$ so that we have 
$xx^I=(Nx_1, \ldots, Nx_s,x_{s+1} x'_{s+1}, x'_{s+1}x'_{s+1}, \ldots ,x_r
x'_r, x_rx^1_r)$. We want to solve $tyt^I=xx^I$ with $x \in L(tyt^I)$;
for this assume 
$tyt^I = (a_1,a_2, \ldots, a_s,a_{s+1}, a^1_{s+1}, \ldots , a_r,a'_r)$;
since $tyt^I$ is symmetric we have $a^I_j=a_j(j=1,2,\ldots s)$ and
$a'_l=a_l (l=s+1, \ldots ,r)$. From what precedes we are reduced to solving
the following system of equations;  

\noindent 
$\alpha)$~  $Nx_j=a_j$, $j=1,2, \ldots s$ where $a_i \in K_i$ and $N$
denoted the norm map of the extension fields $L \otimes K_j/K_j$. 

\noindent
$\beta)$~ $x_l x'_l=a_l$, $l=s+1, \ldots r a_l \in K_i$  

\noindent
of these $\beta)$ is trivial. For solving $\alpha)$ by Sublemma a it
is enough to know the local solvability of the equations $\alpha$ at
all places of $K_j$. Now if $v$ is any place of $K$ then 

\noindent
$(L \otimes K_j)\otimes K_v \cong \underset {w/v}\oplus (L \otimes 
K_j)_w$ where $w$ runs through all extensions of $v$ to the field $L
\otimes K_j (j=1,2,\ldots s)$. This implies $L(tyt^I)\otimes K_v
\overset{s} {\underset{i=1}\oplus} \underset {w/v} \otimes (L \otimes
K_i)_w \overset{r}{\underset{j=s+1}\oplus} L \otimes K_j \otimes
K_v$. This shows that if the equation $tyt^I=xx^I$is solvable with $x
\in L(tyt^I) \otimes K_v$  for\pageoriginale all places $v$ of $K$
then system of equation $\alpha)$ will be solvable locally at all
places of $K_j$. As observed before this will imply the global
solvability of equations $\alpha)$. This proves step 1).  

\setcounter{proofofstep}{1}
\begin{proofofstep}%prof 2
Let $u_v \in A^*_{K_v}$ be a solution of $u_vu^I_v=y$. We claim that
$u_v$ can be so chosen that $Nu_v=1$. To see this replace $u_v$ by
$u_v.v_v$; the condition $y=(u_v v_v)(u_v v_v)^I$ then means
$v_vv^I_v=1$ and $N(u_v v_v)=1$ means $N v_v=Nu^{-1}_v=c$ say. From
$Ny=1$ we get $c_vc^I_v=1$. Hence our claim will be achieved if the
following problems is solved: given $c_v \in L \otimes K_v$ such that
$c_vc_v^I=1$ and that $c_v$ is norm of $A \otimes K_v$ to find $r_v
\in \otimes K_v$ satisfying the conditions $N r_v=c_v$. This we shall
do now. In case $i$), this is immediate. In case $ii$) $A_{K_v} \cong A
\otimes_L L_w$ is an algebra over $L_w$ with an involution of the
second kind. If $v$ is non-archimedean $A_{K_v}$ must be a matrix
algebra; the same holds for archimedean $v$, since then $L_w \cong
\mathbb{C}$; moreover if $x$ is a matrix of this algebra say
$x=(x_{ij})$ then $x^I=ax^*a^{-1}$ where $x^*=(x^I_{ij})$ and a is a
hermitian matrix. The condition $r_vr^I_v=1$ means that $r_v$ is a
unitary matrix corresponding to $a$. Hence we have to find a unitary
matrix of a with given determinant $c_v$; by choosing an orthogonal
basis one can assume\pageoriginale that a is diagonal 
$\begin{pmatrix}
 d_1 & &\\
 &\ddots & \\
& &d_n 
\end{pmatrix}$; since
   $c_vc_v^I=N_{L_{w/K_v}}c_v=1$ we can find elements $d_1, \ldots
,d_n$ of $L^*_w$ such that $N_{L_{w/K_v}}d_i=d_id_i^I=1$ and
that $d_1 \cdots d_n=c_v$ (for we can arbitrarily choose
$d_1,d_2,d_{n-1}$ to satisfy $N_{L_{w/K_v}} (d_i)=1$ and then $d_n$ by
the condition $d_1 \cdots d_n=c_v$). The matrix 
 $ 
\begin{pmatrix}
d_1 &  ..\\
 &\ddots & \\
& &d_n
\end{pmatrix}
$ can then be taken for $u_v$. This finishes step 2).
 \end{proofofstep}
 
\begin{step}%%% 3
 We shall describe three situations in which
 $tyt^I=xx^I$ is solvable with $x \in L(tyt^I)\otimes K_v$. Situation
 a) $t \cong u^{-1}_v$ in $A_{K_v}$ in the sense of the norm
 topology on $A_{K_v}$. Suppose $\mathscr{O}$ is any order in $A_K$;
 we can assume $\mathscr{O}^I=\mathscr{O}$ since otherwise we can
 replace $\mathscr{O}$ by the order $\mathscr{O} \cap \mathscr{O}^{I}$
 which will satisfy this condition. Situation $b$) $v$ non archimedean
 unramified in $L/K$ and $tyt^I \in \mathscr{O}_v$. Situation $c$) $v$
 decomposes into two places in $L$. In situation $a$) 
 $tyt^I \cong u^{-1}_v yu^{-I}_v.=1$ so that by the binomial theorem
 $tyt^I$ is the square of an element of $K(tyt^I)\otimes K_v$; hence
 we can write $tyt^I=x_vx^I_v$ with $x_v \in K (tyt^I) \otimes K_v$;
 this is what we wanted. In situation $b$) since $tyt^I \in
 \mathscr{O}_v \cap K(tyt^I)$, the components of $tyt^I$ in $K(tyt^I)
 \otimes K_v$ are\pageoriginale integers; these components are
 moreover units as 
 follows from $Ntyt^I=1$. Since $L/K$ is unramified at $v$ the
 components $L \otimes K_i (i=1,2, \ldots s)$ of $L(tyt^I)$ are also 
 unramified at $v$. Since in an unramified local extension any unit is
 a local norm we conclude $tyt^I$ can be written as $x_vx_v^I$ with
 $x_v \in L(tyt^I) \otimes K_v$. In situation $c$), the place $v$ of
 $K$ decomposes  into two distinct places in each of the components $L
 \otimes K_i (i=1,2, \ldots ,s)$ of $L(tyt^I)$. This shows that the
 local degree corresponding to $v$ of the extension field $L \otimes
 K_i /K_i$ are all unity and so we can find in this case too elements
 $x_v \in L(tyt^I) \otimes K_v$ with property $tyt^I=x_vx_v^I$. This
 completes the proof of step 3. 
\end{step}

\setcounter{proofofstep}{3}
\begin{proofofstep} %proof of step 4
 Let $S$ be a finite set of places of $K$ containing all $v$ which are
 either archimedean or non-archimedean ramified in $L$, or
 non-archimedean and $y \notin \mathscr{O}_v$, and two
 further places $v_o$, $v_1$ for which $A_{K_v}$ is the direct sum of two
 matrix algebras over $K_v$. We claim that $t_{v_1} \in A_{K_{v_1}}$ can be
 so chosen that $K_{v_1}(t_{v_1} yt^I_{v_1})/K_{v_1}$ is a separable
 algebra of maximal degree and such that $NT_{v_1}=1$. By the choice
 of $v_1$ if $v_1$ splits into the places $w_1$, $w_2$ in $L/K$ we have
 $A_{K_v} \cong M_n (L_{w_1}) \oplus M_n (L_{w_2})$. Let $y=(y_1,y_2)$
 and set $t_{v_1}=(t_{w_1},1)$; then $t_{v_1}yt^I_{v_1}=
 (t_{w_1}y_1,y_2 t_{w_1}^I)$. We have to choose $t_{w_1}$ such
 that $Nt_{w_1}y_1=1$ and such that the characteristic  polynomial of
 $t_{w_1}y_1$ is separable. With this choice of $t_{w_1}$, the
 resulting $t_{v_1}$ will satisfying our requirements. To construct
 $t_{w_1}$ we have only to find element $d_1, \ldots ,d_n$ in
 $L_{v_1}$ which are different and such\pageoriginale that their
 product is equal to 1; this is clearly possible; we can then take
 $t_{w_1} = \dfrac{1}{y_1} 
\begin{pmatrix}
d_1 & &\\ 
& \ddots &  \\
&& d_n 
 \end{pmatrix}$. 
We have therefore constructed $t_{v_1} \in
 A_{K_{V_1}}$ such that $Nt_{v_1} = 1$ and such that
 $K_{v_1}(t_{v_1} yt^I_{v_1})/K$ is a separable algebra of maximal
 degree. To complete step 4 we find $t \in A_K^*$ such that i) $Nt=1$
 2) $t \approx u_v^{-1}$ in the $v$-topology for $v \in S$, $v \neq
 v_0$, $v_1$ and $t \simeq t_{V_1}$ in the $v_1$-topology. 3) $t \in
 \mathscr{O}_v$ for all $v \notin S$. Then the principal polynomial of
 $tyt^{I}$ is separable so $K(tyt^I)$ is a separable algebra of
 maximal degree. For this choice of $t$ any place $v$ will satisfy one
 of the conditions a), b) or c) stated in step 3 and we shall
 be through. The existence of $t$ follows from sublemma~\ref{chap5:sublemb}b) applied
 to the simple algebra $A$ with centre $L$; namely an approximation
 condition in the $v$-topology is equivalent to similar conditions in
 the $w$-topologies for the extensions $w_1$ of $v$ of $L$, and $t \in
 \mathscr{O}_v$ is equivalent to $t \in \mathscr{O}_w$ for the same $w's$. 
\end{proofofstep}

\begin{coro*}
Finitely many local solutions of $y=xx^{I}$ can be approximated by a
global solution, i.e. if $T$ is a finite set of places and if
$y=x_vx_v^I$ with $x_v \in A_{K_v}$, $v \in T$ then there is an $x \in
A_K$ with $xx^I = y$ and $x \approx x_v$ in the $v$-topology. 
\end{coro*}

\begin{proof}
Let $u \in A$ satisfy $y=uu^I$; the existence of this $u$ is
guaranteed by lemma~\ref{chap5:lem1}. Write $x_v = us_v$; from $uu^I=x_v x_v^I$ we
get $s_vs_v^I = 1$. If we can find $s \in A_K^*$ such that $ss^I = 1$
and $s \approx s_v$ for $v \in T$ then writing $x = us$ we see that
$x \approx us_v$ and that $y = xx^I$ so that the corollary will be
proved; hence we have only to find such an $s$. For this we make use
of the Cayley transform: in the representation\pageoriginale $A_{K_v}
\approxeq M_P(D_1)\oplus M_q (D_2)$ or $A_{K_v} \approxeq M_P(D)$ suppose to
start with that the eigenvalues of the components of $s_v$ are all
different from $-1$; then $(1+s_v)^{-1}$ exists. The relation
$s_vs_v^{I} = 1$ then shows that $(1-s_v)(1+s_v)^{-1}$ is skew
symmetric; call this $p_v$; then $p^I_v=-p_v$; we can now approximate
the skew symmetric elements $p_v$ by a skew symmetric element $p$ of
$A$ since we have only to approximate the entries. Going back by the
inverse transformation we can define $s = \dfrac{1-p}{1+p}$; then
$ss^I = 1$ and $s \approx s_v$ for $v \in T$. If the eigen values of
the components of $s_v$ are not all different from $-1$ then we can
write $s_v$ as a product of two elements for which the eigenvalues are
all different from $-1$ and we can proceed as before, This proves the
corollary. 
\end{proof}

The lemma just proved is the essential step in providing the following
more general theorem due to Landherr [$L$]; a proof of this along the
same lines as the one given here has been found independently by
T. Springer. 

\medskip
\noindent{\textbf{Landherr's theorem} (Form I):}
Let $y \in A_K^*$ be an element such that $y^I = y$. Suppose the
equation $y = xx^I$ is solvable with $x \in A_{K_v}$ for  every
infinite place $v$; assume moreover that for every non archimedean
place $v$ there exists $ z_v \in L_{K_v}$ satisfying the equation $Ny
= z_v z_v^I$. Then the equation $y = xx^I$ is solvable with $x \in
A_K^*$. 

\medskip
\noindent{\textbf{Proof of Landherr's theorem.}}
Let $v$ be archimedean and let $x_v \in A_{K_v}$ is such that $y =
x_vx_v^I$ holds. Taking norms on both sides we get $Ny = u_vu_v^I$
with $u_v \in L_{K_v}$. If $v$ is non archimedean we are given that
$Ny=z_vz_v^I$.\pageoriginale These two equations clearly show that
$Ny$ is a local 
norm in the extension $L/K$ at all places $v$ of $K$. Hence by the
quadratic norm theorem (stated in sublemma~\ref{chap5:sublema}) we can find $z \in L$
such that $Ny = zz^{I}$. Now suppose $v$ is an infinite place. Write
$Nx_v = z.u_v$ where $u_v \in L_{K_v}$. The condition $Ny = zz^{I}$
then implies $u_v u_v^I = 1$. Now apply the corollary to 
lemma~\ref{chap5:lem1} for
the set of infinite places and the local solutions $u_v$ of the
equation $uu^I = 1$. Hence if $u \approx u_v$, $u \in L_K$ then $z.u
\approx Nx_v$ which implies that $z.u/Nx_v$ is an $n^{\text{th}}$
power; this is easily proved by the binomial theorem. Hence $z.u/Nx_v$
is a reduced norm from $A_{K_v}$, i.e. $z.u$ is a reduced norm from
$A_{K_v}$. This is true for every archimedean place. At a
non archimedean place $v,z.u$ is again a local reduced norm as we have
seen in \S~\ref{chap4:sec4.3}, lemma~\ref{chap4:lem1}. Hence by the
norm theorem for simple 
algebras we can find $t \in A$ such that $z.u = Nt$. We shall prove
that the conditions of lemma~\ref{chap5:lem1} are satisfied for $t^{-1}yt^{-I}$ in
place of $y$. Clearly $t^{-1}yt^I$ is symmetric. $Ny=(zu).(zu)^I$
implies $N(t^{-1}yt^{-I})=1$. We have to prove that $t^{-1}yt^{-I}$ is
of the form $y_vy_v^I$ for every place $v$ of $K$, with $y_v \in
A_{K_v}$. If $v$ is infinite then $t^{-1}yt^{-I} =
t^{-1}x_vx_v^It^{-I} = (t^{-1}x_v)(t^{-1}x_v)^I$ and this case is
settled. Let $v$ be non-archimedean. We shall use the notations of the
beginning of the paragraph \S~\ref{chap5:sec5.5}. Since by 
\S~\ref{chap4:sec4.1} theorem~\ref{chap4:thm1} the 
one dimensional Galois cohomology $H^1(K_v,G)$ is trivial the mapping
$A_{K_v}\longrightarrow H_{K_v}$ is surjective.The element
$(t^{-1}yt^{-I},1)$ is clearly an element of $H_{K_v}$; hence there
exists $y_v \in A_{K_v}^*$ such that $t^{-1}yt^{-I} = y_vy^I_v$. This
proves that the condition of lemma~\ref{chap5:lem1} 
are satisfied\pageoriginale for
this $t^{-1}yt^{-I}$. Hence by that lemma there exists $x \in A_K$ 
satisfying $t^{-1}yt^{-I} = xx^{I}$; this implies $y = (tx)(tx)^I$ and
so Landherr's theorem is proved. There is a second formulation of
Landherr's theorem which runs as follows: 

\medskip
\noindent{\textbf{Landherr's theorem} (2nd formulation).}
If $y \in A_K^*$ is $I$-symmetric and if $y=xx^{I}$ is solvable with
$x \in A_{K_v}$ for every place $v$ of $K$ then it is solvable with $x
\in A_K$. 

\begin{proof}
Let $y = x_vx_v^{I}$; then taking norms we have $Ny=z_vz_v^I$ where
$z_v=Nx_v \in L_{K_v}$. Hence the assumption of the first formulation
are satisfied and so $y=xx^{I}$ can be solved with $x \in A_K$. 
\end{proof}


\section{Proof of Proposition~1 
when $n$ is odd}\label{chap5:sec5.6}

The proof of lemma~\ref{chap5:proofoflem1} concludes the second reduction 
of proposition~\ref{chap5:prop1}; accordingly for providing proposition~\ref{chap5:prop1} we can assume $y =
1$. The proposition then takes the form 

\begin{propa}\label{chap5:propa}
Let $z \in L_K^*$ be such that $zz^{I} = 1$; if the equations $z = Nx$
and $xx^I = 1$ are solvable simultaneously with $x \in A_{K_v}$ for
all places $v$ of $K$ then they can be solved simultaneously with $x
\in A_K$. This is proved by means of mathematical induction on $n$ and
the inductive proof makes use of another 
\end{propa}

\begin{propa}\label{chap5:propb}
Let $z \in L_K^*$ be $I$-symmetric; if the equations $x^I=x$ and
$z=Nx$ are solvable simultaneously with $x \in A_{K_v}$ for all places
$v$ of $K$ then they can be solved simultaneously with $x \in A_K$. 

We shall prove these propositions now. We first consider the case when
$n$ is odd. The idea of the proof may be explained as follows: 
\begin{enumerate}
\renewcommand{\labelenumi}{\theenumi)}
\item Construct\pageoriginale a commutative separable $L$-algebra $B$
of degree $n$ and an involution $J$ on $B$ which coincides with $I$ on
$L$ such that 
$B=L(x)$ and $z=N_l^B(x)$, $xx^J=1$ (or $x^J=x$ in the case $(b)$). Here
$N_L^B$ denotes the usual algebra norm got by the regular
representation. 

Involutions which coincide with $I$ on $L$ will be called $I$-
involutions in future. 

\item Imbed $B$ in $A$, the imbedding being identity on $L$.

\item Change the imbedding given in 2) by an inner automorphism of $A$
so as to get an imbedding of algebras with involution. If we grant
1), 2) and 3) then the proofs of propositions~\ref{chap5:propa}) and \ref{chap5:propb}) are
simple. For since $B$ is a separable algebra of dimension $n$,
$N_L^B(x)$ is just the reduced norm of $x$ and by construction $z = Nx$,
$xx^I = 1$ (or $x^I = x$). 
\end{enumerate}
\end{propa}

\setcounter{step}{0}
\begin{step}[Construction of $B$]
Here again for any place $v$ we
consider the two cases i) and ii) mentioned in \S~\ref{chap5:sec5.5}, namely
$L_{K_v} \approxeq L_{w_1}\oplus L_{w_2}$ or $L_{K_v}\approxeq L_w$;
corresponding to these two cases we have either $A_{K_v}\approxeq A_1
\oplus A_2$ where $A_1=A \otimes_L L_{w_1}$, $A_2 = A \otimes_L
L_{w_2}$ or $A_{K_v}\approxeq A
\otimes_L L_w$. We claim that the local solutions $x_v$ of the
equations $z=Nx$ $xx^I=1$ (resp. $x^I=x, z=Nx$) can be assumed to be
regular. This is done as follows: 
\end{step}

\begin{romancase}%case i
{\em (Corresponding to proposition~\ref{chap5:propa}).} Let $z=(z_1,z_2)$,
  $x_v=(x_v^{(1)},\break x_v^{(2)})$ then clearly
  $z_1=Nx^{(1)}$, $z_2=Nx_v^{(2)}$; as in the proof of Eichler's norm
  theorem $x_v^{(1)}$ can be replaced by a regular\pageoriginale
  element also 
  denoted by $x_v^{(1)}$ of norm $z_1$. The condition $x_vx_v^I=1$
  give $x_v^{(1)} x_v^{(2)}=1$; so if $x_v^{(2)}$ is determined by
  this condition both $x_v^{(1)}$ and $x_v^{(2)}$  will be
  regular. Hence $x_v$ can be assumed regular. 
\end{romancase}

\setcounter{romancase}{0}
\begin{romancase}%case i
{\em (corresponding to proposition~\ref{chap5:propb}).} $z^I=z$ implies $z_1=z_2$ and
  $z=Nx$ implies $z_1=Nx_v^{(1)}$; by the same argument as above
  $x_v^{(1)}$ can be assumed to be regular; since $x_v^I=x_v$ implies
  $x_v^{(1)}=x_v^{(2)},x_v^{(2)}$ is also regular; hence $x_v$ can be
  assumed regular. 
\end{romancase}

\begin{romancase}%%% ii
{\em (corresponding to proposition~\ref{chap5:propa}).} Here
  $A_{K_v}\approxeq M_n(L_w)$, a 
  matrix algebra over $L_w$; if $x=(x_{ij})\in M_n(L_w)$ and if
  $x^*=(x_{ji}^I)$ then there is a hermitian matrix a, i.e. a matrix
  such that $a^*=a$ for which $x^I=ax^* a^{-1}$ holds; $xx^I=1$
  implies that $x$ is unitary with respect to $a$. This case occurred
  in the course of the proof of lemma~\ref{chap5:proofoflem1} in 
  \S~\ref{chap5:sec5.5}. As explained in 
  that place we can find a regular unitary matrix $x_v$ with norm
  equal to $z$. 
\end{romancase}

\setcounter{romancase}{1}
\begin{romancase}%case ii
{\em (corresponding to proposition~\ref{chap5:propb}).} In the notations above $a$ can be
  assumed to be diagonal by a choice of orthogonal basis. It is then
  easy to find a regular diagonal matrix $x_v$ with entries in $K$ and
  of determinant $z;x_v$ will then be $I$-symmetric and
  $z=Nx_v$. Hence the claim is proved and the local solutions $x_v$
  can be assumed to be all regular. 
\end{romancase}

\begin{remark*}
It is to be noted that the only essential local condition on $z$ occurs
when $L_{K_v}\approxeq L_{w_1} \oplus L_{w_2}$, $v$ real infinite and
$A_{K_v}$ is a direct sum of matrix rings over quaternion algebras; at
all other places the equations in question are automatically
solvable. 
\end{remark*}

Let the principal polynomial $f_v(X)$ of $x_v$ over $L_{K_v}$ be given
by\pageoriginale\break $f_v(X)=X^n-a_1^{(v)}X^{n-1}+\cdots +$, where we write the
coefficients $a_1^{(v)},a_2^{(v)},\ldots $, alternatively with positive
and negative signs. Applying $I$ to $f_v$ we will get the principal
polynomial of $x_v^{I}$; in the case of Proposition~\ref{chap5:propa})
$x_v^I=x_v^{-1}$; the principal polynomial of $x_v^{-1}$ is equal to
$X^n-a_{n-1/z}X^{n-1}+\cdots -\dfrac{1}{z}$; this must be the same as
$f_v$ so that we get $a^{v}_{n-i}=z(a^{(v)}_i)^I$. In the case of
Proposition~\ref{chap5:propb})since $x^{I}_{v}=x_v$ we have $f^I_v=f_v$ so that
$(a^{(v)}_i)^I=a^{(v)}_i$. Let $S$ be the set of places $v$ which are
either archimedean or such that $A_{K_v}$ is not isomorphic to a
direct sum of matrix algebras or itself a matrix algebra. The set $S$
is finite. Approximate the $a^{(v)}_i$ for $v\epsilon S$ by
$a_i\epsilon L$ with $a_{n-i}=za^{I}_{i}$ in the case of Proposition~\ref{chap5:propa}) 
and $a^{I}_{i}=a_i$ in the case of Proposition~\ref{chap5:propb}); since the
equations for the $a_i$ are linear, this is possible by ordinary
approximation theorem; define $f(X)$ by
$f(X)=X^n-a_1X^{n-1}+\cdots +(-1)^n_z$. Finally define $B=L[X]/
(f(X))$. Since the $f_v(X)$ are separable (because $x_v$ are regular)
by taking close approximations we can assume $f(X)$ to be
separable. Hence $B$ is a separable algebra of degree $n$; again
depending on the closeness of the approximation we can assume
$L[X]/(f(X)\otimes_{K_v}=L_v[X]/(f(X))$ to be isomorphic to
$L_{K_v}[X]/(f_v(X))$ for $v \in S$; this can be done as observed
in the proof of norm theorem for simple algebras by using Newton's
method of approximating roots of polynomials. We then define an
involution $J$ on $B$ by the requirement $(X\mod f(X))^I = X^{-1}\mod
f(X)$ (and resp $(X \mod f(X))^I= X\mod f(X))$  and  $J$
restricted to $L$ is $I$. Then $J$ is an $I$-involution of
B.\pageoriginale By construction if $x$ denotes the residue class of
$X \mod f(X)$ then $B=L(x)$ and $z=N^B_L(x)$, $xx^J=1$
(resp. $x^J=x$). This completes the proof of step 1).  


\begin{step} %step 2.
For $v\in S$ let $B_v$ denote the algebra
$L_{K_v}[X]/(f_v(X))=L_{K_v}(x_v)$; we saw in step 1, that there is an
isomorphism of algebras $B_{K_v}\cong B_v$; we claim that by taking
approximations of step 1 close enough we get an isomorphism
$(B_{K_v},J)\cong (B_v,I)$. This is seen as follows. Let $\bar{x}$ be
the image of $x_v$ under the isomorphism $\theta^{-1}$. To get an
isomorphism af algebras with involution we require $\theta
(\bar{x}^J)=x^{-1}_{v}$. Now since $B_v$ is separable it has only
finitely many automorphisms; hence the composite of two involution
being an automorphism we conclude that $B_v$ has only finitely many
involution. Since $x_v\to \theta(\bar{x}^J)$ is an involution of $B_v$
the set of image $\theta(\bar{x}^J)$ corresponding to the various
isomorphisms $\theta B_{K_v}\cong B_v$is finite; clearly $x\simeq
\bar{x}$ which implies that $\bar{x}^J \approx x^{-1}$;
i.e. $\bar{x}^J\approx 
\bar{x}^{-1}$; hence $\theta (\bar{x}^J)$ approximates
$x^{-1}_{v}$. But since the number of $\theta(\bar{x}^J)$ that can
occur is finite we see that for a sufficiently good approximation
$\theta (\bar{x}^J)=x^{-1}_{v}$ so that we have actually an
isomorphism $(B_{K_v},j)\cong (B_v,I)$ for $v\in S$. This shows
that $(B,J)$ can be imbedded in $(A,I)$ locally at all places
$v\in S$. If $v\notin S$, $A_{K_v}$ splits and $B_{K_v}$ can
be imbedded in $A_{K_v}$ by regular representation. But this need not
respect the involutions $J$ and $I$. In any case we find that $B$ is
embeddable in $A$ locally at all places of $K$. Hence $B$ can imbedded
in $A$; since the local imbeddings are identity on $L, B$ can be
imbedded in $A$ such $a$ way\pageoriginale that this imbedding is
identity on $L$. This finishes the proof of step 2. corresponding to
proposition~\ref{chap5:propa}). The same can be done corresponding to 
proposition~\ref{chap5:propb}) too.   
\end{step}

\setcounter{proofofstep}{2}
\begin{proofofstep} %step 3.
 By step 2 we can assume $B\subset A$; the involution $J$ on the
 maximal commutative semisimple subalgebra $B$ can be extended to
 $A$ by \S~\ref{chap2:sec2.5} theorem~1. We denote
 the extension by the same 
 symbol $J$. By Skolem- Noether's theorem there exists $t\epsilon
 A^*_K$, $t^I=t$ such that $x^J=tx^It^{-1}$ for all $x\epsilon B$. We
 shall choose $s\epsilon A^*_K$ such that $x\to s^{-1}xs$ gives an
 imbedding of $(B,J)$ in $(A,I)$. In order this is true it is
 necessary and sufficient that we have $s^{-1}x^Js=(s^{-1}xs)^I$ for
 $x\epsilon B$. Now $x^I=t^{-1}x^Jt$ so that 
 $x^J=ss^Ix^Is^{-I}s^{-1}=(ss^It^{-1})x^J(ss^I t^{-1})^{-1}$. 
\end{proofofstep}

This means we should that $ss^I t^{-1}\epsilon B^1$, the commutant
of $B$ which is $B$ itself since $B$ is maximal commutative. Hence we
require $ss^I=bt$ with $b\epsilon B, s\epsilon A^*_K$. We shall first
find $b$ and then $s$. We showed above that $(B,J)$ can be imbedded in
$(A,I)$ locally at all places $v\epsilon S$, in particular at the
infinite places. Hence the equation $ss^I=bt$ is satisfied for some
$s_v\epsilon A^*_{K_v}$, $b_v\epsilon B_{K_v}$ for every infinite place
$v$. Approximate the finitely many $I$-symmetric elements $b_vt$ by an
I-symmetric element $b_ot$ in $Bt$. Then $ss^I=b_ot$ is solvable with
$s\epsilon A^*_{K_v}$ for all infinite places $v$. By taking norms
$c=N(b_0t)\epsilon K$ is a norm from  $L\otimes K_v/K_v$, and
therefore $ss^{I} = c^{-1}b_0t = bt$ is solvable with $s \in
A^{*}_{K_{v}}$. On the  other hand $N (bt) = N(c^{-1} b_0 t) = c^{1-n}
= c^{(1-n)/2}(c^{(1-n)/2})^I$. So by Langherr's theorem $ss^I = bt$ is
solvable globally. Hence the mapping $x \rightarrow s^{-1}xs$ gives an
imbedding of\pageoriginale $(B,J)$ in $(A,I)$. The same can be done
for proposition~\ref{chap5:propb}) Hence step 3 is complete and  so 
proposition~\ref{chap5:propa} and  \ref{chap5:propb}
are proved when $n$ is odd. 

\section{Proof of Propositions a), b) when $n$ is even}\label{chap5:sec5.7} 

The idea is the following 
\begin{enumerate}[I)]
\item Construct an $I$-invariant quadratic extension $N$ of $L$, $N
  \subset A$ and a primitive element $y$ of $N/L$ i.e. an element
  for which $N = L(y)$ such that 1) $N^{N}_{L}y = z$, $yy^I = 1$ (resp
  $y^I = y$), 2) the equations $y = \bar{N}x$,  $xx^I = 1$  (resp. $x^I =
  x$) are solvable locally in $N'$, the  commutant of $N$ in  $A$;
  here $\bar{N}$ denotes the reduced norm mapping of the simple
  algebra $N'$ with centre $N$. Observe that if $M$ denotes the field
  $M =  \{a \in N/a^I = a\}$ then  $M$ is quadratic over $K$ and that
  $N$ is the composite of $M$ and $L$; the  latter shows that the
  commutant  of $N$ is the intersection of those of $M$ and $L$
  i.e. $N' = M'$, $M'$ being the commutant of $M$ in $A$. The proof of
  the proposition will be by induction on the power of 2
  contained in  $n$ as factor. This is justified as we have proved the
  propositions for odd $n$; since  $[N^1 : N] =\dfrac{[N' : L]}{2} =
  \dfrac{[A : L]}{2(N:L)} = (\dfrac{n}{2})^2$ and the hypothesis of
  the  propositions  are satisfied for $N'$ and $y$ in the place $A$
  and $z$ respectively induction applies; by induction we can
  therefore assume the truth of the  proposition for $N'$; hence the
  equations in 2) are solvable  globally; let $x$ be a  global
  solution; then since reduced norm of $x$ in $A$ is equal to
  $N^{N}_{L}y = z$ we find that this $x$ gives a global solution of
  the  equations $Nx = z $ ($N$ denotes reduced norm\pageoriginale in
  $A$), $xx^I = 1$ (resp. $x^I =x)$; we have remarked in 
  \S~\ref{chap5:sec5.6} that   for local 
  solvability of our problem the only conditions come from those real
  infinite places for which the algebra is isomorphic to a direct sum
  of two matrix rings over the quaternions. We shall take care of the
  local conditions 2) by constructing $N$ in such a way that this
  critical case does not occur for any place $w$ of $M$. Let $w$ be an
  extension of the place $v$ of $K$. If $K_v \cong \mathbb{C}$, or $N
  \otimes K_v \cong \mathbb{C}$, then $w$ is certainly not
  critical. If $A \otimes K_v$ is isomorphic to 
  the direct sum of two matrix rings over $K_v$ then $N' \otimes_M
  M_w$ is isomorphic to the direct sum of two matrix rings over $M_w$. If
  finally $A \otimes K_v$ is isomorphic to a direct sum of two
  matrix rings over the quaternions, then we shall construct $N$ such
  that  $N_w \cong \mathbb{C}$, and so $w$ is not  critical either.  

\item We shall construct $N$ abstractly to start with; we then
  construct a commutative separable $L$-algebra $B$ of maximal degree
  with an $I$-involution $J$ such that i) $(N, I)$ is imbeddable in
  $(B,J)$ so that $N$ can be identified with a subfield of $B$ and
  then $J/N = I/N$ ii) $B= N (x)$ for a suitable $x$. 

\item Imbed $B$ in $A$; extend $J$ to $A$ by the theorem on extension
  of involutions, and then change the imbedding by an inner
  automorphism  to get an imbedding of algebras with involution. The
  constructions outlined in I, II  and III will be achieved once
  we prove the following lemmas. 
\end{enumerate}


\setcounter{lem}{0}
\begin{lem}\label{chap5:s5.7:lem1} %lemma 1.
There\pageoriginale exists  a finite set $S$ of places of $K$ including the
archi\-me\-dean places such that for $ v \notin S$ and any commutative
separable $L_{K_{v}}$-algebra with  $I$-involution $J$ say $B_v$ of
dimension  $n$ there exists an imbedding of $(B_v,J)$ into
$(A_{K_{V}},I)$. 
\end{lem}

\begin{lem}\label{chap5:s5.7:lem2}%lemma 2.
For every $v \in S$ there exists $y_v$, $x_v$ in $A_{K_{v}}$  such
that  
\begin{enumerate}[i)]
\item $N_v = L_{K_{v}} (y_v)$, $B_v = N_v (x_v)$ are commutative
  separable algebras  

\item  $N_v \cong L_{K_{v}}[Y]/_{Y^2 - \lambda_v Y + z}$ under the
  mapping which takes the residue class of $Y$ onto $y_v$. 

\item such that $y_v y^I_V = 1$  (Resp $y^I_V = y_v$) and  

\item  $B_v \cong N_v[X]/_{(x^{\dfrac{n}{2}} + \cdots)}$ under the
  mapping taking the residue class of $X$ on to $x_v$, the
  coefficients of $X^{\dfrac{n}{2}} + \cdots$ being in $L_{K_{v}}$. If
  $A_{K_{v}}$ is a direct sum of matrix rings over quaternion algebras
  then  $y_v$ can be so chosen  that the field  $M_v$ of
  $I$-invariance $N_v$ is isomorphic to $\mathbb{C}$. 
\end{enumerate} 
\end{lem}

\begin{lem}\label{chap5:s5.7:lem3} %lemma 3
After possibly replacing  $z$ by  $zNu^{-1}$ with $u \in A_K$, $uu^I =
1$ (resp. by $zNuNu^I$ with $u \in A^*_K$) there exists a place $w
\notin S$ with $L_{K_{w}}$ a field and  a quadratic field extension
$N_w$ with an $I$-involution $J_{N_{W}}$ such that $N_w =
L_{K_w}(y_w)$ with $y_w$ satisfying the conditions $N_{L_{K_w}} (y_w)
= z$, $y_w y^J_w = 1$ (resp~$y^J_w = y_w$). 
\end{lem}

\begin{lem}\label{chap5:s5.7:lem4}%lemma 4.
Let $K$ be a number field, $L,M$ two different quadratic extensions of
it; let $N$ be the  composite of $L$ and $M$. Suppose there exists a
place $w$ of $K$ such that $N_{K_{w}}$ is a field; then for a given
$c \in K^*$, if the equation $(N_{L_{K}} l)  = (N^M_K m)c$ is solvable
locally then it is solvable  globally. Finitely many local solutions
can be approximated.\pageoriginale We shall assume these lemmas and
show how $N$, $B$ 
and $J$ can be constructed; first we make the replacement necessitated
by lemma~\ref{chap5:s5.7:lem3}. This does not affect local and global solvability. Now
let $Y^2 - \lambda_w Y+z$ be the minimal polynomial of $y_w$ in $N_w /
L_w$; where $N_w$ is constructed  as in lemma~\ref{chap5:s5.7:lem3}. Let $\lambda \in L$
approximate the $\lambda_v's$ for $v \in S$ and $\lambda_w$. Define
$N=L[Y]/Y^2 - \lambda Y+z$; since $Y^2 - \lambda_w Y+z$ is irreducible
so is $Y^2- \lambda Y+z$ irreducible over $L$; hence $N$ is a filed;
let $y$ be the residue class of $Y$ modulo $(Y^2 - \lambda Y+z)$; then
$N = L(y)$. As in the proof of step 2 of Proposition~\ref{chap5:propa}) and \ref{chap5:propb})
of \S~\ref{chap5:sec5.6} if the approximation is good enough then
the stipulation 
$J/L= I/L$, $y^J = y^{-1}$ (reap. $y^J=y$) will define an $I$-involution
$J$ on $N$; similarly approximating the coefficients of the polynomial
$X^{\dfrac{n}{2}}+ \cdots +$ given for $B_v$, $v \in S$ in lemma~\ref{chap5:s5.7:lem2} we
get a polynomial with coefficients in $N$ and a maximal commutative
separable algebra $B = N [X]/ X^{\dfrac{n}{2}} + \cdots$ with an
involution also denoted by $J$ extending the involution $J$ on $N$; if
our approximations are good enough we have as in the proof of step of
$1$ of Propositions~\ref{chap5:propa}) and \ref{chap5:propb}) of \S~\ref{chap5:sec5.6} that
$B_{K_v} \cong B_v$ 
for $v \in S$ so that $B_{K_v}$ is imbeddable in $A_{K_v}$ for $v \in
S$; by lemma~\ref{chap5:s5.7:lem1} this is true even if $v \notin S$; hence $B$ is
locally imbeddable in $A$ at places $v$ of $K$. 
Hence $B$ is imbeddable in $A$ globally. Since $N$ is imbeddable in
$B$ this simultaneously gives an imbedding of $N$ in $A$ so that we
can assume hereafter that $L \subset N \subset B \subset A$. Next we
extend the involution $J$ on $B$ to $A$ by the theorem on extensions of
involutions; we denote the extension also by the same letter $J$. By
Skolem Noether's theorem we can find $t \in A$, $t^I = t$ such that
$x^J = tx^I t^{-1}$ holds for every $x \in A$. We want to choose an $s
\in A^*$ such that $x \to s^{-1}xs$ given an imbedding of $(N, J)$ into
$(A,I)$; this replaces $N$ by $s^{-1}Ns$; the necessary\pageoriginale
and sufficient 
condition for this is that the following equations hold as in the
proof of the case of odd $n: ss^I = ut$, $u \in N'$ and $u^J =u$. We
claim that these equations are solvable locally with $s \in A_{K_v}$, $u
\in N'_{K_v}$ for all $v$; this is seen as follows: if $v \in S$ we
know that $N_{K_v} \cong L_{K_v} [Y]/ (Y^2 - \lambda_v Y + z)$ in the
notations of lemma~\ref{chap5:s5.7:lem2}, and this will moreover be an isomorphism of
algebras with involution if the approximations are close enough as we
saw in the case of odd dimension. By lemma~\ref{chap5:s5.7:lem2} then $(N_{K_v, J})$ is
imbeddable in $(A_{K_v}, I)$ for $v \in S$. If $v \notin S$ lemma~\ref{chap5:s5.7:lem1}
asserts that the algebra $(B_{K_v}, J)$ can be imbedded in $(A_{K_v},
I)$; this  then gives an imbedding of $(N_{K_v}, J)$  in  $(A_{K_v},
I)$; hence $(N, J)$ is imbeddable locally in $(A,I)$ so that the
equations $ss^I = ut$, $u \in N'$, $u^J = u$ are solvable locally
everywhere; if $(s_v, u_v)$ are local solutions at the place $v$ taking
reduced norms on both sides of the equation $s_v s^I_v = u_v t$ we get
$l_v l_v^I = (N_L^N m_v)$. Nt where $l_v = Ns_v $ and $m_v =
\bar{N}u_v$ ($\bar{N}$ denotes the reduced norm of  $N'$ over
$N$). Since  $L$ and $M$ are linearly disjoint over $K$ we have $N^N_L
m_v= N^M_K m_v$; Moreover $l_v l_v^I = N^L_K l_v$; hence $ N^L_K l_v =
(N_K^M m_v)(Nt)$. This shows that the equations $ N^L_K l = (N^M_K
m)(Nt)$ are solvable locally everywhere; applying 
lemma~\ref{chap5:s5.7:lem4} we can
approximate the local solutions $(l_v, m_v)$ for $v$ at infinity by a
global solution say $(l,m)$; write $1- \alpha_v = \dfrac{m}{m_v}$; if the
approximations is close enough $(1-\alpha_v )^{\dfrac{1}{n}}$ can be
developed by a power series and since $\alpha^J_v = \alpha_v$ applying
$J$ to the terms of this power series we get $(1 -
\alpha)^{\dfrac{1}{n}}$ is $J$-invariant; hence $\dfrac{m}{m_v}$ is the
reduced norm in $N'$ of a  $J$-invariant element;\pageoriginale since
$m_v = 
\bar{N}u_v$ with $u^J_v = u_v$ we see that the equation $m = \bar{N}u$
is solvable locally at infinity  by $J$-invariant elements; we shall now
apply Proposition~\ref{chap5:propb}); the local conditions for the solvability of $m
= \bar{N}u$ come only from the infinite places  and we have  shown that
the equation is solvable locally at infinity. Since the maximum power
of $2$ dividing $[N' : N]$ is less  than the corresponding number for
$[A : L]$ we can apply the induction hypothesis to $N'$, $m \in N'$
which is $J$-symmetric; hence we can find $u \in N'$ with $m = \bar{N}u$
and $u^J = u$. 
\end{lem}

Next the equation $ss^I = ut$ will be solved by using Landherr's
theorem first formulation; we have proved that this is solvable
locally at the places in $S$, in particular at infinity; next by
construction of $m$ we have $N(ut)= N^L_K l = ll ^I$; moreover
$(ut)^I = t^I u^I = t.t^{-1}. u^j.t = ut$. Hence the conditions of
Landherr's theorem are satisfied and so we can find $s \in A_K$ with
$ss^I = ut$. This solves the problem of imbedding $(N, J)$ globally in
$(A,I)$. Identifying $N$ with its image we can write $N = L(y)$; by
construction this $N$ and $y$ have all properties required in 1) of
the beginning of the proof. As for the requirement 2) the local
conditions necessary to ensure the local solvability are void in view
of lemma~\ref{chap5:s5.7:lem2}. 

We shall now go on to the proofs of the lemmas 1 - 4.

\setcounter{proofoflem}{0}
\begin{proofoflem}%% 1
Let $\mathscr{O}$ be an order in $A$ which we assume to be $I$-invariant
(otherwise take $\mathscr{O} \cap \mathscr{O}^I$). If $v$ is some
place of $K$ and  $B$ a separable algebra over $L_{K_v}$ we shall
denote the set of integers of $B$ of $\mathscr{O}(B)$. Let $S$ be the
set of these places $v$ of $K$ which are\pageoriginale either
archimedean or 
ramified in $L/K$ or such that $\mathscr{O}_v$ is not a matrix over
$\mathscr{O}(L_{K_v})$; the non-archimedean places which satisfy the
property are divisors of the discriminant of $\mathscr{O}$ and so
finite in number; since the places satisfying either the first or
second property are also finite in $S$ is a finite  set. We claim this
$S$ will have the property stated in the lemma: Let $v \notin S$. 
 \end{proofoflem} 


\setcounter{romancase}{0}
 \begin{romancase}%%% i
$L_{K_v} \cong K_v \oplus K_v$; in this case $A_{K_v} \cong A_1 \oplus
   A_2$ where $A_1, A_2$ are matrix rings over $K_v$ and $I$
   interchanges the components. Similarly $B_v \cong B_1 \oplus B_2$
   and $J$ interchanges the components; by the regular representation
   $B_1$ can be imbedded in $A_1$; if $f$ is this imbedding and $b\in
   B_1$ then $f(b^J) = f(b)^I$ extend this to an imbedding of $(B_v,
   J)$ into $(A_{K_v}, I)$. 
 \end{romancase} 

 \begin{romancase} %case ii
$L_{K_v}$ is a field; in this case $A_{K_v} \cong M_n (L_{K_v})$ and
   if $x \in A_{K_v}$ is considered as a matrix $(x_{ij})$ over
   $L_{K_v}$ then $x^I = ax^* a ^{-1}$ where $x^* = (x^I_{ji})$ and a is
   a fixed hermitian matrix i.e., $a^* =a$. Since $\mathscr{O}^I =
   \mathscr{O}$ we have a $\mathscr{O}_v a ^{-1} = \mathscr{O}_v$; now
   a is determined up to a scalar matrix over $K_v$, multiplying a by
   a suitable scalar matrix over $K_v$ multiplying a by a suitable
   scalar matrix over $K_v$, since $v$ is unramified in $L/K$, we can
   assume a to be a primitive matrix; the condition $a \mathscr{O}_v
   a^{-1} = \mathscr {O}_v$ will then imply that $a$, $a^{-1} \in
   \mathscr{O}_v$. Hence the discriminant of the hermitian form
   corresponding to a, namely delta is a unit in $L_{K_v}$; but since
   $a^* = a$ deta is invariant under $I$ which implies that deta $\in
   K_v$. Using the fact that $L_{K_v}/ K_v$ is unramified we can write
   det $a = \lambda \lambda^I$ with $\lambda \in
   L_{K_v}$. Now\pageoriginale over a 
   $p$-adic field any hermitian from is determined by its discriminant
   and dimension; choosing a matrix $u \in M_n (L_{K_v})$ with
   determinant $\lambda$ the matrix $uu^I$ is hermitian with
   discriminant equal to det $a$; hence we have shown that a can be
   written as $uu^I$. 
\end{romancase} 
 
 Write $A_{K_v}$ as End $(V)$, where $V$ is a $n$-dimensional vector
 space over  $L_{K_v}$ and End $(V)$ means the endomorphism ring. The
 action of $I$ on End $(V)$ can be described as follows; let $u,v$ be
 two vectors of $V$; we consider them as $n$-tuples over $L_{K_v}$; let
 $(u,v) = uav^*$; take $x \in$ End $V$ then we have $(ux, v) = (uxav^*)
 = ua (vax^* a^{-1})^* = (u, vx^I)$. We have to construct an embedding of
 $(B_v,J)$ into the endomorphism ring of such a vector space with
 hermitian form. On the space $B_v$ we introduce the hermitian form
 defined by $(u,v)= Tr^{B_v}_{L_{K_v}} (uv^J c)$ where $c$ is an
 invertible element in $B_v$ to be chosen properly to satisfy $c^J =
 c$ and to make the discriminant of $(u,v)$ a unit. This is a
 non-degenerate hermitian form since trace map in a separable algebra
 in non-trivial. Let $\mathscr{O} (B_v)^* = \{ u \in B_v | (u, v) \in
 \mathscr{O} (L_{K_v})$ $\forall v \in \mathscr{O} (B_v)\}$. The
 hermitian form is unimodular (i.e., discriminant a unit) if and only
 if $\mathscr{O}(B_v) = \mathscr{O}(B_v)^*$ (a nonzero regular lattice
 in a quadratic space is unimodular if and only if it is equal to its
 dual). As $v$ runs through elements of $\mathscr{O}(B_v), v^J c$ runs
 through elements of $\mathscr{O}(B_v).c$; hence $\mathscr{O}(B_v)^* c$
 is just the dual of $\mathscr{O}(B_v)$ with respect to $Tr$ and so is
 equal to $\vartheta ^{-1}_{B_v/ L_{K_v}}$, the inverse different of
 $B_v. B_v$ is a direct sum of local fields and $\mathscr{O}(B_v)$
 is the direct sum of rings of integers in these fields each of which
 is a principal ideal ring and\pageoriginale so $\mathscr{O}(B_v)$
 itself is a 
 principal ideal ring; hence $\vartheta^{-1} _{B_v/ L_{K_v}}$ can be
 written as $\mathscr{O}(B_v)c$ with $c \in B_v$; since
 $\vartheta^{-1}_{B_v/ L_{K_v}}$ is invariant under $J$ and $L_{K_v}/
 K_v$ is 
 unramified we can take $c$ to satisfy $c^J = c$. The dimensions of the
 vector spaces $B_v$ and $V$ are the same and by this choice of $c$
 the hermitian form $(u,v)$ and $B_v$ and the hermitian form coming
 from the matrix $a$ on $V$ are isomorphic. 

Next imbed $B_v$ in End $(B_v)$ by regular representation; we then
claim that $J$ goes into the involution $*$ with respect to the matrix
of $(u,v)$; for if $x \in B_v$ and $u,v$ are vectors of $B_v$ then
$(ux,v) = Tr (u x v^J c) = Tr (u(x^J v)^J c) = (u, x^J v)$. This
proves lemma~\ref{chap5:s5.7:lem1}. 


\setcounter{lem}{1}
\begin{lem}%%%% 2
\setcounter{romancase}{0}
\begin{romancase} %%case i
$v$ non-archimedean and $L_{K_v} \cong K_v \oplus K_v$ and consequently
  $A_{K_v}\cong A_1 \oplus A_2$ the involution $I$ interchanging the
  components. The problem reduces to one concerning $A_1$, i.e., if
  $y_v = (y_1, y_2)$ we have to construct $y_1$ so that $K_v (y_1)$
  will be a separable sub-algebra of $A_1$ and then fix $y_2$ by the
  condition $y_v y^I_v = 1$ (resp $y^I_v = 1$). Let $D$ be the
  quaternion division algebra over $K_v$; if $z = (z_1, z_2)$ then we
  know that $z_1$ is the reduced norm of a regular element of the
  division algebra $D$ and so the principal polynomial of $z$ say $Y^2
  - \lambda_1 Y + z_1$ is irreducible over $K_v$; let $N_1 =
  \dfrac{K_v [Y]}{(Y^2 - \lambda_1 Y+z_1)}$ then $N_1$ is a field
  extension of $K_v$ of degree 2. Since the degree $n$ of $A_1$ is
  even by local theory of central simple algebras the field $N_1$,  can
  be imbedded in $A_1$; let $y_1$ be the image of the residue class of
  $Y$; then we can write $N_1 = K_v(Y_1)$; choosing $y_2$ to
  satisfy\pageoriginale the condition $y_2 = y^{-1}_1$ (resp $y_2 =
  y_1$) $K_v (y_1) \oplus K_v (y_2)$ will be the separable algebra $N_v$
  sought.  
\end{romancase}
\end{lem}


\begin{romancase} %case ii 
$v$ archimedean and $L_{K_v} \cong K_v \oplus K_v$. If $K_v \cong
  \mathbb{R}$ and $z = (z_1, z_2)$ with $z > 0$, essentially the same
  argument as in case $i$ applies. In particular by the local
  solvability condition, this happens if $A_{K_v}$ is the direct sum
  of two matrix rings over the quaternions, and then by construction
  $N_1$ and so the algebra of $I$-invariant elements in $N_v$ is
  isomorphic to $\mathbb{C}$. In all other cases $A_{K_v} \cong A_1
  \oplus A_2$ with $A_1$, $A_2$ isomorphic to $M_n (K_v)$ the $n \times
  n$ matrix ring over $K_v$. In the construction of case i we may
  then use an arbitrary $\lambda_1$, but now $N_1$ is not necessarily a
  field, but may be isomorphic to $K_v \oplus K_v$. If so we have to
  be careful with the embedding of $N_1$ into $A_1$ and we do it by
  mapping $(u, v) \in K_v \oplus K_v = N_1$ into $\left(\begin{smallmatrix} 
u_\cdot & & & &  \\
& \cdot u & & & \\
& & v & & \\
& & & v\cdot & \\
& & & & \cdot v
 \end{smallmatrix}  \right)\in M_n (K_v) =
  A_1$. For $X_1$ we take any regular diagonal matrix. 
\end{romancase}

\begin{romancase} %case iii
$L_{K_v}$ is a field; here $A_{K_v} \cong M_n (L_{K_v})$ and $I$ has
  the action $x^I = ax^* a^{-1}$ where a is a fixed hermitian matrix
  with the usual notations; by choosing an orthogonal basis we can
  assume the hermitian form to be diagonal; choose $c \in L_{K_v}$
  such that $cc^{I} = 1$ (resp $c^{I} = c$) and such that $c \neq
  z/c$; take for $y_v$ the matrix 
$$
\left.  
\left(
\begin{array}{c|c}
{}^oo_o & O\\\hline
O & {}^{\pi/\varepsilon} {}_{z/c}
\end{array}
\right)
\right\}^n_n;
$$ then $y_v y_v^I = 1$
  (resp $y^I_v = y_v$); the principal polynomial of this
  matrix is $(Y - c) (Y - z/c)$ which is separable;
  consequently\pageoriginale the 
  algebra $\dfrac{L_{K_v} [Y]}{(Y-c)(Y-z/c)}$ is separable and is
  isomorphic to $L_{K_v} \oplus L_{K_v}$. We  can take this algebra
  for $N_v$ and any regular diagonal matrix for $x_v$. 
\end{romancase} 

\setcounter{proofoflem}{2}
\begin{proofoflem} %proof of lemma 3.
By algebraic number theory there exists infinitely many places for
which $L_{K_w}$ is a field. Choose such a $w \notin S$. In the case of
Proposition a) approximate the local solution $x$ of $z = Nx$ by $u
\in A_K$ with $u$ having the property $uu^{I} =  1$; then $z
\approx Nu$ and so $z/Nu$ can be assumed to be a square $r^2$ say where
$r \in L_K$; now $zz^I = 1$ and $Nuu^I$ so that $rr^I = \pm 1$. Since
$r$ can be taken to approximate $1$ we can have $rr^I = 1$. Replacing
$z$ by $z/Nu$ we have only to prove the lemma for this new $z$. Let
$M_w$ be a quadratic extension of $K_w$ different from $L_{K_w}$ which
exists for the $\mathcal{P}$-adic field  $K_w$. Then if $N_w$ denotes
the composite of $L_w$ and $M_w, \ldots N_w$ is quadratic over $L_w$
and we have $z  = N_{L_w}^w (r)$; we put $y_{w_N} = rs$ with $s$ in
$N_w$ but not in $L_{K_w}$ satisfying the conditions $N_{L_w}^w (s) =
1$ and $N_{M_w}^{N_w}(s) = 1$; if $H$ resp. $J$ are the non-trivial
automorphisms of $N_w$ over $L_w$ resp. $M_w$, $s =
\dfrac{tt^{HJ}}{t^Ht^J}$ with suitable $t \in N_w$ satisfies these
conditions. This $y_w$ clearly satisfies all the requirements of the
lemma. In the case of proposition b), if $z$ is a norm from
$L_w/K_w$, we may first change $z$ to $zNu Nu^I$ and so assume $z =
r^2$ with $r^I = r$, similar to case $a)$ and then put $N_w = L_w M_w$
and $y_w = rs$ with $s$ in $M_w$ but not in $K_w$,  $N_{K_w}^{M_w}(s)
= 1$. On the otherhand if $z$ is not a norm from $L_w/K_w$ choose a
quadratic extension $M_w/K_w$ from\pageoriginale which $z$ is a norm $z =
N_{K_w}^{M_w} (y_w)$. Then necessarily $L_w$ is different from $M_w$
and $y_w \in K_w$ so we are through. 
\end{proofoflem}

We shall now go to the proof of lemma~4 which is the only remaining
thing to be proved for establishing theorem~\ref{chap5:thm1a} a) for
groups of type 
${}^2A_n$. Consider the diagram below  
\[
\xymatrix{
& N \ar@{-}[dr] \ar@{-}[dl] & \\
M \ar@{-}[dr]& & L \ar@{-}[dl]\\
& K & 
}
\]
here $M$ and $L$ are quadratic extensions of $K$ and $N$ is the
composite of $M$ and $L$; we are given $c \in K^*$ and our
assumptions are \; i) the equation $N^L_K l = c N^M_K m$ is solvable
locally; i.e. given a place $v$ of $K$ the equation is solvable with
$l \in L \otimes K_v$ and $m \in M \otimes K_v$; \; ii) there is at
least one place $w$ of $K$ such that $M_{K_w}$ is a field. We then
want to assert the solvability of $N^L_K l =  c N^M_K m$ globally,
i.e. with $l \in L$ and $m \in M$. Let $G_m$ be the 1-dimensional
multiplicative group; consider $L^*, M^*$ as two dimensional tori over
$K$ and let $T = L^* \times M^*$ be their product which is again a
torus. Since $N$ is a splitting field for both $L^*$ and $M^*$ it is a
splitting field $T$; consider a map $T \to G_m$ defined by $(x, y) \to
(N^L_K x) (N^M_K y^{-1})$. This map is defined over $N$ and using the
fact that $N$ splits $T$ one can see that the map is surjective; Let
$T'$ be the kernel; then $T'$ will be again a torus over $K$ split by
$N$. 
\begin{equation*}
1 \to T' \to T \to G_m \to 1 \qquad \cdots . \tag{1}\label{c5:eq1}
\end{equation*}
will\pageoriginale be an exact sequence defined over $N$; the ground
field being of characteristic zero the homomorphism $T \to G_m$ will
be separable; hence taking rational points over $N$ we get an exact
sequence   
$$
1 \to T'_N \to T_N \to (G_m)_N \to 1
$$

The homomorphisms involved in this sequence are g-homomorphi\-sms where
$g$ denotes the Galois group of $N/K$. To any given place  $v$ of $K$
we select arbitrarily a place $v'$ of $N$ extending $v$ and keep it
fixed throughout; the decomposition group of $v'$ depends only on $v$
and not on the extension $v'$ chosen since $N/K$ is abelian; hence we
can denote it by $g_v$: then $g_v$ will be the Galois group of
$N_{K_{v'}} / K_v$. Passing to $N_{v'}$-rational points in \eqref{c5:eq1} we
will get a commutative diagram  
\[
\xymatrix{
1 \ar[r] & T'_N \ar[r]\ar[d] & T_N \ar[r] \ar[d] & (G_m)_N \ar[r]
\ar[d] & 1 \\
1 \ar[r] & T_{N_{v'}} \ar[r] & T_{N_{v'}} \ar[r] & (G_m)_{N_{v'}}
\ar[r] & 1
}
\]
where the vertical maps are inclusions; here the rows are respectively
g-exact and $g_v$-exact sequences; and the vertical maps are
compatible with the inclusion $g_v \to g$; hence passing to cohomology
we get the following commutative diagram: 
\[
\xymatrix@C=1.4cm{
T_K \ar[r]^{\alpha} \ar[d]_f & K^{\ast}  \ar[r]^{\beta} \ar[d]_g & H^1
(g_{N/K}, T'_N) \ar[d]_h \\
T_{K_v} \ar[r]_{\bar{\alpha}} & K^\ast_v \ar[r]_{\bar{\beta}} &
H'(g_v, T'_{N_v})
}
\]

Now\pageoriginale $g(c)$ is in the image of $\bar{\alpha}$ by
assumption of local 
solvability of $N_K^L l = c N^M_K m$; hence $\bar{\beta}$ maps $g(c)$
into \eqref{c5:eq1} which implies that $h$ maps $\beta(c)$ into \eqref{c5:eq1}; the
lemma is equivalent to proving that $c$ is in the image of $\alpha$,
i.e. we have to show that $\beta (c) = (1)$: hence the proof of the
lemma will be achieved if the product map $H^1 (g_{N/K}, T^1_N) \to
\prod\limits_{v}H (g_v, T'_{N_v'})$ is injective. But this we have
proved in \S~\ref{chap3:sec3.2}, theorem~\ref{chap3:thm6} a). 

If finally $(l_v, m_v)$ are finitely many local solutions and $(l, m)$
is a global solution, then $(a_v, b_v) = (l_v l^{-1}, m_vm^{-1})$ are
local solutions of $N^L_K a = N^M_K b$. If we can approximate these by
a global solution $(a, b)$, then $(al, bm)$ will be  a global solution
of our original equation approximating the given local solutions
$(l_v, m_v)$.  Now it can be shown that every solution $(a_v, b_v)$ is
of the form $a_v = c_v N^N_L d_v$, $b_v = c_vN^N_M d_v$ with $c_v \in
K_v$, $d_v \in N \otimes K_v $; so we can put $a = cN^N_L d$, $b= cN_M^N
d$ with $c \in K$, $d \in N$ approximating $c_v$, $d_v$. This completes
the proof of lemma~4 and of theorem~\ref{chap5:thm1a} a) for groups of type
${}^2_{A_n}$. 


\section{Proof of theorem 1a for groups of type
  $C_n$}\label{chap5:sec5.8} 

By the classification given in \S \ref{chap5:sec5.1}, groups of
type $C_n$ are 
either the symplectic groups or the special unitary groups of
hermitian forms over quaternion algebras. In the case of symplectic
group the theorem is a consequence of \S \ref{chap1:sec1.7},
Example \ref{chap1:exam3}. In the
second case since the special unitary group coincides with the unitary
group, we have to consider $G = U_n(C/K, h)$ where $C$ is a quaternion
algebra and\pageoriginale $h$ is a hermitian form. The proof for this
case is given 
by induction on the integer $n$. For $n=1, U_1(C/K, h)$ is isomorphic
to a group of type $A_1$ and by our proof for groups of the latter
type theorem~\ref{chap5:thm1a} a) holds for $U_1 (C/K, h)$. Hence by induction
assume theorem~\ref{chap5:thm1a} a) is proved for unitary groups in $(n-1)$
dimension, $n\geq 2$. Let $V$ be the vector-space on which the unitary
group $U_n$ operates. This space $V$ will be of dimension $4n$ over
$K$. Let $x_o$ be an anisotropic vector of $V$. Let $h(x_o) = c$ where
$c \in K^*$. Let $U_{n-1} $ be the unitary group corresponding to the
orthogonal complement of  $x_o$; let $H = U_{n-1}$; consider the
following commutative diagram: 
\[
\xymatrix{
H^1 (K,H) \ar[r] \ar[d]_\alpha & H^1 (K,G) \ar[d]^\beta\\
\prod H^1 (K_v , H) \ar[r] & \prod H^1 (K_v, G)
}
\]
we have to prove that $\beta$ is injective; let $(a) \in H^1 (K, G)$
be mapped onto (1) by $(\beta)$; then $\beta(a)$ is in the image of
$\psi$;  hence by proposition~\ref{chap1:prop1} of \S~\ref{chap1:sec1.5} the
twisted homogeneous 
space $_a(G/H)$ has a $K_v$-rational point for every $v \in \infty$;
we shall prove that this implies $_a(G/H)$ has a $K$-rational point; we
shall also prove that $\psi$ is injective. Granting these we apply
proposition~\ref{chap1:prop1} of \S~\ref{chap1:sec1.5} again; hence
there exists 
$(b) \in H^1 (K, 
H)$ such that $\varphi (b) = a$; now $\psi \circ \alpha (b) = \beta
\circ \varphi
(b) = (1)$, so that by the injectivity of $\psi$ we have $\alpha (b) =
(1)$; but by induction assumption $\alpha$ is injective hence $b =
(1)$ which implies $a=(1)$ which is what is required to be proved; we
shall now prove the\pageoriginale two assertions made. The group $G$
operates 
transitively on the sphere $\left \{ x \in V \bigg/ h(X)=c \right \}$
over $\bar{K}$ and $H$ is the isotropy subgroup of $x_\circ$ of this
sphere; hence $G/H$ is isomorphic to this sphere over $\bar{K}$; we
can twist both $V$ and $h$ by the cocycle $a$ since $h$ is invariant
under all the automorphism $a_s, s \in (\bar{K}/K)$; let the twisted
sphere be $\left \{x \in V'/h' (x)=c \right \}$ which is then
isomorphic to $_a(G/H)$ over $\bar{K}$. Since $_a(G/H)$ has a
$K_v$-rational point for every place $v$ of $K$ the preceding
isomorphism implies that $h'(X)=c$ is solvable locally at all
completion $K_v$ of $K$; now $h'$ can be considered as a quadratic
form over $K$ in $4n$ variables; this quadratic form over $K$
represents the nonzero $c$ locally at $K_v$ for all places $v$ of $K$
by assumption; hence Minkowski-Hasse's theorem it presents $c$
globally in $K$ and so  $_a(G/H)$ has a $K$-rational points. Next we
shall prove the injectivity of $\psi$; from the exact sequence $1 \to
H \to G \to (G/H)\to 1$ of $g_{\bar{K}_v/K_v}$-sets we get exact
sequence 
\begin{equation*}
G_{K_v}\to (G/H)_{K_v}\to H^1 (K_v,H)\to H^1 (K_v,G) \tag{1}\label{c5:eq11}
\end{equation*} 
   
Now the map $G_{K_v} \to (G/H)_{K_v}$ is defined through the operation
of $G$ on the homogeneous space $G/H$; by lemma~\ref{chap2:lem2} of 
\S~\ref{chap2:sec2.6} the 
operation of $G_{K_v}$ on $(G/H)_{K_v}$ is transitive; hence the map
$G_{K_v} \to (G/H)_{K_v}$ is surjective which then implies by the
exactness of \eqref{c5:eq11} that the map $h^1(K_v,H)\to H^1(K_v,G)$ is
injective. Hence the map $\psi$ is injective.  
   

\section{Quadratic forms}\label{chap5:sec5.9}
   
If $G = \Spin_n$, $n = 3$,\pageoriginale by considering the Dynkin
diagram we get 
isomorphisms of $G$ onto groups of type $A_m$ or $C_m$ so that 
theorem~\ref{chap5:thm1a} a) is true for these $n's$. So assume $n \geq 4$; choose a
non-isotropic vector $x_\circ \in V$, $V$ being the vector space on
which the quadratic form is given; let $0_{n-1}$ be the orthogonal
group of its orthogonal complement; let $H$ be its simply connected
covering; then $H$ is $\Spin_{n-1}$; for proving theorem~\ref{chap5:thm1a}) 
we use induction on $n$; so assume the theorem for $n-1$; consider the
comutative diagram below.  
\begin{equation*}
\vcenter{\xymatrix{
(G/H)_K \ar[r]^\varphi \ar[d]_f & H^1 (K,H) \ar[r]^\psi \ar[d]_g & H^1
    (K,G) \ar[d]_h \\
\prod\limits_{v\in\infty} (G/H)_{K_v} \ar[r]^\alpha &
\prod\limits_{v\in\infty} H^1 (K_v, H) \ar[r]^\beta &
\prod\limits_{v\in\infty} H^1 (K,G) 
}}\tag{2}\label{c5:eq2}
\end{equation*}

Let $(a)\in H^1(K,G)$ be mapped onto \eqref{c5:eq11} by $h$; then as in the
discussion of $C_n$, ${}_a(G/H)$ has $K_v$-rational point for every
$v$; now we have $\Spin/ \Spin_{n-1} \cong SO_n /SO_{n-1} \cong
O_n/O_{n-1}$ which is isomorphic to the sphere $\{ x \in V /
\mathscr{G}(x) = c \}$ where $c = \mathscr{G}(x_o)$; hence over
$\bar{K}$ $a(G/H) \cong  \left \{ x \in V' \bigg/ \mathscr{G}' (x) = c
\right\}$ where $(V', \mathscr{G'})$ is got by twisting $(V,
\mathscr{G})$ by the cocycle $a$; by assumption the quadratic form
$\mathscr{G}'(x)$ represents $c$ locally at infinity. Since $n \ge 4$
the quadratic form $\mathscr{G}'(x)$ represents $c$ locally at the
non-archimedean completion of $K$ as well; hence $c$ is represented by
$\mathscr{G'}(x)$ locally in all $K_v$; applying Hasse-Minkowski's
theorem $\mathscr{G'}(x)$ represent $c$ globally; hence $_a(G/H)$ has
a $K$-rational point; this implies the existence of $b \in H^1 (K,H)$
such that $\psi(b) = a$; then\pageoriginale $\beta (g(b)) = (1)$ so
that there 
exists $c \in \prod\limits_{v \in \infty}$ which $\alpha (c) = g(b)_1$;
we shall prove presently that $c$ can be so chosen that it is  
in the image of $f$; granting this there exists $d \in (G/H)_K$ such
that $f(d) = c$; then $g(\varphi(d))= g(b)$; by induction assumption
$g$ is injective so that $b = \varphi (d)$; but then $a= \varphi (b)
=\varphi o \varphi(d)=(1)$ and so $h$ will be injective;  hence we have
only to prove $c$ can be chosen as required above. By the exactness of
the bottom row in~\eqref{c5:eq2} two elements of $\prod \limits_{v \in
  \infty}(G/K)_{K_v}$ will go into the same element under the map
$\prod (G/H)_{K_v}\to \prod H^1 (k_v,H)$ if and only if there differ
by an element of $\prod G_{K_v}$ as factor hence the fact that $c$ can
be chosen to lie in the image of $f$ will follow from the lemma below:  

\setcounter{lem}{0}
\begin{lem} %lemma 1.
Given elements $x_v \in (G/H)_{K_v}$ for archimedean there exist
elements $u_v \subset G_{K_v}$ such that $u_v x_v \in (G/H)_K$ and are
the same for all $v$. 
\end{lem}

\begin{proof}
Here $G/H$ is the sphere $T = \left \{ x \in V \bigg/ \mathscr{G}(x) =
c \right \}$ and so $(G/H)_{K_v}$ is the set of solutions of
$\mathscr{G}(x) = c$ rational over $K_v$. By Witt's theorem
$(O_n)_{K_v} = O_{K_v}$ acts transitively on the sphere $T$; since
$x_o \in T$ we can find $t_v \in O_{K_v}$ such that $x_v = t_v x_o$;
if $t_v$ is improper by multiplying $t_v$ on the right by a reflection
in a plane containing $x_o$ we can make product proper and $t_v x_o$
is not disturbed by this change; hence without loss of generality we
can assume $t_v \in SO_{K_v}$; let $a$ be the matrix of the quadratic
form $\mathscr{G}$ with respect to some basis; let $x^I = a^t x
a^{-1}$ for $x \in O_n$; then $xx^I = 1$ by definition of $O_n$;
approximate the $t'_v s$ by a $t \in SO_K$ and put $x = tx_o$ so that
$x \in (G/H)_K$ and $x \simeq x_v$; we shall now show that $x$ is in
$G_{K_v}x_v$; the orbit of $x_v$ under the\pageoriginale action of
$G_{K_v}$ is just 
$(G/H)_{K_v}$ by Witt's theorem; now $\Spin_n \to SO_n$ is surjective
and is a local isomorphism over $\bar{K}_v$ since it is a covering;
hence $(\Spin_n)_{\bar{K}_v}$ is local isomorphism; this homomorphism
is compatible with the action of the Galois group $g_{\bar{K}_v/K_v}$;
hence forming the group of fixed points under the action of
$g_{\bar{K}_v / K_v}$ in the above groups we get a local isomorphism
$(\Spin_n)_{K_v}\to (SO_n)_{K_v}$; this shows that the latter map is
surjective  onto a neighbourhood of 1 in $(SO_n)_{K_v}$; now by
construction $t_vt^{-1} \approx 1$ and $t_vt^{-1}\in (SO_n)_{K_v}$
hence $t_vt^{-1}$ is the image of some element $u^{-1}_v \in
(Spin_n)_{K_v}$ under the above homomorphism; then $x = tx_o =
tt^{-1}_vx_v$; going back from $T$ to $G/H$ by the isomorphism $G/H
\cong T$ we get $x = u_v x_v$ with $u_v \in G_{K_v}$; hence the lemma
is proved and consequently theorem~\ref{chap5:thm1a} a) is proved for
the group under consideration. 
\end{proof}  
      

\section[Skew hermitian forms over quaternion division
  algebras]{Skew hermitian forms over quaternion\hfil\break division
  algebras}\label{chap5:sec5.10} 
      
Write $G = \Spin_n(D/K, h)$ where $D$ is a quaternion division algebra
and $h$ is a skew-hermitian form. If $n = 2$ or 3, $G$ is isomorphic
to a group of type $A_1 \times A_1$ or $A_3$ and the theorem is proved
for these types. Hence we can assume $n \ge 4$. We can then carry out
the procedure adopted for spin groups of quadratic forms almost word
for word; for 
this we need to know the analogue of Witt's theorem, i.e. Given two
anisotropic vectors $x$ and $y$ of the same length meaning $h(x) =
h(y)$ there exists a proper unitary matrix $t$ transforming $x$ into
$y$; this we proved in \S~\ref{chap2:sec2.6}, lemma~\ref{chap2:lem2}.

 We\pageoriginale also need to know the Minkowski- Hasse's theorem for
 skewhermitian forms. This we shall state and prove as a proposition.   
      
\begin{prop*}
Let $D$ be a quaternion division algebra over $K$; let $h$ be a skew
hermitian form in $n \ge 2$ variables over $D$; let $c$ be a nonzero
skew quaternion of $D$; then is the equation $h'(x)=c$ has a solution
locally at all places $v$ of $K$ then it has a global solution. 
\end{prop*}   
         
Clearly the proof of this proposition will complete the proof of
theorem~\ref{chap5:thm1a} a) for $G$. 

\medskip
\noindent{\textbf{Proof of the Proposition.}}
We shall first prove the proposition for $n=2$ and 3. Let $V'$ be
the vector space on which $h'$ is given. We shall construct a vector
space $V$ with a hermitian form $h$ such that both $V$ and $V'$ have
the same dimension and discriminants and such that $V=Wl(x_o)$ with
$h(x_o)=c$. This is done as follows; first let $n=2$. We shall find a
skew quaternion $b$ such that the reduced norm of $\begin{pmatrix} b &o
  \\o &c \end{pmatrix} $ shall be equal to the discrimination $d$ of
$V'$; this is equivalent to requiring $bb^I=
\dfrac{d}{cc^I}$. Expressing $b$ in terms of a basis of $D/K$, $bb^I$
becomes a ternary form over $K$. Hence we require the form $bb^I$ to
represent $\dfrac{d}{cc^I}$. By the Minkowski-Hasse's theorem for
quadratic forms it is enough to check the local solvability of the
equation $bb^I=\dfrac{d}{cc^I}$. Now suppose $x'_v$ are the given
solution of $h'(x)=c $ at the places $v$ of $K$. If  $D_vy_v$ denotes
the orthogonal complements of $x'_v$ in $V'_{K_v}$, then
$h(y_v)H^{-1})^I=d/cc^I$. This proves the local solvability of
$bb^I=d/cc^I$. Hence as observed above\pageoriginale it is also
globally solvable 
with $b \in D$. Then $\begin{pmatrix} b &o \\o &c \end{pmatrix} $
define a hermitian form $h$ on a 2-dimensional vector space $V/D$;
clearly $h$ represents the skew quaternion $c$. If $n \ge 3$ we can
carry out a similar procedure using lemma~\ref{chap4:lem4} of 
\S~\ref{chap4:sec4.3}. Let 
$U_{n-1}$ denote the unitary group of $(W,h)$. By construction $(V,h)$
is isomorphic to $(V', h')$ over $\bar{K}$. Let $f:V \to V'$ be this
isomorphism. Then $a_s = f^{-1} \circ {}^s f$ is a 1-cocycle of
$g_{\bar{K}/K}$ with 
values in $U_n(V)$, the unitary group of $V$. The discriminants of $V$
and $V'$ being equal by \S~\ref{chap2:sec2.6} lemma~\ref{chap2:lem3} 
we know that $(a_s)$ comes 
from $H^1(K,SU_n)$ so that we can assume $a_s \in SU_n$. Let $T= \left
\{ x\in V\bigg / h(x)=c \right \},T'= \left \{ x \in V' \bigg /h'
(x)=c \right \}$ be spheres in $V,V'$ respectively. Clearly $T$ is got
by twisting the sphere $T$ with the 1-cocycle $(a_s)$. Our problem
is to show that $h'(x)=c$ has a global solution i.e. the sphere $T'$
has a $K$-rational point. Now by lemma~\ref{chap2:lem2} of 
\S~\ref{chap2:sec2.6} $T$ is isomorphic 
over $\bar{K}$ to the homogeneous space $SU_n/SU_{n-1}$. Hence the
sphere $T'$ is isomorphic to the twisted homogeneous space
$_a(SU_n/SU_{n-1})$. The problem therefore reduces to showing that the
latter has a $K$-rational point. By \S~\ref{chap1:sec1.5}
proposition~\ref{chap1:prop1}, this is 
equivalent to proving that the 1-cocycle $a_s$ comes from
$SU_{n-1}$. The local solvability of $h'(X)=c$ implies that locally at
all places the cocycle $a_s$ comes from $SU_{n-1}$. Hence for the
proof of the proposition we are reduce to proving the following: given
$(a_s) \in H^1 (K,SU_n)$ such that its image $(b_s)$ in $H^1(K_v,SU_n)$,
is contained in the image of $H^1(K_v,SU_{n-1}) \to H^1(K_v,SU_n)$ for
all places $v$ of $K$ to show that $(a_s)$ is in the image of
$H^1(K,SU_{n-1})\to H^1(K,SU_n)$. We shall prove this\pageoriginale
now. In the 
diagram below we write $H^1(SU_n)$ to mean both $H^1(K,SU_n)$ and
$H^1(K_v,SU_n)$; let $1 \to Z_2 \to \Spin_n \to SU_n \to 1,1 \to Z_2
\to \Spin_{n-1} \to SU_{n-1} \to 1$  be the covering maps. From these
we get a commutative diagram 
\[
\xymatrix{
H^1 (SU_{n-1}) \ar[r]^g \ar[d]_{\delta_1} & H^1 (SU_n)
\ar[d]_{\delta_2} \\
H^1 (Z_2) \ar[r]^{\rm identity} & H^2 (Z_2)
}
\] 
By assumption $\delta_2(a_s) \in$ Image of $\delta_1$ locally. We first
consider the case $n=2$. $SU_1$ is a torus with a quadratic splitting
field (See \S~\ref{chap3:sec3.1} Example~\ref{chap3:exam4}). 
$\Spin_1$ being a covering of $SU_1$ 
is again a torus with a quadratic splitting field. Clearly $\Spin_1$
satisfies the condition of \S~\ref{chap3:sec3.2} 
theorem~\ref{chap3:thm6} a), and so Hasse 
Principle for $H^2$ of $\Spin_1$ is valid. $\Spin_1$ being comutative
the diagram above can be supplemented by the sequences  
$$
H^1(SU_1) \xrightarrow{{\delta}_1}  H^2 (Z_2) \xrightarrow{p} H^2 (\Spin_1).
$$
 
 Since $\delta_2 (a_s) \in$ image of $\delta_1$ locally we have
 $p(\delta_2 (a_s))=\{ 1\}$ locally at all places of $K$. By the Hasse
Principle quoted above we have $p(\delta(a_s))=\{ 1\}$ in
 $H^2(K,\Spin_1)$. This clearly implies $\delta_2(a_s)$ is in the
 image of $H^1(K,SU_1)$ by the map $\delta_1$. Next if $n=3$ the group
 $SU_2$ being semisimple and connected the same conclusion holds by
 virtue of \S~\ref{chap5:sec5.2} theorem~\ref{chap5:thm2}. Hence in
 either case we can find 
 $(b)\in H'(K, SU_{n-1})$ such that $\delta_1(b)=\delta_2(a)$. Twisting
 the whole situation\pageoriginale by the cocycle $b$, we may assume $\delta
 _2(a)=1$, i.e. that the cocycle a comes from a cocycle $b$ of the spin
 group. Now $T' \cong {}_a(SU_n/SU_{n-1})\cong_b(\Spin_n/
 \Spin_{n-1})$. Hence we are reduced to proving the following: given an
 element $b \in H^1 (K, \Spin_n)$ which comes from $\Spin_{n-1}$
 locally at all places of $K$, to show that $b$ comes from
 $\Spin_{n-1}$. We shall prove this now. We have a commutative diagram 
\[
\xymatrix{
H^1 (K, \Spin_{n-1}) \ar[r]^g \ar[d]_\beta & H^1 (K, \Spin_n)
\ar[d]_\gamma\\
\prod\limits_{v\in\infty} H^1 (K_v, \Spin_{n-1}) \ar[r]^h &
\prod\limits_{v\in\infty} H^1 (K_v, \Spin_n)
}
\]
  If $n=2$, $\Spin_1$ is an algebraic torus so that by 
\S~\ref{chap3:sec3.2} theorem~\ref{chap3:thm6} b) corollary the map
  $\beta$ is surjective. If $n=3$, $\Spin_2$ 
  being connected and semisimple by theorem~\ref{chap5:thm1b})
  $\beta$ is surjective 
  again. For $n = 2,3$, $\Spin_n$ is isomorphic to a group of type
  $A_n$ so that by theorem~\ref{chap5:thm1a}) applied to groups of
  this type, which we have already proved, we find that $\gamma$ 
  is injective. By  assumption 
  $\gamma(b)=h(c)$ for some $c \in \prod \limits_{v \in \infty}h^1
  (K_v, \Spin_{n-1})$. By the surjectivity of $\beta$ lift $c$ to
  $1$-cocycle $d$ of $\Spin_{n-1}$; then $\gamma(g(d))=\gamma
  (b)$. Using the injectivity of $\gamma$ we find $g(d)=b$, i.e. $b$
  comes from $H^1 (K, \Spin_{n-1})$. This is what we wanted to
  prove. Hence the proposition is established for the cases $n=2,3$.    
 
 
 Next let us consider the case $n \geq 4$. Let $x_v$ be the given
 local solution of $h'(x)=c$ for $v \in S$. Approximate the solutions
 $x_v, v \in \infty$ by a vector $x \in V$ and let $W$ be a three
 dimensional regular subspace of $V$ containing $x$. If the
 approximation is good enough the restriction\pageoriginale $h''$ of
 $h'$ to $W$ represent $c$ locally for all $v \in \infty$. BY 
 Lemma~\ref{chap4:lem4} of \S~\ref{chap4:sec4.3} the same is 
 true for $v \notin \infty$. By the
 case $n=3$, $h''$ and therefore $h'$ represents $c$ globally.  
 
 Another proof of this proposition, due to $T$. Springer, is given in
 an appendix.  

\section{Applications}\label{chap5:sec5.11}


\noindent{\textbf{Classification of quadratic forms}}

Let $\mathscr{G}$ be a non-degenerate form over any field $K$. Then
$H^1(K, O (\mathscr{G}))$ is isomorphic to the set of $K$-equivalent
classes of quadratic forms over $K$. The exact sequence $1 \to SO \to O \to
Z_2 \to 1$ where $O \to Z_2$ is the determinant map gives rise to an
exact sequence of cohomology sets 
$$
O_K \to Z_2 \to H^1(K,SO) \to H^1(K,O) \to  H^1 (K,Z_2)  
$$

Since $O_K \to Z_2$ is surjective in view of the existence of
reflections we see that the map $H^1(K,SO) \to H^1(K,O)$ has trivial
kernel. By a familiar twisting argument we find that $H^1(K,SO) \to
H^1(K,O)$ is injective. 

The map $H^1(K,O) \to H^1(K,Z_2) \cong K^*/K^{*^2}$ maps a class of
quadratic forms onto the quotient of its discriminant by that of $q$
(by an argument similar to the proof of lemma~\ref{chap2:lem3} in 
\S~\ref{chap2:sec2.6}). So 
$H^1(K,SO)$ is isomorphic to the set of $K$-classes of quadratic forms
of fixed dimension $n$ and discriminant $d$. Among these let
$\mathscr{G}$ be one of maximal index and consider\pageoriginale the
exact sequence  
$$
1 \to Z_2 \to \Spin \to SO \to 1. 
$$ 

We arrive at an exact sequence of cohomology sets,
{\fontsize{10}{12}\selectfont
\begin{equation*}
\Spin_K \to SO_K \to H^1(K,Z_2) \to H^1(K,\Spin) \to H^1(K,SO) \to
H^2(K,Z_2)  \tag{2}
\end{equation*}}

The map $SO_K \to H^1(Z_2) \cong K^*/K^{*^2}$ is the spinor norm
$(cf.~[E_3])$. Using the exact sequences $1 \to Z_2 G_m
\xrightarrow{\rm square}  G_m \to 1$ we get $1 \to H^2(K,Z_2)\to B_K
\xrightarrow{\text{multiplication by 2}}  B_K$ which is an exact
sequence. Hence $H^2(K,Z_2)$ is isomorphic to the subgroup of elements
of $B_K$ which are of order 2. The map $H^1(K,SO)\to H^2 (K,Z_2)$ is
called the Hasse-Witt map (cf.\ [sp]). Hence we have found three
invariants of a quadratic form $\mathscr{G}$ namely $i$) dimension of
$\mathscr{G}$ $ii)$ discriminant of $\mathscr{G}$ $iii$) the
Hasse-Witt invariant. 

We claim that over a $\mathscr{P}$-adic field $K$ these invariants
completely characterise a given $K$-equivalent class of quadratic
form. This follows immediately from the result $H^1(K,\Spin)= \{ 1 \}$
of chapter~\ref{chap4}, the exact sequences (2), and a twisting argument. 

\section*{Quadratic forms over number fields.}

We shall show the connection between theorem~1 and the ordinary
Hasse principle for equivalence of quadratic forms. We shall
assume first $n = \dim \mathscr{G} \geq 3$, we have a comutative
diagram with exact rows:  
{\fontsize{9}{11}\selectfont
\[
\xymatrix{
H^1(K,Z_2) \ar[r] \ar[d]^\lambda & H^1 (K, \Spin) \ar[r]^f
\ar[d]^\alpha & H^1 (K,SO) \ar[r]^f \ar[d]^\beta & H^2 (K, Z_2)
\ar[d]^\gamma \\
\prod\limits_{v\in\infty} H^1 (K_v, Z_2) \ar[r] &
\prod\limits_{v\in\infty} H^1 (K_v, \Spin) \ar[r] & \prod\limits_v H^1
(K_v, SO) \ar[r] & \prod\limits_v H^2 (K_v, Z_2)
}
\]}

We\pageoriginale want to know if $\beta$ is injective. By the
splitting criterion 
for simple algebras (in fact quaternion algebras) the map $\lambda$ is
injective. By theorem~\ref{chap5:thm1a}) the map $\alpha$ is
injective. We claim 
that $\lambda$ is surjective; this is because $H^1(K_v,Z_2)\cong
K^*_v/K^{*^2}_v$ and $\lambda$ surjective means that we must be able
to find an element of $K$ with prescribed signs at the real
places. This is clearly possible. Hence by lemma~\ref{chap5:lem1} of
\S \ref{chap5:sec5.1} the 
map $\beta$ is injective. 

Next using the exact sequences $1 \to SO \to O \xrightarrow{\det}  Z_2
\to 1$ we get a commutative diagram. 
\[
\xymatrix{
1 \ar[r] \ar[d] & H^1 (K,SO) \ar[r] \ar[d]^{\bar{\beta}} & H^1 (K,O)
\ar[r] \ar[d]^{\bar{\alpha}} & H^1 (K,Z_2) \ar[d]^{\bar{\gamma}}\\
1 \ar[r] & \prod\limits_v H^1 (K_v, SO) \ar[r] & \prod\limits_v H^1
(K_v, O) \ar[r] & \prod\limits_v H^1 (K_v, Z_2)
}
\]
 
 By what we showed above $\bar{\beta}$ is injective; by algebraic
 number theory if an element of $K^*$ is a square at all places of
 $K$, then it is a square in $K$. This shows that $\bar{\gamma}$ is
 injective. Hence again by lemma~\ref{chap5:sec5.1:lem1} of \S
 \ref{chap5:sec5.1} we see that 
 $\bar{\alpha}$ is injective. This is what we wanted to prove. If
 $V,V'$ are two quadratic spaces of dimension $n<3$, which are
 isomorphic locally everywhere, let $W$ be a $(3-n)$-dimensional
 space. Then $(V \perp W)_v \cong (V' \perp W)_v$ for all places
 $v$. By what we have just proved $V \perp W \cong V' \perp W$, and
 Witt's theorem implies $V \cong V'$ 
 

 \section*{Skew-hermitian forms over a quaternion division algebra}
 
 If we try to carry over the above investigations to skew hermitian
 form over quaternion division we find some differences. Let $D$
 be\pageoriginale a
 quaternion division algebra over $K$, either a $\mathscr{P}$-adic
 field or a number field, $h$ a skew-hermitian form over $D$, and $U$
 the unitary group of $h$. Then the norm mapping $U \to Z_2$ gives
 rise to the discriminant map $H^1(K,U) \to H^1(K,Z_2)$. Next the
 exact sequences $1 \to Z_2 \to \Spin \to SU \to 1$ gives rise to the
 cohomology sequence   
{\fontsize{10}{12}\selectfont
\begin{equation*}
\Spin_K \to SU_K \to H^1 (K,Z_2) \to H^1 (K,\Spin) \to H^1(K,SU) \to
H^2(K,Z_2) \tag{4} \label{chap5:eq4}
 \end{equation*}} 
 
 We proved in \S \ref{chap2:sec2.6}, lemma~\ref{chap2:lem1} a) that
 $SU_K=U_K$; using this in 
 the exact sequence 
 $$
 (SU)_K \to U_K \to Z_2 \to H^1 (K,SU) \to H^1(K,U) \to H^1(K,Z_2)
 $$
we find that
 $Z_2 \to H^1 (K,SU)$ is injective; now let $K$ be a
 $\mathscr{P}$-adic field. Then we saw in \S~\ref{chap4:sec4.1}
theorem~\ref{chap4:thm1} that
 $H^1 (K,\Spin)= \{ 1\}$. Using this in (\ref{chap5:eq4}) we find that
there is an 
 injection $H^1(K,SU) \to H^2 (K,Z_2)$.  But in this case we have seen
 $H^2 (K,Z_2)\cong Z_2$. Hence we have $H^1(K,SU)\cong Z_2$. This
 shows that in (\ref{chap5:eq4}) the discriminant mapping $H^1(K,U) \to H^1
 (K,\break Z_2) \cong K^* /K^{*^2}$ has trivial kernel; by a twisting
 argument the discriminant map is injective. Hence a complete set of
 invariants are the dimension and discriminant $(cf. [J],[Ts])$. 

 In the case of number fields the injectivity of the map $H^1(K,SU)\to
 \prod\limits_v H^1(K_v,SU)$ follows as in the case of quadratic forms
 but if we try to apply the argument leading to the proof of the 
 Hasse Principle we find the following diagram 
{\fontsize{9}{11}\selectfont
\[
\xymatrix{
1 \ar[r] & Z_2 \ar[r] \ar[d] & H^1 (K, SU) \ar[r] \ar[d] & H^1 (K,U)
\ar[r] \ar[d] & H^1 (K,Z_2) \\
1 \ar[r] & \prod\limits_{v \in S} Z_2 \ar[r] & \prod\limits_v H^1
(K_v, SU) \ar[r] & \prod\limits_v H^1 (K_v, U) \ar[r] & \prod\limits_v
H^1 (K_v, Z_2)
}
\]}\pageoriginale
where $S$ is the set of places $v$ at which the quaternion division
algebra $D$ does not split. From this diagram it is not possible to
prove the injectivity of $H^1(K,U) \to \prod\limits_{v}
H^1(K_v,U)$. In fact Hasse principle for skew-hermitian form is
false. We shall prove this statement now. 

Let $V$ be the $n$-dimensional vector space over $D$ on which $h$ is
defined. We want to find the number of $(V', h')$, where $V'$ is a
$n$-dimensio\-nal vector space over $D$ and $h'$ a skew hermitian from
over $V'$ such that $(V,h)\cong (V',h')$ locally everywhere but not
globally. We need a  

\begin{lemma*}
Let $(V,h)\cong (V',h')$ locally everywhere; let $W$ be any hyperplane
in $V$, i.e. a subspace of dimension $n-1$; assume $W$ to be
non-degenerate. Then $V'$ contains a subspace $W'$ isometric to $W$. 
\end{lemma*}

\begin{proof}
We shall apply induction on $n$; for $n=1$ the result is trivial. So
let $n>2$; by induction assume the result for all spaces of dimension
$\le n-1$. Let $a \in W$ be a vector such that $h(a)\neq 0$; consider
the equation $h' (x)=h(a)$. This is solvable locally at all places of
$K$ since $(V,h)\cong (V',h')$ locally everywhere. By the proposition
of \S~\ref{chap5:sec5.10} we know that the equation has a global
solution; let $a 
\in V'$ be such that $h'(a')=h(a)$. Write $W= \Da \perp W_1,V=\Da
\perp V_1$ and $V'=\Da' \perp V'_1$;\pageoriginale since $\Da \cong
\Da'$ by 
construction and $V \cong V'$ locally everywhere by assumption,
applying Witt's theorem we find that $V_1 \cong V'_1$ locally
everywhere. Clearly $W_1 \subset V_1$, and is a non- degenerate
hyperplane. Hence by induction assumption $V'_1$ contains a subspace
$W'_1$ which is isometric to $W_1$. Then clearly $W' =\Da \perp W'_1$
is a subspace of $V'$ isometric to $W$. This proves the lemma. 
\end{proof}

In the notations above write $V=W \perp \bar{V}$, $V' =W' \perp
\bar{V}^1$. By construction $W \cong W'$. Hence $V \cong V'$ locally
everywhere if and only if $\bar{V}\cong \bar{V}'$ locally
everywhere. This reduces the problem of finding the number of
$(V^1,h^1)$ which are isomorphic to $(v,h)$ locally everywhere but not
globally to the case of 1-dimensional spaces. So let us assume $\dim
V=1$. Then by \S~\ref{chap3:sec3.1} Example~\ref{chap3:exam4} $SU$
is a torus with a quadratic 
splitting field. Hence by \S~\ref{chap3:sec3.2} theorem~\ref{chap3:thm6}a) 
the Hasse principle is true in any dimension. We then have a 
commutative diagram with exact rows: 
{\fontsize{9}{11}\selectfont
\[
\xymatrix{
1 \ar[r] & Z_2 \ar[r] \ar[d]^p & H^1 (K, SU)  \ar[r]^g \ar[d]^q & H^1
(K,U) \ar[r] \ar[d]^r & H^1 (K, Z_2) \ar[d] \\
1 \ar[r] & \prod\limits_{v\in S} Z_2 \ar[r] & \prod\limits_v H^1 (K_v,
SU) \ar[r] & \prod\limits_v H^1 (K_v, U) \ar[r] & \prod\limits_v H^1
(K_v, Z_v)
}
\]}

Consider $\ker(\psi)$. Since $p$ is injective any element of
$\ker(\gamma)$ comes from $H^1(K,SU)$. Hence $\ker \gamma \cong
\ker(\gamma g ) / Z_2$ since $Z_2 \subset \ker (\gamma g)$; this
implies $\ker\gamma \cong \ker(tq)/Z_2 \cong q^{-1}(u(\prod\limits_{v
  \in S} Z_2))/Z_2$.  

Let\pageoriginale $X= \Hom (G_m,SU)$. Since $SU$ is a sub torus of the 
multiplicative group of $D$, for any $v \in S$ the decomposition group
$g_{L_w}/K_v$ acts non-trivially on $X$. So we have $H^1(K_v,SU)
\cong \hat {H}^{-1}(g_{L_{w}/K_{v}},X)\cong Z_2$ and
$u(\prod\limits_{v \in S} Z_2) = \prod\limits_{v \in
  S}H^1(K_v,SU)$. By \S~\ref{chap2:sec2.2} 
we have the commutative diagram with exact bottom row 


Here $a$ and $b$ are surjective since $g_{L/K}$ is cyclic, and $\hat
{H}^{-1}(g_{L/K},X) \cong Z_2$. So $\bar{q}$ is injective and the
cardinality of $q^{-1}(\prod\limits_{v \in
  S}\hat{H}^{-1}(g_{L_{w}/K_{v}},X))$ is equal to the cardinality of
$\prod\limits_{v \in S}\hat{H}^{-1}(g_{L_{w}/K_{v}},X)$ divided by
that of its image under $b$, $i.e$. equal to $2^{s-1}$ if $S$ contains
$s$ places. Hence $\ker(\gamma)$ has $2^{s-2}$ elements, $i.e$. there
are exactly $2^{s-2}$ classes of skew hermitian quaternionic forms
which are locally isomorphic but not globally. If $s>2$ then there are
skew hermitian quaternionic forms which are locally everywhere
isomorphic but not globally. 
\newpage

\begin{landscape}
\[
\xymatrix{
& & H^1 (K, SU) \ar[r]  & \oplus H^1 (K_v, SU) & \\
& & H^1 (g_{L/K}, X \otimes L^\ast) \ar[u] &  \oplus H^1 (g_{L_w}/
  K_v, X \otimes L^\ast_w) \ar[u]\\
\oplus \hat{H}^{-2} (g_{L_w}/ K_v, X) \ar[r]^a & \hat{H}^{-2}
(g_{L/K},X) \ar[r] & \hat{H}^{-1} (g_{L/K}, X \otimes W)
\ar[r]^{\bar{q}} \ar[u] & \oplus_v \hat{H}^{-1} (g_{L_w}/ K_v, X)
\ar[r]^b\ar[u] & \hat{H}^{-1} (g_{L/K}, X) 
}
\]
\end{landscape}
