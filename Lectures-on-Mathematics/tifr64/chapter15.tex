\chapter{Equivalent For of It\^o Process}\label{chap15}

LET\pageoriginale $(\Omega,\mathscr{F},P)$ BE A probability space with
$(\mathscr{F}_{t})_{t\geq 0}$ and increasing family of sub
$\sigma$-algebras of $\mathscr{F}$ such that
$\sigma({\displaystyle{\mathop{U\ \mathscr{F}_{t}}_{t\geq
      0}}})=\mathscr{F}$. Let

\begin{enumerate}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{(\theenumi)}
\item $a:[0,\infty)\times \Omega\to S^{+}_{d}$ be a progressively
  measurable, bounded function taking values in $S^{+}_{d}$, the class
  of all $d\times d$ positive semidefinite matrices with real entries;

\item $b:[0,\infty)\times\Omega\to \mathbb{R}^{d}$ be a bounded,
  progressively measurable function;

\item $X:[0,\infty)\times \Omega\to \mathbb{R}^{d}$ be progressively
  measurable, right continuous and continuous a.s. $\forall (s,w)\in
  [0,\infty)\times \Omega$.
\end{enumerate}

For $(s,w)\in [0,\infty)\times \Omega$ define the operator
$$
L_{s,w}=\frac{1}{2}\sum\limits^{d}_{i,j=1}a_{ij}(s,w)\frac{\p^{2}}{\p
  x_{i}\p x_{j}}+\sum\limits^{d}_{j=1}b_{j}(s,w)\frac{\p}{\p x_{j}}.
$$

For $f$, $u$, $h$ belonging to $C^{\infty}_{0}(\mathbb{R}^{d})$,
$C^{\infty}_{0}([0,\infty)\times \mathbb{R}^{d})$ and
  $C^{1,2}_{b}([0,\infty)\times \mathbb{R}^{d})$ respectively we
    define $Y_{f}(t,w)$, $Z_{u}(t,w)$, $P_{h}(t,w)$ as follows:
\begin{gather*}
Y_{f}(t,w)=f(X(t,w))-\int\limits^{t}_{0}(L_{s,w}(f)(X(s,w))ds,\\
Z_{u}(t,w)=u(t,X(t,w))-\int\limits^{t}_{0}\left(\frac{\p u}{\p
  s}+L_{s,w}u\right)(s,X(s,w))ds,\\
P_{h}(t,w)=\exp[h(t,X(t,w))-\int\limits^{t}_{0}\left(\frac{\p h}{\p
    s}+L_{s,w}h\right)(s,X(s,w)ds-\\
{}-\frac{1}{2}\int^{t}_{0}\langle
a(s,w)\nabla_{x}h(s,X(s,w)),\nabla_{x}h(s,X(s,w))\rangle ds].  
\end{gather*}

\begin{theorem*}
The\pageoriginale following\label{page103} conditions are equivalent.
\begin{enumerate}
\renewcommand{\theenumi}{\roman{enumi}}
\renewcommand{\labelenumi}{\rm(\theenumi)}
\item $X_{\theta}(t,w)=\exp[\langle
  \theta,X(t,w)\rangle-\int\limits^{t}_{0}\langle \theta,
  b(s,w)\rangle ds-\int\limits^{t}_{0}\langle
  \theta,a(s,w)\theta\rangle ds]$

is a martingale relative to $(\Omega,\mathscr{F}_{t},P)$, $\forall
\theta \in \mathbb{R}^{d}$.

\item $X_{\lambda}(t,w)$ is a martingale $\forall_{\lambda}$ in
  $\mathbb{R}^{d}$. In particular $X_{i\theta}(t,w)$ is a martingale
  $\forall \theta\in \mathbb{R}^{d}$.

\item $Y_{f}(t,w)$ is a martingale for every $f\in
  C^{\infty}_{0}(\mathbb{R}^{d})$

\item $Z_{u}(t,w)$ is a martingale for every $u\in
  C^{\infty}_{0}([0,\infty)\times \mathbb{R}^{d})$.

\item $P_{h}(t,w)$ is a martingale for every $h\in
  C^{1,2}_{b}[(0,\infty)\times \mathbb{R}^{d})$.

\item The result (v) is true for functions $h\in
  C^{1,2}([0,\infty)\times \mathbb{R}^{d})$ with linear growth, i.e.\@
    there exist constants $A$ and $B$ such that $|h(x)|\leq A|x|+B$.
\end{enumerate}
\end{theorem*}

The functions $\dfrac{\p h}{\p t}$, $\dfrac{\p h}{\p x_{i}}$, and
$-\dfrac{\p^{2}h}{\p x_{i}\p x_{j}}$ which occur under the integral
sign in the exponent also grow linearly.

\begin{remark*}
The above theorem enables one to replace the martingale condition in
the definition of an It\^o process by any of the six equivalent
conditions given above.
\end{remark*}

\begin{proof}
(i)\ (ii).~ $X_{\lambda}(t,\cdot)$ is $\mathscr{F}_{t}$-measurable
  because it is progressively measurable. That
  $E(|X_{\lambda}(t,w)|)<\infty$ is a consequence of (i) and the fact
  that $a$ is bounded.

The function
$\lambda\xrightarrow{\phi}\dfrac{X_{\lambda}(t,w)}{X_{\lambda}(s,w)}$
is continuous for fixed $t$, $s$, $w$, $(t>s)$. Morera's theorem shows
that $\phi$ is analytic. Let $A\in \mathscr{F}_{s}$. Then
$$
\int\limits_{A}\frac{X_{\lambda}(t,w)}{X_{\lambda}(s,w)}dP(w)
$$\pageoriginale
is analytic. By hypothesis,
$$
\int\limits_{A}\frac{X_{\lambda}(t,w)}{X_{\lambda}(s,w)}dP(w)=1,\ \forall
\lambda \in \mathbb{R}^{d}.
$$

Thus
$\int\limits_{A}\dfrac{X_{\lambda}(t,w)}{X_{\lambda}(s,w)}dP(w)=1$,
$\forall$ complex $\lambda$. Therefore
$$
E(X_{\lambda}(t,w)|\mathscr{F}_{s})=X_{\lambda}(s,w),
$$
proving
(ii). (ii) $\Rightarrow$ (iii). Let
$$
A(t,w)=\exp\left[-i\int\limits^{t}_{0}\langle \theta, b(s,w)\rangle
  ds+\frac{1}{2}\int\limits^{t}_{0}\langle \theta, a(s,w)\theta\rangle
  ds\right],\theta\in \mathbb{R}^{d}.
$$

By definition, $A$ is progressively measurable and continuous. Also
$|\dfrac{dA}{dt}(t,w)|$ is bounded on every compact set in
$\mathbb{R}$ and the bound is independent of $w$. Therefore $A(t,w)$
is of bounded variation on every interval $[0,T]$ with the variation
$||A||_{[0,T]}$ bounded uniformly in $w$. Let
$M(t,w)=X_{i\theta}(t,w)$. Therefore
$$
\sup\limits_{0\leq t\leq T}|M(t,w)|\leq e^{1/2\ T}\sup\limits_{0\leq
  t\leq T}|\langle\theta,a\theta\rangle|.
$$

By (ii) $M(t,\cdot)$ is a martingale and since
\begin{align*}
& E\left(\sup\limits_{0\leq t\leq
  T}|M(t,w)|~||A||_{[0,T]}(w)\right)<\infty, \forall T,\\
& M(t,\cdot)A(t,\cdot)-\frac{1}{2}\int\limits^{t}_{0}M(s,\cdot)dA(s,\cdot)
\end{align*}
is a martingale (for a proof see Appendix), i.e. $Y_{f}(t,w)$ is a
martingale when $f(x)=e^{i\langle \theta,x\rangle}$.

Let $f\in C^{\infty}_{0}(\mathbb{R}^{d})$. Then $f\in
\mathscr{F}(\mathbb{R}^{d})$ the Schwartz-space. Therefore by the
Fourier inversion theorem
$$
f(x)=\int\limits_{\mathbb{R}^{d}}\hat{f}(\theta)e^{i\langle
  \theta,x\rangle}d\theta. 
$$\pageoriginale

On simplification we get
$$
Y_{f}(t,w)=\int\limits_{\mathbb{R}^{d}}\hat{f}(\theta)Y_{\theta}(t,w)d\theta
$$
where $Y_{\theta}\equiv Y_{e}i\langle \theta,x\rangle$. Clearly
$Y_{f}(t,\cdot)$ is progressively measurable and hence
$\mathscr{F}_{t}$-measurable. 

Using the fact that
$$
E(|Y_{\theta}(t,w)|)\leq
1+t~d|\theta|~||b||_{\infty}+\frac{d^{2}}{2}|\theta|^{2}~||a||_{\infty},
$$
the fact that $\mathscr{F}(\mathbb{R}^{d})\subset
L^{1}(\mathbb{R}^{d})$ and that $\mathscr{F}(\mathbb{R}^{d})$ is
closed under multiplication by polynomials, we get
$E(|Y_{f}(t,w)|)<\infty$. An application of Fubini's theorem gives
$E(Y_{f}(t,w)|\mathscr{F}_{s})=Y_{f}(s,w)$, if $t>s$. This proves
(iii).

(iii) $\Rightarrow$ (iv). Let $u\in C_{0}([0,\infty)\times \mathbb{R}^{d})$.

\smallskip
Clearly $Z_{u}(t,\cdot)$ is progressively measurable. Since
$Z_{u}(t,w)$ is boun\-ded for every $w$, $E(|Z_{u}(t,w)|)<\infty$. Let
$t>s$. Then
{\fontsize{10pt}{12pt}\selectfont
\begin{align*}
& E(Z_{u}(t,w)-Z_{u}(s,w)|\mathscr{F}_{s})=\\
& =E(u(t,X(t,w)-u(s,X(s,w)|\mathscr{F}_{s})-E(\int\limits^{t}_{s}(\frac{\p
  u}{\p
  \sigma}+L_{\sigma,w}u)(\sigma,X(\sigma,w)d\sigma|\mathscr{F}_{s})\\
&\q =E(u(t,X(t,w)-u(t,X(s,w))|\mathscr{F}_{s})+E(u(t,X(s,w)-u(s,X(s,w))|\mathscr{F}_{s})-\\
&\q -E(\int\limits^{t}_{s}(\frac{\p u}{\p
  \sigma}+L_{\sigma}u_{w})(\sigma,X(\sigma,w))d\sigma|\mathscr{F}_{s})\\
&\q =
E(\int\limits^{t}_{s}(L_{\sigma,w}u)(t,X(\sigma,w))d\sigma|\mathscr{F}_{s})+\\ 
&\q +E(\int\limits^{t}_{s}(\frac{\p u}{\p
  \sigma}(\sigma,X(s,w))d\sigma|\mathscr{F}_{s})-\\
&\q -E(\int\limits^{t}_{s}(\frac{\p u}{\p
  \sigma}+L\sigma^{u},w)(\sigma,X(\sigma,w))d\sigma|\mathscr{F}_{s}),\q\text{by
  (iii)}\\
&\q =
E(\int\limits^{t}_{s}[L_{\sigma,w}u(t,X(\sigma,w))-L_{\sigma,w}u(\sigma,X(\sigma,w))]d\sigma|\mathscr{F}_{s})\\
&\q +E(\int\limits^{t}_{s}[\frac{\p u}{\p
    \sigma}(\sigma,X(s,w))-\frac{\p u}{\p
    \sigma}(\sigma,X(\sigma,w))]d\sigma|\mathscr{F}_{s})\\
&\q
=E(\int\limits^{t}_{s}(L_{\sigma,w}u(t,X(\sigma,w))-L_{\sigma,w}u(\sigma,X(\sigma,w))]d\sigma|\mathscr{F}_{s})\\
&\q
-E(\int\limits^{t}_{s}d\sigma\int\limits^{\sigma}_{s}L_{\rho,w}\frac{\p
  u}{\p \sigma}(\sigma, X(\rho,w))d\rho|\mathscr{F}_{s})
\end{align*}}\relax\pageoriginale

The last step follows from (iii) (the fact that $\sigma>s$ gives a
minus sign).
\begin{align*}
&=E(\int\limits^{t}_{0}d\sigma\int\limits^{t}_{\sigma}\frac{\p}{\p\rho}L_{\sigma,w}u(\rho,X(\sigma,w))d\rho|\mathscr{F}_{s})\\
&-E(\int\limits^{t}_{s}d\sigma\int\limits^{\sigma}_{s}L_{\rho,w}\frac{\p
    u}{\p \sigma}(\sigma,X(\rho,w))d\rho|\mathscr{F}_{s})\\
&=0
\end{align*}
(by Fubini). Therefore $Z_{u}(t,w)$ is a martingale.

Before proving (iv) $\Rightarrow$ (v) we show that (iv) is true if
$u\in C^{1,2}_{b}([0,\infty)\break \times \mathbb{R}^{d}$. Let $u\in
  C^{1,2}_{b}$. 

(*) Assume that there exists a sequence $(u_{n})\in
  C^{\infty}_{0}[[0,\infty)\times \mathbb{R}^{d}]$ such that
$$
u_{n}\to u,\frac{\p u_{n}}{\p t}\to \frac{\p u}{\p t},\frac{\p
  u_{n}}{\p x_{i}}\to \frac{\p u}{\p x_{i}},\frac{\p u_{n}}{\p x_{i}\p
  x_{j}}\to \frac{\p^{2}u}{\p x_{i}\p x_{j}}
$$\pageoriginale
uniformly on compact sets.

Then $Z_{u_{n}}\to Z_{u}$ pointwise and
$\sup\limits_{n}(|Z_{u_{n}}(t,w)|)<\infty$.

Therefore $Z_{u}$ is a martingale. Hence it is enough to justify (*).

For every $u\in C^{1,2}_{b}([0,\infty)\times \mathbb{R}^{d})$ we
  construct a $u\in C^{1,2}_{b}((-\infty,\infty)\times
  \mathbb{R}^{d})\equiv C^{1,2}_{b}(\mathbb{R}\times \mathbb{R}^{d})$
  as follows. Put
$$
u(t,x)=
\begin{cases}
u(t,x),\text{~ if~ }t\geq 0,\\
C_{1}u(-t,x)+C_{2}u(-\frac{t}{2},x),\text{~ if~ }t<0;
\end{cases}
$$
matching $\dfrac{\p \tilde{u}}{\p t}$, $\dfrac{\p u}{\p t}$ at $t=0$ and
$\hat{u}(t,x)$ and $u(t,x)$ at $t=0$ and $\tilde{u}(t,x)$ and $u(t,x)$
at $t=0$ yields the desired constants $C_{1}$ and $C_{2}$. In fact
$C_{1}=-3$, $C_{2}=4$. (*) will be proved if we obtain an
approximating sequence for $\tilde{u}$. Let $S:\mathbb{R}$
be any $C$ function such that if $|x|\leq 1$,
$$
S(x)=
\begin{cases}
1, &\text{if~ } |x|\leq 1,\\
0, &\text{if~ } |x|\geq 2.
\end{cases}
$$

Let $S_{n}(x)=S\left(\dfrac{|x|^{2}}{n}\right)$ where
$|x|^{2}=x^{2}_{1}+\cdots+x^{2}_{d+1}$. Pur
$u_{n}=S_{n}\tilde{u}$. This satisfies (*).

(iv) $\Rightarrow$ (v). Let
$$
h\in C^{1,2}_{b}([0,\infty)\times \mathbb{R}^{d}).
$$

Put $u=\exp(h(t,x))$ in (iv) to conclude that
$$
M(t,w)=e^{h(t,X(t,w))}-\int\limits^{t}_{0}e^{h(s,X(s,w))}\left[\frac{\p
    h}{\p s}+L_{s,w}h+\frac{1}{2}\langle
  \nabla_{x}h,a\nabla_{x}h\rangle ds\right]
$$
is a martingale.

Put\pageoriginale
{\fontsize{10pt}{12pt}\selectfont
$$
A(t,w)=\exp -\left[\int\limits^{t}_{0}\frac{\p h}{\p
    s}(s,w)+L_{s,w}-(s,w)+\frac{1}{2}\langle
  a(s,w)\nabla_{x}h,\nabla_{x}h\rangle ds\right].
$$}\relax
$A((t,w))$ is progressively measurable, continuous everywhere and
$$
||A||_{[0,T]}(w)\leq C_{1}\in C_{2}T
$$ 
where $C_{1}$ and $C_{2}$ are
constants. This follows from the fact that $|\dfrac{dA}{dt}|$ is
uniformly bounded in $w$. Also $\sup\limits_{0\leq t\leq T}|M(t,w)|$
is uniformly bounded in $w$. Therefore
$$
E(\sup\limits_{0\leq t\leq T}|M(t,w)|~||A||_{[0,T]}(w))<\infty.
$$

Hence $M(t,\cdot)A-\int\limits^{t}_{0}M(s,\cdot)dA(s,\cdot)$ is a
martingale. Now
$$
\dfrac{dA(s,w)}{A(s,w)}=-\left[\frac{\p h}{\p
    s}(s,w)+L_{s,w}h(s,w)+\frac{1}{2}\langle
  a\nabla_{x}h,\nabla_{x}h\rangle\right] 
$$

Therefore
\begin{gather*}
M(t,w)=e^{h(t,X(t,w))}+\int\limits^{t}_{0}e^{h(s,X(s,w))}\frac{dA(s,w)}{A(s,w)}.\\
M(t,w)A(t,w)=P_{h}(t,w)+A(t,w)\int\limits^{t}_{0}e^{h(s,X(s,w))}\frac{dA(s,w)}{A(s,w)}\\ 
\int\limits^{t}_{0}M(s,\cdot)dA(s,\cdot)=\int\limits^{t}_{0}e^{h(s,X(s,w))}dA(s,w)\\
+\int\limits^{t}_{0}dA(s,w)\int\limits^{s}_{0}e^{h(\sigma,X(\sigma,w))}\frac{dA(\sigma,w)}{A(\sigma,w)}
\end{gather*}

Use Fubini's theorem to evaluate the second integral on the right
above and conclude that $P_{h}(t,w)$ is a martingale.

(vi) $\Rightarrow$ (i) is clear if we take $h(t,x)=\langle
\theta,x\rangle$. It only remains to prove that (v) $\Rightarrow$
(vi).

(v) $\Rightarrow$ (vi). The technique used to prove this is an
important one and we shall have occasion to use it again.

\setcounter{step}{0}
\begin{step}{0}
Let\pageoriginale
$h(t,x)=\theta_{1}x_{1}+\theta_{2}x_{2}+\cdots\theta_{d}x_{d}=\langle
\theta,x\rangle$ for every $(t,x)\in [0,\infty)\times \mathbb{R}^{d}$,
  $\theta$ is some fixed element of $\mathbb{R}^{d}$. Let
$$
Z(t)=\exp \left[\langle \theta, X_{t}\rangle
  -\int\limits^{t}_{0}\langle \theta, b\rangle
  ds-\frac{1}{2}\int\limits^{t}_{0}\langle \theta,a\theta\rangle ds\right]
$$

We claim that $Z(t,\cdot)$ is a supermartingale.
\end{step}

Let $f:\mathbb{R}\to \mathbb{R}$ be a $C^{\infty}$ function with
compact support such that $f(x)=x$ in $|x|\leq 1/2$ and $|f(x)|\leq
1$, $\forall x$. Put $f_{n}(x)=nf(x/n)$. Therefore $|f_{n}(x)|\leq
C|x|$ for some $C$ independent of $n$ and $x$ and $f_{n}(x)$ converges
to $x$.

Let $h_{n}(x)=\sum\limits^{d}_{i=1}\theta_{i}f_{n}(x_{i})$. Then
$h_{n}(x)$ converges to $\langle \theta,x\rangle$ and $|h_{n}(x)|\leq
C'|x|$ where $C$ is also independent of $n$ and $x$. By (v),
$$
Z_{n}(t)=\exp\left[h_{n}(t,X_{t})-\int\limits^{t}_{0}\left(\frac{\p
    h_{n}}{\p
    s}+L_{s,w}h\right)ds-\frac{1}{2}\int\limits^{t}_{0}\langle
  a\nabla_{x}h_{n},\nabla_{x}h_{n}\rangle ds\right]
$$
is a martingale. As $h_{n}(x)$ converges to $\langle \theta,x\rangle$,
$Z_{n}(t,\cdot)$ converges to $Z(t,\cdot)$ pointwise. Consequently
$$
E(Z(t))=E(\varliminf Z_{n}(t))\leq \varliminf E(Z_{n}(t))=1
$$
and $Z(t)$ is a supermartingale.

\begin{step}%2
$E(\exp B\sup\limits_{0\leq s\leq t}|X(s,w)|)<\infty$ for each $t$ and
  $B$. For, let $Y(w)=\sup\limits_{0\leq s\leq t}|X(s,w)|$,
  $Y_{i}(w)=\sup\limits_{0\leq s\leq t}|X_{i}(s,w)|$ where
  $X=(X_{1},\ldots,X_{d})$. Clearly $Y\leq
  Y_{1}+\cdots+Y_{d}$. Therefore
$$
E(e^{BY})\leq E(e^{BY}1 e^{BY}2\ldots e^{BY}d).
$$
\end{step}

The\pageoriginale right hand side above is finite provided
$E(e^{BY}i)<\infty$ for each $i$ as can be seen by the generalised
Holder's inequality. Thus to prove the assertion it is enough to show
$E(e^{BY}i)<\infty$ for each $i=1,2,\ldots d$ with $aB'$ different
from $B$; more specifically for $B'$ bounded.

Put $\theta_{2}=0=\theta_{3}=\ldots=\theta_{d}$ in Step 1 to get
$$
u(t)=\exp[\theta_{1}X_{1}(t)-\int\limits^{t}_{0}\theta_{1}b_{1}(s,\cdot)ds-\frac{1}{2}\theta^{2}_{1}\int\limits^{t}_{0}a_{11}(s,\cdot)ds]
$$
is a supermartingale. Therefore
\begin{equation*}
P\left(\sup\limits_{0\leq s\leq t}u(s,\cdot)\geq \lambda\right)\leq
\frac{1}{\lambda}E(u(t))=\frac{1}{\lambda},\ \forall \lambda >0.
\end{equation*}
(Refer section on Martingales). Let $c$ be a common bound for both
$b_{1}$ and $a_{11}$ and let $\theta_{1}>0$. Then $(*)$ reads
$$
P\left(\sup\limits_{0\leq s\leq t}\exp\theta_{1}X_{1}(s)\geq \lambda
\exp(\theta_{1}ct+\frac{1}{2}\theta^{2}_{1}ct)\right)\leq
\frac{1}{\lambda}. 
$$

Replacing $\lambda$ by
$$
e^{\lambda\theta_{1}}e^{-ct\theta_{1}-1/2 ct\theta^{2}_{1}}
$$
we get
$$
P\left(\sup\limits_{0\leq s\leq t}\exp\theta_{1}X_{1}(s)\geq
\exp\lambda \theta_{1}\right)\leq
e^{-\lambda\theta_{1}+\theta_{1}ct+1/2\theta^{2}_{1}ct},
$$
i.e.
$$
P\left(\sup\limits_{0\leq s\leq t}X_{1}(s)\geq \lambda\right)\leq
e^{-\lambda\theta_{1}+\theta_{1}ct+1/2\theta_{1}^{2}ct},\ \forall \theta_{1}>0.
$$

Similarly
$$
P\left(\sup\limits_{0\leq s\leq t}-X_{1}(s)\geq \lambda\right)\leq
e^{-\lambda\theta_{1}+\theta_{1}ct+1/2\theta^{2}_{1}tc},\ \forall \theta_{1}>0.
$$

As
$$
\{Y_{1}(w)\geq \lambda\}\left\{\sup\limits_{0\leq s\leq t}X_{1}(s)\geq
\lambda\right\}\cup\left\{\sup\limits_{0\leq s\leq t}-X_{1}(s)\geq
\lambda\right\}, 
$$\pageoriginale
we get
$$
P\{Y_{1}\geq \lambda\}\leq
2e^{-\lambda\theta_{1}+\theta_{1}ct+1/2\theta^{2}_{1}ct},\ \forall \theta_{1}>0.
$$

Now we get
\begin{align*}
E(\exp BY_{1}) &=
\frac{1}{B}\int\limits^{\infty}_{0}\exp(Bx)P(Y_{1}\geq
x)dx\q(\text{since~ }Y_{1}\geq 0)\\
&\leq
\frac{2}{B}\int\limits^{\infty}_{0}\exp(Bx-x\theta_{1}+\theta_{1}ct+\frac{1}{2}\theta^{2}_{1}ct)dx\\
&<\infty,\q\text{if}\q B<\theta_{1}
\end{align*}

This completes the proof of step 2.

\begin{step}%3
$Z(t,w)$ is a martingale. For
\begin{gather*}
|Z_{n}(t,w)|=Z_{n}(t,w)\\
=\exp\left[h_{n}(X_{t})-\int\limits^{t}_{0}\left(\frac{\p h_{n}}{\p
    s}+L_{s,w}h_{n}\right)dx-\frac{1}{2}\int\limits^{t}_{0}\langle 
a\nabla_{x}h_{n},\ \nabla_{x}h_{n}\rangle ds\right]\\
\leq \exp\left[h_{n}(X_{t})-\int\limits^{t}_{0}L_{s,w}h_{n}\right]
\end{gather*}
(since $a$ is positive semidefinite and $\p h_{n}/\p s=0$).
\end{step}

Therefore $|Z_{n}(t,w)|\leq A\exp(B\sup\limits_{0\ s\ t}|X(s,w)|)$
(use the fact that\break $|h_{n}(s)|\leq C|x|$ and $\dfrac{\p h_{n}}{\p
  x_{i}}$, $\dfrac{\p^{2}h_{n}}{\p x_{i}\p x_{j}}$ are bounded by the
same constant). The result now follows from the dominated convergence
theorem and Step 2. 
\end{proof}

\begin{remark*}
In Steps 1, 2 and 3 we have proved that (v) $\Rightarrow$ (i). The
idea of the proof was to express $Z(t,\cdot)$ as a limit of a sequence
of martingales\pageoriginale proving first that $Z(t,\cdot)$ is a
supermartingale. Using the supermartingale inequality it was then
shown that $(Z_{n})$ is a uniformly integrable family proving thereby
that $Z(t,\cdot)$ is a martingale.
\end{remark*}

\begin{step}%4
Let $h(t,x)\in C^{1,2}([0,\infty)\times \mathbb{R}^{d})$ such that
  $h(t,x)$, $\dfrac{\p h}{\p s}(t,x)$, $\dfrac{\p h}{\p x_{i}}(t,x)$,
  $\dfrac{\p^{2}h}{\p x_{i}\p x_{j}}(t,x)$ are all dominated by
  $\alpha|x|+\beta$ for some suitable scalars $\alpha$ and
  $\beta$. Let $\phi_{n}$ be a sequence of real valued $C^{\infty}$
  functions defined on $\mathbb{R}^{d}$ such that
$$
\phi_{n}=
\begin{cases}
1\text{~ on~ } |x|\leq n\\
0\text{~ on~ }|x|\geq 2n
\end{cases}
$$
and suppose there exists a common bound $C$ for
$$
\phi_{n},\frac{\p \phi_{n}}{\p x_{i}},\frac{\p^{2}\phi_{n}}{\p x_{i}\p
  x_{j}}(\forall n).
$$

Let $h_{n}(t,x)=h(t,x)\phi_{n}(x)$. By (v) $Z_{h_{n}}(t,w)$ is a
martingale. The conditions on the function $h$ and $\phi_{n}$'s show
that
$$
|Z_{h_{n}}(t,w)|\leq A\exp \left(B\sup\limits_{0\leq s\leq t}|X(s,w)|\right)
$$
where $A$ and $B$ are constants. By Step 2, $(Z_{h_{n}})$ are
uniformly integrable. Also $Z_{h_{n}}(t,\cdot)$ converges pointwise to
$P_{h}(t,\cdot)$ (since $h_{n}\to h$ pointwise). By the dominated
convergence theorem $P_{h}(t,\cdot)$ is a martingale, proving (vi).
\end{step}





