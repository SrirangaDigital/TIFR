\setcounter{chapter}{-1}
\chapter{Preliminaries} % chapter 0

\section{Measurable space}\pageoriginale\label{chap0-sec1} 
% sec 1.

Let $\Omega$ be a set and let $S(\Omega)$ denote the set of all
subsets of $\Omega$. $\mathbb{A} \subset S(\Omega)$ is called an
\textit{algebra} if it is closed under finite unions and
complementations; an algebra
$\mathbb{B}$ closed under countable unions is called a Borel
algebra. For $\mathbb{C} \subset S(\Omega)$ we denote by
$\mathbb{A}(\mathbb{C})$ and $\mathbb{B} (\mathbb{C})$, the algebra
and Borel algebra, respectively, generated by $\mathbb{C}$. $M \subset
S(\Omega)$ is called a \textit{monotone class} if $A_n \in M$, $n=
1$, $2,\ldots$, and $\{ A_n \}$ monotone implies that $\lim \limits_n
A_n \in M$. We have the following lemma. 

\medskip

\noindent \textbf{Monotone Lemma.}
 If $M$ is a monotone class containing an algebra $\mathbb{A}$ then $M
 \supset \mathbb{B} (\mathbb{A})$.  

 
The proof of this lemma can be found in $P$. Halmos: Measure theory. 

For any given set $\Omega$ we denote by $\mathbb{B} (\Omega)$ a Borel
algebra of subsets of $\Omega$. 
\begin{defi*}
  A pair $(\Omega$, $ \mathbb{B} (\Omega))$ is called a 
\textit{measurable space}. $A \subset \Omega$ is called measurable if $A
  \in \mathbb{B} (\Omega)$. 
\end{defi*}

Let $(\Omega_1$, $ \mathbb{B}_1 (\Omega_1))$ and $(\Omega_2$, $
\mathbb{B}_2 (\Omega_2)$ be measurable spaces. A function $f$:
$\Omega_1 \to \Omega_2$ is called \textit{measurable} with respect
to $\mathbb{B}_1 (\Omega_1)$ if for every $A \in
\mathbb{B}_2(\Omega_2)$, $ f^{-1}(A) \in \mathbb{B}_1 (\Omega_1)$. 

Now suppose that $\Omega_1$ is a set, $(\Omega_2$, $ \mathbb{B}
(\Omega_2))$ a measurable space and $f$ a function on $\Omega_1$ into
$\Omega_2$. Let $\mathbb{B}(f)$ be the class\pageoriginale 
of all sets of the form
$f^{-1}(A)$ for $A \in \mathbb{B} (\Omega_2)$. Then $\mathbb{B}(f)$ is
a Borel algebra, and is the least Borel algebra with respect to which
$f$ is measurable.  

Let $(\Omega_i$, $ \mathbb{B}_i (\Omega_i) $, $ i \in I$, be
measurable spaces. Let $\Omega = \prod_i \Omega_i$ denote the Cartesian
product of $\Omega_i$ and let $\pi_i : \Omega$ --- $\Omega_i$ be defined
by $\pi_i(w) = w_i $. Let $\mathbb{B} (\Omega)$ be the least Borel
algebra with respect to which all the $\pi_i$'s are measurable. The
pair $(\Omega$, $ \mathbb{B} (\Omega))$ is called the \textit{product
  measurable space}. $\mathbb{B}(\Omega)$ is the least Borel algebra
containing the class of all sets of the form 
$$
\{ f: f(i) \in E_i \},
$$
where $E_i \in \mathbb{B}_i (\Omega_i)$. A function $F$ into $\Omega$
is measurable if and only if $\pi_i F$ is measurable for every $i \in
I$. 

\section{Probability space}\label{chap0-sec2}  
% sec 2

Let $\Omega$ be a set, $\mathbb{A} \subset S(\Omega)$ an algebra. A
function $P$ on $\mathbb{A}$ such $p(\Omega)=1$, $ 0 \leq p(E) \leq 1$
for $E \in \mathbb{A}$, and such that $p(EUF) = p(E) + p(F)$ whenever
$E$, $ F \in \mathbb{A}$ and $E \cap F = \phi$, is called an 
\textit{elementary probability measure} on $\mathbb{A}$. Let $(\Omega$, $
\mathbb{B} (\Omega))$ be a measurable space and $p$ an elementary
probability measure on $\mathbb{B}$. If $A_n \in \mathbb{B}$, $ A_n$
disjoint, imply $p(\bigcup \limits_{n} A_n) = \sum p(A_n)$ we say that
$p$ is a \textit{probability measure} on $\mathbb{B} (\Omega)$. The
proof of the following important theorem can be found in $P$. Halmos:
Measure theory. 

\begin{theorem*}[(Kolmogoroff)]  
 If\pageoriginale $p$ is an elementary probability measure on
 $\mathbb{A}$ then $p$ 
 can be extended to a probability measure $P$ on
 $\mathbb{B}(\mathbb{A})$ if and only if the following continuity
 condition is satisfied: 
 $$
 A_n \in \mathbb{A}, A_n \supset A_{n+1}, \bigcap_n A_n = \phi \text{
   imply } \lim_n p(A_n) =0. 
 $$

 Further under the above condition the extension is unique.
\end{theorem*}

\begin{defi*}
A triple $(\Omega$, $ \mathbb{B}$, $P)$, where $P$ is a probability
measure on $\mathbb{B}$, is called a {\em probability space.} 
\end{defi*} 
 
A real-valued measurable function on a probability space is called a
\textit{random variable}. If a vandom variable $x$ is integrable we
denote the integral by $E(x)$ and call it the \textit{expectation}
of $X$. 
 
Let $(\Omega_2$, $ \mathbb{B}_2)$ be a measurable space, $(\Omega_1$,
$ \mathbb{B}_1 $, $ P_1)$a probability space and $f: \Omega_1 \to
\Omega_2$ a measurable function. Define $P_2(E) = P_1(f^{-1}(E))$ for
every $E \in \mathbb{B}_2$. Then $(\Omega_2$, $ \mathbb{B}_2$, $P_2)$
is a probability space and for every integrable function $g$ on
$\Omega_2$,  $E(g 0 f)= \int g 0 f d P_1 = \int gdP_2 = E(g)$. We say
that $f$ \textit{induces} a measure on $\mathbb{B}_2$. In case $x$
is a random variable, the measure induced on the line is called the
\textit{probability distribution} of $x$. 
 
We shall prove the following formulae which we use later 
\textit{Inclusion-exclusion formula}. Let $(\Omega $, $ \mathbb{B}$, $ P)$
be a probability space and $A_i \in \mathbb{B}$, $ i= 1$, $2,\ldots,
n$. Then  
$$
P\left(\bigcup^n_{i=1} A_i\right) = \sum_i P(A_i) - \sum_{i < j} P(A_i \cap A_j)
+ \sum_{i < j < k} P(A_i \cap A_j \cap A_k)- \ldots 
$$

To\pageoriginale prove this, let $\chi_B$ denote the characteristic
function of $B$. 
Then
\begin{align*}
  P(\cup A_i) & = E(\chi_{\cup A_i}) = E(1- \chi_{\cap A_i}c) =
  1-E \left(\prod \chi_{A_i^c}\right)\\ 
  & = 1-E(( 1-\chi_{A_1}) (1-\chi_{A_2}) \ldots (1- \chi_{A_n}))\\
  & = 1-E \bigg[1- \sum_i \chi_{A_i} + \sum_{i < j} \chi_{A_i}
    \chi_{A_j}- \sum_{i < j<k} \chi_{A_i} \chi_{A_j} \chi_{A_k}+
    \ldots \bigg]\\ 
  & = \sum_i E(\chi_{A_i}) - \sum_{i < j} E(\chi_{A_i \cap A_j}) +
  \sum_{i < j < k} E(\chi_{A_i \cap A_j \cap A_k})- \ldots\\ 
  & = \sum_i P(A_i) - \sum_{i < j} P(A_i \cap A_j) + \ldots
\end{align*} 

The following \textit{dual inclusion-exclusion formula} is due to
Hunt. We have  
\begin{align*}
  P(\cap A_i) & = 1- P(\cup A^c_i) = 1- \bigg\{ \sum_i P(A^c_i) -
  \sum_{i < j} P(A^C_i \cap A^c_j) + \ldots \bigg\}\\ 
  & = 1- \bigg\{ \sum_i (1-P(A_i)) - \sum_{i < j}(1-P(A_i \cup A_j)) +
  \ldots \bigg\}\\ 
  & = 1- \bigg\{ n - \sum_i P(A_i) - \binom{n}{2} + \sum_{i < j} P(A_i
  A_j) + \ldots \bigg\}\\ 
  & = \left[ 1- \binom{n}{1} + \binom{n}{2} \ldots \right] + \sum_i
  P(A_i) - \sum_{i < j} P(A_i \cup A_j) + \ldots \\ 
  &= \sum_i P(A_i) - \sum_{i < j} P(A_i \cup A_j)+ \ldots
\end{align*}

A collection $(\chi_t$, $ t \in T)$ of random variables $x_t$, $ T$
being some\pageoriginale indexing set, is called a \textit{stochastic}
or  \textit{random process}. We generally assume that the indexing set $T$ is an
interval of real numbers. 

Let $\{ x_t$, $ t \in T\}$ be a stochastic process. For a fixed 
$\omega x_t (\omega)$ is a function on $T$, called a
\textit{sample function} of the process. 

Lastly, an \textit{$n$-dimensional random variable } is a measurable
function into $R^n$; an \textit{$n$-dimensional random process} is a
collection of n-dimensional random variables. 

\section{Independence}\label{chap0-sec3}  
% sec 3.

Let ($\Omega$, $\mathbb{B}$, $P$) be a probability space and
$\mathbb{B}_i$, $ i = 1$, $2, \ldots,n$, $n$ Borel subalgebras of
$\mathbb{B}$. They are said to be \textit{independent} if for any
$E_i \in \mathbb{B}_i$, $i \leq i \leq n$, $P(E_1 \cap, \ldots \cap
E_n) = P(E_1) \ldots P(E_n)$. A collection
$(\mathbb{B}_{\alpha})_{\alpha \in I}$ of Borel subalgebras of
$\mathbb{B}$ is said to be independent if every finite subcollection
is independent. 

Let $X_1, \ldots, x_n$ be $n$ random variables on $(\Omega$, $
\mathbb{B}$, $ P)$ and $\mathbb{B}(x_i)$, $ 1 \leq i \leq n$, the
least Borel subalgebra of $\mathbb{ B}$ with respect to which $x_i$ is
measurable. $x_1, \ldots x_n$ are said to be independent if
$\mathbb{B}_1, \ldots, \mathbb{B}_n$ are independent. 

Finally, suppose that $\{ x_{\alpha}(t$, $w) \}_{\alpha \in I}$ is a
system of random processes on $\Omega$ and $\mathbb{B}_{\alpha}$ the
least Borel subalgebra of $\mathbb{B}$ with respect to which
$x_{\alpha}(t$, $w)$ is measurable for all $t$. The processes are said
to be \textit{stochastically independent} if the
$\mathbb{B}_{\alpha}$ are independent. 

We give some important facts about independence. If $x$ and $y$ are
random variables on $\Omega$ the following statements are equivalent: 
\begin{enumerate}[(1)]
\item $E(e^{i \alpha x + i \beta y}) = E(e^{i \alpha x}) E(e^{i \beta
  y})$,\pageoriginale $\alpha$, and $\beta$ real; 

\item The measure induced by $z(w) = (x(w) $, $ y(w))$on the plane is
  the product of the measures induced by $x$ and $y$ on the line; 
\item $x$ and $y$ are independent.
\end{enumerate}

\section{Conditional expectation}\label{chap0-sec4}  
% sec 4.

Let $(\Omega$, $ \mathbb{B}$, $ P)$ be a probability space and
$\mathbb{C}$ a Borel subalgebra of $\mathbb{B}$. Let $x(w)$ be a
real-valued integrable function. We follow Doob in the definition of
the conditional expectation of $x$. 

Consider the set function $\mu$ on $\mathbb{C}$ defined by $\mu(C)=
E(x:C)$. Then $\mu (C)$ is a bounded signed measure and $\mu(C)=0$ 
if $P(C) =0$. Therefore by the Radon-nikodym
theorem there exists a unique (upto $P$-measure $0$) function $\varphi
(w)$ measurable with respect to $\mathbb{C}$ such that  
$$
\mu (C) = E (\varphi : C).
$$

\begin{defi*}
$\varphi (w)$ is called the {\em conditional expectation } of $x$
  with respect to $\mathbb{C}$ and is denoted by $E(x/ \mathbb{C})$. 
\end{defi*}  

The conditional expectation is not a random variable but a set of
random variables which are equal to each other except for a set of
P-measure zero. Each of these random variables is called a
\textit{version} of $E(x/ \mathbb{C})$. 

The following conclusions (which are valid with probability 1) result
from the definition. 
\begin{enumerate}
\item $E(1 / \mathbb{C}) = 1$.\pageoriginale
\item $E(x / \mathbb{C}) \geq 0 $ if $x \geq 0$.
\item $E(\alpha x + \beta y / \mathbb{C}) = \alpha E(x/ \mathbb{C}) +
  \beta E (y / \mathbb{C})$. 
\item $| E(x / \mathbb{C})| \leq E( |x| / \mathbb{C})$.
\item If $x_n \to x$, $ |x_n| \leq S$ with $E(S) < \infty$,then 
  $$
  \lim_n E(x_n / \mathbb{C}) = E(x / \mathbb{C}).
  $$

\item If $\sum_n E(|x_n|) < \infty$, then $E( \sum \limits_n x_n /
  \mathbb{C})= \sum \limits_n E(x_n / \mathbb{C})$. 

\item If $x$ is $\mathbb{C}$-measurable, then $E(xy / \mathbb{C}) =
  xE(y / \mathbb{C})$. 

  In particular, if $x$ is $ \mathbb{C}$-measurable, then $E(x / \mathbb{C})=x$.
\item If $x$ and $\mathbb{C}$ are independent, then $E(x / \mathbb{C}) = E(x)$.
\item If $\mathbb{C} = \{ A: P(A) = 0 \text{ or } 1 \}$, then $E(x /
  \mathbb{C}) = E(x)$. 
\item If $ \mathbb{C}_1 \supset  \mathbb{C}_2$, then $E(x /
  \mathbb{C}_2) = E (E(x / \mathbb{C}_1) /\mathbb{C}_2)$ and, in
  particular, \break $E(E(x / \mathbb{C}))) = E(x)$. 
\end{enumerate}

\section{Wiener and Poisson processes}\label{chap0-sec5}  
% sec 5.

The following processes are very important and we shall encounter\break many
examples of these. 

We shall define a Wiener process and establish its existence.

Let $\bigg\{ x_t (w), 0 \leq t < \infty \bigg\}$ be a stochastic
process such that  
\begin{enumerate}
\renewcommand{\labelenumi}{(\theenumi)}
\item for almost all $w$ the sample function $x_t(w)$ is a continuous
  function on [$0$, $ \infty$] and vanishes at $t = 0$;  

\item $P(w: x_{t_{1}}(w) \in E_1, \ldots, x_{t_{n}}(w) - x_{t_{n-1}} (w)
  \in E_n) = P (w: x_{t_{1}}(w) \in E_{1}) \ldots P(w : x_{t_n} (w) -
  x_{t_{n-1}} (w) \in E_n$, where $t_1 < t_2 < \ldots < t_n$. This
  means that\pageoriginale $x_{t_{1}}$, $ x_{t_{2}}- x_{t_{1}}, \ldots, x_{t_{n}}
  -x_{t_{n-1}}$ are independent if $t_1 < \ldots < t_n;$  

\item $ P(w: x_t (w) - x_s (w) \in E) = [ 2 \pi (t-s)]^{\frac{1}{2}}
  \int \limits_E e^{-x^2 / 2 (t-s)}dx$. 
\end{enumerate}

Then the process is called a \textit{Wiener process}. This process is
extremely important and we shall now construct a Wiener process which we shall
use later. This incidentally will establish the existence of  Wie\-ner
process. 

Let $\Omega = C[ 0, \infty)$ be the space of all real continuous
  functions on $[0$, $ \infty)$. We introduce an elementary
    probability measure on $\Omega$ as follows. 

For any integer $n$, $ 0< t_{1} < t_2 \ldots < t_n < \infty$ and a
Borel set $B^n$ in $R^n$, let  
$$
\displaylines{\hfill 
E=  \bigg\{ w : w \in \Omega \text{ and } (w(t_1), \ldots, w(t_n)) \in B^n
  \bigg\}, \hfill \cr
  \text{and}\hfill \cr 
  p_{t_{1}\ldots t_n} (E) = \mathop{\int\cdots\int}_{B^{n}} N(t_1,  0,
  x_1) N(t_2-t_1, x_1, x_2) \ldots N(t_n - t_{n-1}, x_{n-1}, x_n)
  \hfill \cr
  \hfill dx_1 \ldots dx_n\hfill \cr
  \text{where} \hfill N(t, x,y) = \dfrac{1}{\sqrt{2 \pi t}}
  e^{-(y-x)^2 /2t }\hfill }
$$

If $0 < u_1 < \ldots < u_m < \infty$ is a set of points containing
$t_1, \ldots,t_n$ and $t_r = u_{i_r}, r = 1, 2, \ldots,n$, then $E$
can also be written as  
$$
  E= \bigg\{ w: w \in \Omega \text{ and } (w(u_1), \ldots, w (u_m)) \in
  B^m \bigg\},
$$
and\pageoriginale then
$$
p_{u_{1} \ldots u_m} (E) = \idotsint\limits_{B^m} N(u_1, 0, x_1)
  \ldots N(u_m - u_{m-1}, x_{m-1}, x_m) dx_1 \ldots dx_m,
$$
where $B^m$ is the inverse image of $B^m$ under the mapping $(x_1,
\ldots, x_m) \to (x_{1_1}, \ldots, x_{i_{n}}$ of $R^m$ into
$R^n$. Using the formula  
$$
\int N(t,x,y) N(s,y,z)dz = N(t + s, x, z),
$$
we can show that $p_{{u{_1}} \ldots u_m}(E) = p_{{t{_1}} \ldots t_n}(E)$.

Now suppose that $E$ has two representations 
\begin{align*}
E & = \bigg\{ w: (w(t_1) , \ldots , w(t_n)) \in B^n, B^n \subset R^n \bigg\}\\
  & = \bigg\{ w: (w(s_1) , \ldots , w(s_m)) \in B^m, B^m \subset R^m \bigg\},
\end{align*}
and $0 < u_1 < \ldots < u_r$ is the union of the sets $\{ t_1, \ldots,
t_n \}$ and $\{ s_1, \ldots , s_m \}$. Then from the above,
$p_{t_{1} \ldots t_n}(E)= p_{{u{_1}} \ldots u_r}(E)= p_{{s{_1}}
  \ldots s_m}(E)$. Hence\break $p_{{t{_1}} \ldots t_n}(E)$ does not depend
on the choice of the representation for $E$. We denote this by
$p(E)$.

The class $\mathbb{A}$ of all such sets $E$, for all $n$, for all such
$n$-tuples\break $(t_1, \ldots, t_n)$ and all Borel sets of $R^n$, is easily
shown to be an algebra. It is not difficult to show that $p$ is an
elementary probability measure on $\mathbb{A}$. This elementary
probability measure is called the \textit{elementary Wiener
  measure}.

We\pageoriginale shall presently prove that $p$ satisfies the
continuity condition 
of Kolmogoroff's theorem. Hence $p$ can be extended to a probability
measure $P$ on $\mathbb{B}(\mathbb{A})$, which we call the 
\textit{Wiener measure} on $(\Omega, \mathbb{B} (\mathbb{A}))$. It will
then follow that $P(w : w(0) = 0)=1$.  

Now let $x_t(w) = w(t)$. Then evidently $\{ x_t, 0 \leq t  < \infty
\}$ is a stochastic process with almost all sample functions
continuous and vanishing at $t = 0$. We show that $\{ x_t, 0 \leq t  <
\infty \}$ is a Wiener process. 

The function $f: (x_1 , x_2)$ --- $x_2 - x_1$ of $R^2 \to R^1$ is
continuous and hence for any Borel set $E \subset R^1$, the set $B =
f^{-1}(E) = \{ (x_1, x_2) : x_2 - x_1 \in E \}$ is a Borel set in
$R^2$. Therefore  
\begin{align*}
  p\{ w: x_t - x_s \in E \} & = P\{ w : (w(s), w(t)) \in B = f^{-1}(E) \}\\
  & = \iint_B  N(s, o, x_1) N(t-s, x_1, x_2) dx_1 dx_2.
\end{align*}

The transformation $(x_1, x_2) \to (x,y)$ with $x = x_1, y= x_2 - x_1$
gives  
\begin{align*}
  P(w : x_t - x_s \in E) & =  \iint\limits_{\{ (x,y) : y \in E \}} N(s,
  0, x) N(t-s, x,y+x) dxdy\\ 
  & = \int\limits_E N(t-s, 0, y) dy.
\end{align*}

Again 
$$
P\{ w: x_{t_{1}} \in E_1, \ldots, x_{t_{n}}-x_{t_{n-1}} \in E_n \}=
P\{w: (w(t_1), \ldots, w(t_n) \in B^n \}, 
$$
where $ B^n = \{(x_1, \ldots,x_n) : x_1 \in E_1, x_2-x_1 \in E_2 ,
\ldots, x_n - n_{n-1} \in E_n \}$. 

Therefore\pageoriginale
\begin{align*}
  P & \{w: x_{t_{1}} \in E_1,\ldots, x_{t_{n}} - x_{t_{n-1}} \in E_n
  \}\\ 
  & = \idotsint\limits_{B^n}  N(t_1, o, x_1) \ldots N(t_n - t_{n-1},
  x_{n-1}, x_n) dx_1 \ldots dx_n\\ 
  & = \int \limits_{E_1 x}\ldots \int \limits_{ x E_n} N(t_1, 0, x'_1)
  \ldots N(t_n - t_{n-1}, 0, x'_n) dx'_1 \ldots dx'_n\\ 
  & = P\{ w: x_{t_{1}} \in E_1 \} P\{ w: x_{t_{2}} - x_{t_{1}} \in
  E_2\} \ldots P\{ w: x_{t_{n}}-x_{t_{n-1}} \in E_n \}, 
\end{align*}
where $x'_1 = x_1, x'_2 = x_i - x_{i -1} i = 2, \ldots , n$. We have
proved that $(x_t)$ is a Wiener process. 

It remains to prove that $p$ satisfies the continuity condition. We
shall prove the following more general theorem. 

\begin{theorem*}
(Prohorov, `Convergence of stochastic processes and limit theorems
  in Probability Theory', Teoria veroyatnesteii $e$ eyo primenania
  Vol. I Part 2, 1956). 
\end{theorem*}

Let $p$ be an elementary probability measure on $\mathbb{A}$ 
which is a probability measure when restricted to sets of $\mathscr{A}$
dependent on a fixed set $t_1, \ldots , t_n$. Let $E$ denote expectations with
respect to $p$. If there exist $a > 0, b>1$ and $c> 0$ such that
$E(|x_t - x_s|^a) \leq C_{|t-s|^b}$ then $p$ can be extended to a
probability measure on $\mathbb{B}(\mathbb{A})$. 

\begin{proof}
Let $A_n \supset A_{n+1}, n= 1,2, \ldots, A_n \in \mathbb{A}$ be
  such that $p(A_n)> \in >0$, for all $n$. We prove that $\bigcap
  \limits_n A_n \neq \phi$. 

Let $A_n = \{ w : (w(t^{(n)}_1),\ldots, w(t_{r_{n}}^{(n)}))
\in B_n \}$, where $B_n \in \mathbb{B}(R^{r_n})$ (the set of Borel
subsets of $R^{r_{n}}$). For each $n$ there exists\pageoriginale a
$q_n$ such that (a) each 
$t^{(n)}_i \leq q_n$, (b) at most one $t^{(n)}_i$ is contained in any
closed interval $\left[(k-1)2^{-q_n}, k 2^{-q_n}\right]$ for $k=1, 2, \ldots, q_n
2^{q_n}$. By adding superfluous suffixes if necessary, one can assume
that each point $k 2^{-q_n}, k=0,1, \ldots, q_{n}2^{q_n}$, is in
$\{t^{(n)}_i, \ldots t^{(n)}_{r_n}\}$, and moreover (by adding, say,
the midpoint if necessary) that in each open interval $(( k-1)2^{-q_n},
k2^{-q_n})$ there is exactly one point of $(t^{(n)}_1, \ldots ,
t^{(n)}_{r_n})$. Thus $r_n = q_{n}2^{q_n + 1}$ and $t^{(n)}_{2k} =
k2^{-q_n}$. Finally, by adding superfluous sets when necessary one may
assume that $q_n =n$ i.e., that  
$$
\displaylines{\hfill 
A_n = \left\{ w: \left(w\left(t^{(n)}_1\right), \ldots,
  w\left(t^{(n)}_{n2^{n+1}}\right)\right) \in B_n
  \right\},\hfill \cr
  \text{where}\hfill t^{(n)}_{2k}= k2^{-n}~\text{ and}~ \left(t^{(n)}_1, \ldots,
  t^{(n)}_{n2^{n+1}}\right) \subset \left(t^{(n+1)}_{1}, \ldots, t^{(n+1)}_{(n+2)
    2^{n+2}}\right).\hfill } 
$$

Since $p$ is a probability measure when restricted to sets dependent
on a fixed set $s_1, \ldots , s_k$, we can further assume that each
$B_n$ is a closed bounded subset $R^{n2^{n+1}}$. Now, since $E(|x(s)
-x(t)|^a) \leq C|s-t|^b$, 
\begin{align*}
  p(w:|w(t^{(n)}_{i}) - w(t^{(n)}_{i-1})| & \geq |t^{(n)}_{i}-
  t^{(n)}_{i-1}|^{\delta}) = p(w: |w(t^{(n)}_{i}) - w(t^{(n)}_{i-1})|^a
  \geq\\ 
  & \geq |t^{(n)}_{i} - t^{(n)}_{i-1}|^{a\delta}) \leq
  C|t^{(n)}_{i}-t^{(n)}_{i-1}|^{b-a\delta}
 \end{align*} 
 
Choose $\delta > 0$ such that $\lambda = b-a \delta -1 > 0$. Then 
$$
p(w: |w(t^{(n)}_{i}) - w(t^{(n)}_{i-1})| \geq |
t^{(n)}_{i}-t^{(n)}_{i-1}|^{\delta}) \leq C|t^{(n)}_{i} -
t^{(n)}_{i-1}|^{1+\lambda} \leq C 2^{-n (1 + \lambda)} 
$$

Hence\pageoriginale
$$
p\left(\bigcup \limits^{n2^{n+1}}_{i=2} \left(w: |w (t^{(n)}_{i}) -
w(t^{(n)}_{i-1}) | \geq | t^{(n)}_{i}-t^{(n)}_{i-1}|^{\delta}\right)\right) \leq
\dfrac{Cn_2^{n+1}}{2^{n(1+)}} = 2. C. n. 2^{-\lambda n}.
$$ 

Since $\sum n2^{-n \lambda}$ is convergent, there exists $m_o$ such
that $2C \sum \limits^{\infty}_{n=m_0} \break n_2^{-n \lambda} <
\dfrac{\in}{2}$. 

Then for $l \geq m_0$,
$$
\displaylines{\hfill 
  p\left(\bigcup^l_{n=m_0} \bigcap^{n_2^{n+1}}_{i =2 }\left(w:|w(t^{(n)}_{i}) -
  w(t^{(n)}_{i-1})|\geq |t^{(n)}_{i} - t^{(n)}_{i-1}|^{\delta}\right)\right) <
  \frac{\in}{2},\hfill \cr 
  \text{and so}\hfill  
  p\left(\bigcap^{\ell}_{n=m_o} \bigcap^{n_2^{n+1}}_{i=2} \left(w:|w(t^{(n)}_{i}) -
  w(t^{(n)}_{i-1})|< |t^{(n)}_{i} - t^{(n)}_{i-1}|^{\delta}\right)\right) > 1-
  \frac{\in}{2}.\hfill } 
$$

It follows that
$$
p\left(A_1 \cap \bigcap^{l}_{n=m_0}
\bigcap^{n_2^{n+1}}_{i=2} \left(w:|w(t^{(n)}_{i}) - w(t^{(n)}_{i})|<
|t^{(n)}_{i} - t^{(n)}_{i-1}|^{\delta}\right)\right) > 1- \frac{\in}{2}, 
$$
and so this set is non-empty. Call this set $B'_l$. Then $B'_l \supset
B'_{l +1}$ and $A_l \supset B'_l$. We prove that $\bigcap
\limits^{\infty}_{m_0} B'_l \neq \phi$. 

From each $B'_1$ choose a function $w_l$ linear in each interval
$[t^{(l)}_{i-1}, t^{(l)}_{i}]$. Such a function exists since for each
$w \in B'_l$ there corresponds such a function determined completely
by $(w(t^{(l)}_{1}),\ldots, w(t^{(l)}_{l_2 l+1}))$. We can assume
that $w(t^{(l)}_{1})=0$, since zero never occurs in the points which
define sets of $\mathbb{A}$. Now if $l \geq m_o$ 
$$
|w_l (t^{(n)}_{i}) - w_l(t^{(n)}_{i-1})| < |t^{(n)}_{i} -
t^{(n)}_{i-1}|^{\delta} \leq 2^{-n \delta}, m_0 \leq n \leq 1, 1 \leq
i \leq n2^{n+1}, 
$$
so\pageoriginale that $|w_{l} (k2^{-n}) - w_l((k-1)2^{-n})| \leq
2.2^{-n \delta}$, $1 \leq k \leq n2^n, m_0 \leq n \leq l$. Given
$k2^{-l}, k'2^{-l}, k' < 
k, k2^{-l} < 2^{-m_0}$, there exists $q \leq l$ such that $2^{-q} \leq
k2^{-l}- k' 2^{-l} < 2^{-q +1}$. In the interval $[k' 2^{-l},
  k2^{-l}]$ there exist at most two points of the form $j2^{-q}, (j+1)
2^{-q}$. Then since $w_l \in B'_q, | w_l (j2^{-q}) - w_l
((j+1)2^{-q})| < 2.2^{-q \delta}$. Repeating similar arguments we can
prove that  
$$
|w_l(k2^{-l}) - w_l(k' 2^{-l}) | \leq 4 (1-2^{- \delta})^{-1} 2^{-q
  \delta} \leq \lambda | k2^{-l}-k' 2^{-l}|^{\delta}, 
$$
$\lambda$ being a constant. Now we can easily see that 
$$
|w_1(t^{(l)}_{i})-w_l(t^{(l)}_{j})| <
\mu|t^{(l)}_{i}-t^{(l)}_{j}|^{\delta} \text{ if }|t^{(l)}_{i} -
t^{(l)}_{j}| \leq 2^{-m_0} \text{ say}. 
$$

From this easily follows, using linearity of $w_l$ in each interval\break
$\left[t^{(l)}_{i}, t^{(l)}_{i+1}\right]$, that if $t^{(l)}_{i} \leq t \leq s
\leq t^{(l)}_{j}$, then  
$$
|w_l(t) - w_l(s) | \leq 4 \mu| t^{(l)}_{i} - t^{(l)}_{j}|^{\delta}.
$$

Now since $w_{l+p} \in A_l$ for every $p \geq 0, (w_{l+p}(t^{(l)}_{1})
, \ldots , w_{l+p}(t^{(l)}_{l2^{l+1}})) \in B_l$. Since $B_l$ is
compact, this sequence has a limit point in $B_l$. Since the same is
true for every $l$, we can by the diagonal method, extract a
subsequence $\{w_n\}$, say, such that $w_n(t^{(l)}_{i})$ converges
for all $i$ and for all $l$. 

Now let $t_0$ and $\eta > 0$ be given. For large $n_0$ suppose
that\pageoriginale 
$t^{(n_0)}_{i} \leq t_0 \leq t^{(n_0)}_{i+1}, | t^{(n_0)}_{i} -
t^{(n_0)}_{i+1} < 2^{-n_0}< \eta_2$. Then if $l$ and $m$ are large and
$t^{(n_0)}_{i} \leq t^{(l)}_{j} \leq t_0 \leq t^{(l)}_{j+1} \leq
t^{(n_0)}_{i+1}, t^{(n_0)}_{i} \leq t^{(m)}_{k} \leq t_0 \leq
t^{(m)}_{k+1} \leq t^{(n_0)}_{i+1}$, we have  
\begin{align*}
|w_l (t_0) - w_m (t_0) | \leq | w_l (t_0) - w_l(t^{(l)}_{j}) | + |
  w_1 (t^{(l)}_{j})- w_l(t^{(n_0)}_{i}) |+| w_l (t^{(n_0)}_{i})\\ 
  - w_m(t^{(n_0)}_{i})| 
  + |w_m(t^{(n_0)}_{i}) -w_m(t^{(m)}_{k})|+| w_m(t^{(m)}_{k})
  -w_m(t_0)|\\ 
  \leq |t_0 -t^{(l)}_{j}|^{\delta} + \mu| t^{(l)}_{j}- t^{(n_0)}_{i}
  |^{\delta}+ \eta_2 + |t^{(n_0)}_{i}-t^{(m)}_{k}|^{\delta} \mu + |
  t^{(m)}_{k}-t_0|^{\delta} < A \eta_2, 
\end{align*}

A being some constant. This is true for any $t \in [t^{(n_0)}_{i},
  t^{(n_0)}_{i+1}]$. This shows that the limit exists at every point
of $R'$. Also using $|w_l(t) - w_l(s) | < 4 \mu|t^{(l)}_{i}-
t^{(l)}_{j} |^{\delta}$, we easily see that the limit function say
$w$, is continuous. Also since $(w(t^{(l)}_{1}, \ldots,
w(t^{(l)}_{l2^{l+1}})) \in B_l$ for all $l, \bigcap\limits_{l \geq
  m_0} B'_l \neq \phi$. We have proved the theorem. 

In our case we have 
$$
p(x_t- x_s \in E) = [2 \pi (t-s) ]^{-\frac{1}{2}} \int\limits_E
e^{\frac{-x^2}{2(t-s)}} dx 
$$
\end{proof}

\smallskip
\noindent
\textbf{Poisson processes}. 
Let $(x_t, 0 \leq t < \infty)$ be a stochastic process such
that\pageoriginale   
\begin{enumerate}
\item for almost all $w$ the sample function  
$x_{t}(w)$ is a step function
increasing with jump $1$
  and vanishes at $t = 0$; 
 
\item $P(x_t - x_s = k) = e^{ -\lambda (t - s)} \dfrac{(t -s)^k
  \lambda^k}{k}$ with $\lambda > 0$;  

\item $P(x_{t_1} \in E_1 , x_{t_2} - x_{t_1} \in E_2 , \ldots ,
  x_{t_n} \in E_n ) = P(x_{t _1} \in E_1) \ldots  P(x_{t_n} - x_{t_{n-1}}
  \in E_n)$; i.e., $x_{t_1},\ldots,x_{t_n} - x_{t_{n - 1}}$ are
  independent if $t_1 < t_2 \ldots < t_n$; then the process is called
  a \textit{Poisson process}.  
\end{enumerate}
