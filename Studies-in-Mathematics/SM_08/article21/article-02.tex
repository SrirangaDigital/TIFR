\title{Singular Modular Forms of Degree $s$}\label{art02}
\markright{Singular Modular Forms of Degree $s$}

\author{By~ S.~Raghavan}
\markboth{S.~Raghavan}{Singular Modular Forms of Degree $s$}

\date{}
\maketitle

\setcounter{page}{307}
\setcounter{pageoriginal}{262}
{\bf 1.}~For\pageoriginale a natural nubmer $s$, let $H_{s}$ denote
the Siegel half-plane of degree $s$, namely the space of $s$-rowed
complex symmetric matrices $W=U+iV$ with $U$, $V$ real and $V$
positive-definite. The Siegel modular group
$
\Gamma_{s}=\Sp(s,\bfZ)=\{M=\left(\begin{smallmatrix} A & B\\ C &
D\end{smallmatrix}\right)|A,B,C,D$ $s$-rowed integral square matrices with 
$$
M
\left(
\begin{array}{cc}
0 & E_s\\
-E_s & 0
\end{array}
\right)
M'
=
\left(
\begin{array}{cc}
0 & E_s\\
-E_s & 0
\end{array}
\right),
$$
where $E_s$ is the $s$-rowed identity matrix and for a
matrix $N$, $N'$ denotes the transpose of $N$\} acts on $H_{s}$ as a
discontinuous group of analytic homeomorphisms $W\mapsto M\langle
W\rangle =(AW+B)(CW+D)^{-1}$ of $H_{s}$ (called modular
transformations of degree $s$). By a modular form of degree $s$ and
weight $k(\geq 0)$ we mean a complex-valued function $f$ holomorphic
in the $s(s+1)/2$ independent elements of $W$ such that $f(M\langle
W\rangle )\det(CW+D)^{-k}=f(W)$ for every $M=\left(\begin{smallmatrix}
A & B\\ C & D\end{smallmatrix}\right)\in \Gamma_{s}$ and further, for
$s=1$, $f$ is bounded in a fundamental domain for $\Gamma_{s}$ in
$H_{s}$ \cite{art02-key6}. Let $\{\Gamma_{s},k\}$ denote the complex
vector space of such modular forms. Every $f\in \{\Gamma_{s},k\}$ has
the Fourier expansion
\begin{equation*}
f(W)=\sum_{N}a(N)\exp (\pi i \ tr \ (NW))\tag{1}\label{art02-addeq1}
\end{equation*}
where $tr$ denotes the trace and $N$ runs over all $s$-rowed integral
non-negative definite matrices with even diagonal elements. If
$a(N)=0$ for every positive definite $N$, we call $f$ a {\em singular
modular form}. On the other hand, if $a(N)=0$ for all $N$ which are
not positive-definite, $f$ is known as a cusp form. It is immediate
that the only cusp form which is, at the same time, a singular modular
form is the constant $0$. Writing $W$ in $H_{s}$ as
$\left(\begin{smallmatrix} Z & w\\ w' & z\end{smallmatrix}\right)$
with $z\in H_{1}$, $Z\in H_{s-1}$, we know $g=\Phi(f)$ given by
$g(Z)=\lim\limits_{\lambda\to \infty}f\left(\left(\begin{smallmatrix}
Z & 0\\ 0' & i\lambda\end{smallmatrix}\right)\right)$ is in
$\{\Gamma_{s-1},k\}$. This map
$\Phi:\{\Gamma_{s},k\}\to \{\Gamma_{s-1},k\}$ (with
$\{\Gamma_{0},k\}=\bfC$, by convention) is known\pageoriginale as the
Siegel operator and its kernel consists precisely of cusp forms in
$\{\Gamma_{s},k\}$. 

It is clear that $\{\Gamma_{s},k\}$ contains no singular modular form
$\neq 0$, if and only if every $f$ in $\{\Gamma_{s},k\}$ is uniquely
determined by the set of its Fourier coefficients $\{a(N)|N$ positive
definite$\}$ referring to \eqref{art02-addeq1}.

For $s=1$, a singular modular form is necessarily a constant. For
$s>1$, we know from Resnikoff (\cite{art02-key3}, \cite{art02-key4})
that singular modular forms can exist only for $k$ of the form $r/2$
with $r$ integral and $0\leq r<s$; such weights, for given $s$, are
called {\em singular weights.}

Even for $s>1$, it turns out, as we shall see in a while, that
singular modular forms are particularly simple in their structure; in
fact, they are quite arithmetical in nature in as much as they are
just linear combinations of theta series associated with
``positive-definite even quadratic forms of determinant 1 in $r$
variables'' (and with $W\in H_{s}$). It is well known that such
quadratic forms exist only when $r$ is a multiple of $8$.

{\bf 2.}~Let $S$ be an $r$-rowed integral positive-definite
matrix. Then associated to $S$ and $W\in H_{s}$, we define the theta
series
$$
t(W;S)=\sum_{G}\exp (\pi i\ tr \ (G'\ SG \ W))
$$
where the summation is over all integral matrices $G$ of $r$ rows and
$s$ columns. The series represents a holomorphic function of $W$ on
$H_{s}$. From Witt \cite{art02-key7}, we know that it is a modular
form of degree $s$ and weight $r/2$, if $S$ is positive-definite,
integral with diagonal elements even and of determinant 1; as already
mentioned, 8 has to divide $r$ in this case. Thus, for $s>r$, $t(W;S)$
is always a singular modular form for such $S$, since, in the
expansion \eqref{art02-addeq1} for $t(W;S)$ only $N$ of the form $G'SG$ with integral
$G$ of $r(<s)$ rows and $s$ columns can occur. From the analytic
theory of quadratic forms \cite{art02-key5}, we know that, for given
$r$ divisible by 8, all such even positive-definite $S$ of determinant
1 constitute a single ``genus'' consisting of finitely many
$\bfZ$-equivalence classes (Two $r$-rowed matrices $A$, $B$ are said
to be $\bfZ$-{\em equivalent}, if there exists an integral matrix $U$
of determinant $\pm 1$ such that $U'AU=B$).\pageoriginale Let
$S_{1},\ldots,S_{h}$ form a complete set of representatives of these
classes. Then $t(W;S_{i})$ depends only on the class of $S_{i}$ for
$1\leq i\leq h$. We claim that $t(W;S_{i})$, $1\leq i\leq h$ are
linearly independent over the field of complex numbers for $W\in
H_{r}$. In fact, the Fourier coefficient of $t(W;S_{i})$ corresponding
to $S_{j}$ (in place of $N$) as in \eqref{art02-addeq1} is given by
$\delta_{ij}E(S_{j})$ where $\delta_{ij}$ is the Kronecker delta and
$E(S_{j})$ is the number of integral matrices $U$ with
$U'S_{j}U=S_{j}$. Any linear relation of the form $\sum\limits_{1\leq
i\leq h}b_{i}t(W;S_{i})=0$ with $b_{i}$ not all zero, immediately
implies that $b_{i}E(S_{i})=0$ for every $i$ and yields a
contradiction, since we have $E(S_{i})\geq 2$, always. It is
immediately seen, by applying the $\Phi$-operator, that for $s\geq r$
and $W\in H_{s}$, $t(W,S_{1}),\ldots,t(W,S_{h})$ are linearly
independent.

\begin{theorem*}
Every (singular) modular form of degree $s$ and weight $r/2$ with $r$
integral and $0<r<s$ vanishes identically unless $r$ is a multiple of
$8$. If $8$ divides $r$, every modular form of degree $s$ and weight
$r/2$ is a linear combination of the theta series $t(W;S_{i})$, $1\leq
i\leq h$, where $W\in H_{s}$ and $S_{1},\ldots,S_{h}$ are
representatives of $\bfZ$-equivalence classes of $r$-rowed
positive-definite integral matrices with even diagonal elements and
determinant $1$.
\end{theorem*}

\begin{remark*}
The theorem does not say anything about the nature of
$\{\Gamma_{r},r/2\}$ for $r$ divisible by $8$. If the Siegel operator
from $\{\Gamma_{r+1},r/2\}$ to $\{\Gamma_{r},r/2\}$ were onto, then
one can conclude that $\{\Gamma_{r},r/2\}$ is generated over $\bfC$ by
theta series. If $r=8$, we know from
(\cite{art02-key1}, \cite{art02-key2}) that $\{\Gamma_{s},4\}$ has
dimension 1 over $\bfC$ for $s\leq 4$. It has been conjectured by
Freitag that even for $5\leq s\leq 8$, $\{\Gamma_{s},4\}$ has
dimension 1, being generated by a theta series.
\end{remark*}

Assume that the theorem has been proved for $s=r+1$. We then claim
that it is valid for $s>r+1$. First, for $r$ not divisible by 8, if
$\{\Gamma_{r+1},r/2\}$ consists only of 0, then the Siegel operator
$\Phi$ from $\{\Gamma_{r+2},r/2\}$ is clearly onto
$\{\Gamma_{r+1},r/2\}=\{0\}$ and its kernel is already $\{0\}$ since
every cusp form which is a singular form vanishes identically. Thus,
for $r$ not divisible by 8, $\{\Gamma_{r+2},r/2\}=\{0\}$ and a similar
argument gives $\{\Gamma_{s},r/2\}=\{0\}$ for $s\geq r+2$. On the
other hand, let, for $r$ divisible by 8, $\{\Gamma_{r+1},r/2\}$ be a
linear combination of theta series $t(W;S_{i})$,\pageoriginale $1\leq
i\leq h$ with $W\in H_{r+1}$. If $W^{*}=\left(\begin{smallmatrix} W &
*\\ * & *\end{smallmatrix}\right)\in H_{r+2}$, clearly
$\Phi(t(W^{*};S_{i}))=t(W;S_{i})$, i.e. the Siegel operator from
$\{\Gamma_{r+2},r/2\}$ is onto. Again by the same argument as above,
$\Phi$ is an isomorphism, implying that $\{\Gamma_{r+2},r/2\}$ is
generated by theta series for $r$ divisible by 8; the spaces
$\{\Gamma_{s},r/2\}$ for $s>r+2$ are taken care of in a similar
manner.

Therefore, we proceed to prove the theorem for $s=r+1$. Let
$\{\Gamma_{r+1},r/2\}$ {\em contain an} $f\neq 0$. For
$W=\left(\begin{smallmatrix} Z & w\\ w' & z\end{smallmatrix}\right)\in
H_{r+1}$ with $z\in H_{1}$, $Z\in H_{r}$, let us write \eqref{art02-addeq1}
as 
\setcounter{equation}{0}
\begin{equation}
f(W)=\sum_{N}a(N)\exp (\pi i(mz+2n'w+tr(TZ))\label{art02-eq2}
\end{equation}
where $N$ runs over all matrices of the form
$\left(\begin{smallmatrix} T &n\\ n' & m\end{smallmatrix}\right)$
which are non-negative definite, $(r+1)$-rowed, integral with even
diagonal elements, $T$ being $r$-rowed. Further, $f$ being a singular
modular form, $a(N)=0$ for $\det N>0$. If $\det T>0$, we can write $N$
above as 
$$
N=
\begin{pmatrix}
T & 0\\
0' & m-T^{-1}[n]
\end{pmatrix}
\begin{bmatrix}
E & T^{-1}n\\
0' & 1
\end{bmatrix}.
$$
Here $E_{r}$ denotes the $r$-rowed identity matrix and for two
matrices $A$, $B$ we abbreviate $B'AB$ (when defined) as $A[B]$. Thus,
for $\det T>0$, we have necessarily $m=T^{-1}[n]$.

For integral $A$ with $\det A=1$, we have $f(W[A])=f(W)$. This gives
$a(N)=a(N[A])$. In particular, for integral $r$-rowed columns $g$ and 
$$
N=
\begin{pmatrix}
T & n\\
n' & T^{-1}[n]
\end{pmatrix},
N_{1}=
\begin{pmatrix}
T & Tg+n\\
(Tg+n)' & T^{-1}[Tg+n]
\end{pmatrix}
=N
\begin{bmatrix}
E_{r} & g\\
0' & 1
\end{bmatrix}
$$ 
the corresponding coefficients $a(N)$ and $a(N_{1})$ coincide.

For positive $T$ as above and an integral $r$-rowed column $l$ with
$T^{-1}[l]$ even, let $b(T;l)=a\left(\left(\begin{smallmatrix} T & l\\
l' & T^{-1}[l]\end{smallmatrix}\right)\right)$ and let $b(T;l)=0$
otherwise. Then $b(T;Tg+l)=b(T;l)$ for every integral $g$. Let $l$ run
over a complete set of $r$-rowed integral columns such that no
two\pageoriginale distinct columns say $l_{1}$, $l_{2}$ satisfy
$l_{1}=l_{2}+Tg$ for some integral column $g$ (We write
$l\text{~mod~}T$, in symbols). We can write
\begin{align}
f(W) &= \sum_{T>0}\exp (\pi i\
tr(TZ))\sum_{l\text{~mod~}T}b(T;l)\sum_{g}\exp (\pi iz\
T^{-1}[Tg+l]+\notag\\
&\quad +2\pi i (Tg+l)'w)+\sum_{T_{1}\geq 0,\det
T_{1}=0}h(z,w;T_{1})\exp(\pi i\ tr(T_{1}Z))\label{art02-eq3}
\end{align}
where $T$, $T_{1}$ respectively run over positive-definite and
singular non-negative-definite $r$-rowed integral matrices with even
diagonal elements and $g$ runs over all $r$-rowed integral
columns. Let us abbreviate the innermost sum in the first term on the
right side of \cite{art02-key3} as $\vartheta(z,w;T,l)$. It is easy to
see that
\begin{align*}
\begin{pmatrix}
Z & w\\
w' & z
\end{pmatrix}
&= W\mapsto W_{1}=
\begin{pmatrix}
Z-z^{-1}ww' & z^{-1}w\\
z^{-1}w' & -z^{-1}
\end{pmatrix}\\
&= 
\begin{bmatrix}
E_{r} & 0 & 0 & 0\\
0' & 0 & 0' & -1\\
0 & 0 & E_{r} & 0\\
0' & 1 & 0' & 0
\end{bmatrix}
\langle W\rangle
\end{align*}
is a modular transformation of degree $s$. Now, since
$f\in \{\Gamma_{s},r/2\}$, we have
\begin{equation}
f(W_{1})z^{-r/2}=f(W)\label{art02-eq4}
\end{equation}
taking that branch of $z^{-r/2}$ assuming the value $\exp(-\pi ir/4)$
corresponding to the point $iE_{r+1}$. On the other hand, it is easy
to check that, for positive-definite $T$,
\begin{align*}
& \vartheta(-z^{-1},z^{-1}w; T,l)=\exp (\pi iz^{-1}T[w])\times\\
&\quad \times \sum_{g\text{~integral}}\exp(-\pi i\ T[g+T^{-1}l-w]z^{-1})\\
&= \exp (\pi iz^{-1}T[w])(\det(iz^{-1}T))^{-1/2}\times\\
&\quad \times \sum_{g\text{~ integral}}\exp(\pi iz\ T^{-1}[g]+2\pi i\
g'(T^{-1}l-w)) 
\end{align*}
using the theta transformation formula. Let us write $T^{-1}g$ again
as $T^{-1}j+p$ where $j$ runs modulo $T$ and $p$ runs over all
integral columns as $g$ does so. Then we have
\begin{align}
& \vartheta (-z^{-1},z^{-1}w; T,l)\notag\\
&=(i/z)^{-r/2}(\det T)^{-1/2}\exp(\pi iz^{-1}T[w])\times\notag\\
&\quad \times \sum_{j\text{~mod~}T} \ \sum_{p\text{~integral}} \exp
(\pi i\ T[p+T^{-1}j]z+\notag\\
&\quad +2\pi i\ l'(T^{-1}j+p)-2\pi i(Tp+j)'w)\notag\\
&=(i/z)^{-r/2}(\det T)^{-1/2}\exp (\pi iz^{-1}T[w])\times\notag\\
&\quad \times \sum_{j\text{~mod~}T}\exp(-2\pi i\ l'T^{-1}j)\vartheta(z,w;T,j)\label{art02-eq5}
\end{align}\pageoriginale 
noting that $exp(2\pi i\ l'p)=1$ and making the change $p\to -p$ and
$j\to -j$. From \eqref{art02-eq3}, \eqref{art02-eq4}
and \eqref{art02-eq5}, we obtain
\begin{align*}
& z^{r/2}\sum_{0<T,j\text{~mod~}T}b(T,j)\vartheta(z,w;T,j)\exp (\pi i\
tr(TZ)\\
&\quad +z^{r/2}\sum_{T_{1}}h(z,w;T_{1})\times\times \exp (\pi i\ tr(T_{1}Z))\\
&= \sum_{T,l\text{~mod~}T}b(T;l)\exp(\pi i\ tr(TZ)-\pi iz^{-1}T[w])\\
& \quad \times\vartheta (-z^{-1},z^{-1}w;T,l)+\\
&\quad + \sum_{T_{1}}h(-z^{-1},z^{-1}w;T_{1})\exp (\pi i\
tr(T_{1}Z)-\pi iz^{-1}T_{1}[w])\\
&= (i/z)^{-r/2}\sum_{T,l\text{~mod~}T}b(T;l)(\det T)^{-1/2}\exp(\pi i\
tr(TZ))\times \\
&\quad \times \sum_{j\text{~mod~}T}\exp(-2\pi i\
j'T^{-1}l)\vartheta(z,w;T,j)+\\
&\quad +\sum_{T_{1}}h(-z^{-1},z^{-1}w;T_{1})\exp (-\pi i\
z^{-1}T_{1}[w])\exp (\pi i\ tr(T_{1}Z))\\
&= (i/z)^{-r/2}\sum_{0<T,j\text{~mod~}T}(\det
T)^{-1/2}\sum_{l\text{~mod~}T}b(T;l)\exp(-2\pi i\ j'T^{-1}l)\times\\
&\quad \times \exp(\pi i\ tr(TZ))\vartheta(z,w;T,j)\\
&\quad +\sum_{T_{1}}h(-z^{-1},z^{-1}w;T_{1})\exp (-\pi i\
z^{-1}T_{1}[w])\exp(\pi i\ tr(T_{1}Z)).
\end{align*}
Comparing the coefficient of $\exp(\pi i \ tr(TZ))$ for fixed
positive-definite $T$ on both sides, we get
\begin{align*}
& z^{r/2} \sum_{j\text{~mod~}T}b(T;j)\vartheta(z;w;T,j)=(i/z)^{-r/2}(\det
T)^{-1/2}\times \\
& \times \sum_{j\text{~mod~}T}\vartheta(z;w;T,j)\sum_{l\text{~mod~}T}b(T:l)\exp
(-2\pi i\ j'T^{-1}l).
\end{align*}

This\pageoriginale implies, in turn, that
$$
b(T:j)=\exp(-\pi ir/4)(\det T)^{-1/2}\sum_{l\text{~mod~}T}b(T;l)\exp
(-2\pi il'T^{-1}j).
$$
In particular, we have for $T$ with det $T>0$,
\begin{equation}
a\left(
\begin{pmatrix}
T & 0\\
0' & 0
\end{pmatrix}
\right)=(\det T)^{-1/2}\exp(-\pi i\ r/4)\sum_{l\text{~mod~}T}a\left(
\begin{pmatrix}
T & l\\
l' & T^{-1}[l]
\end{pmatrix}
\right)\label{art02-eq6}
\end{equation}
(cf.~\cite{art02-key1}(13), p.~284, \cite{art02-key4}\S\S\
5-6). Note that $(\det T)^{1/2}$ is the positive square
root.

For given positive-definite $T$ and $l\text{~mod~}T$ as above, there
exists an integral matrix $A$ of determinant 1 such that
\begin{equation}
\begin{pmatrix}
T & l\\
l' & T^{-1}[l]
\end{pmatrix}
=A'
\begin{pmatrix}
T_{0} & 0\\
0' & 0
\end{pmatrix}
A.\label{art02-eq7}
\end{equation}
Since the left hand side is integral with even diagonal elements and
of rank $r$, the same is true of $T_{0}$. If
$A=\left(\begin{smallmatrix} d & c\\ b & a\end{smallmatrix}\right)$
with $r$-rowed square $d$, we have $T=T_{0}[d]$ implying that $d$ is
nonsingular. Further $l=d'T_{0}c$. If $\det d=\pm 1$, then
$l=d'T_{0}d$.  $d^{-1}c=Td^{-1}c$ ($\equiv 0\text{~mod~}T$, in the
sense that $l=Tg$ for an integral column $g$). Thus, if there exists
an integral $l$ not of the form $Tg$ for an integral $g$ such that
$T^{-1}[l]$ is even, then necessarily $\det d$ has absolute value
atleast equal to 2. On the other hand, there always exists an integral
$l$ such that $T^{-1}[l]$ is an even integer.

Let us call $T$ {\em imprimitive} if there exists an integral matrix
$d$ with $\det d\neq 0$, $\pm 1$, such that $T[d^{-1}]$ is integral
with even diagonal elements. If $T$ is not imprimitive, we call $T$
{\em primitive}.

For primitive $T$, the only term occurring on the right side
of \eqref{art02-eq5} corresponds to $l=0$ (i.e. $l\equiv 0(\text{mod~
}T)$). In this case then, we have
\begin{equation}
\left(1-
\frac{\exp(-\pi ir/4)}{(\det T)^{1/2}}\right)a
\left(
\begin{pmatrix}
T & 0\\
0' & 0
\end{pmatrix}
\right)=0.\label{art02-eq8}
\end{equation}
Unless
\begin{equation}
\det T=1\quad\text{and}\quad r\equiv 0(\text{mod~ }8),\label{art02-eq9}
\end{equation}
\eqref{art02-eq8} implies that $a\left(\left(\begin{smallmatrix} T &
0\\ 0' & 0\end{smallmatrix}\right)\right)=0$, We may
rewrite \eqref{art02-eq5} as 
\begin{equation*}
a\left(
\begin{pmatrix}
T & 0\\
0' & 0
\end{pmatrix}
\right)=
\frac{\exp (-\pi ir/4)}{(\det T)^{1/2}}\sum_{(d\ c)}a\left(
\begin{pmatrix}
T[d^{-1}] & 0\\
0' & 0
\end{pmatrix}
\right)\tag{$5'$}\label{eq5'}
\end{equation*}\pageoriginale 
where, on the right hand side, the summation is over integral matrices
$(d\ c)$ of $r$ rows and $r+1$ columns having discriminant 1, with
integral non-singular $d$ not mutually differing by a left sided
integral matrix factor of determinant $\pm 1$ and with $c$ running
only modulo $d$. From \eqref{eq5'} and \eqref{art02-eq9}, we conclude that
\begin{equation}
\text{``} a
\left(
\begin{pmatrix}
T & 0\\
0' & 0
\end{pmatrix}
\right)\neq 0, \ \det T>1\text{''}\Rightarrow T\quad\text{~ is
imprimitive.}\label{art02-eq10}
\end{equation}

On the other hand, if there exists $T$ as above with $\det T=1$ and
$a\left(\left(\begin{smallmatrix} T & 0\\ 0' &
0\end{smallmatrix}\right)\right)\neq 0$, then $8$ necessarily divides
$r$, $T$ being $r$-rowed, positive-definite, of determinant 1 and
integral with even diagonal elements. Thus if 8 does not divide $r$,
repeated application of $(5)'$ eventually yields a primitive $T_{0}$
with non-zero $a\left(\left(\begin{smallmatrix} T_{0} & 0\\ 0' &
0\end{smallmatrix}\right)\right)$, since $f\neq 0$ (and $\Phi(f)\neq
0$, as a result).  For such a $T_{0}$, we deduce
from \eqref{art02-eq8} and \eqref{art02-eq9} that $\det T_{0}=1$ and
$r\equiv 0(\text{mod~ }8)$, which is a contradiction. The first
assertion of the theorem is thus proved for $s=r+1$ and hence for
every $s\geq r+1$.

Let us now suppose that $r$ is a (positive) multiple of 8. For the
given $f\in \{\Gamma_{r+1},r/2\}$, we can always find a constant
$u_{i}$ such that the Fourier coefficient
$a\left(\left(\begin{smallmatrix} S_{i} & 0\\ 0' &
0\end{smallmatrix}\right)\right)$ of $f$ is precisely $u_{i}E(S_{i})$
for $1\leq i\leq h$. Let, for given $r$-rowed integral symmetric $R$,
$A(S_{i},R)$ denote the number of integral matrices $G$ for which
$S_{i}[G]=R$. It is immediate from the choice of $u_{i}(1\leq i\leq
h)$ that for $\det T=1$, 
\begin{equation}
a
\left(
\begin{pmatrix}
T & 0\\
0' & 0
\end{pmatrix}
\right)=\sum_{1\leq i\leq h}u_{i}A(S_{i}T)\label{art02-eq11}
\end{equation}
Indeed, $T$ is in the $\bfZ$-equivalence class of exactly one of
$S_{1},\ldots,S_{n}$ and \eqref{art02-eq11} follows from the choice of
$u_{i}$ and from the fact that $f(B'WB)=f(W)$ for integral $B$ of
determinant $\pm 1$. Assume that \eqref{art02-eq11} has been proved
for all integral positive definite $T$ with even diagonal elements and
$\det T<t$. Then from $(5)'$, if $\det T=t$, 
{\fontsize{10pt}{12pt}\selectfont
\begin{align*}
(1-1/(\det T)^{1/2})a
\left(
\begin{pmatrix}
T & 0\\
0' & 0
\end{pmatrix}
\right) &= \frac{1}{(\det T)^{1/2}}\sum_{\substack{(d \ c)\\ |\det
d|\neq 1}} a\left(
\begin{pmatrix}
T[d^{-1}] & 0\\
0' & 0
\end{pmatrix}
\right)\\
&= (1/(\det T)^{1/2})\sum_{\substack{(d \ c)\\ |\det d|\neq
1}}u_{i}A(S_{i},T[d^{-1}]). 
\end{align*}}\relax\pageoriginale
using the hypothesis on \eqref{art02-eq11}. But the last expression is
just 
$$
(1-1/(\det T)^{1/2})\sum\limits_{1\leq i\leq h}u_{i}A(S_{i},T)
$$
since $\sum\limits_{1\leq i\leq h}u_{i}A(S_{i},T)$ is itself
the Fourier coefficient of 
$$
\sum\limits_{1\leq i\leq
h}u_{i}t(W;S_{i})\in \{\Gamma_{r+1},r/2\}
$$ 
corresponding to
$\left(\begin{smallmatrix} T & 0\\ 0' & 0\end{smallmatrix}\right)$
and consequently satisfies $(5)'$. As a result, we have 
$$
a\left(
\begin{pmatrix}
T & 0\\
0' & 0
\end{pmatrix}
\right)
=\sum_{1\leq i\leq h}u_{i}A(S_{i},T)
$$
for $\det T\geq 1$. In other words,
\begin{align*}
(\Phi(f))(Z) &= \sum_{1\leq i\leq h}u_{i}t(Z,S_{i})\\
&=\Phi\left(\sum\limits_{1\leq i\leq h}u_{i}t(W,S_{i})\right)\\
\text{i.e.}\qquad f(W) &= \sum_{1\leq i\leq h}u_{i}t(W,S_{i})
\end{align*}
which completes the proof of the theorem for $s=r+1$.

\medskip
\noindent
{\bf Acknowledgement.}~
We are grateful to Prof.~ H.L.~Resnikoff for having sent a preprint
entitled `Stable spaces of modular forms'. It may be remarked that
relations (3.7) and (3.8) on page 8 of that preprint do not seem to be
correct. 

We learned from Prof. H.~Klingen in December 1976 that Freitag and
Resnikoff have independently proved the assertion: ``singular modular
forms are generated by theta series''. Perhaps, their proof is also on
the same lines as above. We received recently a preprint of
D. M. Cohen and H. Resnikoff entitled ``Hermitian quadratic forms and
hermitian modular forms''; this contains a reference to a preprint of
H. L. Resnikoff entitled ``The structure of spaces of
singular\pageoriginale automorphic forms'' the contents of which are,
however, not known to us.

\begin{thebibliography}{}
\bibitem{art02-key1} M. Eichler: \"Uber die Anzahl der linear
unabh\"angigen Siegelschen Modulformen von gegebenem Gewicht, {\em
Math, Ann.,} 213 (1975), 281-291.

\bibitem{art02-key2} J. Igusa: On Siegel modular forms of genus two,
{\em Amer. J. Math.,} 84 (1962), 175-200.

\bibitem{art02-key3} H. Maass: {\em Siegel's modular forms and
Dirichlet series,} Springer-Verlag Lecture Notes in Mathematics,
No.~216, (1971).

\bibitem{art02-key4} H.~L.~Resnikoff: Automorphic forms of singular
weight are singular forms, {\em Math. Ann.,} 215, (1975) 173-193.

\bibitem{art02-key5} C.~L.~Siegel: \"Uber die analytische Theorie der
quadratischen Formen, {\em Annals Math.} 36, (1935) 527-606: {\em
Gesamm. Abhand.,} vol. I, 326-405, Springer-Verlag, (1966).

\bibitem{art02-key6} C.~L.~Siegel: Einf\"uhrung in die Theorie der
Modulfunktionen n-ten Grades, {\em Math. Ann.} 116, (1939) 617-657:
{\em Gesamm. Abhand.,} vol. II, 97-137, Springer-Verlag, (1966).

\bibitem{art02-key7} E.~Witt: Eine Identit\"at zwischen Modulformen
zweiten Grades, {\em Abh. Math. Sem. Univ. Hamburg,} 14, (1941)
323-337. 
\end{thebibliography}

\vfill\eject
~\phantom{a}
\thispagestyle{empty}

