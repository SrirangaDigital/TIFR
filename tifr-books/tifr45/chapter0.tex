\setcounter{chapter}{-1}
\chapter{Artinian Semi-simple Rings with Involution}\label{c0}

In\pageoriginale this chapter we shall determine the Artinian
semi-simple rings with involutions. The results are all well
known. The final formulation in terms of matrix rings (in \S 2) will
be particularly useful in the sequel. The results which we shall state
without proof can be found in any standard text on associative ring
theory. 

\section[Determination of the semi-simple artinian
rings...]{Determination of the semi-simple artinian rings with 
involution.}\label{c0:sec1} 

Throughout these notes associative rings and algebras will be assumed
to be {\em unital}, that is to contain a unit $1$ such that $a1=a=1a$
for all $a$ in the ring. We recall that such a ring is called {\em
right artinian} if it satisfies one of the following equivalent
conditions: 

\medskip
{\em Minimum Condition:} Any non-vacuous set of right ideals of the
ring contains a minimal element. 

\medskip
{\em Desending chain condition:} There exist no properly descending
infinite chain of right ideals
$\mathfrak{I}_1\supset\mathfrak{I}_2\supset\mathfrak{I}_3\cdots$ 

A right artinian ring is called {\em semi-simple} if it contains no
non-zero nilpotent (two-sided) ideal. An ideal $\mathfrak{N}$ is
nilpotent if there exists a positive integer $N$ such that every
product of $N z_i$ in $\mathfrak{N}$ is $0$. Equivalently, if  
$\mathscr{Z}\mathfrak{L}$ is defined to be the ideal generated by all
be, $b\in \mathscr{Z}, c\in \mathfrak{L}$ and $\mathscr{Z}^{m}$ for
$m=1, 2, \ldots$ is defined by
$\mathscr{Z}^{1}=\mathscr{Z}, \mathscr{Z}^{k}=\mathscr{Z}^{k-1}\mathscr{Z}$
then $\mathfrak{N}^{N}=0$. 

We\pageoriginale recall the fundamental Wedderburn-Artin structure
theorems on semi-simple (right) artinian rings. 

\begin{enumerate}[I.]
\item  If $\mathfrak{a}$ is semi-simple artinian $(\neq 0)$ then
$\mathfrak{a}=\mathfrak{a}_1\oplus\mathfrak{a}_2\oplus\cdots\oplus\mathfrak{a}_3$ 
where $\mathfrak{a}_i$ is an ideal which regarded as a ring is simple
artinian. (A ring $\mathfrak{a}$ is simple if $\mathfrak{a}\neq 0$ and
$0$ and $\mathfrak{a}$ are the only ideals in $\mathfrak{a}$.)
Conversely, if $\mathfrak{a}$ has the indicated structure then it is
semi-simple artinian. 

\item A ring $\mathfrak{a}$ is simple artinian if and only if
$\mathfrak{a}$ is isomorphic to a complete ring $\Delta_n$ of $n\times
n$ matrices over a division ring $\Delta$. This is equivalent to
isomorphism to the ring End$_{\Delta}\mathcal{V}$ of linear
transformations of an $n$ dimensional (left) vector space
$\mathcal{V}$ over a division ring $\Delta$. 

It is easily seen that the {\em simple components} $\mathfrak{a}_i$ in
the first structure theorem are uniquely determined. In the second
structure theorem, $n$ and the isomorphism class of $\Delta$ are
determined by $\mathfrak{a}$. This follows from the following basic
isomorphism theorem. 

\item Let $\mathcal{V}_i$, $i=1,2,$ be a vector space over a division
ring $\Delta_i$ and let $\rho$ be an isomorphism of
End$_{\Delta_{1}}\mathcal{V}_1$ onto
End$_{\Delta_{2}}\mathcal{V}_2$. Then there exists a semi-linear
isomorphism $S$ of $\mathcal{V}_1$ onto $\mathcal{V}_2$ with
associated isomorphism $s$ of $\Delta_1$ onto $\Delta_2$ such that 
\begin{equation*}
A^{\sigma}=S^{-1} AS,\quad A\in \, {\text
End} \mathcal{V}_1.\tag{1}\label{c0:eq1} 
\end{equation*}

We now consider semi-simple artinian rings with involution. First, we
give the basic definitions, which we formulate more generally
for\pageoriginale rings which need not be associative. As in the
associative case, we assume the rings are unital. Also homorphisms are
assumed to map 1 into 1 and subrings contain 1. 


\begin{definition}
A {\em ring with involution} is a pair $(\mathfrak{a},J)$ where
$\mathfrak{a}$ in a ring (with $1$) and $J$ is an involution ($=$
anti-automorphism such that $J^{2}=1$) in $\mathfrak{a}$. A {\em
homomorphism} $\sigma$ of $(\mathfrak{a}, J)$ into a second ring with
involution $(\mathscr{Z}, K)$ in a homomorphism of $\mathfrak{a}$ into
$\mathscr{Z}$ (sending $1$ into $1$) such that $J\sigma =\sigma k$. A
{\em subring} of $(\mathfrak{a}, J)$ is a subring $\mathscr{Z}$
(containing $1$) of $\mathfrak{a}$ which is stable under $J$. An {\em
ideal} of $(\mathfrak{a}, J)$ is an ideal of $\mathfrak{a}$ which is
$J$-stable. ( , ) is {\em simple} if $\mathfrak{a}\neq 0$ and $\mathfrak{a}$ and $0$ are the only ideals of $(\mathfrak{a}, J)$. 
\end{definition}

Let $(\mathfrak{a}, J)$ be simple and assume $\mathscr{Z}$ is an ideal $\neq 0$ in $\mathfrak{a}$. Then $\mathscr{Z}+\mathscr{Z}^{J}$ is an ideal in $(\mathfrak{a}, J)$. Hence $\mathscr{Z}+\mathscr{Z}^{J}=\mathfrak{a}$. Also $\mathscr{Z}\cap \mathscr{Z}^{J}$ is an ideal in $(\mathfrak{a}, J)$ so $\mathscr{Z}\cap\mathscr{Z}=0$. Thus $\mathfrak{a}=\mathscr{Z}\oplus\mathscr{Z}$. If $\mathfrak{L}$ is an ideal in $\mathscr{Z}$ then $\mathfrak{L}+\mathfrak{L}^{J}$ is an ideal in $(\mathfrak{a}, J)$. It follows that $\mathscr{Z}$ is simple. This shows that if $(\mathfrak{a}, J)$ is simple then either $\mathfrak{a}$ is simple or $\mathfrak{a}=\mathscr{Z}\oplus\mathscr{Z}^{J}$ where $\mathscr{Z}$ is simple.

An associative ring with involution $(\mathfrak{a}, J)$ is {\em artinian semi-simple} if $\mathfrak{a}$ is artinian semi-simple. It follows from the first Wedderburn-Artin structure theorem that such a ring with involution is a direct sum of ideals which are artinian simple rings with involution and conversely. An artinian simple ring with involution is of one of the following types:$\mathfrak{a}=\mathscr{Z}\oplus\mathscr{Z}^{J}$ where $\mathscr{Z}\cong \Delta_n$, $\Delta$ a division ring or $\mathfrak{a}\cong \Delta_n$ (or $\cong$ End $\mathcal{V}$ where $\mathcal{V}$ is $n$ dimensional vector space over a\pageoriginale division ring $\Delta$). We now consider the latter in greater detail.

Thus consider End $\mathcal{V}$ where $\mathcal{V}$ is an $n$-dimensional vector space over $\Delta$. Assume End $\mathcal{V}$ has an involution $J$. Let $\mathcal{V}^{\ast}$ be the right vector space of linear functions on $\mathcal{V}$. We denote the elements of $\mathcal{V}^{\ast}$ as $x^{\ast}, y^{\ast}$ etc. And write the value of $x^{\ast}$ at $y$ by $\langle y, x^{\ast}\rangle$. This gives a {\em bilinear pairing} of the left vector space $\mathcal{V}/\Delta$ with the right vector space $\mathcal{V}^{\ast}/\Delta$ in the sense that 
\begin{align*}
   &\langle y_1+y_2, x^{\ast}\rangle = \langle y_1,
   z^{\ast}\rangle+\langle y_2, x^{\ast}\rangle\\ 
   &\langle y_1 x_{1}^{\ast}+x_{2}^{\ast}\rangle=\langle y,
   x_{1}^{\ast}\rangle+\langle y, z_{2}^{\ast}\rangle\tag{2}\label{c0:eq2}\\ 
\langle \alpha y,x^{\ast}\rangle&=\alpha \langle y,x^{\ast}\rangle, \langle y,x^{\ast} \alpha\rangle=\langle y, ^{\ast}\rangle\alpha,\quad \alpha \in \Delta
\end{align*}
Also the pairing is {\em non-degenerate} in the sense that if $\langle y, x^{\ast}\rangle=0$ for all $x^{\ast}\in \mathcal{V}^{\ast}$ then $y=0$ and if $\langle y,x^{\ast}\rangle=0$ for all $y\in \mathcal{V}$ then $x^{\ast}=0$. Let $\Delta^{\circ}$ be the opposite ring of $\Delta:\Delta^{\circ}$ is the same additive group as $\Delta$ and has the multiplication $\alpha \circ \beta=\alpha \beta$. Then if we put $\alpha x^{\ast}=x^{\ast}\alpha, \mathcal{V}^{\ast}$ becomes a(left) vector space over $\Delta^{\circ}$ and the last equation in (2) becomes $\langle y, \alpha x^{\ast}\rangle=\langle y_1,x^{\ast}\rangle\alpha$.

Let $A\in$ End $\mathcal{V}$. Then we have a uniquely determined linear transformation $A^{\ast}$ in End $\mathcal{V}^{\ast}$ satisfying
\begin{equation*}
\langle yA,x^{\ast}\rangle=\langle y_1,x^{\ast}A^{\ast}\rangle,\quad 
y\in \mathcal{V}, x^{\ast}\in \mathcal{V}^{\ast}\tag{3}\label{c0:eq3}
\end{equation*}
This is called the {\em transpose} of $A$. If we use the usual
functional notation $x^{\ast}(y)$ for $\langle y,x^{\ast}\rangle$ then
$x^{\ast}A^{\ast}(y)=x^{\ast}$ is\pageoriginale the resultant of $A$
followed by $x^{\ast}(yA)$ or $x^{*}A^{*}$. It follows directly that 
\begin{equation*}
(A+B)^{\ast}=A^{\ast}+B^{\ast}, (AB)^{\ast}=B^{\ast}A^{\ast}\tag{4}\label{c0:eq4}
\end{equation*}
and $A \to A^{\ast}$ is bijective from End $\mathcal{V}$ to End $\mathcal{V}^{\ast}$. Thus $A\to A^{\ast}$ is an anti-isomorphism of End $\mathcal{V}$ onto End $\mathcal{V}^{\ast}$.

Now suppose End $\mathcal{V}$ has an involution $J$. Since $A\to A^{J}$ and $A\to A^{\ast}$ are anti-isomorphisms, $A^{J}\to A^{\ast}$ is an isomorphism of End $\mathcal{V}$ onto End $\mathcal{V}^{\ast}$ (considered as left vector space over $\Delta^{\circ}$). Hence by the isomorphism theorem III we have a semi-linear isomorphism $(S, s)$ ($S$ with associated division ring isomorphism $s$) of $\mathcal{V}/\Delta$ onto $\mathcal{V}^{\ast}/\Delta^{\circ}$ such that
\begin{equation*}
A^{\ast}=S^{-1}A^{J}S,\quad A\in \,{\text End} \mathcal{V}\tag{5}\label{c0:eq5}
\end{equation*}
Now put
\begin{equation*}
g(x,y)=\langle x, yS\rangle,\quad x, y\in \mathcal{V}.\tag{6}\label{c0:eq6}
\end{equation*}

Then $g$ is additive in both factors, $g(\alpha x, y)=\alpha g(x, y)$ and 
\begin{align*}
g(x, \alpha y)&=\langle x, (\alpha y)S \rangle=\langle x, \alpha^{s}(y s)\rangle\\
&=\langle x, (y S)\alpha^{s}\rangle=\langle x, y S \rangle \alpha^{s}
\end{align*}

The mapping $\alpha \to \alpha^{s}$ is an isomorphism of $\Delta$ onto $\Delta^{\circ}$; hence an anti-automorphism in $\Delta$. The conditions just noted for $g$ are that $g$ is a sesquilinear form on $\mathcal{V}/\Delta$ relative to the anti-automorphism $s$ in $\Delta$. Since the pairing $\langle\; ,\; \rangle$ is non-degenerate it\pageoriginale follows that $g$ is a non-degenerate form: $g(x,\mathcal{V})=0$ implies $x=0$ and $g(\mathcal{V}, x)=0$ implies $x=0$. We have
\begin{align*}
g(x,yA^{J})&=g(x,yS A^{\ast} S^{-1})=\langle x,y S A^{\ast}\rangle\\
&=\langle xA, y S\rangle=g(xA, y).
\end{align*}

Hence $A^{J}$ is the uniquely determined {\em adjoint} of $A$ relative to $g$ in the sense that $g(x,y A^{J})=g(xA,y), x,y\in \mathcal{V}$.

So far we have not used the involutorial character $J^{2}=1$ of $J$. We note first that the sesquilinear character of $g$ implies that if $v\in V$ then $x\to g(v, x)s^{-1}$ is a linear function on $V$.
Hence there exists a $v'\in V$ such that
\begin{equation*}
g(v, x)^{s^{-1}}=g(x,v'),x\in V.\tag{7}\label{c0:eq7}
\end{equation*}
Next we consider the linear mapping $x\to g(x,u)v$ in $V$ where $u,v\in V$. Since
\begin{align*}
g(g(x,u)v,y)&=g(x,u)g(v,y)\\
&=g(x,g(v,y)^{s^{-1}}u),
\end{align*}
it is clear that if we put $A:x\to g(x,u)v$ then $A^{J}$ is $y\to
gA(v,y)^{s^{-1}}$ $u=g(y,v')u$. Since $A^{J^{2}}=A$ this gives
$g(x,u')v'=g(x,u)v$ for all $x,u,v$. This implies that $v'=\gamma v$,
$\gamma\neq 0$, in $\Delta$, (independent of $v$) so by (7), we have 
\begin{equation*}
g(x,y)^{s}=\delta g(y,x),\quad \delta\neq
0\quad \text{in}\, \Delta. \tag{8}\label{c0:eq8} 
\end{equation*}

By\pageoriginale (8) we have $g(x,y)^{s^{2}}=\delta g(x,y)\delta^{s}$. We can choose $x,y$ so that $g(x,y)=1$. Then we get $\delta^{s}=\delta^{-1}$. If $\delta=-1$ we have $g(x,y)^{s}=-g(y,x)$. Then $g(x,y)^{s^{2}}=g(x,y)$ and $g(\alpha x,y)^{s^{2}}=\alpha^{s^{2}}g(x,y)=g(\alpha x,y)=\alpha g(x,y)$. Then $\alpha^{s^{2}}=\alpha$. So $s$ is an involution in $\Delta$ and $g$ is a  semi-degenerate skew hermitian form relative to this involution. If $\delta\neq-1$ then we put $\rho=\delta+1$ and $h(x,y)=g(x,y)\rho$. Then $h$ is sesquilinear relative to the anti-automorphism $t:\alpha \to \rho^{-1}\alpha^{s}\rho$ and $h(x,y)^{t}=(g(x,y)\rho)^{t}=\rho^{t}g(x,y)^{t}=\rho^{t}\rho^{-1}g(x,y)^{s}\rho=\rho^{t}\rho^{-1}\delta g(y,x)\rho=\rho^{t}\rho^{-1}\delta h(y,x)$. Also $\rho^{t}\rho^{-1}=\rho^{-1}\rho^{s}$ so $\rho^{t}\rho^{-1}\delta=(1+\delta)^{-1}(1+\delta^{s})\delta=1$ since $\delta^{s}\delta=1$. Hence $h(x,y)^{t}=h(y,x)$. Then $\alpha^{t^{2}}=\alpha$ so $t$ is an involution in $\Delta$ and $h$ is a non-degenerate hermitian form relative to this involution. Clearly $h(xA,y)=h(x,y A^{J})$ so $A\to A^{J}$ is the adjoint mapping determined by $h$. We have now proved.

\item Let $V$ be a finite dimensional vector space over a division ring $\Delta$ and assume that End $V$ has an involution $J$. Then $\Delta$ has an involution $j:\delta\to \overline{\delta}$ and there exists a non-degenerate hermitian or skew-hermitian form $h$ on $V$ such that $J$ is the adjoint mapping determined by $h$. 

The converse of $IV$ is trivial. Given a non-degernate hermitian or skew-hermitian form $h$ on $V/\Delta$ then the adjoint mapping relative to $h$ is an involution in End $V$. We recall next how such forms are  constructed. Let $(\Delta,j)$ be a division ring with involution and let $V$ be an $n$-dimensional vector space over $\Delta$. Let $(v_1,v_2,\ldots,v_n)$ be\pageoriginale a base for $V/\Delta$ and $H=(\eta_{ij})\in \Delta_n$ be hermintian or skew hermitian, that is, $\overline{H}^{t}=\pm H$ where $\overline{H}=(\overline{\eta}_{ij})$ and the $t$ denotes the transpose. If $x=\sum \xi_i v_i,y=\sum\eta_i v_i$ then we define
\begin{equation*}
h(x,y)=\sum\limits_{i,j=1}^{n}\xi_i\eta_{ij}\overline{\eta}_j.\tag{9}\label{c0:eq9}  
\end{equation*}

Then direct verification shown that $h$ is a hermitian or skew
hermitian form accordings as $H$ is hermitian or skew
hermitian. More\-over, $h$ is non-degernate if and only if $H$ is
invertible in $\Delta_n$. Since it is clear that there exist hermitian
invertible matrices for any involution $j$ and any $n$ (e.g the matrix
$1$) it follows that End $V$ has an involution if and only if $\Delta$
has an involution. We remark that there exist $\Delta$ which have no
involutions. For example, any finite dimensional central division
algebra over the rationals $Q$ of dimensionality $> 4$ has no
involution. We remark also that if $\Delta=\Phi$ is field then $j=1$
is an involution. 

The construction we gave yields all hermitian and skew hermitian forms on $V/\Delta$. Suppose $h$ is a hermitian or skew hermitian form on $V/\Delta$ and, as before, $(v_1,v_2,\ldots,v_n)$ is a base for $V/\Delta$. Then the matrix $H=(h(v_i,v_j))$ of $h$ relative to the given base is hermitian or skew hermitian and if $=\sum\xi_iv_i,y=\sum\eta_i v_i$ then $h(x,y)=\sum\xi_ih(v_{i_{1}}v_j)\overline{\eta}_j$ as before.

Let $h$ have the matrix $H=(\eta_{ij})$ relative to the base $(v_1,
v_2,\ldots,v_n)$ and assume $h$ is non-degenerate or, equivalently,
$H$ is invertible. Let $A\in$ End $V$ and write $v_i
A=\sum \alpha_{ij}v_j$, so $(\alpha)=(\alpha_{ij})$\pageoriginale in
the matrix of $A$ relative to this base. Let $A^{J}$ be the adjoint of
$A$ relative to $h$ and write $v_iA^{J}=\sum\beta_{ij}v_j$. It is
clear that the defining conditions: $h(x A,y)=h(x,y A^{J})$ are
equivalent to the conditions $h(v_i A,v_j)=h(v_i,v_jA^{J}),\;
i,j=1,\ldots,n$. Using the matrices $(\alpha)$ and $(\beta)$ there
$n^{2}$ conditions give the matrix condition
$(\alpha)H=H(\overline{\beta})^{t}, H=(h(v_{ij}v_j))$, where
$(\overline{\beta})^{t}$ is the transposed of the matrix
$(\overline{\beta})=(\overline{\beta}_{ij})$. For, $h(v_iA,v_j)=h(ik
v_k, v_j)=h(\sum \alpha_{ik}v_{k},v_{j})$ and $h(v_j,v_j
A^{J})=h(v_i, \sum \beta_{jk} v_k)=\sum\limits_{k}h(v_i,
v_k)\overline{\beta}_{jk}$ and $\sum\limits_{k}\alpha_{ik}h(v_k,
v_j)=\sum\limits_{k}h(v_i, v_k)\overline{\beta}_{jk},\;
i,j=1,\ldots,n$ 
are equivalent to the matrix condition we noted. Then the matrix of
$A^{J}$ is 
\begin{equation*}
(\beta)=H(\overline{\alpha})^{t}H^{-1}.\tag{10}\label{c0:eq10}
\end{equation*}
Now the mapping $K:(\alpha)\to H(\overline{\alpha})^{t} H^{-1}$ is an
involution in $\Delta_n$. Also $A\to (\alpha)$ is an isomorphism of
End $V$ onto $\Delta_n$ and since this maps $A^{J}\to (\alpha)^{k}$ it
is an isomorphism of $(\End V, J)$ onto $(\Delta_n, K)$. 

We note next that unless $j=1$ then we may normalize $h$ to be
hermitian. Then suppose $j\neq1$ and $h$ is skew hermitian. Choose $j$
so that $\overline{j}\neq j$ and put $\rho=\overline{j}-j\neq 0$. Then
$h'=h \rho$ is sesquilinear relative to the involution
$\alpha\to \beta^{-1}\overline{\alpha}\rho$ and
$\rho^{-1}\overline{h'(x,y)}\rho=\rho^{-1}\overline{h(x,y)\rho}\rho=-(-h(y,x)\rho)=h'(y,x)$. Hence
$h'$ is hermitian. Clearly the adjoint mappings determined by $h$ and
$h'$ are identical. If $j=1$ then $\Delta=\Phi$ is commutative and
again $h$ is hermitian unless the characteristic is $\neq 2$ and
$h(x,y)=-h(y, x)$. Hence the two\pageoriginale two cases we need
consider are $1$) $h$ is hermitian, $2$) $\Delta=\Phi$ a field of
characteristic $\neq 2, j=1, h$, skew symmetric. 

It is easily seen that in the first case unless $\Delta\neq\Phi$ a field of characteristic $2, j=1$ and $h(\;,\;)\equiv 0$ then there exists a base $(u_1,u_2,\ldots,u_n)$ such that the matrix $(h(u_i,u_j))$ is a diagonal matrix $\gamma=\text{diag}\{\gamma_1,\gamma_2,\ldots,\gamma_n\}$ where $\overline{\gamma_i}=\gamma_i\neq 0$. This is proved on pp. 152-157 and pp. 170-171 of Jacobson's {\em Lectures in Abstract Algebra}, Vol. II. The foregoing argument shows that (End $V, J$) is isomorphic to $(\Delta_n, K)$ where $K$ is the involution $(\alpha)\to \gamma(\overline{\alpha})^{t}\gamma^{-1}$ in $\Delta_n$. If we take into account to the case omitted in $1$) and $2$) we see that it remains to assume that $\Delta=\Phi$ a field, $j=1$ and $h(x,x)\equiv0$. In this case $n=2r$ is even and as is well known, there exists a base $(u_1,u_2,\ldots,u_n)$ such that the matrix $(h(u_i, u_j))$ is 
\begin{equation*}
s=\text{diag}\{Q,Q,\ldots,Q\}\quad\text{where}\quad Q=\begin{pmatrix}
0 & 1\\
-1& 0
\end{pmatrix}.\tag{11} \label{c0:eq11}
\end{equation*}

Then (End $V, J$) is isomorphic to $(\Phi_n, K)$ where $K$ is
$(\alpha)\to S^{-1}$ $(\alpha)^{t}S$. 
\medskip
{\em 2. Standard and canonical involutions in matrix rings}. Let
$(\mathscr{O}, j)$ be an associative ring with involution and let
$\mathscr{O}_n$ be the ring of $n\times n$ matrices with entries in
$\mathscr{O}$. As usual, we denote by $e_{ij}$ the matrix whose
$(i,j)$ entry is $1$ and other entries are $0$ and we identify
$\mathscr{O}$ with the set of scalar matrices
$d=\text{diag}\{d,\ldots,d\},\; d\in \mathscr{O}$. Then
$de_{ij}=e_{ij}d$ and every element of $\mathscr{O}_n$ can be written
in one and only one way as $\sum d_{i_{j}}e_{i_{j}},\; d_{i_{j}}\in \mathscr{O}$. Also we have the multiplication table
\begin{equation*}
e_{ij}e_{kl}=\delta_{jk}e_{il}\tag{12}\label{c0:eq12}
\end{equation*}
and\pageoriginale
\begin{equation*}
\sum_{1}^{n}e_{ii}=1.\tag{13}\label{c0:eq13}
\end{equation*}

Write $\overline{d}=d^{j}$ and consider the mapping $J_l:D=(d_{ij})\to \overline{D}^{t}$. As is well-known and redily verified, $J_1$ is an involution in $\mathscr{O}_n$. We shall call this the {\em standard involution} (associated with $j$) in $\mathscr{O}_n$. More generally, let $C=\text{diag}\{c_1,c_2,\ldots,c_n\}$ be a diagonal matrix with inverteble diagonal element $c_i=\overline{c}_i, C^{-1}=\text{diag}\{c_1^{-1},c_2^{-1},\ldots,c_n^{-1}\}$. The the mapping
\begin{equation*}
J_C:D\to C \overline{D}^{t}C^{-1}=C D^{J_{1}}C^{-1}\tag{14}\label{c0:eq14}
\end{equation*}
is an involution. We shall call such an involution a {\em canonical involution} (associated with $j$).

We shall now show that we have the following matrix form of the determination of simple artinian rings with involution given in \S $1$.

\item Any artinian simple ring with involution is isomorphic to a matrix ring with canonical involution $(\mathscr{O}_n, J_c)$ where $\mathscr{O}$ is of one of the following types:
\begin{enumerate}[1.]
\item $\mathscr{O}=\Delta\oplus\Delta^{\circ},\Delta$ a division ring, $j$ the {\em exchange} involution $(a,b)\to(b,a)$.
\item $\mathscr{O}=\Delta$ a division ring, $j$ an involution in $\Delta$.
\item $\Delta=\Phi_2$ the ring of $2\times2$ matrices over a field $\Phi$ the involution $X\to Q^{-1} X^{t} Q$ where $Q=\begin{pmatrix}
0 & 1\\
-1 & 0.
\end{pmatrix}$
\end{enumerate}
The\pageoriginale first possibility we noted for an artinian simple ring with involution is $\Delta_n\oplus\Delta_n^{J}$ are ideals Let $\mathscr{O}=\Delta\oplus\Delta^{\circ}$ and consider the matrix ring $\mathscr{O}_n$ with the standard involution $J_{l}$  determined by the involution $j:(a,b)\to(b,a)$ in $\mathscr{O}$. Let $(a_{ij}),(b_{ij})\in \Delta_n$ and consider the element $(a_{ij})+(v_{ij})^{J}$ of $\Delta_n\oplus \Delta_n^{J}$. We map this into the element of $\mathscr{O}_n$ whose $(i,j)$ entry is $(a_{ij},b_{ji})$. Then direct verification shows that this mapping is an isomorphism of $(\Delta_n\oplus\Delta_n^{J}, J)$ onto $(\mathscr{O}_n, J_1)$. Thus these artinian simple rings with involution are matrix rings with standard involution with coefficient rings of the form $1$ above.

It remains to consider the simple artinian rings with involution $(\mathfrak{a},J )$ such that $\mathfrak{a}$ is simple. The considerations of the last part of \S $1$ show that such an $(\mathfrak{a},J)$ is isomorphic either to a $(\Delta_n, J_c)$ where $(\Delta, J)$ is a division ring with involution and $J_c$ is a corresponding canonical involution or to $(\Phi_{2r},J_{S})$ where $J_{S}$ is the involution $A\to S^{-1}A^{t} S, S=\text{diag}\{Q,Q,\ldots,Q\},Q=\begin{pmatrix}
0 & 1\\
-1 & 0
\end{pmatrix}.$

The first possibility is the case $2$ listed above. Suppose we have
the second possibility. We consider the standard isomorphism of
$\Phi_{2r}$ onto $(\Phi_2)_{r}$ which maps a $2r\times 2r$ matrix onto
the corresponding $r\times r$ matrix of $2\times2$ blocks. It is easy
to check that this is an isomorphism of $(\Phi_{2r}, J_S)$ onto
$((\Phi_2)_r, J_l)$ where $J_{1}$ is the standard involution based on
the involution $X\to Q^{-1} X^{t^{l}}Q$ in $\Phi_2$. Thus we have the
case $3$. 

We\pageoriginale shall show later (Theorem of
Herstein-Kleinfold-Osborn-\break McCrimmon, Chap.III) that the three
possibilities for the coefficient ring $(\mathscr{O}, J)$ we noted
have a uniform characterization as the simple rings with involution
whose non-zero symmetric elements are invertible. It is easy to check
that the rings with involution listed in $1,2,3,$ have these
properties. The converse of $V$ is clear by re-tracing the steps. 

We remark finally that the considerations of matrix rings with involutions can  be generalized to the case in which the coefficient ring is not necessarily associative. If $(\mathscr{O}, J)$ is such a ring then the matrix ring $\mathscr{O}_n$ has the standard involution $D\to \overline{D}^{t}$. Also the notion of canonical involution $J_c$ can be generalized. Here it is required that the entries $c_i$ of the diagonal matrix $C$ are the nucleous of $\mathscr{O}$, that is, there associate with all pairs of elelments $a,b$ of $\mathscr{O} ((a,b)c=a(bc),(ac)b=a(cb), (ca)b=c(ab))$.
\end{enumerate}
