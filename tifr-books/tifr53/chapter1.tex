
\chapter{Differential Calculus in Normed Linear Spaces}\label{chap1}

We\pageoriginale shall recall in this chapter the notions of differentiability in the sense of Gateaux and Frechet for mappings between normed linear spaces and some of the properties of derivatives in relation to convexity and weak lower semi-continuity of functionals on normed linear spaces. We shall use these concepts throughout our discussions.

In the following all the vector spaces considered will be over the field of {\em real numbers $\mathbb{R}$}.

If $V$ is a normed (vector) space we shall denote by $|| \cdot ||_{V}$ the norm in $V$, by $V'$ its (strong) dual with $|| \cdot ||_{V'}$ as the norm and by $\langle \cdot, \cdot \rangle_{V' \times V}$ the duality pairing between $V$ and $V'$. If $V$ is a Hilbert space then $(\cdot, \cdot)_{V}$ will denote the inner product in $V$. If $V$ and $H$ are two normed spaces then $\mathscr{L} (V, H)$ denotes the vector space of all continuous linear mappings from $V$ into $H$ provided with the norm $A \to ||A||_{\mathscr{L}(V, H)} = \sup \{ ||Av||_{H} / ||v||_{V}, v \epsilon V \}$. 

\section{Gateaux Derivatives}\label{chap1-sec1}
Let $V$, $H$ be normed spaces and $A: U \subset V \to H$ be a mapping of an open subset $U$ of $V$ into $H$. We shall often call a vector $\varphi \epsilon V$, $\varphi \neq 0$ a direction in $V$.

\begin{definition}\label{chap1-def1.1}
The mapping $A$ is said to be differentiable in the sense of Gateaux or simply $G$-differentiable at a point $u \epsilon U$ in the direction $\varphi$ if the difference quotient
$$
(A(u + \theta \varphi) - A(u))/\theta
$$
has\pageoriginale a limit $A'(u, \varphi)$ in $H$ as $\theta \to 0$ in $\mathbb{R}$. The (unique) limit $A'(u, \varphi)$ is called the Gateaux derivative of $A$ at $u$ in the direction $\varphi$.
\end{definition}

A is said to be $G$-differentiable in a direction $\varphi$ in a subset of $U$ if it is $G$-differentiable at every point of the subset in the direction $\varphi$.

We shall simply call $A'(u, \varphi)$ the $G$-derivative of $A$ at $u$ since the dependence on $\varphi$ is clear from the notation.

\begin{remark}\label{chap1-rem1.1}
The operator $V \ni \varphi \mapsto A' (u, \varphi) \epsilon H$ is homogeneous:
$$
A'(u, \alpha, \varphi) = \alpha A' (u, \varphi) \text{ for } \alpha > 0.
$$
\end{remark}

In fact,
$$
A'(u, \alpha, \varphi) = \lim_{\theta \to 0} (A(u+\alpha \theta \varphi)-A(u))/ \theta = \alpha \lim_{\lambda \to 0} (A(u+\lambda \varphi))/ \lambda = \alpha A'(u, \varphi).
$$

However, this operator is not, in general, linear as can be seen immediatly from Example \ref{chap1-exam1.2} below.

We shall often denote a functional on $U$ by $J$.

\begin{remark}\label{chap1-rem1.2}
Every lineary functional $L : V \to \mathbb{R}$ is $G$-differentiable everywhere in $V$ in all directions and its $G$-derivative is
$$
L'(u, \varphi) = L(\varphi)
$$
since $(L(u+\theta \varphi) - L(u))/ \theta = L(\varphi)$. It is a constant functional (i.e. independent of $u$ in $V$).
\end{remark}

If a $(u, v) : V \times V \to \mathbb{R}$ is a bilinear functional on $V$ then the functional $J : V \ni v \mapsto J(v) = a(v, v) \epsilon \mathbb{R}$ is $G$-differentiable everywhere in all direction and
$$
J'(u, \varphi) = a(u, \varphi) + a(\varphi, u).
$$ 

If\pageoriginale further $a(u, v)$ is symmetric (i.e. $a(u, v) = a(v, u)$ for all $u, v \epsilon V$) then $J'(u, \varphi) = 2a(u, \varphi)$. This follows immediately from bilinearity :
$$
a(u+\theta, u + \theta \varphi) = a(u, u) + \theta(a(u, \varphi) + a(\varphi, u)) + \theta^{2} a(\varphi, \varphi)
$$
so that
$$
J'(u, \varphi) = \lim_{\theta \to 0} (J(u+\theta \varphi) - J(u))/ \theta = a(u, \varphi) + a(\varphi, u).
$$

The following example will be a model case of linear problems in many of our discussions in the following chapters.

\begin{example}\label{chap1-exam1.1}
Let $(u, v) \mapsto a(u, v)$ be a symmetric bi-linear form on a Hilbert space $V$ and $v \mapsto L(v)a$ linear form on $V$. Define the functional $J : V \to \mathbb{R}$ by
$$
J(v) = \frac{1}{2} a(v, v) - L(v).
$$
\end{example}

It follows from the above Remark that $J$ is $G$-differentiable everywhere in $V$ in all directions $\varphi$ and 
$$
J'(u, \varphi) = a(u, \varphi) - L(\varphi).
$$

In many of the questions we shall assume:
\begin{enumerate}
\item[(i)] $a(.,.)$ is $(bi-)$ continuous: there exists a constant $M > 0$ such that 
$$
a(u, v) \leq M || u ||_{V} || v ||_{V} \text{ for all } u, v \epsilon V; 
$$
\item[(ii)] $a(\cdot, \cdot)$ is $V$-coercive; There exists a constant $\alpha > 0$ such that 
$$
a(v, v) \geq \alpha || v ||_{V}^{2} \text{ for all } v \epsilon V
$$
and
\item[(iii)] $L$ is continuous: there exists a constant $N > 0$ such that
$$
L(v) \leq N || v ||_{V} \text{ for all } v \epsilon V.
$$\pageoriginale
\end{enumerate}

\begin{example}\label{chap1-exam1.2}
The function $f : \mathbb{R}^{2} \to \mathbb{R}$ defined by
\begin{equation*}
f(x, y) = 
\begin{cases}
0 & \text{ if } (x, y) = (0, 0)\\
x^{5}/((x-y)^{2} + x^{4}) & \text{ if } (x, y) \neq (0, 0)
\end{cases}
\end{equation*}
is $G$-differentiable everywhere and in all directions. In fact, if $u = (0, 0) \epsilon \mathbb{R}^{2}$ then given a direction $\varphi = (X, Y) \epsilon \mathbb{R}^{2} (\varphi \neq 0)$ we have
$$
(f(\theta X, \theta Y) - f(0, 0))/ \theta = \theta^{2} X^{5}/ ((X - Y)^{2} + \theta^{2} X^{4})
$$
which has a limit as $\theta \to 0$ and we have
\begin{equation*}
f'(u, \varphi) = f'((0, 0), (X, Y)) = 
\begin{cases}
0 & \text{ if } X \neq Y\\
X & \text{ if } X = Y
\end{cases}
\end{equation*}
One can also check easily that $f$  is $G$-differentiable in $\mathbb{R}^{2}$.
\end{example}

The following will be the general abstract form of functionals in amy of the non-linear problems that we shall consider.

\begin{example}\label{chap1-exam1.3}
Let $\Omega$ be an open set in $\mathbb{R}^{n}$ and $V = L^{p}(\Omega)$, $p > 1$. Suppose $g : \mathbb{R}^{1} \ni t \mapsto g(t) \epsilon \mathbb{R}^{1}$ be a $C^{1}$-function such that
$$
(i)\quad  |g(t)|\leq C|t|^{p} \text{ and } (ii)\quad |g'(t)| \leq C|t|^{p-1}
$$
for some constant $C > 0$. Then
$$
u \mapsto J(u) = \int_{\Omega} g(u(x)) dx
$$
defines a functional $J$ on $L^{p}(\Omega) = V$ which is $G$-differentiable everywhere in all directions and we have
$$
J'(u, \varphi) = \int_{\Omega} g'(u(x)) \varphi (x) dx.
$$\pageoriginale
\end{example}

(The right hand side here exists for any $u$, $\varphi \epsilon L^{p} (\Omega)$).

In fact, since $u \epsilon L^{p} (\Omega)$ and since $g$ satisfies (i) we have
$$
|J(u)| \leq \int_{\Omega} |g(u)|dx \leq C \int_{\Omega} |u|^{p} dx < + \infty
$$
which means $J$ is well defined on $L^{p} (\Omega)$. On the other hand, for any $u \epsilon L^{p} (\Omega)$ since $g'$ satisfies (ii), $g'(u) \epsilon L^{p'} (\Omega)$ where $p^{-1} + p'^{-1} = 1$. For, we have
$$
\int_{\omega} |g'(u)|^{p'} dx \leq C \int_{\Omega} |u|^{(p-1)p'} dx = C \int_{\Omega} |u|^{p} dx < + \infty.
$$

Hence, for any $u, \varphi \epsilon L^{p} (\Omega)$, we have by H\"{o}lder's inequality
$$
\left| \int_{\omega} g'(u) \varphi dx\right| \leq || g'(u) ||_{L^{p}(\Omega)} || \varphi ||_{L^{p}(\Omega)} \leq C || u ||_{L^{p}}^{p/p'} || \varphi ||_{L^{p} (\Omega)} < + \infty.
$$

To compute $J'(u, \varphi)$, if $\theta \epsilon \mathbb{R}$ we define $h : [0, 1] \mapsto \mathbb{R}$ by setting
$$
h(t) = g(u + t\theta \varphi).
$$

Then $h \epsilon C^{1} (0, 1)$ and
$$
h(1) - h(0) = \int_{0}^{1} h'(t) dt = \theta \varphi (x) \int_{0}^{1} g'(u + t \theta \varphi )dt
$$
$(t = t(x))$, $|t(x)| \leq 1$ so that
$$
(J(u + \theta \varphi) - J(u))/ \theta = \int_{\Omega} \varphi (x) \int_{0}^{1} g'(u(x) + t \theta \varphi (x)) dt dx.
$$

One can easily check as above that the function
$$
(x, t) \mapsto \varphi(x) g'(u(x) + t\theta \varphi (x))
$$
belongs to $L^{1} (\Omega \times [0, 1])$ and hence by Fubini's theorem
$$
(J(u + \theta \varphi) - J(u))/ \theta = \int_{0}^{1} dt \int_{\Omega} \varphi (x) g'(u(x) + t \theta \varphi (x))dx.
$$\pageoriginale

Here the continuity of $g'$ implies that
$$
g'(u + t \theta \varphi) \to g'(u) \text{ as } \theta \to 0 \text{ (and hence as } t \theta \to 0) 
$$
uniformly for $t \epsilon [0, 1]$. Morever, the condition (ii) together with triangle inequality implies that, for $0 < \theta \leq 1$.
$$
|\varphi (x) g' (u(x) + t\theta \varphi (x))| \leq C |\varphi (x)| (|u(x)| + |\varphi (x)|)^{p-1}
$$
and the right side is integrable by H\"{o}lder's inequality. Then by dominated convergence theorem we conclude that
$$
J' (u, \varphi) = \int_{\Omega} g'(u) \varphi dx.
$$

\begin{definition}\label{chap1-def1.2}
An operator $A : U \subset V \to H$ ($U$ being an open set in $V$) is said to be twice differentiable in the sense of Gateaux at a point $u \epsilon V$ in the directions $\varphi$, $\psi(\varphi, \psi \epsilon V, \varphi \neq 0, \psi \neq 0$ given) if the operator $u \mapsto A'(u, \varphi) ; U \subset V \to H$ is once $G$-differentiable at $u$ in the direction $\psi$. The $G$-derivative of $u \mapsto A'(u, \varphi)$ is called the second $G$-derivative of A and is denoted by $A''(u, \varphi, \psi) \epsilon H$. 
\end{definition}

$$
\text{ i.e. } A''(u; \varphi, \psi) = \lim_{\theta \to 0} (A'(u + \theta \psi, \varphi) - A'(u, \varphi))/ \theta.
$$

\begin{remark}\label{chap1-rem1.3}
Derivatives of higher orders in the sense of Gateaux can be defined in the same way. As we shall not use derivatives of higher orders in the following we shall not consider their properties.
\end{remark}

Now let $J : U \subset V \to \mathbb{R}$ be a functional on an open set of a normed linear space $V$ which is once $G$-differentiable at a point $u \epsilon U$. If the functional $\varphi \mapsto J'(u, \varphi)$\pageoriginale is continuous linear on $V$ then there exists a (unique) element $G(u) \epsilon V'$ such that
$$
J'(u, \varphi) = \langle G(u), \varphi \rangle_{V' \times V} \text{ for all } \varphi \epsilon V.
$$

Similarly, if $J$ is twice $G$-differentiable at a point $u \epsilon U$ and if the form $(\varphi, \psi) \mapsto J''(u : \varphi, \psi)$ is a bilinear (bi-)continuous form on $V \times V$ then there exists a (unique) element $H(u) \epsilon \mathscr{L} (V, V')$ such that
$$
J''(u; \varphi, \psi) = \langle H(u) \varphi, \psi \rangle_{V' \times V}.
$$

\begin{definition}\label{chap1-def1.3}
$G(u) \epsilon V'$ is called the gradient of $J$ at $u$ and $H(u)
  \epsilon \mathscr{L}\break (V, V')$ is called the Hessian of $J$ at $u$. 
\end{definition}

\section{Taylor's Formula}\label{chap1-sec2}
We shall next deduce the mean value theorem and Taylor's formula of second order for a mapping $A : U \subset V \to H$ (U open subset of a normed linear space V) in terms of the $G$-derivatives of $A$. We shall begin case of functionals on a normed linear space $V$.

Let $J$ be a functional defined on an open set $U$ in a normed linear space $V$ and $u, \varphi \epsilon V, \varphi \neq 0$ be given. Throughout this section we assume that the set $\{u + \theta \varphi ; \theta \epsilon [0, 1]\}$ is contained in $U$. It is convenient to introduce the function $f : [0, 1] \to \mathbb{R}$ by setting
$$
\theta \to f(\theta) = J(u + \theta \varphi).
$$

We observe that if $J'(u + \theta \varphi, \varphi)$ exists then $f$ is once differentiable in $]0, 1[$ and, as one can check immediately
$$
f'(\theta) = J'(u + \theta \varphi, \varphi).
$$\pageoriginale

Similarly if $J''(u + \theta \varphi, \varphi, \varphi)$ exists then $f$ is twice differentiable and 
$$
f''(\theta) = J''(u + \theta \varphi ; \varphi, \varphi).
$$

\begin{proposition}\label{chap1-prop2.1}
Let $J$ be a functional on an open set $U$ of a normed space $V$ and $u \epsilon U$, $\varphi \epsilon V$ be given. If $\{u + \theta \varphi ; \theta \epsilon [0, 1]\} \epsilon U$ and $J$ is once $G$-differentiable on this set in the direction $\varphi$ then there exists a $\theta_{0} \epsilon ]0, 1[$ such that
\begin{equation*}
 J(u + \varphi) = J(u) + J'(u + \theta_{0} \varphi, \varphi)\tag{2.1}\label{chap1-eq2.1}
\end{equation*}
\end{proposition}

\begin{proof}
This follows immediately from the classical mean value theorem applied to the function $f$ on $[0, 1]$ : thete exists a $\theta_{0} \epsilon ]0, 1[$ such that
$$
f(1) = f(0) + 1-f'(\theta_{0})
$$
which is noting nut (\ref{chap1-eq2.1}).
\end{proof}

\begin{proposition}\label{chap1-prop2.2}
Let $U$ be as in Proposition \ref{chap1-prop2.1}. If $J$ is twice
$G$ - differentiable on the set $\{u + \theta \varphi ; \theta \epsilon
[0, 1]\}$ in the directions $\varphi, \varphi$ then there exists a
$\theta_{0} \epsilon ]0, 1[$ such that 
\begin{equation*}
 J(u + \varphi) = J(u) + J'(u, \varphi) + \frac{1}{2} J''(u + \theta_{0} \varphi ; \varphi ,  \varphi).\tag{2.2}\label{chap1-eq2.2}
\end{equation*}
\end{proposition}

This again follows from the classical Taylor's formula applied to the function $f$ on $[0, 1]$.

\begin{remark}\label{chap1-rem2.1}
If $L : V \to \mathbb{R}$ is a linear functional on $V$ then by Remark \ref{chap1-rem1.1} is $G$-differentiable everywhere in all directions and we find that the formula (\ref{chap1-eq2.1}) reads
$$
L(u + \varphi) = L(u) + L(\varphi)
$$
which\pageoriginale is noting but additivity of $L$.
\end{remark}

Similarly, if $a(\cdot, \cdot)$ is a bi-linear form on $V$ then the functional $J(v) = a(v, v)$ on $V$ is twice $G$-differentiable in all pairs directions $(\varphi, \psi)$ and 
$$
J'(u, \varphi) = a(u, \varphi) + a(\varphi, u), J''(u, \varphi, \psi) = a(\psi, \varphi) + a(\varphi, \psi).
$$

Then the Taylor's formula (\ref{chap1-eq2.2}) in this case reads
$$
a(u + \varphi, u + \varphi) = a(u, u) + a(u, \varphi) + a(\varphi, u) + a(\varphi, \varphi)
$$
which is noting but the bilinearity of $a$.

These two facts together imply that the functional
$$
J(v) = \frac{1}{2} a(v, v) - L(v)
$$
of Example \ref{chap1-exam1.1} admits a Taylor expansion of the form (Proposition \ref{chap1-prop2.2})
$$
J(u + \varphi) = J(u) + a(u, \varphi) - L(\varphi) + \frac{1}{2}a(\varphi, \varphi).
$$

We shall now pass to the case of general operators between normed spaces. We remark first of all that the Taylor's formula in the form (\ref{chap1-eq2.1}) is not in general valid in this case. However, we have

\begin{proposition}\label{chap1-prop2.3}
Let $V$, $H$ be two normed spaces, $U$ an open subset of $V$ and let $\varphi \epsilon V$ be given. If the set $\{u + \theta \varphi ; \theta \epsilon [0, 1]\} \subset U$ and $A : U \subset V \to H$ is a mapping which is $G$-differentiable everywhere on the set $\{u + \theta \varphi ; \theta \epsilon [0, 1]\}$ in the direction $\varphi$ then, for any $g \epsilon H'$, there exists a $\theta_{g} \epsilon ]0, 1[$ such that
\begin{equation*}
 \langle g, A (u + \varphi) \rangle_{H' \times H} = \langle g, A(u) \rangle_{H' \times H} + \langle g, A'(u + \theta_{g} \varphi, \varphi) \rangle_{H' \times H}\tag{2.3}\label{chap1-eq2.3}
\end{equation*}
\end{proposition}

\begin{proof}
We define a function $f : [0, 1] \to \mathbb{R}$ by setting
$$
\theta' \mapsto f(\theta) = \langle g, A(u + \theta \varphi) \rangle_{H' \times H}.
$$\pageoriginale
\end{proof}

Then $f'(\theta)$ exists in $]0,1[$ and 
$$
f'(\theta) =  \langle g, A'(u + \theta \varphi, \varphi) \rangle_{H' \times H} \text{ for } \theta \epsilon ]0, 1[
$$ 

Now (\ref{chap1-eq2.3}) follows immediatly on applying the classical mean value theorem to the function $f$.

\begin{proposition}\label{chap1-prop2.4}
Let $V, H, u, \varphi$ and $U$ be as in Proposition \ref{chap1-prop2.4}. If $A : U \subset V \to H$ is $G$-differentiable in the set $\{u + \theta \varphi; \theta \epsilon [0, 1]\}$ in the direction $\varphi$ then there exists a $\theta_{0} \epsilon ]0, 1[$ such that
\begin{equation*}
||A(u + \varphi) - A(u)||_{H} \leq ||A'(u + \theta_{0} \varphi, \varphi)||_{H}.\tag{2.4}\label{chap1-eq2.4}
\end{equation*}
\end{proposition}

The proof of this proposition uses the following Lemma which is a corollary to Hahn-Banach theorem.

\begin{lemma}\label{chap1-lem2.1}
If $H$ is normed space then for any $v \in H$ there exists a $g \epsilon H'$ such that
\begin{equation*}
||g||_{H'} = 1 \text{ and } ||v||_{H} = \langle g, v \rangle_{H \times H}.\tag{2.5}\label{chap1-eq2.5}
\end{equation*}
For a proof see \cite{key34}.
\end{lemma}

\medskip
\noindent{\textit{Proof of Proposition 2.4}}
The element $v = A(u + \varphi) - A(u)$ belongs to $H$ and let $g \epsilon H'$ be an element given by the Lemma \ref{chap1-lem2.1} satisfying (\ref{chap1-eq2.5}) i.e.
$$
||g||_{H'} = 1, ||A(u + \varphi) - A(u)||_{H} = <g, A(u + \varphi) - A(u)>_{H' \times H}.
$$

Since A satisfies the assumptions of Proposition \ref{chap1-prop2.3}
it follows that there exists a $\theta_{0} = \theta_{g} \epsilon ]0,
  1[$ such that 
\begin{align*}
||A(u + \varphi) - A(u)||_{H} & = <g, A(u + \varphi) - A(u)>_{H'
  \times H}\\
& = <g, A'(u + \theta_{0} \varphi, \varphi)>_{H' \times H}\\
& \leq ||g||_{H'} ||A'(u + \theta_{0} \varphi, \varphi)||_{H} = ||A'(u + \theta_{0} \varphi, \varphi)||_{H}.
\end{align*}
proving\pageoriginale (\ref{chap1-eq2.4}).

\begin{proposition}\label{chap1-prop2.5}
Suppose a functional $J : V \to \mathbb{R}$ has a gradient $G(u)$ for  all $u \epsilon V$ which is bounded i.e. there exists a constant $M > 0$ such that $||G(u)|| \leq M$ for all $u \epsilon V$, then we have
\begin{equation*}
|J(u) - J(v)| \leq M||u - v||_{V} \text{ for all } u, v \epsilon V.\tag{2.6}\label{chap1-eq2.6}
\end{equation*}
\end{proposition}

\begin{proof}
If $u, v, \epsilon V$ then taking $\varphi = v - u$ in Proposition \ref{chap1-prop2.1} we can write, with some $\theta_{0} \epsilon ]0, 1[$,
\begin{align*}
J(v) - J(u) & = J'(u + \theta_{0}(v-u), v-u)\\
& = <G(u + \theta_{0} (v-u)), v-u>_{V' \times V}
\end{align*}
and hence
$$
|J(v) - J(u)| \leq ||G(u + \theta_{0} (v-u))||_{V'} ||v-u||_{V} \leq M||v-u||_{V}.
$$
\end{proof}

\section{Convexity and Gateaux Differentiability}\label{chap1-sec3}
A subset $U$ of a vector space $V$ is convex if whenever $u, v \epsilon U$ the segment $\{(1 - \theta)u + \theta v, \theta \epsilon [0, 1]\}$ joining $u$ and $v$ lies in $U$.

\begin{definition}\label{chap1-def3.1}
A functional $J : U \subset V \to \mathbb{R}$ on a convex set $U$ of a vector
space $V$ is said to be convex if
\begin{equation*}
 J((1 - \theta)u + \theta v) \leq (1 - \theta)J(u) + \theta J(v) \text{ for all } u, v \epsilon U \text{ and } \theta \epsilon [0, 1].\tag{3.1}\label{chap1-eq3.1}
\end{equation*}
$J$ is said to be strictly convex if strict inequality holds for all $u, v \epsilon V$ with $u \neq v$ and $\theta \epsilon ]0, 1[$.
\end{definition}

We can write the inequality (\ref{chap1-eq3.1}) in the above definition in the equivalent form 
\begin{equation*}
 J(u + \theta(v - u)) \leq J(u) + \theta(J(v) - J(u)) \text{ for all } u, v \epsilon U \text{ and } \theta \epsilon [0, 1].\tag*{$(3.1)'$}\label{chap1-eq3.1'}
\end{equation*}\pageoriginale

The following propositions relate the convexity of functionals with the properties of their $G$-differentiability

\begin{proposition}\label{chap1-prop3.1}
If a function $J : U \subset V \to \mathbb{R}$ on an open convex set is $G$-differentiable everywhere in $U$ in all directions then
\begin{enumerate}
\item[(1)] $J$ is convex if and only if
$$
J(v) \geq J(u) + J'(u, v-u) \text{ for all } u, v \epsilon U.
$$
\item[(2)] $J$ is strictly convex if and only if
$$
J(v) > J(u) + J'(u, v-u) \text{for all } u, v \epsilon U \text{ with } u \neq v.
$$
\end{enumerate}
\end{proposition}

\begin{proof}
(1) If $J$ is convex then we can write
$$
J(v) - J(u) \geq (J(u + \theta(v - u)) - J(u))/\theta \text{ for all } \theta \epsilon [0, 1].
$$

Now since $J'(u, v-u)$ exists the right side tends to $J'(u, v-u)$ as $\theta \to 0$. Thus taking limits as $\theta \to 0$ in this inequality the required inequality is obtained.

The proof of the converse assertion follows the usual proof in the case of functions. Let $u, v \epsilon V$ and $\theta \epsilon [0, 1]$. We have
\begin{align*}
J(u) & \geq J(u + \theta(v-u)) + J'(u + \theta(v-u)), u(u + \theta(v-u))\\
& = J(u + \theta(v-u)) - \theta J'(u + \theta(v-u), v-u)
\end{align*}
by the homogeneity of the mapping $\varphi \mapsto J'(w, \varphi)$ and
\begin{align*}
J(v) & \geq J(u + \theta(v-u)) + J'(u + \theta(v-u), v-(u + \theta(v - u)))\\
& = J(u + \theta(v-u)) + (1 - \theta) J'(u + \theta(v - u), v-u).
\end{align*}

Multiplying the two inequalities respectively by $(1 - \theta)$ and $\theta$, and adding we obtain
$$
(1 - \theta) J(u) + \theta J(v) \geq J(u + \theta(v-u)),
$$
thus\pageoriginale proving the convexity of $J$.

(2) If $J$ is strictly convex we can, first of all, write
$$
J(v) - J(u) > \theta^{-1} [J(u + \theta(v-u)) - J(u)].
$$

(Here we have used the inequality (\ref{chap1-eq3.1'})). On the other hand, using part (1) of the proposition we have
$$
J(u + \theta(v-u)) - J(u) = J'(u, \theta(v - u)).
$$

Since, by Remark \ref{chap1-rem1.1} of Chapter \ref{chap1}, $J$ is homogeneous in its second argument: i.e.
$$
J'(u, \theta(v-u)) = \theta J'(u, v-u).
$$
\end{proof}

This together with the first inequality implies (2). The converse implication is proved exactly in the same way as in the first part.

\begin{proposition}\label{chap1-prop3.2}
If a functional $J : U \subset V \to \mathbb{R}$ on an open convex set of a normed space $V$ is twice $G$-differentiable everywhere in $U$ and in all directions and if the form $(\varphi, \psi) \mapsto J''(u ; \varphi, \psi)$ is positive semi-definite t. e. if
$$
J''(u: \varphi, \varphi) \geq 0 \text{ for all } u \epsilon U \text{ and } \varphi \epsilon V \text{ with } \varphi \neq 0
$$
then $J$ is convex.
\end{proposition}

If the form $(\varphi, \psi) \mapsto J''(u : \varphi, \psi)$ is positive definite i.e. if
$$
J''(u ; \varphi, \varphi) > 0 \text{ for all } u \epsilon U \text{ and } \varphi \epsilon V \text{ with } \varphi \neq 0
$$
then $J$ is strictly convex.

\begin{proof}
Since $U$ is convex the set $\{u + \theta(v - u), \theta \epsilon [0, 1]\}$ is contained in $U$ whenever $u, v \epsilon U$. Then by Taylor's formula (Proposition \ref{chap1-prop2.2}) we have, with $\varphi = v - u$.
$$
J(v) = J(u) + J'(u, v-u) + \frac{1}{2} J''(u+\theta_{0}(v-u), v-u, v-u)
$$
for some $\theta_{0} \epsilon ]0, 1[.$ Then the positive semi-definitensess of $J''$ implies
$$
J(v) \geq J(u) + J'(u, v - u)
$$\pageoriginale
from which convexity of $J$ follows from (1) of Proposition \ref{chap1-prop3.1}. Similarly the strict convexity of $J$ from positive definiteness of $J''$ follows on application of (2) Proposition \ref{chap1-prop3.1}.
\end{proof}

Now consider the function $J : V \to \mathbb{R}:$
$$
J(v) = \frac{1}{2} a(v . v) - L(v)
$$
of Example \ref{chap1-exam1.1}. We have seen that $J$ twice $G$-differentiable and $J''(u : \varphi. \varphi) = a(\varphi, \varphi)$. Applying Proposition \ref{chap1-prop3.2} we get the

\begin{corollary}\label{chap1-coro3.3}
Under the assumptions of Example \ref{chap1-exam1.1} $J$ is convex (resp. strictly convex) if a $(\varphi, \psi)$ is positive semi-definite (resp. positive definite). i.e. 
\end{corollary}
$J$ is convex if $a(\varphi, \varphi) \geq 0$ for all $\varphi \epsilon V$ (resp. $J$ is strictly convex if $a(\varphi, \varphi) > 0$ for all $\varphi \epsilon V$ with $\varphi \neq 0$).

In particular, if $a(\cdot , \cdot)$ is $V$-coercive then $J$ is strictly convex.

\section[Gateaux Differentiability and Weak Lower...]{Gateaux
  Differentiability and Weak Lower Semi-Continuity}\label{chap1-sec4} 
Let $V$ be a normed vector space. We use the standard notation $``v_{n} \rightharpoonup u''$ to denote weak convergence of a sequence $v_{n}$ in $V$ to u. i.e. For any $g \epsilon V'$ we have
$$
<g, v_{n}>_{V' \times V} \to <g, u>_{V' \times V.}
$$

\begin{definition}\label{chap1-def4.1}
A functional $J : V \to \mathbb{R}$ is said to be weakly lower semi-continuous if for every sequence $v_{n \rightharpoonup} u$ in $V$ we have
$$
\mathop{\lim \inf}_{n \to \infty} J(v_{n}) \geq J(u).
$$
\end{definition}

\begin{remark}\label{chap1-rem4.1}
  The notion of weak lower semi-continuity is a local property. The Definition \ref{chap1-def4.1} and the propositions below can be stated for functionals $J$ defined\pageoriginale on an open subset $U$ of $V$ with minor changes. We shall leave these to the reader.
\end{remark}

\begin{proposition}\label{chap1-prop4.1}
If a functional $J : V \to \mathbb{R}$ is convex and admits a gradient $G(u) \epsilon V'$ at every point $u \epsilon V$ then $J$ is weakly lower semi-continuous.
\end{proposition}

\begin{proof}
Let $v_{n}$ be a sequence in $V$ such that $v_{n} \rightharpoonup  u$ in $V$. Then $<G(u), v_{n} - u>_{V' \times V} \to 0$. On the other hand, since $J$ is convex we have, by Proposition \ref{chap1-prop3.1},
$$
J(v_{n}) \geq J(u) + <G(u), v_{n} - u>
$$
from which on taking limits we obtain
$$
\mathop{\lim \inf.}_{n \to \infty} J(v_{n}) \geq J(u).
$$
\end{proof}

\begin{proposition}\label{chap1-prop4.2}
If a functional $J : V \to \mathbb{R}$ is twice $G$-differentiable everywhere in $V$ in all directions and satisfies
\begin{enumerate}
\item[(i)] $J$ has a gradient $G(u) \epsilon V'$ at all points $u \epsilon V$.
\item[(ii)] $(\varphi, \psi) \mapsto J''(u ; \varphi, \psi)$ is positive semi-definite, i.e. $J''(u; \varphi, \varphi) \geq 0$ for all $u, \varphi \epsilon V$ with $\varphi \neq 0$,
\end{enumerate}
then $J$ is weakly lower semi-continuous.
\end{proposition}

\begin{proof}
By Proposition \ref{chap1-prop3.2} the condition (ii) implies that $J$ is convex. Then the assertion follows from Proposition \ref{chap1-prop4.1}.
\end{proof}

We now apply Proposition \ref{chap1-prop4.2} to the functional
$$
v \mapsto J(v) = \frac{1}{2} a(v, v) - L(v)
$$
of Example \ref{chap1-exam1.1}. We know that it has a gradient
$$
G(u) : \varphi \mapsto <G(u), \varphi> = a(u, \varphi) - L(\varphi)
$$
and\pageoriginale $J''(u; \varphi, \varphi) = a(\varphi, \varphi)$ for all $u, \varphi \epsilon V$.

If further we assume that $a(\cdot ,\cdot)$ is $V$-coercive, i.e. there exists an $\alpha > 0$ such that
$$
(J''(u ; \varphi, \varphi) =) a(\varphi, \varphi) \geq \alpha||\varphi||_{V}^{2} (\geq 0) \text{ for all } \varphi \epsilon V
$$
then by Proposition \ref{chap1-prop4.2} we conclude that $J$ is weakly
lower semi - continuous.

\section{Commutation of Derivations}\label{chap1-sec5}
We shall admit without proof the following useful result on commutativity of the order of derivations.

\begin{theorem}\label{chap1-thm5.1}
Let $U$ be an open set in a normed vector space $V$ and $J : U \subset V \to \mathbb{R}$ be a functional on $U$. If
\begin{enumerate}
\item[(i)] $J''(u; \varphi, \psi)$ exists everywhere in $U$ in all directions $\varphi, \psi \epsilon V$, and

\item[(ii)] for every pair $\varphi, \psi \epsilon V$ the form $u \mapsto J''(u, \varphi, \psi)$ is continuous
\end{enumerate}
then we have
$$
J''(u, \varphi, \psi) = J''(u; \psi, \varphi) \text{ for all } \varphi, \psi \epsilon V.
$$
For a proof we refer to \cite{key12}.
\end{theorem}

As a consequence we deduce the

\begin{corollary}\label{chap1-coro5.2}
If a functional $J : U \subset V \to \mathbb{R}$ on an open set of a normed vector space $V$ admits a Hessian $H(u) \in \mathscr{L} (V, V')$ at every points $u \in U$ and if the mapping $U \ni u \mapsto H(u) \in \mathscr{L} (V, V')$ is continuous then $H(u)$ is self adjoint.
$$
\text{ i.e. } <H(u) \varphi, \psi>_{V' \times V} = <H(u) \psi, \varphi>_{V' \times V} \text{ for all } \varphi, \psi \in V.
$$
\end{corollary}

\section{Frechet Derivatives}\label{chap1-sec6}
Let $V$ and $H$ be two normed vector spaces.

\begin{definition}\label{chap1-def6.1}
A mapping $A : U \subset V \to H$ from an open set $U$ in $V$ to $H$ is said to be F\'{r}echet differentiable (or simply $F$-differentiable) at a point $u \in U$ if there exists a continuous linear mapping $A' (u) : V \to H$, i.e. $A'(u) \in \mathscr{L} (V , H)$ such that
\begin{equation*}
 \lim_{\varphi \to 0} ||A(u + \varphi) - A(u) - A'(u) \varphi||/ ||\varphi|| = 0.\tag{6.1}\label{chap1-eq6.1}
\end{equation*}
\end{definition}\pageoriginale

Clearly, $A'(u)$, if it exists, is unique and is called the Fr\'{e}chet derivative ($F$-derivative) of $A$ at u.

We can, equivalently, sat that a mapping $A : U \subset V \to H$ is $F$-differentiable at a point $u \in U$ if there exists an element $A'(u) \in \mathscr{L}(V ; H)$ such that
\begin{align*}
& A(u + \varphi) = A(u) + A'(u)\varphi + ||\varphi||_{V} \in (u, \varphi) \text{ where } \in(u, \varphi) \in H \text{ and }\\
&  \in(u, \varphi) \to 0 \text{ in } H \text{ as } \varphi \to 0 \text{ in } V.\tag{6.2}\label{chap1-eq6.2}
\end{align*}

\begin{example}\label{chap1-exam6.1}
If $f$ is a function defined in an open set $U \subset \mathbb{R}^{2}$, i.e. $f : U \to \mathbb{R}$, then it is $F$-differentiable if it is once differentiable in the usual sense and
$$
f'(u) = grad f(u) = (\partial f / \partial x_{1} (u), \partial f/ \partial x_{2} (u)) \in \mathscr{L} (\mathbb{R}^{2}, \mathbb{R}).
$$ 
\end{example}

\begin{example}\label{chap1-exam6.2}
In the case of the functional 
$$
v \mapsto J(v) = \frac{1}{2} a(v, v) - L(v)
$$
Of Example \ref{chap1-exam1.1} where (i) and (iii) are satisfied on a Hilbert space $V$ we easily check that $J$ is $F$-differentiable everywhere in $V$ and its $F$-derivative isgiven by
$$
\varphi \mapsto J'(u) \varphi = a(u, \varphi) - L(\varphi).
$$
\end{example}

In\pageoriginale fact, by (i) and (iii) of Example \ref{chap1-exam1.1} $J'(u) \in V'$ since $\varphi \mapsto a(u, \varphi)$ and $\varphi \mapsto L(\varphi)$ are continuous linear and we have
$$
J(u + \varphi) - J(u) - [a(u, \varphi) - L(\varphi)] = a(\varphi, \varphi) = ||\varphi||_{V} \in (u, \varphi)
$$
where $\in (u, \varphi) = ||\varphi||_{V}^{-1} a(\varphi, \varphi)$ and
$$
0 \leq \in (u, \varphi) \leq M||\varphi||_{V}
$$
so that $\in (u, \varphi) \to 0$ as $\varphi \to 0$ in $V$.

We observe that in this case the $F$-derivative of $J$ is the same as the gradient of $J$.

\begin{remark}\label{chap1-rem6.1}
If an operator $A : U \subset V \to H$ is $F$-differentiable then it is also $G$-differentiable and its $G$-derivative coincides with its $F$-derivative. In fact, let A be $F$-differentiable with $A'(u)$ as its $F$-derivative. Then, for $u \in U$, $\varphi \in V$, $\varphi \neq 0$, writting $\psi = \rho \varphi$ we have $\psi \to 0$ in $V$ as $\rho \to 0$ and 
\begin{align*}
& \rho^{-1} (A(u + \rho \varphi) - A(u) - A'(u)\varphi)\\
& = \rho^{-1} (A(u + \psi) - A(u) - A'(u)\psi) \text{ since }  A'(u) \text{ is linear }\\
& = \rho^{-1} ||\psi|| \in (u, \psi) = ||\varphi|| \in (u, \psi) \to 0 \text{ in } H \text{ as } \psi \to 0 \text{ in } H \text{ i.e. as} \rho \to 0.
\end{align*}
\end{remark}

\begin{remark}\label{chap1-rem6.2}
However, in general, the converse is not true. Example \ref{chap1-exam1.2} shows that the function $f$ has a $G$-derivative but not $F$-differentiable. We also note that the $G$-derivative need not be a linear map of $V$ into $H$ (as in Example \ref{chap1-exam1.2}) while the $F$-derivative is necessarily linear by definition and belongs to $\mathscr{L}(V, H)$.
\end{remark}

\begin{remark}\label{chap1-rem6.3}
The notions of $F$-differentiability of higher orders and the
corresponding $F$-derivatives can be defined in an obvious
manner. Since, whenever we have $F$-differentiability we also have $G$
- differentiability the Taylor's\pageoriginale formula and hence all
its consequences remain valid under the assumption of
$F$-differentiability. We shall not therefore mention these facts
again. 
\end{remark}

\section{Model Problem}\label{chap1-sec7}
We shall collect here all the results we have obtained for the case of the functional
$$
v \mapsto J(v) = \frac{1}{2} a(v, v) - L(v)
$$
on a Hilbert space $V$ satisfying conditions (i), (ii) and (iii) of Example \ref{chap1-exam1.1}. This contains, as the abstract formulation, most of the linear elliptic problems that we shall consider except for the case of non-symmetric elliptic operators.
\begin{enumerate}
\item[(1)] $J$ is twice Fr\'{e}chet differentiable (in fact, $F$-differentiable of all orders) and hence is also Gateaux differentiable.
$$
J'(u, \varphi) = a(u, \varphi) - L(\varphi) \text{ and } J''(u ; \varphi, \psi) =a(\varphi, \psi).
$$
$J$ has a gradient and a Hessian at every point $u \in V$
$$
G(u) = (grad J)(u) : \varphi \mapsto a(u, \varphi) - L(\varphi).
$$
Moreover, $H(u)$ is self-adjoint since $a(\varphi, \psi) = a(\psi, \varphi)$ for all $\varphi,\break \psi \in V$.

\item[(2)] {\textit{Taylor's formula for}} $J$ If $u, v, \in V$ then
$$
J(v) = J(u) + \{a(u, v - u) -L(v - u)\} + \frac{1}{2} a(v - u, v - u)
$$

\item[(3)] Since the mapping $v \mapsto a(u, v)$ for any $u \in V$ is continuous linear and $L \in V'$, by the theorem of Fr\'{e}chet-Riesz on Hilbert spaces there exist (unique elements $A u$, $f \in V$ such that
$$
a(u, v) = (A u, v)_{V} \text{ and } L(v) = (f, v)_{V} \text{ for all } v \in V
$$
Clearly\pageoriginale $A : V \to V$ is a continuous linear map. Moreever we have
\begin{align*}
||A||_{\mathscr{L}(V, V)} \leq M \text{ by } (i),\\
(Av, v)_{V} \geq \alpha||v||_{V}^{2} \text{ for all } v \in V \text{ by (ii) and }\\
||f||_{V} \leq N.
\end{align*}
\item[(4)] The functional $J$ is strictly convex in $V$.

\item[(5)] $J$ is weakly lower semi-continuous in $V$.
\end{enumerate}

