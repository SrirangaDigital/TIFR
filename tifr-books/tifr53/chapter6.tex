
\chapter[Elements of the Theory of Control and...]{Elements of the
  Theory of Control and Elements of Optimal Design}\label{chap6} 

This\pageoriginale chapter will be concerned with two problem which
can be treated can be using the techniques developed in the previous
chapters, namely, 
\begin{enumerate}
\item[(1)] the optimal control problem,

\item[(2)] the problem of optimal design.
\end{enumerate}

These two problems are somewhat similar. We shall reduce the problems
to suitable minimization problems so that we can use the algorithms
discussed in earlier chapters to obtain approximations to the solution
of the two problems considered here. 

\section{Optimal Control Theory}\label{chap6-sec1}

We shall give an abstract formulation of the problem of optimal
control and this can be considered as a problem of optimization for a
functional on a convex set of functions. By using the duality method
for example via the theorem of $Ky$ Fan and Sion we reduce our control
problem to a system consisting of the state equation, the adjoint
state equation, and a variational inequality for the solution of the
original problem. The variational inequality can be considered as
Pontrjagin maximum principle well known in control theory. Inorder to
obtain an algorithm we eliminate at least formally the state and
obtain a pure minimization problem for which we can use the
appropriate algorithms described in earlier chapters: 

The theory of optimal control can roughly be described starting from the following data. We are given
\begin{enumerate}
\item[(i)] A\pageoriginale control $u$, which belogs to a given convex set $K$ of functions $K$ is called the set of controls.

\item[(ii)] The state (of the system to be controled) $y(u) \equiv y_{u}$ is, for a given $u \epsilon K$, a solution of a functional equation. This equation is called the state equation governing the problem of control.

\item[(iii)] A functional $J(y, u)$ - called the cost function - defined by means of certain non-negative functionals of $u$ and $y$.
\end{enumerate}

If we set
$$
j(u) = J(y_{u}, u)
$$
then the problem of optimal control consists in finding a solution of the minimization problem:
\begin{equation*}
\begin{cases}
& u \epsilon K \text{ such that}\\
& j(v) = \inf_{v \epsilon K} j(v).
\end{cases}
\end{equation*}

Usually the state equations governing the system to be controled are
ordinary or partial differential equation. 

The main object of the theory is to find necessary (and sufficient)
conditions for the existence and uniqueness of the solution of the
above problem and to obtain algorithm for determining approximations
to the solutions of the problem. We shall restrict ourselves to the
optimal control problem governed by partial differential equaiton of
elliptic type, more precisely, by linear homogeneous variational
elliptic boundary value problems. One can also consider, in a similar
way, the problems governed by partial differential equation of
evolution type. (See, for instance, the book of Lions \cite{key31}.) 

\subsection{Formulation of the Problem of Optimal Control}\label{chap6-subsec1.1}

Let\pageoriginale $\Omega$ be a bounded open set in the Euclidean
space $\mathbb{R}^{n}$ with smooth boundary $\Gamma$. We shall denote
the inner product and the corresponding norm in the Hilbert space
$L^{2} (\Omega)$ by $(\cdot , \cdot)$ and $|| \cdot ||$ while those in
the Sobolev space $V = H^{1} (\Omega)$ by $((\cdot , \cdot))$ and $|||
\cdot |||$ respectively. 

We suppose given the following:

\medskip
\noindent{\textbf{Set of controls.}} A nonempty closed convex subset
$K$ of $L^{2} (\Omega)$, called the set of controls, and we denote the
elements of $K$ by $u$, which we call controls. 

\medskip
\noindent{\textbf{State equation.}} A continuous, bilinear, coercive
form $a(\cdot , \cdot)$ on $V$ i.e. there exists contants $\alpha_{a}
> 0$ and $M_{a} > 0$ such that 
\begin{equation*}
\begin{cases}
|a(\varphi, \psi)| \leq M_{a} |||\varphi||| |||\psi||| & \text{ for all } \varphi, \psi \epsilon V\\
a(\varphi, \varphi) \geq \alpha_{a} |||\varphi|||^{2} & \text{ for all } \varphi \epsilon V.\tag{1.1}\label{chap6-eq1.1}
\end{cases}
\end{equation*}

Let $f \epsilon L^{2} (\Omega)$ be given.

For any $u \epsilon K$ a solution of the functional equation
\begin{equation*}
\begin{cases}
& y_{u} \epsilon V,\\
& a(y_{u}, \varphi) = (f, \varphi) + (u, \varphi) \quad \text{ for all } \varphi \epsilon V\tag{1.2}\label{chap6-eq1.2}
\end{cases}
\end{equation*}
is said to define a state. The system to be governed is said to be
governed by the state equation (\ref{chap6-eq1.2}). We know, by the
results of Chapter \ref{chap2}, that for any $u \epsilon K (\subset
L^{2} (\Omega) \subset V')$ there exists a unique solution $y_{u}$ of
(\ref{chap6-eq1.2}). Thus for a given $f$ and a given control $u
\epsilon K$ there exists a unique state $y_{u}$ governing the system. 

{\em Cost function.} Let $b(\cdot , \cdot)$ be a symmetric, continuous
and positive semidefinite form on $V$. i.e. There exists a constant
$M_{b} > 0$ such that  
\begin{equation*}
\begin{cases}
 b (\varphi, \psi) = b(\psi, \varphi) & \text{ for all } \varphi. \psi \epsilon V\\
 |b(\varphi, \psi)| \leq M_{b} |||\varphi||| |||\psi||| & \text{ for all } \varphi, \psi \epsilon V\\
 B(\varphi, \varphi) \geq 0. &   \tag{1.3}\label{chap6-eq1.3}
\end{cases}
\end{equation*}\pageoriginale

Further let $C \epsilon \mathscr{L} (L^{2} (\Omega), L^{2} (\Omega))$ be an operator the following conditions: there exist positive constants $\alpha_{C} \geq 0$ and $M_{C} > 0$ such that
\begin{equation*}
\begin{cases}
& (Cv, v) \geq \alpha_{C} ||v||^{2}, \text{ for all } v \epsilon L^{2} (\Omega)\\
& ||C|| \leq M_{C}\tag{1.4}\label{chap6-eq1.4}
\end{cases}
\end{equation*}

Let $y_{g} \epsilon V$ be given. We now define the functional
\begin{equation*}
J(y, u) = \frac{1}{2} b(y - y_{g}, y-y_{g}) + \frac{1}{2} (Cu, u)\tag{1.5}\label{chap6-eq1.5}
\end{equation*}

\medskip
\noindent{\textit{Proof of control.}} This consists in finding a solution of the minimization problem:
\begin{equation*}
\begin{cases}
u \epsilon K \text{ such that}\\
J(y_{u}, u) = \inf_{v \epsilon K} J(y_{v}, v)\tag{1.6}\label{chap6-eq1.6}
\end{cases}
\end{equation*}

We shall show in the next section that the problem (\ref{chap6-eq1.6})
has a unique solution. However, we remark that one can also prove that
a solution of (\ref{chap6-eq1.6}) $u$ exists and is unique directly
using the differential calculus of Chapter \ref{chap1} and the results
of Chapter \ref{chap2} on the existence and uniqueness of minima of
convex functionals. 

\begin{definition}\label{chap6-def1.1}
The unique solution $u \epsilon K$ of the problem (\ref{chap6-eq1.6}) is called the optimale control.
\end{definition}

\begin{remark}\label{chap6-rem1.1}
If the control set $K$ is a convex set described by a set of functions
defined over the whole of $\Omega$ and the constraint conditions are
imposed on the whole of $\Omega$ then the problem (\ref{chap6-eq1.6})
is said to be one of distributed control. This is the case we have
considered here. However, we can also consider in a similar way the
problem when $K$ consists of functions defined over\pageoriginale the
boundary $\Gamma$ of $\Omega$ and satisfying constraint conditions on
$\Gamma$. In this case the problem is said to be one of boundary
control - For example, we can consider 
$$
\varphi \mapsto \int_{\Gamma} u \varphi d \sigma
$$
defined on a suiteble class of functions $\varphi$ on $\Gamma$.
\end{remark}

\begin{remark}\label{chap6-rem1.2}
If we set
$$
j(u) = J(y_{u}, u)
$$
then the problem of control is a  minimization problem for the functional $u \mapsto j(u)$ on $K$.
\end{remark}

\begin{remark}\label{chap6-rem1.3}
Usually the state equation governing the system to be controled are
ordinary differential equations or partial differential equation or
linear equations. (See the book of Lions \cite{key31}). 
\end{remark}

\begin{remark}\label{chap6-rem1.4}
We have restricted ourselevs to systems governed by a linear
homogeneous boundary problem of Neumann type with distributed
control. One can treat in a similar way the systems governed  by other
homogeneous or inhomogeneous boundery calue problems; for instance,
problems of Dirichlet type, mixed case we necessarily have
inhomogeneous problems. 
\end{remark}

\begin{remark}\label{chap6-rem1.5}
In practice, the operator $C$ is of the form $\alpha I$ where $\alpha > 0$ is a small number.
\end{remark}

\subsection{Duality and Existence}\label{chap6-subsec1.2}

We shall show that there exists a unique of the optimal control
problem (\ref{chap6-eq1.6}). We make use the existence of saddle point
via the theorem of $Ky$\pageoriginale Fan and Sion (Theorem
\ref{chap5-thm1.2} of Chapter \ref{chap5}) for this purpose. This also
enables us to characterize the solution of the optimal control problem
(\ref{chap6-eq1.6}). As in the earlier chapters we also obtain the
dual problem govergned by the adjoint state equation. 

We consider the optimal control problem as a minimization problem for
this purpose and we duality in the vaiable $y$ keeping $u$ fixed in
$K$. 

We take for the cone $\Lambda$ the space $V = H^{1} (\Omega)$ it self define the functional 
\begin{equation*}
\Phi : V \times \Lambda \to \mathbb{R}\tag{1.7}\label{chap6-eq1}
\end{equation*}
by setting
\begin{equation*}
\Phi (y, u, q) = a(y, q) - (f + u, q).\tag*{$(1.7)'$}
\end{equation*}

It is clear that $\Phi$ is homogeneous of degree in $q$:
$$
\Phi (y, u = \lambda q) = \lambda  \Phi (y, u [ q) \text{ for all } \lambda > 0.
$$

Next $\Phi (y, u ; q) \leq 0$ for all $q \epsilon \Lambda$ if and only
if $u \in K$ and $y$, $u$ are related by the state equation
(\ref{chap6-eq1.2}). In fact, the state equation implies that $\Phi
(y, u ; q) = 0$. Conversely, $\Phi (y, u ; q) \leq 0$ implies that $u
\epsilon K$ and $y$, $u$ are related by the state equation. For, we
have 
$$
a(y, q) - (f + u, q) \leq \text{ for all } q \epsilon \Lambda
$$ 
and since, for any $q \epsilon \Lambda$, $-q \epsilon \Lambda$ also we have
$$
a(y, -q) - (f+u, -q) \leq 0.
$$

The two inequalities together imply that
$$
a(y, q) = (f+u, 1) \text{ for all } q \epsilon \Lambda = V = H^{1}(\Lambda),
$$\pageoriginale
which means that $y = y_{u} = u(u)$. We introduce the Lagrangian $\mathscr{L}$ associated to the minimization problem by setting
\begin{equation*}
\mathscr{L} (z, v ; q) = J(z, v) + \Phi (z, v;q).\tag{1.8}\label{chap6-eq1.8}
\end{equation*}

More explicitly we have
\begin{equation*}
\begin{cases}
& \mathscr{L}(z, v ; q) = \frac{1}{2} b (z-y_{g}, z-y_{g}) + \frac{1}{2} (cz, z) + a(z, q) - (f + v, q)\\
& \text{ for } z \epsilon V, v \epsilon K \text{ and } q \epsilon \Lambda = V.\tag*{$(1.8)'$}\label{chyap6-eq1.8'}
\end{cases}
\end{equation*}

We shall now prove the following theorem:

\begin{theorem}\label{chap6-thm1.1}
There exists a saddle point for $\mathscr{L} (z, v ; q)$ in $V \times K \times V$.

In other words,
\begin{equation*}
\begin{cases}
& \text{ Theorem exists } (y, u ; p) \epsilon V \times K \times V \text{ such that }\\
& \mathscr{L} (y, u ; q) \leq \mathscr{L} (y, u ; p) \leq \mathscr{L} (z, v ; p) \text{ for all } (z, v ; q) \epsilon V \times K \times V.\tag{1.9}\label{chap6-eq1.9}
\end{cases}
\end{equation*}
\end{theorem}

\begin{proof}
The proof will be carried out in several steps.

{\em Step 1.} {\em(Application of the theorem of Ky Fan and Sion).} Let $\ell > 0$ be a constant which we shall choose suitably later. Consider the two sets
\begin{equation*}
\begin{cases}
\Lambda_{\ell} = U_{\ell} = \{ z | z \epsilon V = H^{1} (\Omega) ; |||z||| \leq \ell \} \text{ and }\\
K_{\ell} = \{v | v \epsilon K : ||v|| \leq \ell \}.\tag{1.10}\label{chap6-eq1.10}
\end{cases}
\end{equation*}

It is clear that $\Lambda_{\ell} = U_{\ell}$ is a closed convex and bounded set in $V$. Since $K$ is closed and convex $K_{\ell}$ is  also a closed convex subset of $L^{2} (\Omega)$. Hence, for the weak topologies $V$ and $L^{2}(\Omega)$ are Hausdorff topological vector spaces in which $U_{\ell}$, (respectively $K_{\ell}$) is compact.

On\pageoriginale the other hand, since, for every $(z, v) \epsilon U_{\ell} \times K_{\ell}$, the functional 
$$
U_{\ell} \ni q \mapsto \mathscr{L} (z, v : q) \epsilon \mathbb{R}
$$
is linear and strongly (and hence also for the weak topology on $V$) continuous it is concave and upper semi-continuous (for the weak topology on $V$). The mapping
$$
U_{\ell} \times K_{\ell} \ni (z, v) \mapsto \mathscr{L} (z, v ; q) \epsilon \mathbb{R}
$$
is strongly continuous and hence, in particular, (weakly) lower
semi-continuous for every fixed $q \epsilon \Lambda_{\ell} =
K_{\ell}$. Since the bilinear forms $a(\cdot , \cdot)$, $b(\cdot ,
\cdot)$ on $V$ and $(C \cdot , \cdot)$ on $L^{2} (\Omega)$ are
positive semi-definite and $v \mapsto (v, q)$ is linear it follows
from the results of Chapter \ref{chap1} \S\ \ref{chap1-sec3} that the
mapping 
$$
(z, v) \mapsto \mathscr{L}(, v; q)
$$
is convex.

Thus all the hypothesis of the theorem of Ky Fan and Sion (Theorem \ref{chap5-thm1.2} of Chapter \ref{chap5}) are satisfied. Hence there exists a saddle point $(y_{\ell}, u_{\ell} ; p_{\ell}) \epsilon U_{\ell} \times K_{\ell} \times U_{\ell}$ This is the same as saying
\begin{equation*}
\begin{cases}
& \text{ there exists } (y_{\ell}, u_{\ell} ; p_{\ell}) \epsilon U_{\ell} \times K_{\ell} \times \Lambda_{\ell} \text{ such that }\\
& J(y_{\ell}, u_{\ell}) + \Phi (y_{\ell}, u_{\ell} ; q) \leq
  J(y_{\ell}, u_{\ell}) + \Phi (y_{\ell}, u_{\ell}; p_{\ell})\\
&\qquad\qquad\leq J(z, v) + \Phi (z, v : p_{\ell})\\
& \text{for all } (z, v ; q) \epsilon U_{\ell} \times K_{\ell} \times \Lambda_{\ell}.\tag*{$(1.11)'$}\label{chap6-eq1.11'}
\end{cases}
\end{equation*}

Choosing $\ell > 0$ sufficiently large we shall show, in the following steps that $y_{\ell}, u_{\ell}, p_{\ell}$ are bounded independent of the choice of such an $\ell$.

{\em Step 2.} {\em $u_{\ell}$ is bounded.} In fact, the second
inequality in (\ref{chap6-eq1.11'}) means that the functional  
$$
(z, v) \mapsto \mathscr{L} (z, v ; p_{\ell})
$$ \pageoriginale
on $U_{\ell} \times K_{\ell}$ attains a local minimum at $(y_{\ell}, u_{\ell})$. But since this functional is convex, by Lamma \ref{chap2-lem2.1} of Chapter \ref{chap2}, it is also a global minimum. i.e. We have
\begin{equation*}
\begin{cases}
& \mathscr{L} (y_{\ell}, u_{\ell}, q_{\ell}) \leq \mathscr{L} (y_{\ell}, u_{\ell} ; p_{\ell}) \leq \mathscr{L} (z, v ; p_{\ell})\\
& \text{ for all } z \epsilon V, v \epsilon K \text{ and } q \epsilon \Lambda_{\ell} = U_{\ell}.\tag{1.12}\label{chap6-eq1.12}
\end{cases}
\end{equation*}

Now we fix a $v \epsilon K$ arbitrarily and take $q = 0, z = y_{v}$ in \ref{chap6-eq1.11'} and we obtain
$$
J(y_{\ell}, u_{\ell}) \leq J(y_{\ell}, u_{\ell}) + \Phi (y_{\ell},
u_{\ell} ; p_{\ell}) \leq J(y_{v}, v) \equiv j(v). 
$$

It follows from this that, for any fixed $v \epsilon K$, we have
\begin{equation*}
\Phi(y_{\ell}, u_{\ell}, p_{\ell}) \geq 0 \text{ and } J(y_{\ell},
u_{\ell}) \leq J(v).\tag{1.13}\label{chap6-eq1.13} 
\end{equation*}

But by (\ref{chap6-eq1.3}), (\ref{chap6-eq1.4}) the latter inequality in (\ref{chap6-eq1.13}) implies that 
$$
\frac{1}{2} \alpha_{C} ||u_{\ell}||^{2} \leq J(y_{\ell}, u_{\ell}) \leq j(v).
$$
which means that $u_{\ell}$ is bounded:
\begin{equation*}
||u_{\ell}|| \leq c_{1}, c_{1}^{2} = 2\alpha_{C}^{-1} j(v).\tag{1.14}\label{chap6-eq1.14}
\end{equation*}

{\em Step 3.} {\em $y_{\ell}$ is bounded.} As before we fix a $v \epsilon K$ and take $z = y_{v}$, $q = \ell |||y_{\ell}|||^{-1} \epsilon U_{\ell} = \Lambda_{\ell}$ in \ref{chap6-eq1.11'}. (We may assume that $y_{\ell} \neq 0$, for otherwise there is nothing to prove). We get
$$
J(y_{\ell}, u_{\ell}) + \ell|||y_{\ell}|||^{-1} \Phi(y_{\ell}, u_{\ell}, y_{\ell}) \leq j(v)
$$
because of the homogeneity of $\Phi$ in the last argument. Here $J(y_{\ell}, u_{\ell}) \geq 0$ because of (\ref{chap6-eq1.3}), (\ref{chap6-eq1.4}) and (\ref{chap6-eq1.5}) so that we get
$$
\ell |||y_{\ell}|||^{-1} \Phi (y_{\ell}, u_{\ell} ; y_{\ell}) \leq j(v).
$$
$$
\text{ i.e. }\qquad \ell|||y_{\ell}|||^{-1} \{a(y_{\ell}, y_{\ell}) - (f+ u_{\ell}, y_{\ell}) \} \leq j(v).
$$\pageoriginale

By the coercivity (\ref{chap6-eq1.1}) of $a(\cdot , \cdot)$ on $V$ we have
$$
\alpha_{a} |||y_{\ell}|||^{2} \leq a (y_{\ell}, y_{\ell})
$$
and by the Cauchy-Schwarz inequality we have
$$
|(f + u_{\ell}, y_{\ell})| \leq ||f+u_{\ell}|| ||y_{\ell}|| \leq (||f|| + ||u_{\ell}||) |||y_{\ell}|||.
$$

Hence using (\ref{chap6-eq1.14})
\begin{align*}
\ell \alpha _{a} |||y_{\ell}||| & \leq j(v) + \ell|||y_{\ell}|||^{-1} (f+u_{\ell}, y_{\ell})\\
& \leq j(v) + \ell(||f|| + ||u_{\ell}||)\\
\leq j(v) + \ell (||f|| + C_{1})
\end{align*}
so that, first by dividing by $\ell$, we see that if $\ell > 1$ then 
\begin{equation*}
|||y_{\ell}||| \leq \alpha_{a}^{-1} (j(v) + ||f|| + C_{1}) \equiv
C_{2}. \tag{1.15}\label{chap6-eq1.15}
\end{equation*}

{\em Step 4.} {\em $p_{\ell}$ is bounded.} For this we recall that, as
has already been observed, $(y_{\ell}, u_{\ell})$ is a global minimum
for the convex functional 
$$
g : (z, v) \mapsto \mathscr{L} (z, v ; p_{\ell})
$$
on $V \times K$. Hence, by Theorem \ref{chap2}. \ref{chap2-thm1.3}, the G-derivative of g at $(y_{\ell}, u_{\ell})$ should vanish:
$$
g'(y_{\ell}, u_{\ell} ; \varphi , v) = 0 \text{ for all } (\varphi, v) \epsilon V \times K.
$$

This on calculation of the derivative gives
\begin{equation*}
\begin{cases}
& b(y_{\ell} - y_{g}, \varphi) + (Cu_{\ell}, v) + a(\varphi, p_{\ell}) - (f+u_{\ell}, \varphi) = 0\\
& \text{ for all } (\varphi, v) \epsilon V \times K.
\end{cases}
\end{equation*}

Taking\pageoriginale $\varphi = p_{\ell}$ and $v = u_{\ell}$ we get
$$
(Cu_{\ell}, u_{\ell}) + a(p_{\ell}, p_{\ell}) = (f+u_{\ell}, p_{\ell}) - b(y_{\ell} - y_{g}, p_{\ell}).
$$

Using the coercivity of the terms on the left side and Cauchy - Schwarz
inequality for the first term on the right side together with the
continuity of $b(\cdot , \cdot)$ we find that  
\begin{align*}
\alpha_{a} |||p_{\ell}|||^{2} & \leq \alpha_{C} ||u_{\ell}||^{2} + \alpha_{a} |||p_{\ell}|||^{2} \leq ||f+u_{\ell}|| ||p_{\ell}|| + M_{b} |||y_{\ell} - y_{g} ||| |||p_{\ell} |||\\
& \leq (||f|| + ||u_{\ell}|| + M_{b} |||y_{\ell} - y_{g}|||) |||p_{\ell}|||\\
& (||f|| + c_{1} + M_{b} c_{2} + M_{b} |||y_{g}|||) |||p_{\ell}|||
\end{align*}
which implies that there exists a constant $c_{3} > 0$ such that
\begin{equation*}
|||p_{\ell}||| \leq c_{3}.\tag{1.16}\label{chap6-eq1.16}
\end{equation*}

{\em Step 5.} We now choose $\ell > \max (c_{1}, c_{2}, 2c_{3}, 1)$ and use the sets $U_{\ell}$ and $K_{\ell}$ for the application of the theorem of Ky Fan and Sion.

{\em Step 6.}  {\em To show that} $y_{\ell} = y_{u_{\ell}}$ (i.e. $y_{\ell}$ is the solution of the state equation corresponding to the control $u_{\ell} \epsilon K.$) For this purpose we have to show that
\begin{equation*}
\Phi (y_{\ell}, u_{\ell} ; q) = 0 \text{ for all } q \epsilon \Lambda = V\tag{1.17}\label{chap6-eq1.17}
\end{equation*}

We already know from (\ref{chap6-eq1.13}) that $\Phi (y_{\ell}, u_{\ell} ; p_{\ell}) \geq 0$. Since $q = 2p_{\ell} \epsilon \Lambda = V$ satisfies
$$
|||q||| = 2|||p_{\ell}||| \leq 2c_{3} < \ell
$$
we can take $q = 2p_{\ell}$ in the first inequality of \ref{chap6-eq1.11'} and get
$$
2\Phi (y_{\ell}, u_{\ell} ; p_{\ell}) \leq \Phi (y_{\ell}, u_{\ell}, p_{\ell}).
$$
so that we also have
\begin{equation*}
\Phi (y_{\ell}, u_{\ell} ; p_{\ell}) \leq 0 \tag{1.18}\label{chap6-eq1.18}
\end{equation*}\pageoriginale

Then it follows once again from the first inequality of \ref{chap6-eq1.11'} that
\begin{equation*}
\Phi (y_{\ell}, u_{\ell} ; q) \leq 0 \text{ for all } q \epsilon \Lambda_{\ell} = U_{\ell}\tag{1.19}\label{chap6-eq1.19}
\end{equation*}

If $q \notin U_{\ell}$ then $\ell |||q|||^{-1} q \epsilon U_{\ell}$
which on substituting in (\ref{chap6-eq1.19}) gives
(\ref{chap6-eq1.17}). 

Finally, combining the facts (\ref{chap6-eq1.12}) and
(\ref{chap6-eq1.17}) together with the definition of $\mathscr{L}(z, v ;
q)$ we conclude the there exists a saddle point $(y, u ; p)$ in $V
\times K \times V$. This completes the proof of the theorem. 

The theoem (\ref{chap6-eq1.1}) implies that $(y, u)$ is the solution of
the primal problem and $p$ is the solution of the dual problem. The
equation (\ref{chap6-eq1.17}) is nothing but the fact that $y$ is the
solution $y_{u}$ of the state equation. 

From the above theorem we obtain the main result on existence (and
uniqueness) of the solution to the optimal control problem and also a
characterization of this solution. For this purpose, if we choose $v =
u$ in the second inequality of (\ref{chap6-eq1.9}) we find that $y
\epsilon V$ is the minimum of the convex functional 
$$
h : V \ni z \mapsto \mathscr{L} (z, u ; p) \epsilon \mathbb{R}.
$$

Hence taking the $G$-derivative of h we should have
$$
h' (u, \psi) = b(y - y_{g}, \psi) + a(\psi, p) = 0 \text{ for all } \psi \epsilon V.
$$

Thus we see that p satisfies the equation
\begin{equation*}
a(\psi, p) = -b(y - y_{g}, \psi) \text{ for all } \psi \epsilon V.\tag{1.20}\label{chap6-eq1.20}
\end{equation*}

The equation (\ref{chap6-eq1.20}) is thus the adjoint state equation
in the present problem. Again, in view of the hypothesis
(\ref{chap6-eq1.1}) and (\ref{chap6-eq1.3}) it follows (by the
Lax-Milgram lemma) that, for any given $y \epsilon V$, there exists a
unique solution $p \epsilon V$ of the wquation\pageoriginale
(\ref{chap6-eq1.20}). 

Now consider the functional
$$
k : K \ni v \mapsto \mathscr{L}(y, v ; p) \epsilon \mathbb{R}.
$$

The secone inequality in (\ref{chap6-eq1.9}) with $z = y$ implies that
this functional $k$ is minimum at $v = u$. Again taking G-derivatives we
have 
$$
k'(v, w) = (Cv, w) - (w, p) \text{ for all } w \epsilon K.
$$

The solution of the minimization problem for $k$ on $K$ is, by theorem
\ref{chap2-thm2.2} of Chapter \ref{chap2}, characterized by 
\begin{equation*}
\begin{cases}
& u \epsilon K \text{ such that }\\
& k'(u, v - u) \geq 0 \text{ for all } v \epsilon K,
\end{cases}
\end{equation*}
which is the same as the variational inequality
\begin{equation*}
\begin{cases}
& u \epsilon K \text{ such that }\\
(Cu, v-u) - (p, v-u) \geq 0 \text{ for all } v \epsilon K.\tag{1.21}\label{chap6-eq1.21}
\end{cases}
\end{equation*}
\end{proof}

The above facts can now be summarized as follows:

\begin{theorem}\label{chap6-thm1.2}
Suppose given the set $K$ of controls, the state equation
(\ref{chap6-eq1.2}) and the cost function $J$ defined by
(\ref{chap6-eq1.5}) such that the hypothesis (\ref{chap6-eq1.1}),
(\ref{chap6-eq1.3}) and (\ref{chap6-eq1.4}) are satisfied. Then we
have the following: 
\begin{enumerate}
\item[(i)] The optimal control problem (\ref{chap6-eq1.6}) has a
  unique solution $u \epsilon K$.

\item[(ii)] The unique solution u of the optimal control problem us
  characterized by the coupled system consisting of the pair of
  equations (\ref{chap6-eq1.2}) and (\ref{chap6-eq1.20}) defining the
  state y and the adjoint state p governing the system together with
  the variational inequality (\ref{chap6-eq1.21}).

\item[(iii)] A solution $(y, u ; p)$ to (\ref{chap6-eq1.2}),
  (\ref{chap6-eq1.20}) and (\ref{chap6-eq1.21}) exists (and is unique)
  and is the unique saddle point of the Lagrangian $\mathscr{L}$
  defined by (\ref{chap6-eq1.8}).\pageoriginale 
\end{enumerate}
\end{theorem}

\begin{remark}\label{chap6-rem1.6}
The variational inequality (\ref{chap6-eq1.21}) is nothing but the well known maximum principle of Pontrjagin in the classical theory of controls.
\end{remark}

\subsection{Elimination of State}\label{chap6-subsec1.3}

In order to obtain algorithm for the construction of approximations to
the solution of the optimal control problem (\ref{chap6-eq1.6}) we use
the characterization given by Theorem (\ref{chap6-eq1.2}) (ii) to
obtain a pure minimization problem with constraints. This is achieved
by eliminating the state $y_{u}$ which occurs explicitly in the above
characterization. 

We can rewrite the problem of control (\ref{chap6-eq1.6}) in terms of
the operators defined on $V$ by the bilinear forms $a(\cdot , \cdot)$
and $b(\cdot , \cdot)$ and the operator defined by the inclusion
mapping of $V = H^{1} (\Omega)$ in $L^{2} (\Omega)$. 

In fact, for any fixed $y \epsilon V$, the linear form 
$$
\varphi \mapsto a(y, \varphi)
$$
is continuous linear on $V$ by (\ref{chap6-eq1.1}) and hence by
Riesz-representation theorem there exists a unique element $Ay
\epsilon V$ such that 
\begin{equation*}
a(y, \varphi) = ((Ay, \varphi)) \text{ for all } \varphi \epsilon V.\tag{1.22}\label{chap6-eq1.22}
\end{equation*}

Once again from (\ref{chap6-eq1.1}) the mapping $y \mapsto Ay$ is a
continuous linear operator on $V$. Similarly, by (\ref{chap6-eq1.3})
there exists a continuous linear operator $B$ on $V$ such that 
\begin{equation*}
b(y, \varphi) = ((By, \varphi)) \text{ for all } \varphi \epsilon V.\tag{1.23}\label{chap6-eq1.23}
\end{equation*}

Finally since the inclusion mapping of $V$ in $L^{2} (\Omega)$ is
continuous linear it follows\pageoriginale that for any $u \epsilon
L^{2} (\Omega)$ the linear mapping $v \mapsto (u, v)$ on $V$ is a
continuous linear functional. Hence there exists a continuous linear
operator $D : L^{2} (\Omega) \to V$ such that 
\begin{equation*}
(u, v) = ((Du, v)) \text{ for all } u \epsilon L^{2}(\Omega), v \epsilon V.\tag{1.24}\label{chap6-eq1.24}
\end{equation*}

The state equation can now be written as
$$
((Ay, \varphi)) = ((Df + Du, \varphi)) \text{ for all } \varphi \epsilon V.
$$
which is the same as the operational equation in $V$:
\begin{equation*}
Ay = Df + Du.\tag{1.25}\label{chap6-eq1.25}
\end{equation*}

In view of the well known result of Lax and Miligram we have

\begin{theorem}\label{chap6-thm1.3}
Under the hypothesis (\ref{chap6-eq1.1}) the state equation
(\ref{chap6-eq1.2}) (or equilvalently (\ref{chap6-eq1.25})) has a
unique solution $y_{u} \epsilon V$ for any given $u \epsilon L^{2}
(\Omega)$ and there exists constant $c > 0$ such that 
\begin{equation*}
||| y ||| \leq c (||| Df ||| + ||| Du |||).\tag{1.26}\label{chap6-eq1.26}
\end{equation*}
\end{theorem}

This is equivalent to saying that the operator $A$ is invertible,
$A^{-1}$ is a continuous linear operator on $V$ and (\ref{chap6-eq1.26})
gives an estimate for the norm of $A^{-1}$. Hence we can write 
\begin{equation*}
y_{u} = A^{-1} (Df + Du)\tag{1.27}\label{chap6-eq1.27}
\end{equation*}
as the solution of the state equation.

Next we shall reduce the optimal control problem (\ref{chap6-eq1.6})
to a minimization problem as follows. We substitute $y_{u}$ given by
(\ref{chap6-eq1.27}) in the cost function (\ref{chap6-eq1.5}) and thus
we eliminate the state from the functional to minimize. Using
(\ref{chap6-eq1.23}) together with (\ref{chap6-eq1.27}) we can write 
\begin{align*}
b(y_{u} - y_{g}, y_{u} - y_{g}) & = ((B(y_{u}- y_{g}), y_{u} - y_{g}))\\
& = ((B[A^{-1} (Df + Du) - y_{g}], A^{-1} (Df+Du) - y_{g}))\\
& = ((BA^{-1} Du, A^{-1} Du)) + 2((B(A^{-1} Df - y_{g}), A^{-1} Du))\\
&    \quad + ((B(A^{-1} Df - y_{g}), A^{-1} Df - y_{g}))\\
& =  ((A^{-1 *} BA^{-1} Du, Du)) + 2((A^{-1*} B(A^{-1} Df - y_{g}),\\
&\qquad\qquad Du)) + G(f, y_{g})
\end{align*}\pageoriginale
where $A^{-1*}$ is the adjoint of the operator $A^{-1}$ and $G(f, y_{g})$ denoted the functional
$$
G(f, y_{g}) = ((BA^{-1} Df - By_{g}, A^{-1} Df - y_{g}))
$$
which is independent of $u$. Once again using (\ref{chap6-eq1.24}) we can write
$$
b(y_{u} - y_{g}, y_{u} - y_{g}) = (A^{-1*} BA^{-1} Du, u) + (A^{-1*} B(A^{-1} Df-y_{g}), u) + G(f, y_{g})
$$
and hence the cost function can be written in the form 
$$
j(u) = \frac{1}{2} (A^{-1*} BA^{-1} Du, u) + (A^{-1*} B(A^{-1} Df
-y_{g}), u) + G(f, y_{g}) + \frac{1}{2} (Cu, u). 
$$

Setting  
\begin{equation*}
\begin{cases}
& \mathscr{A} = A^{-1*} BA^{-1} D + C \text{ and }\\
& \mathscr{F} = A^{-1*} B(A^{-1} Df - y_{g})\tag{1.28}\label{chap6-eq1.28}
\end{cases}
\end{equation*}

We have the following

\begin{proposition}\label{chap6-prop1.1}
The optimal control problem (\ref{chap6-eq1.6}) is equivalent to the minimization problem:
\begin{equation*}
\begin{cases}
& \text{ to find } u \epsilon K \text{ such that }\\
& j(u) = \inf_{v \epsilon K} j(v) \text{ where }\\
& j(v) = \frac{1}{2} (\mathscr{A} v, v) - (\mathscr{F}, v) + G(f, y_{g}).\tag{1.29}\label{chap6-eq1.29}
\end{cases}
\end{equation*}
\end{proposition}

We\pageoriginale observe that, since the last term in the expression
for the quadra\-tic functional $j(v)$ is a constant (independent of $v$),
$u \epsilon K$ is a solution of (\ref{chap6-eq1.29}) if and only if $u$
is a solution of the minimization problem: 
\begin{equation*}
\begin{cases}
& \text{ to find } u \epsilon K \text{ such that }\\
& k(u) = \inf_{v \epsilon K} k(v) \text{ where }\\
& k(v) = \frac{1}{2} (\mathscr{A} v, v) - (\mathscr{F}, v).\tag{1.30}\label{chap6-eq1.30}
\end{cases}
\end{equation*}

We know by the results of Chapter \ref{chap2} \S\ \ref{chap2-sec3}
(Theorem \ref{chap2-thm3.1}) that the problem (\ref{chap6-eq1.30}) has
a unique solution and it is characterized by the condition 
$$
k' (u, v - u) \geq 0 \text{ for all } v \epsilon K,
$$
where $k(\cdot , \varphi)$ denotes the $G$-derivative of $k( \cdot
)$. This is nothing but the variational inequality 
\begin{equation*}
\begin{cases}
& \text{ To find } u \epsilon K \text{ such that }\\
& (\mathscr{A}u - \mathscr{F}, v-u) \geq 0 \text{ for all } v \epsilon K.\tag{1.31}\label{chap6-eq1.31}
\end{cases}
\end{equation*}

This variational inequality (\ref{chap6-eq1.31}) together with the
state equation is an equivalent formulation of the characterization of
the optimal control problem given by Theorem (\ref{chap6-eq1.2})
(ii). More precisely, we have the following 

\begin{theorem}\label{chap6-thm1.3a}
The solution of the optimal control problem (\ref{chap6-eq1.6}) is
characterized by the variational inequality: 
\begin{equation*}
\begin{cases}
& \text{ To find } u \epsilon K \text{ such that }\\
& (Cu - p_{u}, v - u) \geq 0 \text{ for all } v \epsilon K\tag{1.32}\label{chap6-eq1.32}
\end{cases}
\end{equation*}
\end{theorem}
where $p_{u}$ is the adjoint state.

\begin{proof}
We\pageoriginale  have by the definitions (\ref{chap6-eq1.28}) of
$\mathscr{A}$ and $\mathscr{F}$ 
$$
\mathscr{A} u - \mathscr{F} = A^{-1*} B(A^{-1} Du + A^{-1} Df - y_{g}) + Cu
$$
which on using the state equation (\ref{chap6-eq1.25}) becomes 
\begin{equation*}
\mathscr{A} u - \mathscr{F} = A^{-1*} B(y_{u} - y_{g}) + Cu.\tag{1.33}\label{chap6-eq1.33}
\end{equation*}
\end{proof}

If we now define $p_{u}$ by setting
\begin{equation*}
-p_{u} = A^{-1*} B(y_{u}-y_{g})\tag{1.34}\label{chap6-eq1.34}
\end{equation*}
then we see that $p_{u}$ satisfies the functional equation
$$
((A^{*} p_{u}, \psi)) = -((B(y_{u}-y_{g}), \psi)) \text{ for all } \psi \epsilon V.
$$

We notice that this is nothing but the adjoint state equation:
$$
a(\psi, p_{u}) = -b(y_{u} - y_{g}, \psi) \text{ for all } \psi \epsilon V.
$$

Thus if, for a given control $u \epsilon K, y_{u}$ is the solution of
the state equation then $p_{u}$ defined by (\ref{chap6-eq1.34}) is the
solution of the adjoint state equation. Moreover, we have 
\begin{equation*}
\mathscr{A} u - \mathscr{F} = Cu - p_{u}.\tag*{$(1.33)'$}\label{chap6-eq1.33'}
\end{equation*}
 
Substituting \ref{chap6-eq1.33'} in the variational inequality
(\ref{chap6-eq1.31}) we obtain the assertion of the theorem. 

We are thus reduced to a pure minimization problem in $K$ for which we have known algorithms.

\subsection{Approximation}\label{chap6-subsec1.4}

The formulation of the optimal control problem as a pure minimization
problem given above in Section (\ref{chap6-eq1.3}) together with the
algorithms described in earlier\pageoriginale chapters for the
minimization problem will immediately lead to algorithm to determine
approximations to the solution of the optimal control problem
(\ref{chap6-eq1.6}). Hence we shall only mention this briefly in the
following. 

We observe first of all that the operator $\mathscr{A}$ is $L^{2}
(\Omega)$-coercive and bounded. In fact, in view of
(\ref{chap6-eq1.24}) and (\ref{chap6-eq1.23}) we can write 
\begin{align*}
(A^{-1*} BA^{-1} Du, u) &= ((A^{-1*} BA^{-1} Du, Du))\\ 
&= (BA^{-1} Du, A^{-1} Du) = b(A^{-1} Du, A^{-1} Du) \geq 0. 
\end{align*}

Since we also have $(Cu, u) \geq \alpha_{C} ||u||^{2}$
we find that $\mathscr{A}$ is $L^{2} (\Omega)$-coercive and
\begin{equation*}
(\mathscr{A}u, u) = (A^{-1*} Ba^{-1} Du 6 Cu, u) \geq \alpha_{C}
  ||u||^{2}, u \epsilon V.\tag{1.35}\label{chap6-eq1.35} 
\end{equation*}

To prove that is bounded we note that $A^{-1}$ is the operator
$$
L^{2} (\Omega) \ni f + u \mapsto y_{u} \epsilon L^{2}(\Omega)
$$
defining the solution of the state equation:
\begin{equation*}
\begin{cases}
y_{u} \epsilon V \text{ such that }\\
a(y_{u}, \varphi) = ((Ay_{u}, \varphi)) = ((D(f+u),\varphi)) \text{
  for all } \varphi \epsilon V. 
\end{cases}
\end{equation*}

Here taking $\varphi = y_{u}$ and using the coercivity of the bilinear
form $a(\cdot , \cdot)$ we see that 
$$
\alpha_{a} |||y_{u}|||^{2} \leq |||Df + Du||| |||y_{u}|||
$$
and hence
$$
|||y_{u}||| \leq |||A^{-1} (Df + Du)||| \leq \alpha_{a}^{-1} |||Df + Du|||.
$$
which implies that $A^{-1}$ is bounded and in fact, we have
\begin{equation*}
||A^{-1}||_{\mathscr{L}(V, V)} \leq \alpha_{a}^{-1}.\tag{1.36}\label{chap6-eq1.36}
\end{equation*}

Now since all the operators involved in the definition of
$\mathscr{A}$ are linear and bounded it follows that $\mathscr{A}$ is
also bounded. Moreover, we also have 
\begin{align*}
|| \mathscr{A} ||_{\mathscr{L}(L^{2}  (\Omega), L^{2} (\Omega))} =
||A^{-1*} BA^{-1} D + C ||_{\mathscr{L}(L^{2} (\Omega), L^{2}
  (\Omega))}\\ 
\leq ||A^{-1}||^{2}_{\mathscr{L}(V, V)} ||B||_{\mathscr{L}(V, V)}
||||D||_{\mathscr{L}(L^{2} (\Omega), V)} + ||C||_{\mathscr{L}(L^{2}
||(\Omega), L^{2} (\Omega))} 
\end{align*}
and hence (since $||D||_{\mathscr{L}(L^{2} (\Omega), V)} = 1)$
\begin{equation*}
||\mathscr{A}||_{\mathscr{L} (L^{2} (\Omega), L^{2} (\Omega))} \leq
  \alpha_{a}^{-2} M_{b} + M_{c}.\tag{1.37}\label{chap6-eq1.37}  
\end{equation*}

We\pageoriginale are now in a position to describe the algorithms.

\medskip 
\noindent{\textbf{Method of contraction.}} We recall the the solution
of the optimal control problem is equivalent to the solution of the
minimization problem (\ref{chap6-eq1.29}) and that the solution of
this is characterized by the variational inequality
(\ref{chap6-eq1.31}): 
\begin{equation*}
\begin{cases}
& u \epsilon K \text{ such that }\\
& (\mathscr{A} u - \mathscr{F}, v - u) \geq 0 \text{ for all } v \epsilon K.
\end{cases}
\end{equation*}

We can now use the method of contraction mapping (as is standard in
the proof of existence of solutions of variational inequality - see,
for instance, Lions and Stampacchia [ ] ) to describe an algorithm for
the solution of the variational inequality (\ref{chap6-eq1.31}). 

{\em Algorithm.} Suppose we know an algorithm to calculate numerically
the projection $P$ of $L^{2} (\Omega)$ onto $K$. Let $\rho$ be a constant
(which we fix) such that 
\begin{equation*}
0 < \rho < 2\alpha_{C}^{-1} / (\alpha_{a}^{-2} M_{b} + M_{C}) = 2\alpha_{a}^{2} / \alpha_{C} (M_{b} + \alpha_{a}^{2} M_{C}).\tag{1.38}\label{chap6-eq1.38}
\end{equation*}

Let $u_{\circ} \epsilon K$ be arbitrarily chosen. Suppose $u_{\circ},
\cdots , u_{m}$ are determined starting from $u_{\circ}$. We define
$u_{m+1}$ by setting 
\begin{equation*}
u_{m+1} = P \Phi (u_{m})\tag{1.39}\label{chap6-eq1.39}
\end{equation*}
where
\begin{equation*}
\Phi (u_{m}) = u_{m} - \rho \mathscr{A}u_{m} + \rho^{2}
\mathscr{F}\tag*{$(1.39)'$}\label{chap6-eq1.39'} 
\end{equation*}

We can express $\Phi (u_{m})$ in terms of the operators $A$, $B$, $C$ and
the data $f$ and $y_{g}$ as follows: 
\begin{equation*}
\Phi (u_{m}) = u_{m} - \rho(A^{-1*} BA^{-1} Du_{m} + Cu_{m}) +
\rho^{2} A^{-1*} B(A^{-1} Df - y_{g}).\tag{1.40}\label{chap6-eq1.40} 
\end{equation*}

The choice (\ref{chap6-eq1.38}) of $\rho$ implies that the mapping
\begin{equation*}
T : K \ni w \mapsto P \Phi (w) \epsilon K\tag{1.41}\label{chap6-eq1.41}
\end{equation*}\pageoriginale
is a contraction, so that $T$ has a fixed point $u$ in $K$ to which
the sequence $u_{m}$ converges. 
 
\medskip
\noindent{\textbf{Method of gradient with projection.}} We consider the minimization
problem for the quadratic functional 
\begin{equation*}
v \mapsto \mathscr{G} (v) = \frac{1}{2} (\mathscr{A} v, v) -
(\mathscr{F}, v)\tag{1.42}\label{chap6-eq1.42} 
\end{equation*}
on $K$. Since $\mathscr{A}$ is coercive, we can use the method of
Chapter \ref{chap4}, Section \ref{chap4-sec3} and we can show that we
can choose as convergent choices for $\rho > 0$ a constant and for the
direction of descent 
\begin{equation*}
w_{m} = grad \mathscr{G} (u_{m}) / ||grad \mathscr{G} (u_{m})||.\tag{1.43}\label{chap6-eq1.43}
\end{equation*}

Thus starting from an arbitrary $u_{\circ} \epsilon K$, we define
\begin{equation*}
u_{m+1} = P_{K} (u_{m} - \rho grad \mathscr{G} (u_{m}) / ||grad
\mathscr{G} (u_{m})||)\tag{1.44}\label{chap6-eq1.44} 
\end{equation*}
where $P_{K}$ is the projection of $L^{2} (\Omega)$ onto $K$.

This method, however, requires the computation of $\mathscr{G}
(u_{m})$ and its gradient at each step. For this purpose, knowing
$u_{m} \epsilon K$ we have to solve the state equation: 
\begin{equation*}
\begin{cases}
& y_{m} \epsilon V \text{ such that }\\
& a(y_{m}, \varphi) = (f + u_{m}, \varphi) \text{ for all } \varphi \epsilon V
\end{cases}
\end{equation*}
to obtain $y_{m}$ and the adjoint state equation:
\begin{equation*}
\begin{cases}
& p_{m} \epsilon V \text{ such that }\\
& a(\varphi, p_{m}) = -b(y_{m} - y_{g}, \varphi) \text{ for all } \varphi \epsilon V
\end{cases}
\end{equation*}
to\pageoriginale obtain the adjoint state $p_{m}$. We can then calculate grad $\mathscr{G} (u_{m})$ by using 
\begin{equation*}
grad \mathscr{G} (u_{m}) = Cu_{m} - p_{m}.\tag{1.45}\label{chap6-eq1.45}
\end{equation*}

We shall not go into details of the algorithm which we shall leave to the reader.

\begin{remark}\label{chap6-rem1.7} 
This method is rather long as it involves several steps for each of
which we have sub-algorithms for computations. Hence this procedure
may not be very economical. 
\end{remark}

\setcounter{subsection}{45}
\subsection{}%%%% 1.46
As an illustration of the methods described in this section we
consider the following two-dimensional optimal control problem: Let
$\Omega$ be a bounded open set in $\mathbb{R}^{2}$ with smooth
boundary $\Gamma$. We consider the following optimal control problem  
\begin{equation*}
\text{ State equation :}
\begin{cases}
& -\triangle y_{u} + y_{u} = f + u \text{ in } \Omega\\
& \partial y_{u} / \partial \underline{n} = 0 \text{ on } \Gamma
\end{cases}
\end{equation*}
where $\underline{n}$ denotes the exterior normal vector field to $\Gamma$

Controal set : \qquad $K = \{u \epsilon L^{2} (\Omega) | 0 \leq u(x) \leq 1$ a.e. on $\Omega \}$

Cost function : \qquad $J(y, u) = \int_{\Omega} (|y_{u} - y_{g}|^{2} + |u|^{2}) dx$.

We shall leave the description of the algorithm to this problem on the
lines suggested in this section as an exercise to the reader. 

\section{Theory of Optimal Design}\label{chap6-sec2}

In this section we shall be concerned with the problem of optimal
design. We shall show that certain free boundary problems can be
considered as special cases of this type of optimal design problem. We
shall consider a special case of one-dimensional problem and explain a
very general method to obtain a solution to the problem, which also
enables us to give algorithms to obtain approximations for the
solution. This method can be seen to be readily applicable to the
higher dimensional problems also except for some technical
details. Though there is a\pageoriginale certain similarity  with the
problem of optimal control we cannot use the duality method earlier
used in the case as we shall see later. 

\setcounter{subsection}{-1}
\subsection{Optimal Design}\label{chap6-subsec2.0}

In this section we shall give a general formulation of the problem of
optimal design. Once again this problem will be considered as a
minimization problem for a suitable class of functionals. As in the
case of optimal control problem these functionals are defined through
a family of state equations. We shall consider here the states
governing the system to be determined by variational elliptic boundary
value problems. Though there is some analogy with the optimal control
problem studied in the previous section there is an important
difference because of the fact in the present case the convex set $L$
(in our case the set $K$ will be the whole of an Hilbert space), on
which the given functional is to be minimized, itself is in some sense
to be determined, as it is a set of functions on the optimal domian to
be determined by the problem. Therefore this problem cannot be treated
as an optimal control problem and requires somewhat different
techniques than the ones used before. 

Roughly speaking the problem of optimal design can be described as follows: Suppose given
\begin{enumerate}
\item[(1)] A family of possible domians $\Omega$ (bounded open sets in
  the Euclidean space) having certain minimum regularity properties. 

\item[(2)] A family of elliptic boundary value problems describing the
  states, one each on a $\Omega$ of the family in (1). 

\item[(3)] A cost function $j$ (described in terms of the state
  determined by (2) considered as a functional of the domian $\Omega$
  in the family). 
\end{enumerate}

Then\pageoriginale the problem consists in finding a domian $\Omega
^{*}$ in the given family for which $j(\Omega^{*})$ is a minimum. 

We shall describe a fairly general theory to obtain a solution to the
optimal design problem. In order to simplify the details we shall,
however, describe our general method in the special case of one
dimension. Thus the states governing the problem is described by
solutions of a two point boundary value problem for a linear second
order ordinary differential equation. We shall first describe the main
formal steps involved in the reduction of the problem to one of
minimization in a fixed domian. We shall then make the necessary
hypothesis and show that this formal procedure is justified. 

\subsection{Formulation of the Problem of Optimal Design}\label{chap6-subsec2.1}

Let $\mathscr{A}$ be a family of bounded open sets $\Omega$ in
$\mathbb{R}^{n}$ and let $\Gamma$ denote the boundary of $\Omega,
\Omega \epsilon \mathscr{A}$. We assume that every $\Omega \epsilon
\mathscr{A}$ satisfies some regularity properties. For instance, every
$\Omega \epsilon \mathscr{A}$ satisfies a cone condition or every
$\Omega \epsilon \mathscr{A}$ has a locally Lipschitz boundary etc. 

We suppose the following data:

(1) For each $\Omega \epsilon \mathscr{A}$ we are given a bilinear form
$$
V \times V \ni (y, \varphi) \mapsto a(\Omega ; y, \varphi) \epsilon \mathbb{R}
$$
on $V = V_{\Omega} = H^{1} (\Omega)$ such that
\begin{enumerate}
\item[(i)] it is continuous ; i.e. there exists a constant $M_{\Omega} > 0$ such that
\begin{equation*}
a(\Omega ; \varphi, \psi) \leq M_{\Omega} ||\varphi||_{V} ||\psi||_{V}
\text{ for all } \varphi, \psi \epsilon V = H^{1}(\Omega), \Omega
\epsilon \mathscr{A}.\tag{2.1}\label{chap6-eq2.1} 
\end{equation*}
\item[(ii)] it is $H^{1} (\Omega)$ -coercive : there exists a constant $C_{\Omega} > 0$ such that
\begin{equation*}
a(\Omega ; \varphi, \varphi) \geq C_{\Omega} ||\varphi||_{H^{1} (\Omega)}^{2}, \text{ for all } \Omega \epsilon H^{1} (\Omega), \Omega \epsilon \mathscr{A}.\tag{2.2}\label{chap6-eq2.2}
\end{equation*}
\end{enumerate}

\begin{example}\label{chap6-exam2.1}
Let\pageoriginale $\Omega \epsilon \mathscr{A}$ and
$$
a(\Omega; \varphi, \psi) = (\varphi, \psi)_{H^{1} (\Omega)} = \int_{\Omega} \left(\sum_{j} \frac{\partial \varphi}{\partial x_{j}} \frac{\partial \psi}{\partial x_{j}} + \varphi \psi \right)dx.
$$
\end{example}

(2) For each $\Omega \epsilon \mathscr{A}$ we are given a continuous linear functional $\varphi \mapsto L(\Omega ; \varphi)$ on $H^{1} (\Omega), \Omega \epsilon \mathscr{A}$.

\begin{example}\label{chap6-exam2.2}
Let $F \epsilon L^{2} (\mathbb{R}^{n})$ and $f = F |_\Omega$ = restriction of $F$ to $\Omega$.
$$
L(\Omega ; \varphi) = \int_{\Omega} f\varphi dx. \text{ for all }
\varphi \epsilon H^{1} (\Omega), \Omega \epsilon \mathscr{A}. 
$$

Consider the variational elliptic boundary value problem:
\begin{equation*}
\begin{cases}
& \text{ To find } y = y_{\Omega} \epsilon H^{1} (\Omega) \text{ such that }\\
& a(\Omega ; y, \varphi) = L(\Omega ; \varphi), (\text{ for all } \varphi \epsilon H^{1} (\Omega)).\tag{2.3}\label{chap6-eq2.3}
\end{cases}
\end{equation*}
\end{example}

We know by Lax-Milgram lemma that under the assumptions (1) and (2)
there exists a unique solution $y_{\Omega} \epsilon H^{1} (\Omega)$
for this problem (\ref{chap6-eq2.3}). We observe that since $f$ is given
as $F |_{\Omega}$ this solution $y_{\Omega}$ depends only on the
geometry of $\Omega, \Omega \epsilon \mathscr{A}$. 

\medskip{\textbf{(3)  Cost function.}} For each $\Omega \epsilon \mathscr{A}$ we are
given a functional on $H^{1} (\Omega)$ : 
\begin{equation*}
H^{1} (\Omega) \ni z \mapsto J(\Omega ; z) \epsilon \mathbb{R}\tag{2.4}\label{chap6-eq2.4}
\end{equation*}

\begin{example}\label{chap6-exam2.3}
\begin{equation*}
\begin{cases}
& J(\Omega ; z) = \int_{\Gamma} |z-g|^{2} d \sigma, \text{ where }\\
& g \epsilon \gamma_{\circ} G = G | \Gamma, G \epsilon H^{1} (\Omega), \Omega \epsilon \mathscr{A}.
\end{cases}
\end{equation*}
\end{example}

\begin{example}\label{chap6-exam2.4}
\begin{equation*}
\begin{cases}
& J(\Omega ; ) = \int_{\Omega} |z-g|^{2} dx, \text{ where }\\
& G \epsilon L^{2} (\mathbb{R}^{n}) \text{ and } g = G | \Omega, \Omega \epsilon \mathscr{A}.
\end{cases}
\end{equation*}
\end{example}

\setcounter{subsection}{4}
\subsection{Example of a family $\mathscr{A}$ of domains.} Suppose $B$
and $\omega$ are two fixed open subsets of $\mathbb{R}^{n}$ such that
$\overline{\omega} \subset B$. Let $A$ be the family of open sets
$\Omega$ in $\mathbb{R}^{n}$ such that $\omega \subset \Omega \subset
B$ and $\Omega$ satisfies some regularity property (say, for instance,
$\Omega$\pageoriginale satisfies a cone condition). 

Define
\begin{equation*}
j(\Omega) = J(\Omega; y_{\Omega}), \Omega \epsilon \mathscr{A}\tag{2.5}\label{chap6-eq2.5}
\end{equation*}
where $y_{\Omega}$ is the (unique) solution of the homogeneous boundary value problem (\ref{chap6-eq2.3}).

The problem of optimal design consists in minimizing $j(\Omega)$ over $\mathscr{A}$:
\begin{equation*}
\begin{cases}
& \text{ To find } \Omega^{*} \epsilon \mathscr{A} \text{ such that }\\
& j(\omega^{*}) = \inf_{\Omega \epsilon \mathscr{A}} j(\Omega).\tag{2.6}\label{chap6-eq2.6}
\end{cases}
\end{equation*}


{\em Optimal design and free boundary problem.} Certain free boundary
problems can be considered as a problem of optimal design as is
illustrated by the following example in two dimensions. 

Let $\Gamma_{\circ}$ be a smooth curve in the plane $\mathbb{R}^{2}$
defined by an equation of the form 
\begin{equation*}
z(x) = x_{1} - \varphi (x_{2}) = 0,\tag{2.7}\label{chap6-eq2.7}
\end{equation*}
where $\varphi : I = [0, 1] \ni x_{2} \mapsto \varphi (x_{2}) \epsilon
\mathbb{R}_{+}$ is a  smooth function. Let $Q$ denote the (open) strip
in $\mathbb{R}^{2}$ : 
\begin{equation*}
Q = \{x = (x_{1}, x_{2}) \epsilon \mathbb{R}^{2} | x_{1} > 0, 0 < x_{2} < 1 \}.\tag{2.8}\label{chap6-eq2.8}
\end{equation*}

Consider the open set $\Omega$ given by
\begin{equation*}
\Omega = \{x \epsilon Q | z(x) < 0 \} \equiv \{x = (x_{1}, x_{2}) \epsilon Q | x_{1} < \varphi (x_{2}) \}.\tag{2.9}\label{chap6-eq2.9}
\end{equation*}

The boundary $\Gamma$ of $\Omega$ decomposes into a union $\sum \cup
\Gamma_{\circ}$ with $\sum^{\circ} \cap \Gamma_{\circ}^{\circ} =
\phi$. 

There exists a one-one correspondence between $\Omega$ and the
function $z$, Thus the family $\mathscr{A}$ is determined by the family
of smooth functions 
$$
z : Q \to \mathbb{R}.
$$

Let\pageoriginale us consider the optimal design problem:
\begin{equation*}
\begin{cases}
& a(\Omega; y, \varphi) = (y, \varphi)_{H^{1} (\Omega)}, \text{ for } y, \varphi \epsilon H^{1} (\Omega);\\
& L(\Omega ; \varphi) = (f, \varphi)_{L^{2} (\Omega)}, \text{ for } \varphi \epsilon H^{1} (\Omega) \text{ where } f = F | \Omega, F \epsilon L^{2} (\mathbb{R}^{2})\\
& J(\Omega ; z) = \int_{\Gamma_{\circ}} |z(x)|^{2} d\sigma, \text{ where } d\sigma \text{ is the line element on $\Gamma_{\circ}$.}\tag{2.10}\label{chap6-eq2.10}
\end{cases}
\end{equation*}

Then $y = y_{\Omega}$ is the unique solution of the Neumann problem:
\begin{equation*}
\begin{cases}
& y_{\Omega} \epsilon H^{1}(\Omega)\\
& (y_{\Omega}, \varphi)_{H^{1}(\Omega)} = (f, \varphi)_{L^{2} (\Omega)} \text{ for all } \varphi \epsilon H^{1} (\Omega)\tag{2.11}\label{chap6-eq2.11}
\end{cases}
\end{equation*}
and
\begin{equation*}
j(\Omega) = J(\Omega ; y_{\Omega}) = \int_{\Gamma_{\circ}} |y_{\Omega} (x)|^{2} d\sigma.\tag{2.12}\label{chap6-eq2.12}
\end{equation*}

The optimal design problem then becomes
\begin{equation*}
\text{ To find } \Omega^{*} \text{ such that } j(\Omega^{*}) \leq
j(\Omega) \text{ for all } \Omega \epsilon \mathscr{A} \text{ In other
  words,} \tag{2.13}\label{chap6-eq2.13}
\end{equation*}

\begin{equation*}
\begin{cases}
& \text{ To fin } y_{\Omega^{*}} \epsilon H^{1} (\Omega^{*}) \text{ such that }\\
& \int_{\Gamma^{*}} |y_{\Omega^{*}} (x)|^{2} d\sigma \text{ is minimum }\tag*{$(2.13)'$}\label{chap6-eq2.13'}
\end{cases}
\end{equation*}

Suppose now that $\inf_{\Omega \epsilon \mathscr{A}} j(\Omega) = j(\Omega^{*}) = 0$. The it follows that
\begin{equation*}
y_{\Omega^{*}} = 0 \text{ a.e. on } \Gamma_{\circ}^{*}\tag{2.14}\label{chap6-eq2.14}
\end{equation*}

In this case, the optimal design problem reduces to the following so called ``free boundary problem'' :

To find a domian $\Omega^{*} \epsilon \mathscr{A}$ whose boundary is
of the form $\Gamma^{*} = \sum \cup \Gamma_{\circ}^{*}$ where $\sum$
is a fixed curve while $\Gamma_{\circ}^{*}$ is a curve determined by
the solution of the homogeneous boundary value problem 
\begin{equation*}
\begin{cases}
& -\triangle y + y = f \text{ in } \Omega^{*}\\
& \partial y / \partial \underline{n} = 0 \text{ on } \sum\\
& \partial y / \partial \underline{n} = 0, y = 0 \text{ on } \Gamma_{\circ}^{*}.\tag*{$(2.13)''$}\label{chap6-eq2.13''}
\end{cases}
\end{equation*}\pageoriginale

This equivalent formulation is obtained in the standard manner from
the state equation (\ref{chap6-eq2.3}) using the Green's formula
together with the condition (\ref{chap6-eq2.14}). Free boundary
problems occur naturally in many contexts - for example in theorey of
gas dynamics. 

\setcounter{subsection}{1}
\subsection{A Simple Example}

We shall illustrate our general method to obtain approximations to the
solution of the optimal design problem for the following one
dimensional problem. 

Let $\mathscr{A}$ denote the family of open intervals
\begin{equation*}
\Omega_{a} = (0, a), a \geq 1\tag{2.15}\label{chap6-eq2.15}
\end{equation*}
on the real line.

{\em State equation.} Assume that an $f \epsilon L^{2} (\mathbb{R}^{1})$ is given. The state governing the system is a solution of the following problem:
\begin{equation*}
\begin{cases}
& \text{ To find } y_{\Omega_{a}} \epsilon H^{1} (\Omega_{a}) \equiv H^{1}(0, a) \text{ such that }\\
& a(\Omega_{a} ; y_{\Omega_{a}}, \varphi) \equiv \int\limits_{0}^{a}
  \left(\dfrac{dy_{\Omega_{a}}}{dx} \dfrac{d\varphi}{dx} +
  y_{\Omega_{a}} \varphi \right) dx\\
& = \int\limits_{0}^{a} f \varphi dx \equiv
  L(\Omega_{a} ; \varphi), \text{ for all } \varphi \epsilon H^{1}
  (\Omega_{a}).\tag{2.16}\label{chap6-eq2.16} 
\end{cases}
\end{equation*}

On integration by parts (or more generally, using the Green's formula) we see that this is nothing but the variational formulation of the two pointy boundary value problem (of Neumann type boundary value problem):
\begin{equation*}
\begin{cases}
& \text{ To find } y_{\Omega_{a}} \epsilon H^{1} (\Omega_{a}) \text{ satisfying }\\
& \dfrac{d^{2} y_{\Omega_{a}}}{dx^{2}} + y_{\Omega_{a}} = f \text{ in } \Omega_{a}\\
& \dfrac{dy_{\Omega_{a}}}{dx} (0) = 0 = \dfrac{dy_{\Omega_{a}}}{dx} (a)\tag*{$(2.16)'$}\label{chap6-eq2.16'}
\end{cases}
\end{equation*}\pageoriginale

\medskip
\noindent{\textbf{Cost function.}} Suppose given a $g \epsilon L^{2} (0, 1)$. Define
\begin{equation*}
j(a) = \frac{1}{2} \int_{0}^{1} |y_{\Omega_{a}} - g|^{2} dx.\tag{2.17}\label{chap6-eq2.17}
\end{equation*}

\medskip
\noindent{\textbf{Problem of optimal design.}}
\begin{equation*}
\begin{cases}
& \text{ To find } a^{*} \geq 1 (\text{ i.e. to find } \Omega^{*} = \Omega_{a^{*}}) \text{ such that }\\
& j(a^{*}) \leq j(a) \text{ for all } a \geq 1. \tag{2.18}\label{chap6-eq2.18}
\end{cases}
\end{equation*}

\begin{remark}\label{chap6-rem2.1}
It appears natural to consider $a$ as the control variable and use the
duality argument as we did in the case of the optimal control
problem. However, since the space $V = H^{1} (\Omega_{a})$ varies with
a the duality method may not be useful to device algorithms. 
\end{remark}

In what follows, we shall adopt the following notation to simplify the writing:
\begin{equation*}
\begin{cases}
& y_{\Omega_{a}} (x) = y(a, x)\\
& \partial y / \partial x (a, x) = y'(a, x)\\
& \partial y / \partial a (a, x) = y_{a} (a, x)\tag{2.19}\label{chap6-eq2.19}
\end{cases}
\end{equation*}

\subsection{Computation of the Derivative of $j$.}

We shall use the method of gradient to obtain algorithms to construct
approximations converging to the required solution of the problem
(2.18). In order\pageoriginale to be able to apply the gradient method
we make the formal computation of the gradient of $j$ (in the present
case, the derivative of $j$) with respect to $a$ in this section. We
justify the various steps involved under suitable hypothesis in the
next section. 

Settinf for $\varphi \epsilon H^{1} (\Omega_{a})$
\begin{equation*}
F(a, x) = y' (a, x) \varphi' (a, x) + y(a, x) \varphi (a, x) - f(a, x)
\varphi (a, x)\tag{2.20}\label{chap6-eq2.20} 
\end{equation*}
we can write the state equation (\ref{chap6-eq2.16}) as
\begin{equation*}
K(a) = \int_{0}^{a} F(a, x) dx = 0\tag{2.21}\label{chap6-eq2.21}
\end{equation*}

Here since we have a Neumann type boundary value problem for a second
order ordinary differential operator the test function $\varphi$
belongs to $H^{1} (\Omega_{a})$ and so $\varphi$ is defined in a
variable domian $\Omega_{a} = (0, a)$. This may cause certain
inconveniences, which however can easily be overcome be overcome as
follows: 
\begin{enumerate}
\item[(1)] We can take $\varphi$ to be the restriction to $\Omega_{a}$
  of a function $\psi \epsilon H^{1}\break (0, + \infty)$ and write the
  state equation as 
{\fontsize{10}{12}\selectfont
$$
\int_{0}^{a} \{y' (a, x) \psi' (x) + y(a, x) \psi(x) - f(a, x) \psi
(x)\} = 0, \text{ for } \psi \epsilon H^{1} (0, + \infty). 
$$}

Such a choice for the test functions $\varphi \epsilon H^{1}
(\Omega_{a})$ would suffice when the state is described by a Neumann
type problem (as we have in the present case.) But if the boundary
conditions are of Dirichlet type this choice is not suitable since the
restrictions of functions in $H^{1} (0, + \infty)$ to $\Omega_{a}$ do
not necessarily give functions in the space of test functions
$H_{\circ}^{1} (\Omega_{a})$. We can use another method in which such
a problem do not arise and we shall use this method. 

\item[(2)] Suppose $\psi \epsilon H^{m} (\Omega_{1}), \Omega_{1}(0,
  1)$ and $m \geq 2$. Then the function $x \mapsto \varphi(a, x)$
  defined by 
\begin{equation*}
\varphi (a, x) = \psi (x/a)\tag{2.22}\label{chap6-eq2.22}
\end{equation*}\pageoriginale
is well defined in $\Omega_{a}$ and belongs to $H^{m} (\Omega_{a})
\hookrightarrow H^{1} (\Omega_{a})$. (This inclusion, we note is a
dense inclusion.) We also note that, in this case, if $\Psi \epsilon
H_{\circ}^{m} (\Omega_{1})$ then $\varphi \epsilon H_{\circ}^{m}
(\Omega_{a})$ and conversely. 
\end{enumerate}

Thus we set
\begin{equation*}
F(a, x) = y'(a, x) \psi (x / a) + (y(a, x) -f(x)) \psi (x / a) \text{
  for } \psi \epsilon H^{m}
(\Omega_{1})\tag*{$(2.20)'$}\label{chap6-eq2.20'} 
\end{equation*}
and we can write the state equation with this $F$ as
\begin{equation*}
K(a) = \int_{0}^{a} F(a, x) dx = 0\tag{2.21}
\end{equation*}

We shall make use of the following classical result to calculate the derivative $dK / da$.

Let $\Lambda$ denote the closed subset of the $(x, a)$-plane:
\begin{equation*}
\Lambda = \{(x, a) \epsilon \mathbb{R}^{2} ; a \geq 1 \text{ and } 0
\leq x \leq a \}.\tag{2.23}\label{chap6-eq2.23} 
\end{equation*} 

Suppose $F : \Lambda \to \mathbb{R}$ be a function satisfying:

{\em Hypothesis (1).} For every $a \geq 1$, the real valued function
$$
x \mapsto F(a, x)
$$
is continuous in $0 \leq x \leq a$.

{\em Hypothesis (2).} For every $x \epsilon [0, a]$, the function
$$
a \mapsto F(a, x)
$$
is differentiable and $\partial F / \partial a : \Lambda \to \mathbb{R}$ is continuous. Then the integral
$$
K(a) = \int_{0}^{a} F(a, x) dx
$$
exists, $a \mapsto K(a)$ belongs to $C^{1} (1 \leq a < + \infty)$ and we have
\begin{equation*}
\frac{dK}{da} (a) = \int_{0}^{a} \partial F / \partial a (a, x) dx + F(a, a)\tag{2.24}\label{chap6-eq2.24}
\end{equation*}\pageoriginale

\begin{remark}\label{chap6-rem2.2}
We observe that this classical result has a complete analogue also in
higher dimensions and we have a similar identity for\break $grad_{a} K$
(with respect to $a$) in place of $dK / da$.  
\end{remark}

Now differentiating the equation \ref{chap6-eq2.20'} with respect to $a$
and using the above result we get 
\begin{align*}
dK / da (a) & = \int_{0}^{a} \partial F / \partial a (a, x) dx + F(a, a)\\
& = \int_{0}^{a} [\{y'_{a} (a, x) \psi' (x/a) + y_{a} (a, x) \psi (x/a) \} +\\
& + \{y' (a, x) (\psi' (x/a))_{a} + y(a, x) (\psi(x/a))_{a} - f(x) (\psi(x/a))_{a} \}] dx\\
& + [y'(a, x) \Psi' (x/a) + y(a, x) \psi (x/a) - f(x) \psi (x/a) ]_{x=a} = 0.
\end{align*}

We observe that, if $m \geq 2$ then $x \mapsto (\psi(x/a))_{a} \epsilon H^{1} (0, a)$. In fact,
\begin{align*}
(\psi(x/a))_{a} & = (-x/a^{2}) \psi' (x/a) \epsilon L^{2} (\Omega_{a}),\\
(\psi (x/a))'_{a} & = (-1/a^{2}) \psi' (x/a) + (-x/a^{3}) \psi'' (x/a) \epsilon L^{2} (\Omega_{a}).
\end{align*}
where $\psi'$ and $\psi''$ are (strong) $L^{2}$ -derivatives of $\psi$, which exist since $\psi \epsilon H^{2} (0, 1)$.

Hence by the state equation (\ref{chap6-eq2.16}) we find that
\begin{align*}
\int_{0}^{a} & \{y' (a, x)(\psi'(x/a))_{a} + y(a, x)(\psi(x/a))_{a} - f(x) (\psi(x/a))_{a} \} dx\\
& = a (\Omega_{a} ; y_{\Omega_{a}}) (\psi(x/a))_{a} - L(\Omega_{a} ; (\psi(x/a))_{a}) = 0
\end{align*}

Thus we conclude that
\begin{align*}
& \int_{0}^{a} \{ y'_{a} (a, x) \Psi' (x/a) + y_{a}(a, x) \psi (x/a) \} dx\\
& = -  [ y'(a, x) \psi' (x/a) + y(a, x) \psi(x/a) - f(x) \psi (x/a)
  ]_{x=a}, \tag{2.25}\label{chap6-eq2.25}
\end{align*}
for all $\psi \epsilon H^{m} (0, 1)$ with $m \geq 2$.

\begin{remark}\label{chap6-rem2.3}
It\pageoriginale is obvious that the above argument easily carries
over to dimensions $\geq 2$ of rhte computation of $grad_{a} K(a)$. 

Finally, we calculate the derivative of the cost function $j$ with respect to $a$ and we have
\begin{align*}
dj/da & = \frac{1}{2} d/da \int_{0}^{1} |y(a, x) - g(x)|^{2} dx\\
& = \int_{0}^{1} (y(a, x) - g(x)) y_{a} (a, x) dx.\tag{2.26}\label{chap6-eq2.26}
\end{align*}
\end{remark}

In (\ref{chap6-eq2.26}) we eliminate the derivative $y_{a}$ of the
state $y_{\Omega_{a}}$ using the adjoint state equation. The adjoint
state $p_{\Omega_{a}} = p(a, x)$ is the solution of the equation: 
\begin{equation*}
\begin{cases}
& \int_{0}^{a} \{\varphi'(x) p' (a, x) + \varphi(x) p(a, x) \} dx = \int_{0}^{1} (y(a, x) - g(x)) \varphi(x) dx,\\
& \text{ for all } \varphi \epsilon H^{1} (0, a).\tag{2.27}\label{chap6-eq2.27}
\end{cases}
\end{equation*}

If we know that $y(a, x)$ is sufficiently regular, for instance say,
$y_{a} \epsilon H^{1}\break (\Omega_{a})$ then taking $\varphi = y_{a} (a,
x)$ in the adjoint state equation (\ref{chap6-eq2.27}) above we obtain 
\begin{align*}
dj/da & = \int_{0}^{1} (y(a, x) - g(x)) y_{a}(a, x) \qquad {\text{bf (2.26)}}\\
& = \int_{0}^{a} \{ y'_{a} (a, x) p'(a, x) + y_{a}(a, x)p(a, x) \} dx
\qquad {\text{bf (2.27)}}
\end{align*}

This together with (2.25) for $\psi = p$ gives
\begin{equation*}
dj/da = -[y'(a, x) p'(a, x) + y(a, x)p(a, x) - f(x) p(a, x) ]_{x=a}\tag{2.28}\label{chap6-eq2.28}
\end{equation*}


\subsection{Hypothesis and Results}\label{chap6-subsec2.4}

In the calculation of the derivatives of the cost function $j(a)$ in
the previous section we have made use of the regularity properties of
the state $y_{\Omega_{a}} = y(a, x)$ as well as that of the adjoint
state $p_{\Omega_{a}} = p(a, x)$ with respect to both the variables
$x$\pageoriginale and $a$. This in turn implies the regularity of the
function $F(a, x)$ define by \ref{chap6-eq2.20'} which is required for
the validity of the theorem on differentiation of the integral $K(a)$
of $F(a, x)$. The regularity of $y(a, x)$. The regularity of $y(a, x)$
and $p(a, x)$ are again necessary in order that the expression on the
right side of (\ref{chap6-eq2.28}) for the derivative value problmes
for (ordinary) differential equation, the regularity of $y$ and $p$ as a
consequence of suitable hypothesis on the data $f$ and $g$. 

We begin with the following assumptions on the data:

{\em Hypothesis (3).} For all $a \geq 1, t \mapsto f(at) \epsilon H^{1} (0, 1)$.

{\em Hypothesis (4).} $g \epsilon H^{1} (0, 1)$.

Then we have the following
\begin{proposition}\label{chap6-prop2.1}
{\em (Existence of the derivatives $y_{a}$ and $y'_{a}$).} Under the hypothesis (3) on f, if $y(a, x)$ is the solution of the state equation (\ref{chap6-eq2.16}) then 
\begin{enumerate}
\item[(i)] $x \mapsto y(a, x) \epsilon H^{3} (0, a)$
\item[(ii)] $y_{a}$ exists and $x \mapsto y_{a} (a, x) \epsilon H^{2} (0, a)$ and as a consequence we have
\item[(iii)] $x \mapsto y(a, x) \epsilon C^{2} ([0, a])$  and
\end{enumerate}
$\qquad x \mapsto y_{a}(a, x) \epsilon C^{1} ([0, a]).$
\end{proposition}

\begin{proof}
By a change of variable of the form
\begin{equation*}
x = at, x \epsilon (0, a) \text{ and } t \epsilon (0, 1)\tag{2.29}\label{chap6-eq2.29}
\end{equation*}
we can transform the state equation (\ref{chap6-eq2.16}) to a two
point boundary value problem in the fixed domain $\Omega_{1} = (0,
1)$. Under the transformation (\ref{chap6-eq2.29}) we have the one-one
corresponding between $y$ and $u$ given by 
\begin{equation*}
y(a, at) = u(a, t), u(a, x/a) = y(a, x)\tag{2.30}\label{chap6-eq2.30}
\end{equation*}
and for $m \geq 1$ we have:
\begin{equation*}
x \mapsto y(a, x)\epsilon H^{m} (0, a) \text{ if and only if } t \mapsto u(a, t) \epsilon H^{m}(0, 1)\tag{2.31}\label{chap6-eq2.31}
\end{equation*}\pageoriginale

Similarly if $\varphi \epsilon H^{m}(0, 1)$ then
\begin{equation*}
x \mapsto \psi(a, x) = \varphi(x/a) = \varphi(t) \epsilon H^{m} (0, a)\tag{2.32}\label{chap6-eq2.32}
\end{equation*}
and conversely. Moreover, we also have
\begin{equation*}
\begin{cases}
& y'(a, x) = a^{-1} \partial u / \partial t (a, x/a) = a^{-1} u_{t} (a, x/a)\\
& \psi' (a, x) = a^{-1} \varphi_{t} (x/a),\tag{2.33}\label{chap6-eq2.33}
\end{cases}
\end{equation*}
so that the state equation can now be written as 
\begin{equation*}
\begin{cases}
& \int_{0}^{a} \{a^{-2} u_{t} (a, x/a) \varphi_{t} (x/a) + u(a, x/a) \varphi(x/a)-f(x)\varphi(x/a) \}dx = 0\\
& \text{ for all } \varphi \epsilon H^{m}(0, 1).\tag{2.34}\label{chap6-eq2.34}
\end{cases}
\end{equation*}
\end{proof}

By the transfomation (\ref{chap6-eq2.29}) this becomes
\begin{equation*}
\begin{cases}
& \int_{0}^{1} \{a^{-2} u_{t}(a, t) \varphi_{t}(t) - (u(a, t) + f(at)) \varphi(t) \} dt = 0\\
& \text{ for all } \varphi \epsilon H^{m}(0, 1).\tag*{$(2.34)'$}\label{chap6-eq2.34'}
\end{cases}
\end{equation*}

Since $h^{m}(0, 1)$ is dense in $H^{1}(0, 1)$ (for any $m \geq 1$) it
follows that \ref{chap6-eq2.34'} is valid also for any $\varphi
\epsilon H^{1}(0, 1)$. This means that $t \mapsto u(a, t)$ is a
solution of the two point boundary value problem 
\begin{equation*}
\begin{cases}
& u = u(a, t)\\
& d^{2} u / dt^{2} + u = f(at)\\
& u_{t}(a, 0) = 0 = u_{t}(a, 1)\tag*{$(2.34)''$}\label{chap6-eq2.34''}
\end{cases}
\end{equation*}

Since $t \mapsto f(at) \epsilon H^{1}(0, 1)$ by Hypothesis (3) we know, form the regularity theorey for (ordinary) differentail equation, that
$$
t \mapsto u(a, t) \epsilon H^{3} (0, 1)
$$\pageoriginale
which proves (i). Then by Sobolev's lemma $t \mapsto u(a, t) \epsilon C^{2} ([0, 1])$. It follows then that
\begin{equation*}
x \mapsto y(a, x) = u(a, x/a) \epsilon C^{2} ([0, 1]).\tag{2.35}\label{chap6-eq2.35}
\end{equation*}
which proves the second part of (iii).

In order to prove that $y_{a}$ exists and is regular it is enough to
prove the same for $u_{a}$. For this purpose, we shall show the
$u_{a}$ satisfies a second order (elliptic) variational boundary value
problem. 

We note that, by the theorem of dependence on parameters, the solution
of \ref{chap6-eq2.34''} as a functiona of the variable a is
differentiable since the Hypothesis (3) implies that 
\begin{equation*}
(df/da)(at) = tf_{t} (at) \epsilon L^{2} (0, 1).\tag{2.36}\label{chap6-eq2.36}
\end{equation*}

Now if we differentiate \ref{chap6-eq2.34'} with respect to $a$ we get
\begin{equation*}
\begin{cases}
& \int_{0}^{1} \{a^{-2} u_{t, a}(a, t) \varphi_{t}(t) + u_{a} (a, t) \varphi(t) \} dt\\
& = 2a^{-3} \int_{0}^{1} u_{t} (a, t)\varphi_{t} (t) dt + \int_{0}^{1} f_{t} (at) t\varphi (t) dt.\\
& \text{ for all } \varphi \epsilon H^{m} (0, 1).\tag{2.37}\label{chap6-eq2.37}
\end{cases}
\end{equation*}

Here on the right side the first term exists since $t \mapsto u_{t}(a,
t) \epsilon L^{2} (0, 1)$ while the second term exists since $t
\mapsto f_{t} (at) \epsilon L^{2} (0, 1)$ by Hypothesis (3). Now $t
\mapsto u(a, t) \epsilon H^{3} (0, 1)$ implies that $u_{t, t} \epsilon
H^{1} (0, 1) \subset L^{2}(0, 1)$ and so on integrating by parts we
find that 
$$
\int_{0}^{1} u_{t} (a, t)\varphi_{t} dt = -\int_{0}^{1} u_{t, t} (a,
t) \varphi(t) dt + [u_{t} (a, t) \varphi (t)]_{t=0}^{t=1}.  
$$

Since\pageoriginale $u_{t} (a, t) = a y'(a, x)$ the boundary
conditions in \ref{chap6-eq2.34''} on $y$ imply that 
$$
[u_{t}(a, t) \varphi(t)]_{t=0}^{t=1} = [ay' (a, x) \varphi
  (x/a)]_{x=0}^{x=a} = 0. 
$$

Hence the right side of (\ref{chap6-eq2.37}) can be written as
\begin{equation*}
\int_{0}^{1} \{-2a^{-3} u_{t, t} (a, t) + t f_{t} (at) \} \varphi (t)
dt.\tag{2.38}\label{chap6-eq2.38} 
\end{equation*}

Since $-2a^{-3} u_{t, t} (a, t) + t f_{t} (a, t) \epsilon L^{2} (0,
1)$ we conclude that $u_{a} (a, t)$ satisfies a variational second
order (elliptic) boundary value problem (\ref{chap6-eq2.37}) with the
right hand side (\ref{chap6-eq2.38}) data in $L^{2}(0, 1)$. Then by
the regularity theory of solutions of (ordinary) differential equation
it follows that 
\begin{equation*}
t \mapsto u_{a} (a, t) \epsilon H^{2} (0, 1)\tag{2.39}\label{chap6-eq2.39}
\end{equation*}

Then 
\begin{equation*}
y_{a} (a, x) = u_{a} (a, x/a) + (-x/a^{2}) u_{t} (a, x/a) \epsilon H^{2} (0, a)\tag*{$(2.39)'$}\label{chap6-eq2.39'}
\end{equation*}
which proves the assertion (ii). Again, applying Sobolev's lemma to $y_{a}$, the second part of (iii) is also proved. This proved the proposition completely.

We also have the following regularity property for the adjoint state $p(a, x)$.

\begin{proposition}\label{chap6-prop2.2}
If satisfies the Hypothesis (3) and g the Hypothesis (4) then the adjoint state $x \mapsto p(a, x)$ belongs to $H^{3} (0, a)$ and consequently $x \mapsto p(a, x) \epsilon C^{2} ([0, a])$.
\end{proposition}

\begin{proof}
The adjoint state equation (\ref{chap6-eq2.27}) is transformed by (\ref{chap6-eq2.29}) as follows:
$$
p(a, at) = q(a, t) \text{ and } \psi (a, x) = \varphi (x/a)
$$
\begin{equation*}
\begin{cases}
& \int_{0}^{a} \{a^{-2} q_{t} (a. x/a) \varphi_{t} (x/a) + a(a, x/a) \varphi(x/a) \}dx\\
& = \int_{0}^{a} (y(a, x/a) - g(x/a)) \varphi(x/a) dx, \text{ for all } \varphi \epsilon H^{1} (0, a)
\end{cases}
\end{equation*}

That\pageoriginale is, we have
\begin{equation*}
\begin{cases}
& \int_{0}^{1} \{a^{-2} q_{t} (a, t) \varphi_{t} (t) + q(a,
  t)\varphi(t) \} dt = \int_{0}^{1} (u(a, t) - g(t)) \varphi(t) dt.\\ 
& \text{ for all } \varphi \epsilon H^{1} (0, 1).\tag{2.40}\label{chap6-eq2.40}
\end{cases}
\end{equation*}
\end{proof}

Since on the right hand side $t \mapsto u(a, t) - g(t) \epsilon H^{1}
(0, 1)$ by Proposition (\ref{chap6-prop2.1}) above it follows, again
by the regularity theory for ordinary differential equations, that 
\begin{equation*}
t \mapsto q(a, t) \epsilon H^{3} (0, 1)\tag{2.41}\label{chap6-eq2.41}
\end{equation*}

This is equivalent to saying that
\begin{equation*}
x \mapsto p(a, x) \epsilon H^{3} (0, a).\tag*{$(2.41)'$}
\end{equation*}

By Sobolev's lemma it follows that $x \mapsto p(a, x) \epsilon C^{2}
([0, 1])$, completing the proof of the proposition. 

Next we verify that $F$ defined by \ref{chap6-eq2.20'} satisfies the
required Hypothesis (1) and (2) for the validity of the calculation of
$dj/da$. 

If we assume that $\varphi \epsilon H^{3}(0, 1)$ then $x \mapsto
\varphi (x/a) \epsilon H^{3} (0, a)$ and then by Sobolev's lemma, $x
\mapsto \varphi(x/a) \epsilon C^{2} ([0, 1])$ and $\varphi'(x/a)
\epsilon H^{2} (0, a) \subset C^{1} ([0, 1])$. Hence we find, on using
Proposition (\ref{chap6-prop2.1}) (i) and (iii), that 
\begin{equation*}
x \mapsto F(x, a) = y'(a, x) \varphi'(x/a) + (y(a, x) - f(x)) \varphi(x/a) \epsilon C^{\circ} ([0, a])\tag{2.42}\label{chap6-eq2.42}
\end{equation*} 
since we know that $f \epsilon H^{1} (0, a) \subset C^{\circ} ([0,
  a])$ by Hypothesis (3) and Sobolev's lemma. Moreover,
differentiating the expression for $F$ with respect to a using
Proposition (\ref{chap6-prop2.1}) (ii) and (iii) we see that 
\begin{align*}
& x \mapsto y'_{a} (a, x) \varphi'(x/a) + y_{a} (a, x) \varphi(x/a) + y'(a, x) (\varphi'(x/a))_{a}\\
& \qquad  + (y(a, x) - f(x)) (\varphi(x/a))_{a} \epsilon C^{\circ} ([0, a])\tag{2.43}\label{chap6-eq2.43}
\end{align*}
which\pageoriginale proves that $F : \Lambda \to \mathbb{R}$ satisfies
the Hypothesis (1) and (2).This the expression on the right hand side
of (\ref{chap6-eq2.28}) has a meaning since 
\begin{equation*}
y'(a, x) p'(a, x) + (y(a, x) - f(x)) p(a, x) \epsilon C^{\circ} ([0, a])\tag{2.44}\label{chap6-eq2.44}
\end{equation*}
and we obtain
\begin{equation*}
dj/da = -[y'(a, a)p'(a, a) + (y(a, a) - f(a)) p(a, a)].\tag*{$(2.28)'$}\label{chap6-eq2.28'}
\end{equation*}

Thus we have proved the following main result of this section:
\begin{theorem}\label{chap6-thm2.1}
Under the Hypothesis (3) and (4) on the data f and g the cost function
$a \mapsto j(a)$ is differentiable and $dj/da$ is given by
\ref{chap6-eq2.28'} where $y(a, x)$ and $p(a, x)$ represent the direct
and adjoint state respectively governing the problem of optimal design
(2.18). 
\end{theorem}

\begin{remark}\label{chap6-rem2.4}
The genral method described in this section is not, in general, used
for one-dimensional problems since it is not economical to compute
$dj/da$ which in turn involves computations of $y$ and $p$, and their
derivativex (see \ref{chap6-eq2.28'}. In the case of one dimensional
problems other more efficient and simper methods are known in
literature. The importance of our method consists in its usefulness in
higher dimensions to device algorithms using, for instance, the
gradient method. 
\end{remark}


\begin{thebibliography}{99}
\bibitem{key1} {Brezis, H}.\pageoriginale Multiplicateus de Lagrange
  en torsion \'{e}lasto - plastique, Archive Rat. Mech. Anal. 49
  (1972), 32-40. 

\bibitem{key2} {Brezis, H and Sibony M}., Equivalence de deux
  in\'{e}quations variationnelles et applications, Archive
  Rat. Mech. Anal. 41 (1971), 254-265. 

\bibitem{key3} {Brezis, H and Sibony M}, M\'{e}thodes d'approximation
  et d'it\'{e}ration pourles op\'{e}rateurs monotones, Archive
  Rat. Mech. Anal. 28(1968), 

\bibitem{key4} {Brezis, H. and Stampacchia, G}., Sur la
  r\'{e}gularit\'{e} de la solution d'in\'{e}quations elliptiques,
  Bull. Soc. Math\'{e}matique de France, 96(1968), 153-180.

\bibitem{key5} {Brezis, H. and Stampacchia, G}, Une nouvelles methode
  pour l'\'{e}tude d'\'{e}coulement stationnaires, C. R. Acad. Sci
  Paris. 276(1973),

\bibitem{key6} {C\'{e}a, J}., Optimisation, Th\'{e}orie et
  algorithmes, Dunod, Gauthier - Villars Paris (1971).

\bibitem{key7} {C\'{e}a, J}, Approximation variationelle des
  probl\'{e}mes aux limites Annales de l'Institut Fourier, 14(1964),
  345-344.

\bibitem{key8} {C\'{e}a, J and Glowinski, R}., M\'{e}thodes
  num\'{e}riques pour l'\'{e}coulement lamminaire d'une fluide rigide
  visco-plastique incompressible, Int. Jr. of comp. Math. B, 3(1972),
  225-255.

\bibitem{key9} {C\'{e}a, J and Glowinski, R}, Sur des m\'{e}thodes
  d'optimisation par relaxation, Revue Francaise d'Automatique,
  Informatique, Recherche Op\'{e}rationelle R-3 (1973), 5-32.

\bibitem{key10} {Cryer, C. W.}, The solution of a quadratic
  programming problem using systematic over-relaxation. SIAM J. on
  control 9(1971). 

\bibitem{key11} {Davidon, W. D.}, Variable metric method for
  minimization. A. G. G. Res and Dev. Report No. ANL - 5990 (1959).

\bibitem{key12} {Dieudonn\'{e}, J}., Foundations of modern analysis,
  Academic Press. Newyork (1960).

\bibitem{key13} {Ekeland, I. and Temam R}., Analyse convexe et
  probl\'{e}mes variationelles, Dunod, Gauthier-Villars, Paris
  (1974).

\bibitem{key14} {Fletcher, R}.,\pageoriginale Optimization, Academic
  Press, Landon (1969).

\bibitem{key15} {Fletcher, R. and Powell, M}., A rapidly convergent
  method for minimization, Comp. J. 6(1963), 163-168.

\bibitem{key16} {Fletcher R. and Reeves C. M}., Functional
  minimization by conjugate gradients, Comp. J. 7(1964), 149-153.

\bibitem{key17} {Frank, M, and Wolfe, P}., An algorithm for quadratic
  programming, Naval Res. Log. Quart. 3(1956), 95-110.  

\bibitem{key18} {Glowinski, R}., La m\'{e}thode de relaxation,
  Rendiconti di Matematica, Universit\'{a} di Rome (1971).  

\bibitem{key19} {Glowinski, R}, Sur la minimization, par surrelaxation
  avec projection de fontionneles quadratiques dans les espaces de
  Hilbert, C. R. Acad. Sci. Paris 276(1973). 1421-1423.  

\bibitem{key20} {Glowinski, R., Lions J. L. and Tr\'{e}moli\'{e}res,
  R}., Analyse num\'{e}rique des in\'{e}quations
  variationelles. Volumes 1and 2, Dunod Fauthier-Villars, Paris
  (1976).
  
\bibitem{key21} {Glodstein, A. A}., Convex programming in Hilbert
  spaces, Bull. Amer. Math. Soc. 70(1964), 709-710.  

\bibitem{key22} {Hestenes, M. R}., The conjugate gradient method for
  solving lenear systems, Proc. Symposium in Appl. Math. 6 - Numerical
  Analysis Amer. Math. Soc. and McGraw Hill, New york (1956),
  83-102.  

\bibitem{key23} {Hestenes, M. R}, Multiplier and gradient methods
  J.O.T.A. 4(1969), 303-320.  

\bibitem{key24} {Hestenes, M. R. and Stiefel, E}., Methods of
  conjugate gradient for solving linear systems, J. Res. Nat. Bureau
  of Standarada 49(1952), 409-436. 

\bibitem{key25} {Huard, P}., Resolution of mathematical programming
  with non-linear constraints by the method of centres, Non-linear
  Programming (Edited by Abadie J.) North Holland (1967).   

\bibitem{key26} {Kuhn, H. W}., On a pair of dual non-linear programs,
  Non-linear programming, (Edited by E.M.L. Beale) NATO Summer
  School. Menton (1964), North Holland, Amsterdam (1967), 37-54.   

\bibitem{key27} {Kuhn, H. W}., An a logrithm for equilibrium points in
  bimatrix games, Proc. Nat Acad, Sci, U.S.A. 47(1961), 1657-1662.  

\bibitem{key28} {Kuhn, H. W. and Tucker, A. W}.,\pageoriginale
  Non-linear programming, Proc. Second Berkeley Symposium on
  math. Statistic and Probability, University of California Pres
  (1951), 481-492.  

\bibitem{key29} {Ky - Fan}, Sur un th\'{e}or\'{e}me minimax,
  C. R. Acade. Sci. Paris 259(1964), 3925-3928.  

\bibitem{key30} {Lions, J. L}., Cours d'analyse num\'{e}rique, Ecole
  Polytechnique, Paris (1972).  

\bibitem{key31} {Lions, J. L}, Contole optimal des syst\'{e}mes
  gouvern\'{e}s par des \'{e}quations aux d\'{e}riv\'{e}es partielles,
  Dunod, Gauthier-Villars, Paris (1968).  

\bibitem{key32} {Lions, J. L. and Magenes E}., Probl\'{e}mes aux
  limites non-homog\'{e}nes, Vol.1, Dunod, Gautheir-Villars, Paris
  (1968); (English translation: Non-homogeneous boundary value
  problems Vol.1, Springer-Verlag(1972)).  

\bibitem{key33} {Lions, J. L. and Stampacchia, G}., Variational
  inequalities,Comm. Purw and Appl. Math. 20(1967), 493-519.  

\bibitem{key34} {Loomis, L. H.}, An introduction to abstract harmonic
  analysis, Van Nostrand, New Yorl (1953).  

\bibitem{key35} {Powell, M.J.D.}, A method for non-linear optimization
  in minimization problems, optimization (Edited by R. Fletcher)
  Academic Press, New York (1969).  

\bibitem{key36} {Rockafellat, A.T.}, The multiplier method of
  Hestenses and Powell applies to convex programming, J. Opt. Th. and
  Appl. 12(1973).  

\bibitem{key37} {Rockafellat, A.T.}, Augmented Lagrange multiplier
  functions and duality in non-convex programming SIAM J. on control
  12(1974), 268-285.  

\bibitem{key38} {Rockafellat, A.T.}, Dualtiy and stability in extremum
  problems involving convex functions, Pacific J. Math., 21(1962),
  167-187.  

\bibitem{key39} {Rosen, J, B.}, The gradient projection method for
  non-linear programming, Part I, Linear constraints, SIAM J. 8(1960),
  181-217.  

\bibitem{key40} {Rosen, J, B.}, The gradient projection method for
  non-linear programming, Part II, Non-linear constraints SIAM
  J. 9(1961). 514-532.  

\bibitem{key41} {Sion, M.},\pageoriginale Existence des cols pour les
  functions quasi-convexex at s\'{e}mi-continues,
  C. R. Acad. Sci. paris 244(1954). 2120-2123.  

\bibitem{key42} {Sion, M.}, On general minimax theorems, Pacific
  J. Math. 8(1958), 171-175.  

\bibitem{key43} {Stampacchia G.}, Formes bilin\'{e}aires coercitives
  sur les ensembles convexes, C. R. Acad Sci. Paris 258(1964),
  4413-4416.  

\bibitem{key44} {Stampacchia G.}, Variational inequalities, Theorey
  and Applications of Monotone, operators, Proc. NATO Advanced Study
  Institute, Venice (1968), 101-192.  

\bibitem{key45} {Tr\'{e}moli\'{e}res, A}, La m\'{e}thode des Centers a
  troncature variable, Th\'{e}se $3^{e}$ Cycle, Paris (1968).   

\bibitem{key46} {Tr\'{e}moli\'{e}res, A}, Optimisation
  non-lin\'{e}aire avec containtes, Rapport IRIA.  

\bibitem{key47} {Tucker, A. W.}, Duality theory of linear programs, A
  constructive approach with applications, SIAM Revue 11(1969),
  347-377.  

\bibitem{key48} {Tucker, A. W.}, Solving a matrix game by linear
  programming, IBM J. Res. and Dev. 4(1960), 507-517.  

\bibitem{key49} {Uzawa, H.}, Iterative methods for concave
  programming, Studies in linear and non-linear programming (Edited by
  Arrow, K. J., Hurwitz, L. and Uzawa, H.) Stanford University Press
  (1958), 154-165.  

\bibitem{key50} {Varge, R. S.}, Matrix iterative analysis, Prentice
  Hall, Englewood Clifs, New Jersey (1962).  

\bibitem{key51} {Wolfe, P.}, Method of non-linear programming, Recent
  advances in mathematical programming (Edited by Graves, R. L. and
  Wolfe, P.) McGraw Hill, New York (1963), 67-86. 

\bibitem{key52} {Zoutendijk, G.}, Non-linear programming, A numerical
  survey, SIAM J. on Control, 4(1966), 194-210.   

\bibitem{key53} {C\'{e}a, J.} On the problem of optimal design.

\bibitem{key54} {Fages, R.} A generalized Newton method (to appear).

\bibitem{key55} {Auslander, A.}, M\'{e}thodes num\'{e}riques pour la
  d\'{e}composition et la minimisation de fonctions non
  diff\'{e}rentiables, Numer. Math, 18(1972), 213-223.
\end{thebibliography}



