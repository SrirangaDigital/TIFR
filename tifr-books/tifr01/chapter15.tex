
\chapter{The Zeta Function of Riemann (Contd).}\label{chap15}

\setcounter{section}{9}
\section[Hardy's Theorem]{Hardy's Theorem \cite[p.214]{key16}}\label{chap15:sec10} 
 We have\pageoriginale proved that $\zeta(s)$ has
an infinity of complex zeros in $o<\sigma <1$. Riemann conjectured
that {\em all} these zeros lie on the line $\sigma =\frac{1}{2}$. Though
this conjecture is yet to be proved, Hardy showed in 1914 that an
infinity of these zeros do lie on the `critical' line. We shall prove
this result.

In obtaining the functional equation by the third method, we have used
the formula:
$$
\pi^{-s/2} \Gamma(s/2) \zeta(s) = \frac{1}{s(s-1)} +
\int\limits^\infty_1  \psi (x) (x^{\frac{s}{2}-1} + x^{-s/2 -1/2}) dx,
$$
where $\psi(x) = \sum\limits^\infty_{n=1}e^{-n^2\pi x}$,
$x>0$. Multiplying by $\dfrac{1}{2} s(s-1)$, and writing $x
=\frac{1}{2} + it$, we get
$$
\zeta \left(\frac{1}{2}+it \right) = \equiv (t) = \frac{1}{2} - \left(t^2 + \frac{1}{4} \right) \int\limits^\infty_1 \psi(x) x^{-3/4} \cos \left(\frac{1}{2} t \log x \right)dx
$$
It is a question of showing that $\equiv (t)$, which is an even,
entire function of $t$, real for real $t$, has an infinity of real
zeros.

Writing $x = e^{4u}$, we get
$$
\equiv (t) = \frac{1}{2} - 4 \left(t^2 + \frac{1}{4} \right) \int\limits^\infty_0
\psi (0^{4u}) e^u \cos (2ut) du.
$$

If we write
$$
\psi (u) = \psi (e^{4u}) e^u,
$$
we obtain\pageoriginale
$$
\equiv \left(\frac{t}{2} \right) = \frac{1}{2} - (t^2+1) \int\limits^\infty_0
\phi(u) \cos ut \; du
$$
We wish now to get rid of the factor $(t^2+1)$ and the additive
constant $\frac{1}{2}$ so as to obtain $\equiv (t/2)$ as a cosine
transform of $\phi$. This we can achieve by two integrations (by
parts). However, to get rid of the extra term arising out of partial
integration we need to know $\phi'(0)$. We shall show that
$\phi'(0)=-\frac{1}{2}$. For, by the functional equation of the
theta-function, 
$$
1 + 2 \psi(x) = \frac{1}{\surd x} \left[1 + 2 \psi \left(
  \frac{1}{x}\right) \right] 
$$
or
$$
1+2 \psi (e^{4u}) = e^{-2u} [1 + 2  \psi (e^{-4u})]
$$
or
$$
e^u + 2 e^u \psi (e^{4u}) = e^{-u} + 2 e^{-u} \psi(e^{-4u})
$$
or
$$
e^u + 2 \phi (u) = e^{-u} + 2 \phi (-u)
$$
so that \quad $\dfrac{d}{du} \left[ e^u + 2 \phi (u)\right]_{u=0} = 0$ 
$$
\text{i.e. } \quad \phi'(0) = - \frac{1}{2}.
$$

We also know that $\psi(x) = O(e^{-\pi x})$ as $x \to \infty$. Hence
$$
t^2 \int\limits^\infty_0 \phi(u) \cos u t \; du = \frac{1}{2} -
\int\limits^\infty_0 \phi''(u) \cos ut \; du
$$ 
Hence\pageoriginale
\begin{equation*}
\equiv (t/2) = \int\limits^\infty_0 [\phi''(u) - \phi(u)] \cos ut \;
du \tag{10.1}\label{c15:eq10.1}
\end{equation*}
By actual computation it may be verified that
$$
\phi''(t) - \phi(t) = 4 [6e^{5t} \psi'(e^{4t}) + 4 e^{9t} 
  \psi''(e^{4t})] 
$$
Again if we write
\begin{align*}
\phi(u) & = e^u \psi(e^{4u}) + \frac{1}{2} e^u = \phi(u) + \frac{1}{2} e^u\\
& = \frac{1}{2} e^u \vartheta (e^{4u}),
\end{align*}
then by the theta relation, we have
$$
\Phi (u) = \Phi(-u), \text{ and } \Phi''(u) - \Phi (u) = \phi''(u) -
\phi (u)
$$
Let us now write (\ref{c15:eq10.1}) in the form
$$
\equiv (t) = 2 \int\limits^\infty_0 f(u) \cos ut \; du
$$
We wish to deduce that
\begin{equation*}
f(u) = \frac{1}{\pi} \int\limits^\infty_0 \equiv (t) \cos ut \; dt, 
 \tag{10.2}\label{c15:eq10.2}
\end{equation*}
by Fourier's integral theorem. We need to establish this result.


\medskip
\noindent\textbf{Fourier Inversion Formula.}\cite[p.10]{key5} 
If $f(x)$ is absolutely integrable in $(-\infty, \infty)$, then 
$$
\phi (\alpha) \equiv \int\limits^\infty_{-\infty} f(x) e^{i\alpha x}
dx 
$$
exists for every real $\alpha$, $-\infty < \alpha < \infty$, is
continuous and bounded in $(-\infty, \infty)$. We wish to find out
when 
$$
f(x) = \frac{1}{2\pi} \int\limits^\infty_{-\infty} \phi(\alpha) e^{-i
  \alpha x} d \alpha
$$
for {\em a given $x$}. The conditions will bear on the behaviour of $f$ in a 
neighbourhood\pageoriginale of $x$.

If 
\begin{align*}
S_R (x) & = \frac{1}{2\pi i} \int\limits^R_{-R}e^{-i\alpha x}
\phi(\alpha) d \alpha\\
& = \frac{1}{\pi} \int\limits^\infty_{-\infty} \frac{\sin Rt}{t}
f(x+t) \; dt\\
& = \frac{2}{\pi} \int\limits^\infty_{0} \frac{\sin Rt}{t}
\frac{f(x+t)+f(x-t)}{2} \; dt,
 \end{align*}
and
$$
g_x(t) = \frac{1}{2} \left[f(x+t) + f(x-t) \right] - f(x),
$$
then
\begin{align*}
S_R (x) - f(x) & = \frac{2}{\pi} \int\limits^\infty_0 \frac{\sin
  Rt}{t} g_x(t) \; dt\\
& = \frac{2}{\pi} \left[\int\limits^\epsilon_0 +
  \int\limits^\infty_\epsilon \right] = I_1 + I_2 , \text{ say,}
\end{align*}
for a fixed $\epsilon >0$.

$I_2 \to 0$ as $R \to \infty$, by the Riemann-Lebesgue Lemma. So, if
\; $\dfrac{g_x(t)}{t}$ is absolutely integrable in $(0,\epsilon)$,
then $I_1 \to 0$ as $\epsilon \to 0$. Hence we have the 

\begin{theorem*}\cite[p.10]{key5}
If \; $\dfrac{g_x(t)}{t}$ is absolutely integrable in
$(0,\epsilon)$, then $\lim\limits_{R\to\infty} S_R (x) = f(x)$.
\end{theorem*}

If,\pageoriginale in particular, $f$ is absolutely integrable in
$(-\infty, \infty)$ and differentiable in $(-\infty, \infty)$ then
$\lim\limits_{R\to\infty} S_R(x) = f(x)$ for every $x$ in $(-\infty,
\infty)$. It should be noted that sufficient conditions for the
validity of the theorem are: (i) $f(x)$ is of bounded variation in a
neighbourhood of $x$, and (ii) $f(x)$ is absolutely integrable in
$(-\infty, \infty)$. Then $\lim\limits_{R\to \infty} S_R(x)
=\frac{1}{2} [f(x+0) + f(x-0)]$.

We now return to (\ref{c15:eq10.2}) which is an immediate deduction from the
formula for $\equiv (t)$, on using Fourier's inversion formula.

Now we know that $\equiv(t) = \xi(\frac{1}{2}  + it) = O
(t^{\epsilon_1} e^{-\frac{\pi}{4}t})$; and $\equiv (t)$ is an
entire function of $t$. Hence we are justified in obtaining, by
differentiation of (\ref{c15:eq10.2}),
$$
f^{(2n)} (u) = \frac{(-1)^{n}}{\pi} \int\limits^\infty_0 \equiv (t)
t^{2n} \cos ut\; dt.
$$
Since $\psi(x)$ is regular for $\re x >0$, $f(u)$ is regular for
$-\pi/4 < {\rm Im} \; u  < \dfrac{\pi}{4}$ (Note that $x=e^{2u}$). Let 
$$
f(iu) = c_0 + c_1 u^2 + c_2 u^4 + \cdots
$$
Then 
$$
c_n = \frac{(-1)^n f^{(2n)}(0)}{(2n)!} = \frac{1}{(2n)!\pi}
\int\limits^\infty_0 \equiv (t) t^{2n} dt
$$
If $\equiv (t)$ had only a finite number of zeros, then $\equiv (t)$
would be of constant sign for $t > T$. Let $\equiv (t) > 0$ for
$t>T$. Then $c_n >0$ for $n>2n_0$, since
\begin{align*}
\int\limits^\infty_0 \equiv (t) t^{2n} \; dt & > \int\limits^{T+2}_{T+1}
\equiv (t) t^{2n} \; dt - \int\limits^T_0 |\equiv (t)| t^{2n} \; dt\\
& > (T+1)^{2n} \int\limits^{T+2}_{T+1} \equiv (t) dt - T^{2n}
\int\limits^T_0 |\equiv (t)| \; dt\\
& > 0 \text{ for } n > 2n_0 , \text{ say}.
\end{align*}\pageoriginale

Hence $f^{(n)}(iu)$ increases steadily with $u$ for $n>2n_0$. However
we shall see that $f(u)$, and all its derivatives, tend to zero as $u
\to \dfrac{\pi i}{4}$ along the imaginary axis.

We know that
$$
\psi(x) = x^{-1/2} \psi \left(\frac{1}{x} \right) + \frac{1}{2}
x^{-\frac{1}{2}} - \frac{1}{2}
$$

Further
\begin{align*}
\psi (i+\delta) & = \sum\limits^\infty_{n=1} e^{-n^2(i+\delta)\pi}  =
\sum\limits^\infty_{n=1} (-1)^n e^{-n^2 \pi \delta}\\
& = 2 \sum\limits^\infty_1 e^{-(2n)^2 \pi \delta} -
\sum\limits^\infty_1 e^{-n^2 \pi \delta}\\
& = 2 \psi (4\delta) -\psi (\delta)\\
& = \frac{1}{\surd \delta} \psi \left(\frac{1}{4\delta} \right) - \frac{1}{\delta}
\psi \left(\frac{1}{\delta} \right) - \frac{1}{2}\\
\text{i.e. } \qquad \frac{1}{2} + \psi (i+\delta) & = \frac{1}{\surd
  \delta} \psi \left( \frac{1}{4\delta}\right) - \frac{1}{\surd
  \delta} \psi \left( \frac{1}{\delta}\right)
\end{align*}

Thus $\frac{1}{2} + \psi (x) \to 0$ as $\delta \to 0$, and so do its
derivatives (by a similar argument). Hence $\frac{1}{2} + \psi (u) \to
0$ as $u \to \dfrac{\pi i}{4}$ along the imaginary axis, and so do its
derivatives. Thus $f(u)$ and all its derivatives $\to 0$ as $u -
\dfrac{\pi i}{4}$.
