
\chapter{Relations between Lie groups and Lie algebras - I}\label{chap3} 

\setcounter{section}{3}
\setcounter{subsection}{0}
\subsection{Differential of an analytic
  representation.}\label{chap3-sec3.1}\pageoriginale 

\begin{defi*}
An {\em analytic representation} of a Lie group $G$ into a Lie group $G'$
is an algebraic representation which is an analytic map. 
\end{defi*}

\begin{remark*}
It is true, as we shall see later (Cor. to Th. \ref{chap4-thm4},
Ch. \ref{chap4-sec4.5}) that any 
representation of the underlying topological group G in $G'$ is
itself a representation in the above sense. 
\end{remark*}

We now seek to establish a correspondence between analytic
representations of Lie groups and algebraic representations of their
Lie algebras. As a first step, we prove the following 

\setcounter{proposition}{0}
\begin{proposition}\label{chap3-prop1}%\prop 1
To every analytic representation $h : G \longrightarrow G'$ there
corresponds a map $dh : \mathcal{U}(G)\rightarrow
\mathcal{U}(G')$ which is a representation of algebras such that
$\Delta(f\circ  h)=(dh (\Delta)f)\circ h$. 
\end{proposition}

Let $y \in G$ and $y'=h(y)$. If $f$ is an analytic function on $G'$,
we have 
$$
\tau_y(f\circ  h)(x)=f(h(xy))=f(h(x) h(y))=(\tau_{y'}f)\circ  h (x). 
$$

We may now write down the Taylor formula for both sides of the
equation and equate the coefficients of powers of $y$ (by the
uniqueness of development in power series). We have 
$$
\sum_{\alpha}\dfrac{1}{\alpha !}y^\alpha \Delta_\alpha(f \circ
h)= ( \sum\limits_{\alpha'} \dfrac{1}{\alpha'!} y'^{\alpha'}
\Delta'_{\alpha'} f)\circ h. 
$$

But $h$ being an analytic map, $(h(y))_i =
\sum_{\alpha'}\nu_\alpha^i y^\alpha$. 
There is no constant term in this summation since $(h(y))_i=0$ at
$y=e$. Hence ${y'}^{\alpha'}=\sum_{| \alpha | \ge | \alpha '
  |} \mu^{\alpha'}_{\alpha}y^\alpha$,\pageoriginale where
$\mu^{\alpha'}_{\alpha}$ are constants, and on substitution in the
above equation, we obtain 
\begin{align*}
\sum_{\alpha}\dfrac{1}{\alpha !}y ^\alpha \Delta_\alpha (f\circ
h) & = \sum_{\alpha'}(\frac{1}{\alpha'!}\sum_{\mid \alpha \mid \ge
  \mid \alpha'\mid} \mu^{\alpha '}_{\alpha}y^\alpha
\Delta'_{\alpha'}f)\circ h\\ 
& = \sum_{\alpha} y^\alpha (\sum_{\mid \alpha' \mid \le
  \mid \alpha'\mid} \mu^{\alpha}_{\alpha}\frac{1}{\alpha' !}
\Delta'_{\alpha '} f)\circ  h. 
\end{align*}
the series being uniformly absolutely convergent. If
$D'_{\alpha}$ denotes $\sum_{| \alpha' | \le |
  \alpha'|}\break \mu^{\alpha}_{\alpha}\dfrac{\alpha !}{\alpha' !}
\Delta'_{\alpha'}$,  which is a left invariant differential operator,
then $\Delta_\alpha(f\circ  h) = (D'_{\alpha}f)\circ h$. Moreover, this
equation completely determines $D'_{\alpha}$ since its value at
$e$ given by $D_{\alpha}f (e')=\Delta_\alpha(f\circ h) (e)$. As the
$\Delta_\alpha$ form a basis for $\mathcal{U}(G)$ in $G$, we may
define a linear map $dh : \mathcal{U}(G) \to \mathcal{U}(G')$ by setting
$dh (\Delta_\alpha)=D'_{\alpha}$. It is obvious that $\Delta(~f \circ 
~h)= (dh(\Delta)f)\circ h$ for any  $\Delta \in \mu (G)$. To complete
the proof of proposition \ref{chap3-prop1}, one has only to show that $dh(\Delta_1
\Delta_2)=dh(\Delta_1)dh(\Delta_2)$. 
But this is obvious since
\begin{align*}
(dh(\Delta_1 \Delta_2)f) \circ  h & = \Delta_1 \Delta_2(f \circ h)\\ 
& = \Delta_1(dh(\Delta_2)f \circ h)\\
& = (dh(\Delta_1 dh (\Delta_2)f)\circ  h.\\
\end{align*}

Now, $dh (\Delta_\alpha) = \sum_{| \alpha' | \leq |
  \alpha |} \mu^{\alpha'}_{\alpha}\dfrac{\alpha !}{\alpha'!}
\Delta'_{\alpha'}$ is of order less than or equal to that of
$\Delta_\alpha$. By linearity, the same is also true of any operator
$\Delta \in \mathcal{U}(G)$. Also, $dh$ preserves constant terms. The
image of $\mathfrak{g}$ is in $\mathfrak{g}'$, and by Proposition
\ref{chap3-prop1}, 
$dh$ restricted to $\mathfrak{g}$ is a Lie algebra representation. This
is said to be the \textit{differential} of the map $h$. 

\begin{remarks*}
\begin{enumerate}
\renewcommand{\labelenumi}{(\theenumi)}
\item If we have another representation $h' : G' \rightarrow G''$,
  it is obvious that $d(h' \circ  h)=dh'\cdot dh$. 

\item If\pageoriginale $h$ is an analytic map of a manifold $V$ into a
  manifold $W$, 
  then we can define the differential of $h$ at $x$, viz., $dh_x : T_x
  \rightarrow T_{h(x)}$ where $T_x$, $T_{h(x)}$ are tangent spaces
  at the respective points. This map makes correspond to a tangent
  vector $X$ at $x$, the vector $X'$ at $h(x)$ such that $X'f=X(f \circ
  h )$ for every function $f$ analytic at $h(x)$. However, we cannot,
  in general, define the image a vector field. As we have seen, in the
  case of Lie groups, as long as one is considering only left
  invariant vector fields, one can talk of an image vector field. Thus
  we now have, corresponding to an analytic representation of a Lie
  group $G$ into another Lie group $G'$, two notions of a differential
  map: the linear map of the tangent space at a into that at
  $h(e)=e'$, and the representation of the Lie algebra of $G$ in that
  of $G'$. These two notions are essentially the same in the following
  sense. Let $\varphi$, $\varphi'$  be the canonical vector space
  isomorphisms of $\mathfrak{g}$, $\mathfrak{g}'$ with $T_e$, $T_{e'}$
  respectively. Then the diagram 
\[
\xymatrix@C=1.5cm{
\mathfrak{g}\ar[d]^{dh}\ar[r]^{\varphi} & T_{e}\ar[d]^{dh_{e}}\\
\mathfrak{g}'\ar[r]^{\varphi'} & T_{e'}
}
\]
is commutative.
\end{enumerate}
\end{remarks*}

\begin{proposition}\label{chap3-prop2}%\prop 2
 Let $G$ and $G'$ be two connected Lie groups. An analytic
 representation of $G \rightarrow G'$ is surjective if and only if
 the differential map is surjective. 
\end{proposition}

\begin{proposition}\label{chap3-prop3}%\prop 3
A representation $h$ of a Lie group $G$ in another Lie group $G'$ is
{\em locally injective} (i.e. there axises a neighbourhood of $e$ on
which $h$ is injective) if and only if dh is injective. 
\end{proposition}

These\pageoriginale two propositions are consequences of the corresponding
properties of manifolds, the proofs of which we omit. 


\subsection{Subgroups of a Lie group.}\label{chap3-sec3.2}%\sec 3.2

\begin{defi*}% definition
An analytic map $f$ of a manifold $U$ into another manifold $V$ is
 said to be {\em regular} at a point $x$ in $U$ if the differential
 map $df_x$ is injective. 
\end{defi*}

\begin{defi*}%\def
A {\em submanifold} of an analytic manifold $U$ is a pair $(V, \pi)$
consisting of a manifold $V$ which is countable at $\infty$ and an
injective analytic map $\pi$ of $V$ into $U$ which is everywhere
regular. 
\end{defi*}

\begin{remarks*}
\begin{enumerate}
\renewcommand{\labelenumi}{(\theenumi)}
\item The topology on $\pi (V)$ is not that induced from the topology
  of $U$ in general. For instance, if $T^2$ is the two - dimensional
  torus, $V$ the space of real numbers, and $\pi$ the map $t
  \rightarrow (t, \alpha t)$ of $V$ into $T^2$, where $\alpha$ is
  irrational, it is easy to see that $\pi$ is an injective, analytic,
  regular map. But $\pi$ cannot be a homeomorphism of $V$ into
  $T^2$. For, every neighbourhood of $(0 ,0)$ in $T^2$ contains points
  $(t, \alpha t)$ with arbitrarily large values of $t$. Hence, the
  inverse image of this neighbourhood in $\pi (U)$ with the induced
  topology can never be contained in a given neighbourhood of $0$ 
  in~$R$. 

\item Nevertheless, it is true that locally, for every point $x$ of
  $V$, there exist neighbourhoods $W$ \textit{in} $V$ and $W^1$ in $U$
  which satisfy the following : A coordinate system $(x_1, \ldots ,
  x_n)$ can be defined in $W^1$ such that $W$ is defined by the
  annihilation of certain coordinates. 
\end{enumerate}
\end{remarks*}

\begin{defi*}%\def
 A\pageoriginale Lie subgroup of a Lie group $G$ is a submanifold $(H,
 \pi)$, $\pi(H)$ being a subgroup of $G$. 
\end{defi*}

We define on $H$ the group structure obtained by requiring that $\pi$
be a monomorphism. Since the map $\pi$ of $H$ in $G$ is regular,
locally the analytic structure of $H$ is induced form that of
$G$. Hence the group operations in $H$ are analytic in $H$, as they
are analytic in $G$. $H$ is therefore a Lie group. 

\begin{proposition}\label{chap3-prop4}%\prop 4
 The Lie algebra of a Lie subgroup of a Lie group $G$ can be
 identified with a subalgebra of the Lie algebra of $G$. 
\end{proposition}

In fact, if $(H, \pi)$ is the subgroup, $\pi$ is a representation of
$H$ in $G$ and $d\pi$ is injective since $\pi$ is regular. We identify
the Lie algebra $\mathscr{S}$ of $H$ with the subalgebra
$d\pi\mathscr{(S)}$ or $\mathfrak{g}$. 

\subsection{One-parameter subgroups.}\label{chap3-sec3.3}%\sec 3.3

\begin{defi*}% \def
An analytic representation $\rho$ of $R$ into $G$ is said to be a {\em
  one-parameter subgroup} of $G$. 
\end{defi*}

We know that the representation $\rho$ gives rise to a differential
map $d \rho$ of the Lie algebra of $R$ (spanned by $\dfrac{d}{dt})$
into the Lie algebra of $G$. Let $d \rho (\dfrac{d}{dt})=X=\sum
\lambda_j X_j$. We now form the differential equations satisfied by
the function $\rho$. 

Let $(x_1, x_2, \ldots x_n)$ be a coordinate system in a neighbourhood
of $e$ in $G$ and Let $\rho_i$ denote $x_i\circ \rho$. Now 
\begin{align*}
& \rho_i (t+ t')  = \varphi_1(\rho (t), \rho(t'))\\
& \frac{\partial}{\partial t'}(\rho_i(t+t'))  = \sum_{k}
\frac{\partial \varphi_i}{\partial y_1} (\rho (t), \rho(t')).\frac{d
  \rho_k}{dt}(t) 
\end{align*}

Putting $t'=0$, we get
$$ 
\frac{d \rho_i}{dt}(t) = \sum_{k} \frac{d \rho_k}{dt}(0)
\frac{\partial \varphi_i}{ \partial y_k}(\rho (t), e). 
$$\pageoriginale

If  $X_i=\Delta_{[i]}$, we have
$$
X_i = \frac{\partial}{\partial x_i} + \sum_{j}  a_{ij}(x)
\frac{\partial}{\partial x_j}\quad \text{with}\quad a_{ij}(e)=0. 
 $$

Since $(Xf)\circ \rho = \frac{d}{dt}(f\circ \rho)$ for every function
analytic at $e$, we get 
$$
\frac{d \rho_i}{dt}=(X x_i)\circ \rho\quad\text{by setting} f = x_i.
$$

Hence 
\begin{align*}
\frac{d \rho_i}{dt}(0) & = (X x_i) \circ \rho (0)\\
& = X x_i (e)\\
& = \sum (\lambda_j X_j ) x_i(e)\\
&=\lambda_i.
\end{align*}

To sum up, $\rho$ satisfies the system of differential equations
\begin{enumerate}
\renewcommand{\theenumi}{\Alph{enumi}}
\renewcommand{\labelenumi}{(\theenumi)}
\item  $\dfrac{d \rho_i}{dt} = \sum_{k} \lambda_k  \;  \dfrac{\partial
  \varphi_i}{\partial y_k} \; (\rho (t), e)$ 
 
with the initial condition

\item $\rho_i(0)=0$.

(A) implies  $\dfrac{d \rho_i}{dt}(0)=\lambda_i$.
\end{enumerate}

Now, conversely if are given the system of differential equations
$(A)$ with the initial condition (B), then by Cauchy's theorem on
the existence and uniqueness of solutions of differential equations,
there exists one and only one solution $t \rightarrow \rho (t,
\lambda)$ which is analytic in $t$ and $\lambda$ in a neighbourhood of
$(0, \lambda)$. We shall now show that $\rho(t+u)= \rho(t)\cdot\rho(u)$
for sufficiently small values of $t$ and $u$. 

Let\pageoriginale
\begin{align*}
\sigma'_i(t) & =\varphi_i(\rho (u),\rho (t)).\quad \text{Then}\\
\frac{d \sigma'_i} {dt} &= \sum_{l} \frac{\partial
  \varphi_i}{\partial y_i}(\rho (u),\rho (t))\frac{d \rho_l}{dt}(t)\\ 
& = \sum_{k,j} \lambda_k \frac{\partial \varphi_i}{\partial
  y_l}(\rho (u),\rho (t)) \frac{\partial \varphi_l}{\partial y_k}(\rho
(t),e) 
\end{align*}
since the $\rho_i$ are solutions of (A). On the other hand, we have
\begin{align*}
\varphi_i(\rho (u)\rho (t),y) & = \varphi_i (\rho (u),\rho (t) y)\\
&= \varphi_i(\rho (u),\varphi(\rho (t),y))\\
\frac{\partial \varphi_i}{\partial y_k} (\rho (u)\rho (t), y) & =
\sum\limits^{n}_{l=1} \frac{\partial \varphi_i}{\partial y_l}(\rho
(u),\rho (t)y) \frac{\partial \varphi_l}{\partial y_k}(\rho (t),y). 
\end{align*}

Hence,
$$
\frac{d \sigma'_i}{dt} = \sum_{k} \lambda_k \frac{\partial
  \varphi_i}{\partial y_k}(\sigma'(t), e). 
$$
i.e. $\sigma'_i$ is a solution of (A) with the initial condition
(C): 
$$
\sigma'_i (0) = \varphi_i(e,\rho (u))= \rho_i(u).
$$

Also, $t \rightarrow \sigma(t)= \rho(t+u)$ is a solution of (A)
since the differential equation (A) is a invariant for translations
of it. Also $\sigma(0) = \rho(u)$. 

Hence $\sigma'_i$ and $\sigma_i$ are two sets of solutions of (A)
with the same initial conditions, and therefore 
$$
\sigma'_i(t)= \rho(t + u),\quad\text{i.e.}\quad \varphi_i(\rho (t),\rho (u))=
\rho_i(t + u). 
$$
or $\rho(t) \rho (u)= \rho (t+u)$ for sufficiently small values of $t$
and $u$. Also this map $t \rightarrow \rho (t,X)$ is analytic. We
assume the following 

\begin{lem}\label{chap3-lem1}% lem 1
 Let\pageoriginale $H$ be a connected, locally connected and simply
 connected  topological and $f$ a local homomorphism of $H \rightarrow
 G$ (i.e. a 
 continuous map of a neighbourhood of $e$ into $H$ such that
 $f(xy)=f(x) f(y)$ for all $x$, $y$ such  that $x$, $y$, $xy \in V$). Then
 there exists one and only one representation $\tilde{f}$ of $H$ in
 $G$ which coincides with $f$ on $V$. 
\end{lem} 

We immediately obtain (since $R$ is simply connected), the

\setcounter{thm}{0}
\begin{thm}\label{chap3-thm1}% \the 1
 For every $X \in \mathfrak{g}$, there exists one and only one
   one - parameter subgroup $\rho (t,X)$ {such that} $d \rho
 \dfrac{(d)}{dt}=X$. {The function} $\rho(t, X)$ {is analytic
   in} $t$ {and} $X$. 
\end{thm}

One can assign to any finite dimensional vector space over the real
number field a manifold structure which is induced by that of the
real numbers. In particular, The Lie algebra of a Lie group also has
an analytic structure. Whenever we talk of an analytic map into of
from a Lie algebra, it is to this analytic structure that we refer. 

\medskip
\noindent{\textbf{Proof of the Lemma}}
Consider the Cartesian set product $\hat{H}=H \times G$. We provide
$\hat{H}$ with a topology by defining the neighbourhood system at each
point $(x,y)$ in the following way: 

Let  $W$ be a neighbourhood of $e$ in $H \subset V$, where $V$ can be
assumed to be connected since $H$ is locally connected. The
fundamental system of neighbourhoods at $(x,y)$ is given by $ N(W, x,
y)=\{(x',y'): x' \in x W, y'=y f(x^{-1} x')\}$. It is easily verified
that this satisfies the neighbourhood axioms for a topology, and that
$\hat{H }$ with the usual projection $\pi : H \times G \rightarrow H $ is a
covering space of $H$. Let $H_1$ be the connected component of $(e,e)$
in $\hat{H}$. Then $H_1$ is a connected,  covering space of $H$ and
since $H$ is simply connected,$\pi$ is a homeomorphism of $H_1$ onto
$H$. Let $\eta$ be its inverse. Define $\tilde{f}(x)=\pi_2\circ \eta (x)$
for\pageoriginale every $x$ in $H$ where $\pi_2:H \times G \rightarrow
G$ is the second 
projection. $N(W,x,y)$ is mapped homeomorphically by $\pi$ onto  $x
W$. Hence $N(W,x,y)\subset H_1$ if $W$ is connected and $(x,y)\in
H_1$. It follows that $\tilde{f}$ is a representation which extends
$f$. 

\subsection{The exponential map.}\label{chap3-sec3.4}%\sec 3.4

We shall denote $\rho(t,X)$ by $\exp (t X)$.


But such a notation involves the tacit assumption that $\rho(t,X )$
depends only  on $t X$. In other words, one has to make sure that
$\rho (1, s X)= \rho (s, X)$ before such a notation becomes
permissible. But this is obvious in as much as $t \rightarrow \rho(st,
X)$ is a one -parameter subgroup with $d \rho \dfrac{(d)}{d(st)}=X$ or
$d \rho \dfrac{(d)}{dt}=sX$. The one-parameter subgroup such that $d
\rho \dfrac{(d)}{dt}=sX$ is, by definition, $t \rightarrow  \rho(t, s
X)$. By uniqueness of the one-parameter subgroups, $\rho (st, X)=
\rho(t, sX)$, or in particular, $\rho (s, X )= \rho  (1,s X)$. It is
easy to see that $\exp(tX)\exp(t'X)=\exp(t+t')X$  and $\exp (-X)=(\exp
X)^{-1}$. But, in general, $\exp Y\cdot \exp Y' \neq  \exp (Y+Y')$. 
 
\begin{thm}\label{chap3-thm2}%\the 2
The map $h: X \rightarrow \exp X$ {of} $\mathfrak{g}$ {into} $G$
is an analytic isomorphism of a neighbourhood of $0$ {in}
$\mathfrak{g}$ {onto a neighbourhood of} $e$ {in} $G$. 
\end{thm}
 
In fact, since $h$ is an analytic map, it is enough to show that the
Jacobian of the map $h \neq 0$ in a neighbourhood of the origin. 
$(X_1,\ldots,X_n) $ form a basis for $\mathfrak{g}$, where
$X_i=\Delta_{[i]}$. 
\begin{gather*}
h \left(\sum_{i} y_i X_i \right)=\exp (\sum_i y_i X_i)\\
\frac{\partial h_j}{\partial y_k}(0)=\dfrac{d}{dt}(\exp tX_k)
 {}_j(t=0) = (X_k x_j)_{x=e}=\delta_{jk}. 
\end{gather*}
i.e. the jacobian = $1$ at $e$. By continuity, the Jacobian does not
vanish in\pageoriginale a neighbourhood of $e$. 
 
Now, let $X_1,\ldots, X_n$ be an arbitrary basis of $\mathfrak{g}$.
This can be transported into a system of coordinates in $G$ by means
of the above map. For every $x \in G$ sufficiently near $e$, there
exists one and only one system $(x_1,\ldots,x_n)$ near $0$ such that
$x=\exp(\sum_{i} x_i X_i)$. 
 
This system of coordinates is called the \textit{canonical system of
  coordinates} with respect to any given basis. Hereafter, we will
almost always operate only with a canonical system of coordinates. 
 
\begin{remark*}%\rem 
 Let $x \in V$, $V$ being a neighbourhood of $e$ in which a canonical
 coordinate system exists and $x$ is sufficiently near $e$. Now, if  
\begin{align*}
 x & = \exp(\sum_{i} x_i X_i),\\
 x^p & = \exp (\sum_{i}(p x_i)X_i),
\end{align*}
i.e. the coordinates of $x^p$ are $(px_1,\ldots,px_n)$.
\end{remark*}

 \begin{proposition}\label{chap3-prop5}% \prop 5
 Let $h$ be a representation of $G$ in $H$, and
 $dh:\mathfrak{g}\rightarrow \mathcal{F}$ its differential. Then the
 diagram 
\[
\xymatrix@C=1.5cm{
\mathfrak{g}\ar[d]_{\exp}\ar[r]^{dh} & \mathscr{S}\ar[d]^{\exp}\\
G\ar[r]_{h} & H
}
\]
is commutative.
\end{proposition} 
 
Consider $t \xrightarrow{\rho'} h (\exp  tX)$.
 
This is obviously a one-parameter subgroup, and $d \rho'= dh\circ
d\rho$. 
Therefore
\begin{align*}
h(\exp X) &=\exp(d\rho'(\frac{d}{dt}))\\
 &= \exp (dh (X)).
\end{align*}

It follows, therefore, that if $h(G)=(e)$, $dh$ is the map
$\mathfrak{g}\rightarrow(0)$. 
 
 Conversely,\pageoriginale if $dh=C$, and $G$ connected, $h(\exp X)=e$ for every
 element in a neighbourhood of $e$, and $h=e$. Again, if $G$ is
 connected and two representations $h_1$, $h_2$ of $G$ in $H$ are such
 that $dh_1=dh_2,$ then $h_1=h_2$. 
 
\begin{proposition}\label{chap3-prop6}% \prop 6
For every analytic function $f$ on a neighbourhood of $e$, we have 
$$
f(\exp tX)=\sum^{\infty}_{n=0} \dfrac{t^n}{n!}(X^n f)(e). 
$$

In fact, 
$$
\dfrac{d}{dt} f(\exp tX)=(X f) (\exp tX).
$$

By induction on $n$, we have
$$
\dfrac{d^n}{dt^n} f (\exp tX)=(X^n f)(\exp tX)
$$
or
$$
\left\{\dfrac{d^n}{dt^n} f(\exp tX)\right\}_{t=0}=X^n f(e).
$$

Now, $f(\exp t X)$ is an analytic function of $t$ and by Taylor's
formula, we have  
$$
f(\exp tX)=\sum^{\infty}_{n=0} \dfrac{t^n}{n!}(X^n f)(e)
$$
\end{proposition}

\begin{thm}\label{chap3-thm3}% \the 3
{In canonical coordinates}, {we have}
$\Delta_\alpha=\dfrac{\alpha !}{|\alpha|!} S_\alpha$ {
  where} $S_\alpha$ { is the coefficient of} $t^\alpha$ { in
  the expansion of} $(\sum^{n}_{i=1} t_i X_i)^{|\alpha|}$ {
  and} $S_\alpha \in \mathcal{U}(G)$. 
 \end{thm}
 
 In fact, it is enough to prove the equality of
 $\Delta_\alpha$ and $\dfrac{\alpha!}{|\alpha|!}S_\alpha$
 at $e$ since both $\Delta_\alpha$ and $S_\alpha$ are
 invariant. Now,  
 $$
 f(y)=\tau_y f(e)= \sum\limits_{\alpha} \dfrac{1}{\alpha!} y^\alpha
 \Delta_\alpha f(e) \text{ with } \Delta_\alpha f(e)
 = \left\{\dfrac{\partial^\alpha}{\partial y^\alpha}
 f(y)\right\}_{y=e} 
 $$
$y = \exp (\sum y_i X_i)$ where $y_i$ are the canonical coordinates of $y$. 

Therefore\pageoriginale
\begin{align*}
f(y) &=f(\exp (\sum y_i X_i))\\
&=\sum^{\infty}_{p=0} \dfrac{1}{p !} \left\{(\sum y_i X_i)p_{f}\right\}(e)
 \end{align*}
by Prop. \ref{chap3-prop6}, chapter \ref{chap3}, 5.
 
Taking partial derivatives at $y=e$, we have 
  $$
  \dfrac{\partial^\alpha}{\partial y^\alpha} f(y)\quad \text{at}\quad y=e
  \quad\text{is}\quad \dfrac{\alpha !}{|\alpha| !} (S_\alpha f)(e). 
  $$

  Hence, $Delta_\alpha f(e) = \dfrac{\alpha !}{|\alpha|!}
  S_\alpha f(e)$ which is what we wanted to prove.  
