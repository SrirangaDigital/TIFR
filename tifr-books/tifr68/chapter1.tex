
\chapter[Solutions to Stochastic Differential Equations....]{Solutions to Stochastic Differential Equations as a Function
  of the Starting Point}\label{chap1}%%% 1

\section{Basic Inequalities of Martingale Theory}\pageoriginale %%% 1

The most important inequality in the martingale theory is the Doob's
inequality which states that if $(X(t), F_t, P)$ is a right continuous,
integrable sub-martingale, then  
\begin{equation*}
P( \Sup_{o \leq t \leq T} X(t) \geq \lambda )< \frac{1}{\lambda}
E[X(T), \Sup_{o \leq t \leq T} X(T) \geq \lambda], \lambda>0
\tag{1.1}\label{chap1:eq1.1}  
\end{equation*}
for all $T> 0$.

As a consequence of (\ref{chap1:eq1.1}), one has, assuming that $X(.)
\geq 0$:  
\begin{equation*}
E \left[ \Sup_{o \leq t \leq T} X(t)^p \right]^{1/p} \leq
\frac{p}{p-1}E[X(T)^p]^{1/p}, 1 < p < \infty. \tag{1.2}\label{chap1:eq1.2}   
\end{equation*}

The passage from (\ref{chap1:eq1.1}) to (\ref{chap1:eq1.2}) goes as
follows: 

Let $X(T)^* = \Sup\limits_{0 \leq t \leq T} X(t)$. Then using
(\ref{chap1:eq1.1}) we have   
\begin{align*}
E[ (X(T)^*)^p] &= p \int\limits^{\infty}_0 \lambda^{p-1}P(X(T)^* \geq  
\lambda) d \lambda\\ 
& \leq  p \int \limits^{\infty}_0 \lambda^{p-2}E[x(T),X(T)^* \geq
  \lambda ] d \lambda\\ 
& = p \int \limits^{\infty}_0 \lambda^{p-2}d \lambda
\int\limits^{\infty}_0 P(X(T) \geq \mu,X(T)^* \geq \lambda)d \mu.\\  
& = \frac{p}{p-1}\int\limits^{\infty}_0 E[X(T)^*)^{p-1},X(T)] \geq
\mu] d \mu.\\ 
& = \frac{p}{p-1} E[(X(T)^*)^{p-1},X(T)]\\ 
& \leq
  \frac{p}{p-1}E[(X(T)^*)^p]^{1-1/p}, E[(X(T))^p]^{1/p}
\end{align*} 
where we have used H\"older's inequality to obtain the last line. Now
dividing both sides by $E[(X(T)^*)^{p}]^{1-1/p}$, we get the required
result. 
 
The basic\pageoriginale source of continuous martingales is stochastic 
integrals. Let $(\beta_t, F_t,P)$ 
be a l-dimensional Brownian motion and  $\theta(.)$ be a
$F$.-progressively measurable $\mathbb{R}$-valued function satisfying  
$$
E \left[\int \limits^T_0 | \theta (t)|^2 dt \, \right] < \infty 
$$
for all $T> 0$. Set
$$
X(t) = \int\limits_{0}^{t} \theta (s) d\beta (s).
$$

Then $(X(t), F_t, P)$, and $(X^2 (t) - \int\limits_{0}^{t} \theta (s)^2
ds, F_t, P)$ are continuous martingales. In particular, 
$$
E[X^2 (T) ] = E \left[ \int\limits_{0}^{t} \theta (t)^2dt \right]
\text { for all } T > 0.  
$$

By (\ref{chap1:eq1.2}), this means that
$$
E [(X (T)^*)^2] \le 2E [ \int\limits_{0}^{T} \theta (t)^2
  dt]^{1/2}. 
$$

The following theorem contains an important generalization of this
observation. 

\setcounter{theorem}{2}
\begin{theorem}[Burkholder] % them 1.3
Let $(\beta (t), F_t, P)$ be a 1-dimensional Brownian
  motion and $\sigma (.)$ be a $F$.-progressively measurable $R^n
  \times R^d$-valued function satisfying 
$$
E \left[\int\limits_{0}^{T} \text { Trace } a(t) dt \right] < \infty, T > 0 
$$
where $a(.) = \sigma (.) \sigma (.)^* $. Set $X(t) =
\int\limits_{0}^{t} \sigma (s) d \beta (s)$. Then for $2 \le p <
\infty$ and $T > 0$,  
$$
E[ \Sup_{o \le t \le T} | X (t) |^{p}]^{1/p} \leq  C_p E [
  \int\limits_{0}^{T} \text { Trace } a (t) dt)^{p/2}] ^{1/p} 
$$\pageoriginale
where 
$$
C_p = \left( \frac{p^{p+1}}{2(p-1)^{p-1}} \right)
$$
\end{theorem}

\begin{proof}
By Ito's formula:
\begin{align*}
|X (t)^p |& = p \int\limits_{0}^{t} |X (s) |^{p-2} \sigma (s) X (s) d
\beta (s)\\ 
& + \frac{1}{2} \int\limits_{0}^{t} p |X (s) |^{p-2} (\text {Trace } a
(s) + (p-2) \frac{< X (s), a(s) X (s) >}{|X (s) |^2}ds 
\end{align*}
Thus,
{\fontsize{10pt}{12pt}\selectfont
\begin{align*}
E[ |X(T)|^p]& = \frac{1}{2}E[\int\limits^T_0 p|X(t)|^{p-2} \text{
    Trace } a(t) +(p-2)\frac{< X (t), a(t) X (t) >}{|X (t) |^2}dt]\\ 
& \leq \frac{p(p-1)}{2}E[\int\limits^T_0 p|X(t)|^{p-2} \text{ Trace }
  a(t) dt ]\\ 
& \leq \frac{p(p-1)}{2}E[\Sup_{0 \leq t \leq T}|X(t)|^{p-2} \int
  \limits^T_0 \text{ Trace } a(t) dt ]\\ 
& \leq \frac{p(p-1)}{2}E[\Sup_{0 \leq t \leq
    T}|X(t)|^{p}]^{1-2/p}E[(\int \limits^T_0 \text{ Trace }
  a(t)dt)^{p/2}]^{2/p}
\end{align*}}\relax
and so  
$E[\Sup \limits_{0 \leq t \leq T}|X(t)|^p] < (\dfrac{p}{p-1}) E[
  |X(T)|^p]$ 
$$
\leq \frac{p^{p+1}}{2(p-1)^{p-1}} E[\Sup \limits_{0 \leq t \leq
    T}|X(t)|^p]^{1-2/p} E[(\int\limits^T_0 \text{ Trace } a(t)^{p/2}]^{2/p} 
$$

Now dividing both sides by $E[\Sup \limits_{0 \leq t \leq
    T}|X(t)|^p]^{1-2/p}$ we get the required result. 
\end{proof}


\section[Solutions to Stochastic Differential Equation....]{Solutions to Stochastic Differential Equation as a Function
  of $(t,x)$}\label{chap1:sec2}%%% 2

Let\pageoriginale $\sigma:R^n \to R^n \times R^d$ and $b: R^n \to R^n$
be measurable functions satisfying   
$$
|| \sigma(x)- \sigma(y) ||_{H.S.} \leq L|x-y| , x,y \in R^n
$$
\begin{equation*}
|b(x)-b(y)| \leq L|x-y|, x,y \in R^n \tag{2.1}\label{chap1:eq2.1}  
\end{equation*}
where $L < \infty$ and $||.||_{H.S.}$ denotes the Hilbert Schmidt
norm \footnote{$||A||_{H.S.}$ is the Hilbert-Schmidt norm of the
  matrix $A$. That is, $||A||^2_{H.S.}=$ Trace $AA^{\ast}$.}. 

Also assume that $(\beta(t), F_t(p)$ is a $d-$dimensional Brownian
motion   

\setcounter{theorem}{1}
\begin{theorem} % them 2.2
For each $ x \in R^n$ there exists a unique solution $\xi(.,x)$ to  
\begin{equation*}
\xi(t,x) = x + \int \limits^t_0 \sigma(\xi(s,x)) d \beta(s) + \int
\limits^t_0 b(\xi(s,x))ds, t \geq 0. \tag{2.3}\label{chap1:eq2.3}    
\end{equation*}

In fact, for each $2 \leq p < \infty$ and $T>0$ there are $A_p(T) <
\infty$ such that  
\begin{equation*}
E[\Sup \limits_{0 \leq t \leq T}| \xi (t,x) - \xi(t,y)|^p] \leq A_p(T)
(|x-y|^p) \tag{2.4}\label{chap1:eq2.4}   
\end{equation*}
\end{theorem}

\begin{proof}
The existence of solution is proved by the Picard iteration. Define
$\xi_0(.) =x$ and  
$$
\xi_{n+1}(t) = x + \int \limits^t_0  \sigma(\xi_n(s)) d \beta (s) +
\int \limits^t_0 b(\xi_n) (s)ds 
$$

Then for $2 \leq p < \infty$, 
\begin{align*}
 E[\Sup\limits_{0 \leq t \leq T} &| \xi_{n+1}(t) - \xi_n(t)|^p]^{1/p}\\ 
& \leq E[|\int\limits^t_0  b(\xi_n (t))-
   b(\xi_{n-1}(t)dt|^p]^{1/p}\\ 
& + E[|\int\limits^T_0  (\sigma(\xi_n (s)) - \sigma(\xi_{n-1}(s))) d
   \beta(s)|^p]^{1/p}\\ 
& \leq L \int\limits^T_0 E[|\xi_n (t) - \xi_{n-1}(t) |^p]^{1/p}dt\\ 
& + C_P L E[(\int\limits^T_0|\xi_n(t)- \xi_{n-1}(t)|^2 dt)^{p/2}]^{1/p}\\
& \leq L \int \limits^T_0 E[|\xi_n (t) - \xi_{n-1}(t) |^p]^{1/p}dt\\
& + C_P L T^{(P-2)/(2P)} E[ \int\limits^T_0 |\xi_n (t) - \xi_{n-1}(t)
     |^p dt]^{1/p} 
\end{align*}\pageoriginale
and so 
$$
E[ \Sup_{0 \leq t \leq T}| \xi_n (t) - \xi_{n-1}(t) |^p ] 
$$
$$
\leq 2^{p-1} L^p(T^{p-1}+ C^p_p T^{p-1/2}) \int \limits^T_0 E[ \Sup_{0
    \leq t \leq T}| \xi_n (s) - \xi_{n-1}(s) |^p ]dt. 
$$

From this, it follows by induction that 
$$
E[ \Sup_{0 \leq t \leq T}| \xi_{n+1} (t) - \xi_{n}(t) |^p ]<
\frac{B_p(T)}{n!} 
$$
where $B_p(T) < \infty$. Hence $\xi_n(.)$ converges uniformly on
finite intervals and clearly the limit satisfies
(\ref{chap1:eq2.3}). In fact, we 
have shown that there is a solution $\xi(.)$ such that  
$$
E[ \Sup_{0 \leq t \leq T}| \xi (t)  |^p ] < \infty
$$
for all $T> 0$ and $1 \leq p < \infty$.

To prove\pageoriginale uniqueness, note that if $\eta(.)$ is a second
solution and $\tau_R = \inf \{ t \geq 0: | \eta(.) - x | \geq  R \}$,
then   
$$
 E[ | \eta ( t \Lambda \tau_R) - \xi( t \Lambda \tau_R)|^2] 
 $$
$$
\leq 2L^2 E[ \int \limits^{t \Lambda \tau_R}_{0} | \eta (s)-
  \xi(s)|^2ds] + 2L^2 tE[ \int \limits^{t \Lambda \tau_R}_{0} | \eta
  (s)- \xi(s)|^2 ds]  
$$
and so $\eta(t \Lambda \tau_R)= \xi(t \Lambda \tau_R) \, (a.s.,P)$ for
all $t$ and $R$. Since $\eta(.)$ and $\xi(.)$ are $P - a.s.$ continuous
and $P( \Sup \limits_{ 0 \leq t \leq T}| \xi(t)|< \infty)=1$ for all
$T> 0$, uniqueness is now obvious. 

Finally, 
$$
E[\Sup \limits_{ 0 \leq t \leq T}| \xi (t,y) - \xi(t,x)|^p]^{1/p} 
$$
\begin{align*}
\leq |x-y| & +C_P L E[ \int \limits^T_0| \xi(t,y) - \xi(t,x)|^2
  dt)^{p/2}]^{1/p} \\ 
& + L \int\limits^T_0 E[|\xi(t,y) - \xi(t,x)|p]^{1/p} \, dt 
\end{align*}
and  so 
\begin{align*}
& E[\Sup\limits_{ 0 \leq t \leq T}| \xi (t,y) - \xi(t,x)|^p] \leq
3^{p-1}|x-y|^p +3^{p-1} L^p(C^p_p T^{p-1/p})\\
& \qquad  \int \limits^T_0  E[\Sup\limits_{0 \leq t \leq T}| \xi
  (s,y) - \xi(s,x)|^p]\,dt  
\end{align*}

Therefore 
{\fontsize{10pt}{12pt}\selectfont
$$
E[\Sup\limits_{ 0 \leq t \leq T}| \xi (t,y) - \xi(t,x)|^p] \leq
3^{p-1}|x-y|^p \exp (3^{p-1} L^p  \int\limits^T_0 (C^p_p t^{(p-1)/2}+ 
+ t^{p-1}) \, dt). 
$$}\relax

This proves our theorem.

The importance of (\ref{chap1:eq2.4}) is that it allows us to find a version of
$\xi(t,x)$ which is a.s. continuous with respect to $(t,x)$.  To see
how this is done, we need the following real-variable lemma.
\end{proof}

\setcounter{lemma}{4}
\begin{lemma}\label{chap1:lem2.5} % lem 2.5
Let\pageoriginale $P$ and $\psi$ be strictly increasing continuous
function on $[0, \infty]$ such that $P(0) = \psi(0)=0$ and
$\psi(\infty) = \infty$. Also suppose that $L$ is a normed linear
space and that $f: R^d \to L$ is strongly continuous on $B(a,r)
(\equiv \{ x \in R^d: |x-a| < r \})$. Then   
$$
\int \limits_{B(a,r)} \int \limits_{B(a,r)} \psi \Bigg( \frac{|| f(x)
  -f(y)||}{P(|x-y|)} \Bigg) dx \, dy \leq B 
$$
implies that
$$
||f(x) -f(y)|| \leq 8 \int \limits^{|x-y|}_0 \psi^{-1} \Bigg(
\frac{4^{d+2}}{\gamma^2 u^{2d}} \Bigg) P(du), x,y \in B(a,r) 
$$
where
$$
\gamma= \inf_{x \in B(a,r)} \; \inf_{ 1 < \rho \leq 2} \frac{|B(x, \rho)
  \cap B(a,1)|}{\rho^d} 
$$
\end{lemma}

\begin{proof}
Define
$$
I(x) =\int\limits_{B(a,r)} \psi \Bigg( \frac{|| f(x) -f(y)||}{P(|x-y|)}
\Bigg)  dy . 
$$

Given distinct points $x,y \in B(a,r)$, set $\rho = |x-y|$ and choose
$ c \in B( \dfrac{x+y}{2}, \dfrac{\rho}{2}) \cap B(a,r)$ so that  
$$
I(c) \leq 2^{d+1} \frac{B}{\gamma \rho^d}.
$$

This is possible because $\int \limits_{B(a,r)} I(c)dc \leq B$. Set
$x_o = y_o =c$. Now we choose $x_n$ and $y_n$ for $n \geq 1$ as
follows. Given $x_{n-1} $ and $y_{n-1'}$ define $d_{n-1}$ and
$e_{n-1}$ by  
$$
P(d_{n-1}) = \frac{1}{2} P(2|x_{n-1}-x|) \text{ and } P(e_{n-1}) =
\frac{1}{2} P(2|y_{n-1}-y|). 
$$

Now\pageoriginale choose $x_n \in B(x,\dfrac{1}{2} d_{n-1}) \cap
B(a,r)$ and $y_n \in B(y, \dfrac{1}{2} e_{n-1}) \cap B(a,r)$ so that   
\begin{align*}
& I(x_n)  \leq \frac{2^{d+1}B}{\gamma d^d_{n-1}} \text{ and } \psi \Bigg(
  \frac{||f(x_n) -f(x_{n-1})||}{P(|x_n - x_{n-1}|)} \Bigg) \leq
  \frac{2^{d+1} I(xo-1)}{\gamma d^d_{n-1}}\\ 
& I(y_n)  \leq \frac{2^{d+1}B}{\gamma e^d_{n-1}} \text{ and } \psi
  \Bigg( \frac{||f(y_n) -f(y_{n-1})||}{P(|y_n - y_{n-1}|)} \Bigg) \leq
  \frac{2^{d+1} I(y_{n-1})}{\gamma e^d_{n-1}} 
\end{align*}

This is possible by the same reasoning as that used to find $c$. 

Note that $P(d_n)= \dfrac{1}{2}P(2|x_n-x|) \leq
\dfrac{1}{2}P(d_{n-1})$. Thus $d_n$ decreases to zero. Also, for $n
\geq 1$: 
\begin{align*}
||f(x_n)-f(x_{n-1})|| & \leq \psi^{-1} \Bigg( \frac{ 4^{d+2}
    B}{\gamma^2 d^d_{n-1} d^d_{n-2}} \Bigg) P(|x_n-x_{n-1}|)\\ 
 & \leq \psi^{-1} \Bigg( \frac{ 4^{d+2} B}{\gamma^2 d^{2d}_{n-1} } \Bigg)
P(|x_n - x_{n-1}|) 
\end{align*}
where $d_{-1} = \rho$. Since $2P(d_{n-1}) = P(2|x_{n-1}-x|)$, 
$d_{n-1} < 2|x_{n-1}-x|$. 

Thus
\begin{align*}
P(|x_n-x_{n-1}|) & \leq P(2|x_n-x_{n-1}|) = 2P(d_{n-1})\\
& = 4(P(d_{n-1}) - \frac{1}{2}P(d_{n-1}))\\
& \leq 4(P(d_{n-1}) - P(d_{n})).
\end{align*}

We therefore have:
\begin{align*} 
||f(x_n)-f(x_{n-1})|| & \leq 4 \psi^{-1} \Bigg( \frac{ 4^{d+2}
    B}{\gamma^2 d^{2d}_{n-1}} \Bigg) (P(d_{n-1})-P(d_n))\\ 
& \leq 4 \int\limits^{d_{n-1}}_{dn} \psi^{-1} \Bigg( \frac{ 4^{d+2}
    B}{\gamma^2 u^{2d} } \Bigg) P(du) 
\end{align*}
and so\pageoriginale 
$$
||f(x) - f(c) || \leq 4 \int\limits^{\rho}_{0} \psi^{-1} \Bigg(
\frac{ 4^{d+2} B}{\gamma^2 u^{2d} } \Bigg) P(du). 
$$
The same argument yields 
$$
||f(x) - f(c) || \leq 4 \int\limits^{\rho}_{0} \psi^{-1} \Bigg(
\frac{ 4^{d+2} B}{\gamma^2 u^{2d} } \Bigg) P(du) 
$$
This proves our lemma.
\end{proof}

\begin{lemma}\label{chap1:lem2.6} % lem 2.6
Let $X(x)$, $x \in R^d$, be a family of Banach space valued random
variables with the properties that for some $\alpha > 0$ and $p \geq
d+ \alpha$ 
\begin{equation*}
E[||X(x) -X(y)||^p] \leq C|x-y|^{d+ \alpha}, x, y \in
R^d. \tag{2.7}\label{chap1:eq2.7}    
\end{equation*}

Then there is a family $\tilde{X} (x)$, $\in R^d$ such that
$\tilde{X}(x)= X(x)$ a.s. for each $ x \in R^d $ and $x \to
\tilde{X}(x)$ is a.s. strongly continuous. 
\end{lemma}

\begin{proof}
For each $N \geq 0,$ let $X^{(N)}(.)$ denote the multi linear extension of
the restriction of $X(.)$ to the lattice $\{ k/2^N : k \in
\mathbb{Z}^d \}$. Then it is not hard to check that is a
$C'$(depending on $C$, p and $\alpha)$ such that  
\begin{equation*}
E[||X^{(N)} (x) - X^{(N)} (y)||^p] \leq C' |x-y|^{d+\alpha}
\tag{2.8}\label{chap1:eq2.8}   
\end{equation*}

Now let $\rho = (2d + \alpha/2)p$. Then, by (\ref{chap1:eq2.8}):
$$
\Sup_{N} E[ \int\limits_{B(0,r)} \int\limits_{B(0,r)}] \Bigg( 
\frac{|| X^{(N)} (x) -X^{(N)} (y)||}{|x-y|^{\rho}} \Bigg)^p dx \, dy \leq C"
r^{2d} 
$$
where $C'' < \infty$ depends on $C'$ and $d$. By (\ref{chap1:lem2.5}),
this means that for $L> 0$ 
\begin{align*}
\Sup_{N} P (|| X^{(N)} (x) -X^{(N)} (y)|| & \leq KL^{1/p}|x-y|^{\alpha/2p},
x,y \in B(0,r))\\ 
& \geq 1- \frac{C''r^{2d}}{L},
\end{align*}\pageoriginale
where $K$ depends on $d$, $p$ and $\alpha$. Notice that 
$$
\Sup_ {\substack{ x,y \in B(0,R )\\  x \neq y}}  \frac{|| X^{(N)} (x) 
  -X^{(N)} (y)||}{|x-y|^{\alpha/2p}} 
$$
is a non-decreasing function of $N$. Hence 
$$
P \Bigg( \Sup\limits_{N} \Sup\limits_{\substack{ x,y \in B(0,R )\\  x \neq 
    y}}\frac{|| X^{(N)} (x) -X^{(N)} (y)||}{|x-y|^{\alpha/2p}} \leq
KL^{1/p} \Bigg) \geq 1- \frac{C" r^2d}{L}. 
$$

Since $X^{(n)} \bigg[\dfrac{k}{2^n}\bigg] =
X\bigg[\dfrac{k}{2^n}\bigg]$ for all $N \geq 0$ and  $k \in
\mathscr{Z}^d$, $x^{(N)}(.)$ converges a.s., uniformly on $B(0,r)$
to a continuous function $\tilde{X}(.)$ which coincides with $X(x)$ at
$x = k/2^N \in B(0,r)$. Since  
$$
E[ || X(x) - X(y)||^p] \to 0 \text{ as } |x-y| \to 0, 
$$
it is clear that $\tilde{X}(x) =X(x)$ a.s. for all $x \in 
B(0,r)$. Finally, since $r$ was arbitrary, the proof is complete. 
\end{proof}

\setcounter{exercise}{8}
\begin{exercise} % exer 2.9
Let $f(x) = x Va$. Then $f'(x) = \chi_{[ a, \infty]}(x)$ and $f''(x) =
\delta_a(x)$ (Dirac's $\delta-$function). Thus by ``It$\hat{o}$'s
formula'', if $(\beta_t,F_t,P)$ is a one-dimensional Brownian motion:   
$$
\frac{1}{2} \int \limits^t_0 \delta_a (\beta(s))ds = \beta(t) Va -
\int \limits^t_0 \chi_{[ a, \infty]} (\beta(s))d \beta(s)  
$$

That is, we would suspect that 
$$
\lim_{\varepsilon \downarrow 0} \frac{1}{4 \varepsilon} \int
\limits^t_0 \chi_{[ a-\varepsilon, a+ \varepsilon]} (\beta(s))ds =
\beta(t)Va -\int \limits^t_0 \chi_{[ a, \infty]} (\beta(s)) d
\beta(s). 
$$

To\pageoriginale check this, define 
$$
\ell_a(t) = \beta(t) Va- \int \limits^t_0 X_{[ a, \infty]}(\beta(s)) d \beta(s).
$$

By the technique which we have been using, show that there is a
version $L_a(t) $ of $\ell_a(t)$ which is a.s. continuous in $(t,x)a [
  0, \infty] \times R$. 
Check that for $f \varepsilon C^{\infty}_0 (R)$
$$
\int\limits_R f(a) L_a(t)ds = F(\beta(t)) - \int \limits^t_0
F(\beta(s)) d \beta(s) 
$$
where $F(x) = \int (xVa) f(a)da$.

From this conclude that 
$$
\int\limits_R f(a) L_a(t)da = \frac{1}{2} \int\limits^t_0
f(\beta(s)) ds 
$$
for all such $f's$. The identification of $L_a (t)$ as  
$$ 
\lim_{\varepsilon \downarrow 0} \frac{1}{4 \varepsilon} \int  X_{[
    a-\varepsilon, a+ \varepsilon]} (\beta(s))ds 
$$
is now easy
\end{exercise}

\begin{exercise} % exercise 2.10
Again let $(\beta_t,F_t ,P)$ be a 1-dimensional Brownian
motion. Given $t > 0$ and $\varepsilon > 0$, let $N_{\varepsilon}(t)$
be the number of times that $| \beta(.)|$ goes from $\varepsilon$ to
0 during $[0,t]$. (That is, $N_{\varepsilon} \geq n$ if and only if
there exist $0 < u_1 < v_1 \cdots < u_n < v_n \leq t$ such that
$|\beta(u_j)| = \varepsilon$ and $|\beta(v_j)| = 0$ for $1 \leq j \leq
n)$. Show that  
$$
N_{\varepsilon}(t) \to 2L_0(t) \text{ a. s. } \varepsilon \downarrow
0. 
$$

The idea is the following: First show that 
$$
|\beta(t)| = \int \limits^t_0 \text{ sgn }  \beta (s) d \beta(s) +
2L_0 (t). 
$$

Next\pageoriginale define $\tau_0 =0$ and for $n \geq 1$ 
\begin{align*}
\sigma_n & = \inf \{ t \geq \tau_{n-1}: |\beta(t)| =\varepsilon \}\\ 
\tau_n & = \inf \{ t \geq \sigma_{n}: |\beta(t)| =0 \}.
\end{align*}

Then 
$$
\sum^{\infty}_{1} \bigg( | \beta(\tau_n \Lambda t)|-  | \beta(\sigma_n
\Lambda t)| \bigg) = - \varepsilon N_{\varepsilon}(t) + (|\beta(t)| -
\varepsilon) \sum^{\infty}_1 X_{[ \sigma_n , \tau_n ]}(t). 
$$
 
At the same time:
$$
\sum^{\infty}_{1} \bigg( | \beta(\tau_n \Lambda t)|-  | \beta(\sigma_n
\Lambda t)| \bigg)= | \beta(t)|-\sum^{\infty}_{1}  \int
\limits^{\sigma_n \Lambda t}_{\tau_{n-1} \Lambda t} \text{ sgn }
\beta(s) d \beta(s) - 2L_0 (t). 
$$
Thus 
\begin{align*}
\varepsilon N_{\varepsilon}(t) - 2L_0(t) & = - |\beta(t)|
\sum^{\infty}_{1}  X_{[\tau_{n-1}, \sigma_n]}(t) - \sum^{\infty}_{1}
X_{[ \sigma_n, \tau_n]}(t)\\
& \qquad  + \sum^{\infty}_{1}  \int \limits^{\sigma_n
  \Lambda t}_{\tau_{n-1} \Lambda t} \text{ sgn } \beta(s) d \beta(s). 
\end{align*}
From this check that 
$$
E[ | \varepsilon N_{\varepsilon}(t) - 2L_0 (t) |^2] \leq c_t
\varepsilon, 0 < \varepsilon \leq 1; 
$$
and therefore that 
$$
\frac{1}{n^2} N_{1/n^2}(t) \to 2 L_0 (t) \text{ a.s  \; as } n \to \infty. 
$$

Finally, note that if $1/(n+1)^2 \leq \varepsilon < 1/n^2$, then  
$$
\frac{1}{(n+1)^2} N_{1/n^2} (t) \leq \varepsilon N_{\varepsilon}(t) 
\leq 1/n^2 N_{1/(n+1)^2} (t), 
$$
and so $\varepsilon N_{\varepsilon}(t) \to 2L_0(t)$ a.s. as
$\varepsilon \downarrow 0$.  
\end{exercise}

\setcounter{lemma}{10}
\begin{lemma}\label{chap1:lem2.11} % lem 2.11
  Let\pageoriginale $(\beta(t),F_t,P)$ be a $d-$dimensional Brownian
  motion and suppose that $\sigma(.)$ and $b(.)$ are as in
  (\ref{chap1:eq2.1}). Then   there is a choice of $\xi(t,x)$ solving
  (\ref{chap1:eq2.3}) such that   
$$
(t,x) \to \xi (t,x)
$$ 
\end{lemma}

From now on, $\xi(t,x)$ refers to the map in (\ref{chap1:lem2.11}). We
next want to  
discuss the mapping $x \to \xi(t,x)$ for fixed $t>o$. We will first
show that a.s. the maps $x \to \xi(t,x)$ are 1-1 and continuous
for all $t\ge 0$. 

\begin{lemma}\label{chap1:lem2.12}% lem 2.12
Let $T>0$ and $p$ $R$ be given. Then there is a $C_p(T)<\infty$ such
that 
\begin{equation*}
E[|\xi (t,x)-\xi (t,y)|^p] \ge C_p(T)|x-p|^p,t \in [0,t] \text{ and }
x,y \varepsilon R^n. \tag{2.13}\label{chap1:eq2.13}   
\end{equation*}
\end{lemma}

\begin{proof}
Set $f(z)=|z|^p$ for $z \in R^n-\{0 \}$. Then
$$
\frac {\partial f}{\partial z_i}= p|z|^{p-2}z_i
$$
and
$$
\frac{\partial^2 f}{\partial z_i \partial z_j}= p(p-2)|z|^{p-4}z_iz_j
+\delta_{ij}p|z|^{p-2} 
$$
Now let $x \neq y$ be given and for $0< \in < |x-y|$ let  
$$
\zeta = \inf \{ t \ge 0: |\xi(t,x)-\xi (t,y)| \le \in \} 
$$
and define
$$
z_ \in (t)=\xi (t \Lambda \zeta ,x)-\xi (t \Lambda \zeta_\in,y). 
$$
Now\pageoriginale by It$\hat{o}'s$ formula:
\begin{align*}
|z_\in (t)|^p &- \sum _{i=1}^n \int\limits^{t \Lambda \zeta_\in}_0
(b^i(\xi(s,x))-b^i(\xi(s,y)))\frac{\delta f}{\delta x_i}(z_\in (s))ds
\\ 
&\qquad - \frac{1}{2}\sum _{i=1}^n \int\limits^{t \Lambda \zeta_\in}_o (\sum
_{l=1}^d \sigma^i_l (\xi (s,x)- \xi(s,y))\sigma^j_l (\xi
(s,x)-\xi(s,y))) \\
& \qquad \qquad  \frac{\partial^2 f}{\partial x_i\partial x_j}(z_\varepsilon
(s))ds 
\end{align*} 
is a martingale. Notice that for $0 \le s \le \zeta_\in$:
$$
| \sum _{i=1}^n (b^i(\xi(s,x))-b^i(\xi(s,y))) \frac{\partial
  f}{\partial x_i}(z_\varepsilon (s))| 
$$
$$
\le |p|L|z_\varepsilon|^{p-1} \sum _{i=1}^n|z_{\varepsilon,i}(s)|
\le^{1/2}L|P||z_\varepsilon (s)|^p. 
$$
Also for $0 \le s \le \zeta_ \in$:
\begin{align*}
\sum _{i,j=1}^n& \sum_{\ell=1}^d (\sigma^i_\ell (\xi(s,x))-\sigma^i_\ell
(\xi(s,y)))(\sigma^i_\ell (\xi(s,x))) -\sigma^j_\ell (\xi(s,y))
\frac{\partial^2 f}{\partial x_i \partial x_j}(z_\varepsilon (s)) \\
& \le dL^2 p(p-2)|z_\varepsilon (s)|^{p-2}\sum_{i,j=1}^n
z_{\varepsilon,i}(s)z_{\varepsilon,j}(s)+dL^2p|z_\varepsilon (s)|^p\\  
& \le (dn L^2 p(p-2)+dL^2p)|z_\varepsilon (s)|^p. 
\end{align*}
Thus
$$
E[|z_\varepsilon (t)|^p.]\le |x-y|^p +A_{d,n}(p) \int\limits^t_o
E[|z_\varepsilon (t)|^p]ds, 
$$
and so  
$$
E[|\xi (t \Lambda \zeta_ \in,x)-\xi(t \Lambda \zeta_ \in,y)|^p]
\le|x-y|^p e^{A_d,n(p)t} 
$$

Letting $\in \downarrow 0$, we see that 
$$
E[|\xi (t \Lambda \zeta_ \varepsilon,x)-\xi(t \Lambda \zeta_
  \in,y)|^p] \le|x-y|^p e^{A_d,n(p)t} 
$$
where\pageoriginale $\zeta= \inf \{ t>o:\xi(t,x)= \xi(t,y) \}$. Taking
$p=-1$, we  conclude that $P(\zeta< \infty)=0$ and therefore that
(\ref{chap1:eq2.13}) holds. Lemma (\ref{chap1:lem2.12}) show that for
each $x \neq 
y:\xi(t,x) \neq \xi (t,y)$, $t>0$ a.s. We now have to show that
exceptional set does not depend on $x$ and $y$.  
\end{proof}

\setcounter{lemma}{13}
\begin{lemma} % lem 2.14
Let
$$
\eta (t,x,y)= \frac{1}{|\xi (t,x)- \xi (t,y)|},t>o \text{ and } x \neq
y. 
$$

Then $\eta$ is a.s. a continuous function of $(t,x,y)$ for $t>0$ and
$x \neq y$. 
\end{lemma}

\begin{proof}
In view of (\ref{chap1:lem2.6}) and the fact that $\eta$ is a.s. continuous on
$\{ (t,x,y):\xi (t,x) \neq \xi (t,y) \}$, we need only to show that
for some $p>2(2n+1)$, one has 
\begin{equation*}
E[|\eta (t,x,y)-\eta (t',x',y')|^p] \le C_{p,T} (\delta)(|x-x'|^p
+|y-y'|^p +|t-t'|^{p/2}) \tag{2.15}\label{chap1:eq2.15}    
\end{equation*}
for all $T>0$, $\delta >0$, $0 \le t$, $t' \le T$ and $|x-x'| \Lambda
|y-y'| \ge \delta$. 

But
\begin{align*}
& |\eta (t,x,y)- \eta (t',x',y')|^p\\[4pt]
& \qquad =|\frac{|\xi(t,x)-\xi (t,y)|-|\xi (t',x')-\xi(t',y')|}{|\xi(t,x)-\xi
  (t,y)| \quad |\xi (t',x')-\xi(t',y')|}|^p \\[4pt]
& \le 2^{p-1}|\eta(t,x,y)|^p |\eta (t',x',y')|^p (|\xi(t,x)-\xi
(t',x')|^p)+\\[4pt]
& \qquad +|\xi (t,y)-\xi (t',y')|^p).
\end{align*}
Thus
\begin{align*}
& E[|\eta(t,x,y)-\eta(t',x',y')|^p]\\
& \qquad \le 2^{p-1}E[|\eta(t,x,y)|^ {4p}]^{1/4} E[|\eta(t',x',y')|
    ^{4p}]^{1/4}\\ 
& \qquad \times (E[|\xi(t,x,)-\xi(t',x',)|^{2p}]^{1/2}
  +[|\xi(t,y)-\xi(t',y')|^{2p}]^{1/2}) 
\end{align*}

The\pageoriginale first factors are easily estimated by (\ref{chap1:eq2.7}), so
along as $|x-x'|\Lambda |y-y'| \ge \delta$.  

Moreover, by the argument used to derive (\ref{chap1:eq2.4}), it is
easy to check 
that 
\begin{align*}
& E [|\xi (s,x)-\xi(t,y)|^{2p}] \le C_p (T) (|s-t|^p)+|x-y|^{2p}),\\
& \qquad  0 \le s,t \le T,x,y \in R^n. \tag{2.16}\label{chap1:eq2.16}    
\end{align*}
 Thus (\ref{chap1:eq2.15}) has been proved.
\end{proof}

\setcounter{exercise}{16}
\begin{exercise}% exercise 2.17
Prove (\ref{chap1:eq2.16}) for all $1 \le p < \infty$.

We now want to show that a.s. the map $x \to \xi (t,x)$ is onto for
all $t \ge 0$. The idea is that this is certainly true when $t=0$ and
that the map $\xi (t,.)$ is homotopically connected to $\xi (0,.)$. In
order to take advantage of these facts, we must show that they
continue to hold on the one-point compactification of $R^n$. 
\end{exercise}

\setcounter{lemma}{17}
\begin{lemma}\label{chap1:lem2.18} % lem 2.18
For each $T>0$ and $p \in R$ there is a $C_p(T)<\infty$ such that 
$$
E [(1+ |\xi (t,x)|^2)^p] \le C_p (T) (1+|x|^2)^p,0 \le t \le T.
$$
\end{lemma}

\begin{proof}
\begin{tabular}[t]{lll}
 Let \quad $f(z)$ \, = &  $(1+|z|^2)^p$. \; Then \\[5pt]
\qquad $\partial f/ \partial z_i$  = &  $2p (1+|z|^2)^{p-1}z_i$
\end{tabular}

\noindent
and 
$$
\frac{\partial^2 f}{\partial z_i \partial z_j}=
2p(p-1)(1+|z|^2)^{p-2} z_i z_j +2p \delta_{ij} (1+|z|^2)^{p-1}. 
$$
Hence
\begin{align*}
& E[(1+|\xi(t,x)|^2)^p]- (1+|x|^2)^p\\
& =E [\int \limits^t_o \sum^n_{i=1} b^i (\xi(s,x) \frac{\partial f}{\partial
    z_i} (\xi (s,x))ds]+ \frac {1}{2} E [\int \limits^t_{o}
    \sum^n_{i,j=1} \sum_\ell \sigma^i_\ell (\xi (s,x))\\ 
& \qquad  \sigma^j_\ell (\xi
  (s,x) \frac{\partial^2 f}{\partial z_i \partial z_j}(\xi (s,x))ds]
  \\
& \le C \int\limits^t_o E [(1+ |\xi (s,x)|^2)^p]ds,
\end{align*}
since\pageoriginale
$$
\max_{1 \le i \le n} |b^i(z)|<\max_{1 \le i \le n} |b^i (0)|+L|z| <
2 \max_{1 \le i \le n} |b^i(0)|VL(1+|z|^2)^{1/2} 
$$
and similarly
$$
\max_{\substack {1 \le i \le n \\{1 \le \ell \leq n}}} |\sigma ^i_\ell
(z)| < 2 \max_{\substack {1 \le i \le n \\{1 \le \ell \leq n}}}|\sigma ^i_
\ell (0)|VL(1+ |z|^2)^{1/2}. 
$$

Hence the desired result follows by Gronwall's inequality.
\end{proof}

\setcounter{lemma}{18}
\begin{lemma} % lem 2.19
Let $\bar{R}^{n}=R^n \cup \{ \infty \}$ denote the one-point
compactification of $R^n$. Define 
\begin{equation*}
\eta (t,x)=
\begin{cases}
\frac{1}{1+|\xi (t,x)|},x \in R^n \\ \overset{.}0 \qquad ,x = \infty .
\end{cases}
\end{equation*}

Then $\eta$ is a.s. continuous on $[0, \infty] \times \bar{R}^{n}$ into $R^1$.
\end{lemma}

\begin{proof}
Since $\eta$ is a.s. continuous on $[0, \infty] \times R^n$, if
suffices to show that for each $T >0$ and $\varepsilon >0$ there is
a.s. an $R > 0$ such that $\eta (t,x)< \varepsilon $ if $|x| \ge R$
and $0 \le t \le T$. Choose $p>2(2n+1)$. Then 
$$
|\eta (t,y)-\eta (s,x)|^p \le |\eta (t,y)|^p |\eta (s,x)|^p |\xi
(t,y)-\xi (s,x)|^p 
$$
and so\pageoriginale
{\fontsize{10pt}{12pt}\selectfont
$$
E[|\eta (t,y)- \eta (s,x)^p|] \le E[|\eta (t,y)|^{4p}]^{1/4} E [|\eta
  (s,x)|^{4p}]^{1/4} E [|\xi(t,y)- \xi (s,x)|^{2p}]^{1/2} 
$$}\relax


Since $(1+|x|) \ge (1+ |x|^2)^{1/2} \ge \dfrac{1}{2}(1+|x|)$, we see
from (\ref{chap1:eq2.15}) that  
$$
E[|\eta (t,y)|^{4p}]^{1/4} E [|\eta (s,x)|^{4p}]^{1/4} \le K_p (T) 
(1+|x|)^{-p} (1+|y|)^{-p} 
$$

On the other hand, by (\ref{chap1:eq2.15}),
$$
E [|\xi (t,x)-\xi (s,y)|^{2p}]^{1/2} \le K'_p (T)(|t-s|^{p/2}+|x-y|^p) 
$$
for $0 \le s,t \le T$. Thus
$$
E[|\eta (s,x)- \eta (t,y)^p|] \le K''_p(T)
(\frac{|x-y|}{(1+|x|)(1+|y|)} )^p
+\frac{|t-s|^{p/2}}{(1+|x|)(1+|y|)^p} ] 
$$
 
We now define
$$
\hat{\eta} (t,x)= \eta (t,x/|x|^2) \text{ for } x \neq 0, 
$$
and 
$$
\hat{\eta}(t,0)=0. 
$$

Since $\eta$ is a.s. continuous on $[0, \infty] \times R^n$, we will
be done once we show that $\hat {\eta}$ admits an a.s. continuous
version. Noting that if $|y| \ge |x|>0$: 
\begin{align*}
\frac{ |\frac{x}{|x|^2}- \frac{y}{|y|^2}|}{ (1+ \frac{|x|}{|x|}) (1+
  \frac{|y|}{|y|})} &= \frac{\frac{1}{|y|^2} |\frac{y}{x}|^2 x-y
  |}{\frac{1}{|x| |y|}(1+ |x|) (1+|y|)}\\[5pt] 
&= \frac{ \left| \frac{x}{y}\right | | \left | \frac{y^2}{x} \right |
  x-x|+ \left |\frac{x}{y}\right | |x-y |}{(1+ |x|)(1+ |y|)}\\[5pt]  
&= \frac{ \left | \frac{x}{y} \right |^2 \bigg ( \left |\frac{y}{x}
  \right |^2-1 \bigg ) + \left |\frac{x}{y}\right ||x-y|}
     {(1+|x|)(1+|y|)}\\[5pt]  
&= \frac{\frac{1}{|y|} (|y|-|x|)(|y|+|x|) + \left |\frac{x}{y} \right
       | |x-y|} {(1+|x|)(1+|y|)}\\[5pt]  
& \le 3|x-y|.
\end{align*}\pageoriginale

We see that 
$$
E [ |\hat {\eta}(s,x)-\hat{\eta}(t,y)|^p] \le K''_p (T). [|x-y|^p 
  +|t-s|^{p/2}] 
$$
if $0 \le s$, $t \le T$ and $x,y \neq 0$. Since by (\ref{chap1:lem2.18}) 

$\eta (u,z) \to 0$ in $L^p$ for each $u >0$ as $|z|\to \infty$, this
inequality continuous to hold even when $x$ or $y$ is 0. This, by
(\ref{chap1:lem2.6}), $\hat{\eta}$ admits an a.s. continuous
version. This proves the lemma.
\end{proof}

\setcounter{theorem}{19}
\begin{theorem}% them 2.20
Let $\sigma(.)$ and $b(.)$ be as in (\ref{chap1:eq2.1}) and let
$\xi(t,x)$ be as in (\ref{chap1:lem2.11}). Then a.s. $\xi (t,.)$ is a
homeomorphism of $R^n$ onto $R^n$ for all $t \ge 0$.  
\end{theorem}

\begin{proof}
We have seen that a.s. $\xi(t.)$ determines a one-to-one continuous
map $\bar{\xi}(t,.)$ of $\bar{R}^{n}$ into itself for all $t \ge
0$. Moreover, $\bar{\xi(0,.)}$ is certainly onto. Thus, by standard
homotopy theory, a.s. $\bar{\xi}(t,.)$ is onto all $t \ge 0$. Also,
by the invariance domain theorem $\bar{\xi}(t,.)^{-1}$ must be
continuous. 

Finally, since a.s. $\bar{\xi}(t,\infty)=\infty$ for all $t \ge 0$, we
see that a.s. $\bar{\xi}(t,.)$ is a homomorphism of $R^n$ onto $R^n$ for all
$t \ge 0$. 
\end{proof}



\section{Differentiation with respect to $x$} %%%% 3

We\pageoriginale now want to differentiate $\bar{\xi}(t,x)$ with
respect to $x$.  

\setcounter{lemma}{0}
\begin{lemma}\label{chap1:lem3.1} % lem 3.1
Let $\gamma(t,X)$, $t \ge 0$ and $X \in R^D$, be an a.s. continuous
$R^M-$valued process such that $\gamma(.,X)$ is $F-$progressively
measurable for each $X \in R^D$. Further assume that for $T>0$, $R>0$ and
$2 \le p \le \infty$ there is a $C_p (T,R)< \infty$ such that 
$$
E [ \Sup_{0 \le t \le T} |\gamma(t,X)|^p]< C_p (T,R)(1+|X|)^p, \; |X| \le
R, 
$$
and
$$
E [ \Sup_{0 \le t \le T} |\gamma(t,X)-\gamma(t,Y)|^p] \le C_p
(T,R)|X-Y|^p, |X|V|Y| \le R. 
$$

Let $\hat{\sigma}:R^M\times R^N \to R^N \otimes R^d$ and
$\hat{b}:R^M\times R^N \to R^N$ be $C^\infty-$ functions satisfying 
$$ 
\Sup _{(\lambda , \eta) \; R^M \times R^N} ||\frac{\partial
  \hat{\sigma}}{\partial \eta_i} \bigg ( \gamma, \eta \bigg )
||_{\rm H.S.} V|\frac{\partial \hat {b}} {\partial \eta_j}\bigg ( \gamma,
\eta \bigg )| < \infty , 
$$
for $1 \le j \le N$, and assume that $\hat{\sigma}(\gamma ,0)$ and
$\hat{b}(\gamma ,0)$ and all their derivation slowly
increasing. Finally, let $f:R^D \to R^N$ be a smooth function with
bounded first derivatives. Then for each $X \in R^D$ the equation 
{\fontsize{10pt}{12pt}\selectfont
$$
\eta(t,X)=f(X)+ \int\limits^t_o \hat{\sigma}(\gamma(s,X),\eta
(s,X))d \beta (s) + \int\limits^t_o \hat{b}(\gamma(s,X), \eta (s,X))ds,
t \ge 0  
$$}\relax
has precisely one solution $\eta (.,X)$. Moreover, for $T$, $R>0$ and $2
\le p \le \infty$ there exists $C'_p (T,R)< \infty$ such that 
$$
E[\Sup_{0 \le t \le T}|\eta (t,X)|^p] \le C_p'(T,R)(1+ |X|)^p, |X|
\le R, 
$$
and 
$$
E[\Sup_{0 \le t \le T} |\eta (t,X) - \eta (t-Y)|^p]<
C'_p(T,R)|X-Y|^p, \; |X|V|Y| \le R. 
$$\pageoriginale

In particular, $\eta$ admits a version which is a.s. continuous in
$(t,X)$.  
\end{lemma}

\begin{proof}
The techniques used to prove this lemma are similar to those
introduced in section \ref{chap1:sec2}. The details are left as an
exercise.  
\end{proof}

\begin{lemma}\label{chap1:lem3.2} % lemma 3.2
Let everything be as in lemma (\ref{chap1:lem3.1}). Assume, in addition, that
a.s. $\gamma (t,.) \in C^1 (R^D)$ for all $t \ge 0$ and that for all
$T$, $R >0$ and  $2 \le p \le \infty$ 
$$
\max_{1 \le \ell \le D} E[\Sup_{0 \leq t \leq T} |\frac{\partial
    \gamma}{\partial X_\ell} (t,X)|^p] \le C_p (T,R)(1+|X|)^p, |X| \le
R, 
$$ 
and 
{\fontsize{10pt}{12pt}\selectfont
$$
\max_{1 \le \ell \leq D} E[\Sup_{0 \le t \ell T} |\frac{\partial
    \gamma}{\partial X_\ell} (t,X)-\frac{\partial \gamma}{\partial
    X_\ell} (t,X)|^p] \leq C_p (T, R) | x-y|^p,  |X|V|Y| \leq R. 
$$}\relax

Then a.s. $\eta (t,.) \in C^1 (R^n)$ for all $t \ge 0$ and for $T$, $R
>0$ and $2 \le p \le \infty$ there exists $C_p'(T,R)$ such that 
$$
\max_{1 \le \ell D} E[\Sup_{1 \le \ell T} |\frac{\partial
    \eta}{\partial X}_\ell |^p ] \le C_p'(T,R) (1+ |X|)^p, |X| \le R, 
$$
and
{\fontsize{10pt}{12pt}\selectfont
$$
\max_{1 \le \ell \leq D} E[\Sup_{0 \le t \ell T} |\frac{\partial
    \eta}{\partial X_\ell} (t,X)-\frac{\partial \eta}{\partial X_\ell}
  (t,Y)|^p ] \le C_p'(T,R)|x-y|^p, |X|V|Y| \leq R. 
$$}\relax

In particular, for each $1 \le \ell \le D$, $\dfrac{\partial \eta}{
  \partial X_\ell}$ admits an a.s. continuous version. 
\end{lemma}

\begin{proof}
Choose and fix $1 \le \ell \le D$ and let $e_\ell$ denote the unit
vector in the $\ell$-th direction. For $h \in R \backslash \{0 \}$,
define 
\begin{align*}
& \Delta_h \eta (t,X)= \eta (t,X + he_\ell)- \eta (t,X),\\[4pt] 
& \Delta_h \gamma(t,X)= \gamma (t,X+he_\ell) -\gamma (t,X) 
\end{align*}
and\pageoriginale 
$$
\Delta_h f(X)= f(X+ he_\ell)-f(X).
$$

Then $\Delta_h \eta(.,X)$ is determined by the equation: 
\begin{align*}
\Delta_h (t,X)&= \Delta _h f(X)\\ 
&+ \int\limits^t_o \sum^M _{i=1} (\int\limits^1_o \frac{\partial
  \hat{\sigma}}{\partial \gamma_i}(\gamma (s,X)+ \theta \Delta_h
\gamma (s,X),\eta(s,X)\\
& \qquad \qquad + \theta \Delta _h \eta (s,X))d \theta) \Delta_h
\gamma^i (s,X)d \beta (s)\\ 
& +\int\limits^t_o \sum ^N _{i=1} (\int\limits^1_o \frac{\partial
  \hat{\sigma}}{\partial \eta_j}(\gamma(s,X)+ \theta \Delta_h
\gamma (s,X),\eta(s,X)\\
& \qquad \qquad + \theta \Delta_\theta \eta (s,X))d \eta) \Delta_h
\eta^j(s,X)d \beta (s)\\ 
&+\int\limits^t_o \sum^M_{i=1} (\int\limits^1_o \frac{\partial
  \hat{b}}{\partial \gamma_j}(\gamma (s,X)+ \theta \Delta_h \gamma
(s,X),\eta(s,X)\\
& \qquad \qquad + \theta \Delta_h \eta (s,X))d \theta) \Delta_h
\gamma^i(s,X)ds\\ 
&+\int\limits^t_o \sum\limits^N_{j=1} (\int\limits^t_o \frac{\partial
  \hat{b}}{\partial \eta_j}(\gamma (s,X)+ \theta \Delta_h \gamma
(s,X),\eta(s,X)\\
& \qquad \qquad + \theta \Delta_h \eta (s,X))d \eta) \Delta_h
\eta^j(s,X)ds 
\end{align*}
Thus if
\begin{equation*}
\tilde {\gamma}(t,X,h)=
\begin{bmatrix}
\tilde {\gamma}_{(0)}(t,x,h) \\ 
\tilde {\gamma}_{(1)}(t,x,h) \\ 
\tilde {\gamma}_{(2)}(t,x,h) \\ 
\tilde {\gamma}_{(3)}(t,x,h) \\ 
\tilde {\gamma}_{(4)}(t,x,h) 
\end{bmatrix}
=
\begin{bmatrix}
\gamma(t,X)\\ 
\Delta_h \gamma (t,X)\\ 
\frac{1}{h}\Delta_h \gamma (t,X) \\ 
\eta (t,X) \\ 
\Delta _h \eta (t,X) 
\end{bmatrix}
\end{equation*}
where $\dfrac{1}{h}\Delta_h \gamma t,X) \equiv \dfrac{\partial
  \gamma}{\partial X_\ell} (t,X)$ for $h=0$, and 
\begin{align*}
\tilde{\sigma} (\tilde{\gamma},\tilde{\eta}) &=\sum^{M}_{i=1}\int
\limits^1_o \frac{\partial \sigma}{\partial \gamma_i} (\tilde
       {\gamma}_{(0)} + \theta \tilde{\gamma}_{(1)},\tilde
       {\gamma}_{(3)}+ \theta \tilde{\gamma}_{(4)})d \theta \tilde
       {\gamma}^i_{(2)}\\ 
       &+ \sum^{N}_{i=1}\int\limits^1_o \frac{\partial
         \hat{\sigma}}{\partial \eta_j}((\tilde{\gamma}_{(0)} +
       \theta \tilde{\gamma}_{(1)},\tilde{\gamma}_{(3)} + \theta
       \tilde{\gamma}_{(4)})d \theta \tilde {\eta}^j)  
\end{align*}
and $\tilde{b}(\tilde{\gamma},\tilde{\eta})$ is defined analogously,
then the process $\tilde{\eta}(t,X,h)$ determined by 
\begin{align*}
\tilde{\eta}(t,X,h) &= \frac{\Delta_h f}{h}(X) + \int \limits ^t _o
\tilde{\sigma}(\tilde{\gamma}(s,X,h), \tilde{\eta}(s,X,h))d \beta
(s)\\ 
&+ \int \limits ^t _o \tilde{b}(\tilde{\gamma}(s,X,h),
\tilde{\eta}(s,X,h))ds,
\end{align*}
where\pageoriginale $\Delta_h f /h (X) \equiv \frac{\partial f}{\partial
  X_\ell} (X)$ if  $h=0$, has the property that 
$$
\tilde{\eta}(.,X,h)=\Delta_h \eta(.,X)/h \; \; \text{ a.s.} 
$$
for each $h \in R \backslash \{0\}$ and $X \in R^D$. 
 
Since, by (\ref{chap1:lem3.1}), $\hat{\eta}$ has an a.s. continuous version, we
conclude that $\partial \eta/\partial X_{\ell}$ exists a.s. and has an a.s.
continuous version. Also, by (\ref{chap1:lem3.1}), $\partial \eta /
\partial X_ \ell$ 
satisfies the asserted moment inequalities.  
\end{proof}

\setcounter{theorem}{2}
\begin{theorem}\label{chap1:thm3.3}%%% 3.3
Let $\sigma: R^n \to R^n \otimes R^d$ and $b:R^n \to R^n$ be $C^
\infty-$functions such that $(\partial^{|\alpha|}\sigma / \partial
x^\alpha)$ and $(\partial^{|\alpha|} b / \partial x^\alpha)$ are bounded 
for each $|\alpha|\ge 1$. Let $\xi(t,x)$ be an a.s. continuous
version of the solution of the solution to (\ref{chap1:eq2.3}). Then
a.s. $\xi(t,.) \in C^ \infty (R^n)$ for all $t \ge 0$ and
$(\partial^{|\alpha|}\xi /\partial x^\alpha)$ is a.s. continuous
in $(t,x)$ for all $\alpha$. Moreover, for each $T$, $R >0$, $m \ge 0$ and
$2 \le p < \infty$, there is a $C_p (T,R,m)$ such that 
\begin{equation*}
\underset {|X|\le R} {\Sup} \sum_{|\alpha|\le m} E [\underset {0 \le t
    \le T} {\Sup} |\frac{\partial ^{|\alpha|}\xi}{\partial x^ \alpha}
  (t,x)|^p ] C_p (T,R,m). \tag{3.4}\label{chap1:eq3.4}    
\end{equation*}
\end{theorem}

Finally, for given $m \ge 1$, let $\lambda (.,x)$ denote $\bigg \{
|\dfrac{\partial ^{|\alpha|}\xi}{\partial x^ \alpha} (.,x):|\alpha|\le
m-1 \bigg \}$ and let $\eta (.,x)$ denote $\bigg \{ |
\dfrac{\partial^{|\alpha|}\xi}{\partial x^\alpha} (.,x):|\alpha|= m
\bigg \}$. Then $\eta (.,x)$ is related to $\gamma (.,x)$ by a
stochastic differential equation of the sort described in lemma
(\ref{chap1:lem3.2}).  

In\pageoriginale particular, if
\begin{equation*}
J(t,x)= ((\frac{\partial \xi^i}{ \partial x_j}(t,x)))_{1 \le i,j \le n}
\tag{3.5}\label{chap1:eq3.5}    
\end{equation*}
then $J(t,x)$ is determined by the equation
\begin{align*}
J(t,x) & = I + \sum_{k=1}^d \int\limits^t_o S_{(k)} (\xi
(s,x))J(s,x))d \beta^k (s)\\
& \qquad + \int \limits^t_o B (\xi (s,x))J (s,x)ds,
t \ge 0, \tag{3.6}\label{chap1:eq3.6}    
\end{align*}
where
$$
S_{(k)}= ((\frac{\partial \sigma ^i _k}{\partial x_j}))_{1 \le i,j \le
  n} \text{ and } B =((\frac{\partial b^i}{\partial x_j}))_{{1 \le i,\;j
    \le n}}. 
$$

\begin{proof}
The facts that a.s. $\xi (t,.) \in C^ \infty (R^n)$ for all $t \ge 0$
and that $(\partial ^{|\alpha|} \xi)/\break (\partial x^\alpha)$ is a.s.
continuous for all $\alpha$ is derived by induction on $|\alpha|$,
using (\ref{chap1:lem3.2}) at each stage. The induction procedure
entails showing 
at each stage that derivatives of order $m$ are related to those of
order $\le m-1$ by an equation of the sort described in lemma
(\ref{chap1:eq2.3}), 
and and so the described equation are a consequence of (\ref{chap1:lem3.2}).  
\end{proof}

\setcounter{lemma}{6}
\begin{lemma} % lem 3.7 
Suppose that $\Lambda(.),S_k (.) (1 <k<d)$, and $B(.)$ are
\break $F-$ progressively measurable $R^N \times R^N-$valued functions such
that 
$$
\max _{1 < k<d} ||S_k (.) ||_{H.S.} V ||B(.)|| 
$$
is uniformly bounded and $A(.)$ is an a.s. continuous solution to  
$$
A(t)= A_0+ \sum^d_{k=1} \int\limits^t_o S_k (u)A (u)d \beta^k 
(u)+ \int \limits^t_o B(u)A(u)du,t \ge 0, 
$$
where\pageoriginale $A_o \in R^N \times R^N$  is invertible. Then
a.s. $A(t)$ is invertible for all $t \geq 0$ and $A^{-1}(.)$ satisfies   
 \begin{align*}
 A^{-1}(t)& = A^{-1}_0 - \sum^{d}_{k=1} \int \limits ^t_o A^{-1}(u)S_k
 (u)d \beta^k(u)\\
& \qquad + \int \limits^t_o (\sum^{d}_{k=1} A^{-1} (u)S^2_k
 (u)-A^{-1}(u)B(u))du \;\; t \geq 0. 
 \end{align*}
 \end{lemma}

 \begin{proof}
The theorem is proved by defining $M(.)$ by the equation which
$A^{-1}(.)$ is supposed to satisfy and then using It $\hat{o}$'s
formula to check that  
$$
d(M(t)) \;\;  A(t)) =d(A(t) \;\; M(t))=0.
$$
\end{proof} 


\setcounter{exercise}{7}
\begin{exercise} % exercise 3.8
In order to see how one can guess the equation satisfied by
$A^{-1}(.)$, suppose that $A^{-1}(.)$ exists and denote it by
$M(.)$. Assume that  
$$
dM(t)= \sum^{d}_{k=1}M(t) \tilde{S}_k (t) d \beta^k (t)+ M(.)
\tilde{B}(.)dt 
$$
and use It $\hat{o}$'s formula to find out what $\tilde{S}_k(.)$ and
$\tilde{B}(.)$ must be. 
\end{exercise}


\setcounter{theorem}{8}
\begin{theorem} %%% 3.9 
Let everything be as in theorem (\ref{chap1:thm3.3}). Then a.s. $J(t,x)$ is
invertible for all $(t,x) \in [0, \infty] \times R^n$ and
$J^{-1}(.,x)$ determined by  
\begin{equation*}
J^{-1}(t,x) = I - \sum^{d}_{k=1} \int \limits^{t}_{o} J^{-1} (s,x)S_k
(\xi (s,x))d \beta^k (s) \tag{3.10}\label{chap1:eq3.10}    
\end{equation*}
$$
+ \int \limits^t_o (\sum^{d}_{k=1}J^{-1}(s,x)S^2_k (\xi
(s,x))-J^{-1}(s,x)B(\xi (s,x)))ds. 
$$

In particular,\pageoriginale a.s. $\xi(t,.)$ is a
$C^\infty-$diffeomorphism of $R^n$ onto $R^n$.  
\end{theorem}


\section{An application to Partial Differential Equations} %%% 4

Let $\xi(t,x)$ be as in section (\ref{chap1:sec2}). Then it is well-known
($cf$. Chapter 4 of [$ S \& V$]) that $\xi(t,x)$ is strong Markov in
the sense that if $\tau$ is a finite $F$.-stopping time and $f \in
B(R^n)$ (the bounded measurable functions on $R^n$) then for all $x
\in R^n$: 
\begin{equation*}
E[f (\xi(\tau + t,x))|F_\tau ]=u_f(t, \xi(\tau, x)) \;\; a.s., t \geq 0
\tag{4.1}\label{chap1:eq4.1}    
\end{equation*}
where
\begin{equation*}
u_f (t,x)=E[f (\xi (t,x))], (t,x) \in [0, \infty ]\times
R^n. \tag{4.2}\label{chap1:eq4.2}     
\end{equation*}

\setcounter{lemma}{2}
\begin{lemma}\label{chap1:lem4.3} % lemma 4.3 
Given $x \in R^n$ and $ R > 0$ there exist $A_1 (x,R) < \infty $ and $
0 < A_2 (x,R) < \infty $ depending only on $n$, $\Sup\limits_{y \in
  B(x,R)} \parallel \sigma (y) \parallel_{H.S.}$ and $\Sup\limits_{y
  \in B(x,R)}| b(y)|$ such that 
$$
P(\tau_r \leq h) \leq A_1(x,R) \exp (-A_2 (x,R) r^2/h)
$$
for $0 \leq r \leq R $ and $h > 0$, where
$$
\tau_r =\inf \{t \geq 0 : | \xi (t,x) -x | \geq r \}.
$$
\end{lemma}

\begin{proof}
Given $\theta \in R^n$, define
\begin{align*}
X_\theta (t) & = \exp [ < \theta,\xi (t,x)-x-\int \limits^{t}_{o}b (\xi
  (s,x)ds > \\
& \qquad - \frac{1}{2}\int \limits^{t}_{o} < \theta, \sigma
  \sigma^* (\xi(s,x) \theta > ds] 
\end{align*}

Then by $It \hat{o}$'s formula, $(X_\theta (t \Lambda \tau_R), F_t,
p)$ is a martingale for all $R > 0$. set 
$$
b_R = \Sup_{y \in B(x,R)}| b(y)|, a_R \Sup_{y \in B(x,R)}\parallel
\sigma \sigma^* (y) \parallel _{H.S} 
$$
and\pageoriginale define $h_R = b_R /2$. For $\theta \in S^{n-1}$ (the
unit sphere in $R^{n-1}$,) $\lambda > 0$, $0<r \leq R$ and $0 < h \leq
h_R $:  
\begin{align*}
 P ( \Sup_{0 \leq t \leq h} & < \theta, \xi (t,x)-x> \geq r) < P (
 \Sup\limits_{0 \leq t \leq h} < \theta , \xi  
(t \Lambda \tau_R ,x)\\
& \qquad  -x- \int\limits^{t \Lambda \tau_R}_o b(\xi
(s,x))ds) \geq \frac{r}{2}) \\ 
& < P ( \Sup_{0 \leq t \leq h} X_{\lambda \theta}(t \Lambda \tau_R)
\geq \exp (\frac{\lambda r}{2} - \frac{\lambda^2 h}{2}a_R)) \\ 
& \leq \exp (\frac{\lambda r}{2} + \frac{\lambda^2 h}{2}a_R)  
\end{align*}

Taking $\lambda = r/(2ha_R)$, we obtain
$$
P(\Sup_{0 \leq t \leq h}< \theta , \xi (t,x)-x > \geq r) \leq \exp
(-r^2 / (8ha_R)) 
$$
and so by choosing $\theta $ successively to point along $n$
coordinate axes: 
$$
P(\Sup_{0 \leq t \leq h} \max_{1 \leq i \leq n}| \xi^i (t,x)-x^i |
\geq r) \leq 2n \exp (- r^2/8ha_R) 
$$

Clearly the required estimate follows from this.
\end{proof}

\setcounter{lemma}{3}
\begin{lemma} %lem 4.4
Let $\sigma(.)$ and $b(.)$ be as in theorem (\ref{chap1:thm3.3}) and
define $\xi (t,x)$ accordingly. Given $f \in C ^\infty_\uparrow (R^n)$
(the $C^\infty$-functions $f$ such that the $D^\alpha f$ are slowly
increasing for all $\alpha$), define $u_f(t,x)$ by
(\ref{chap1:eq4.1}). Then $u_f 
\in C^\infty ([0, \infty ) \times R^n)$ and for each $T$, $R > 0$ and $m
  \geq 0 $ there is a $C(T,R,m)< \infty $ such that 
\begin{equation*}
\max_{2 \ell + |\alpha \leq |m }\Sup\limits_{\substack {0 \le t \le T\\{|\alpha |
      \le R}}}| \frac{\partial^\ell}{\partial
  t^\alpha} \frac{\partial^{|\alpha |}u_f}{\partial x^\alpha}(t,x)|
\leq C(T,R,m) 
    \max_{| \alpha | \leq m} \parallel \frac{\partial^{|\alpha
        |}f}{\partial x^\alpha}\parallel_u \tag{4.5}\label{chap1:eq4.5}     
\end{equation*}

Finally, $u_f$ is the unique $u \in C_\uparrow ([0,\infty) \times R^n)
  \cap C^{1,2}((0 , \infty ) \times R^n)$ such that
\begin{gather*}
\frac{\partial u}{\partial t} =Lu, t \geq 0 \tag{4.6}\label{chap1:eq4.6}  \\
\lim_{t \downarrow 0} u(t.,) = f(.)
\end{gather*}\pageoriginale
where
$$
L = \frac{1}{2} \sum^{n}_{i, j=1} (\sigma \sigma
^*)^{ij}(x)\frac{2}{\partial x_i \partial x_j}+ \sum^{n}_{i=1} b^i
(x)\frac{\partial}{\partial x_i} 
$$
\end{lemma}

\begin{proof}
Differentiating $E[f(\xi (t,x))]$ with respect to $x$, one sees by
induction that  
\begin{equation*}
\frac{\partial^{|\alpha|}u_f}{\partial x^\alpha}(t,x) = \sum_{\beta
  \leq \alpha }E \Bigg 
[\frac{\partial^{|\beta|}f}{\partial x^\beta}(\xi (t,x)))P^{\alpha ,
    \beta}( \equiv_{(| \alpha | )}(t,x))\Bigg ],
\tag{4.7}\label{chap1:eq4.7}      
\end{equation*}
in $\bigg \{ \dfrac{\partial^{|\beta|}\xi}{\partial x^\beta}(t,x):
|\beta | \leq |\alpha | \bigg \}$. Using It$\hat{o}'s$ formula and
the fact that \break
$\bigg \{ \dfrac{\partial^{|\beta|}\xi}{\partial
  x^\beta}(.,x): |\beta | \leq |\alpha | \bigg \}$ satisfies a
stochastic differential equation with coefficients in
$C^\infty_\uparrow$, one sees that  
\begin{equation*}
\frac{\partial^\ell}{\partial
  t^\ell}\frac{\partial^{|\alpha|}u_f}{\partial x^\alpha}(t,x) =
\sum_{| \beta |\leq | \alpha | +2 }E \Bigg 
[\frac{\partial^{|\beta|}f}{\partial x^\beta}(t,x) \Phi ^{(\sigma
    ,\beta ,\ell)}( \equiv_{(| \alpha | )}(t,x))\Bigg ],
\tag{4.8}\label{chap1:eq4.8}      
\end{equation*}
where the $\phi^{\alpha , \beta , \ell} \varepsilon C^\infty_\uparrow
(R^{D_{|\alpha |}})$. From (\ref{chap1:eq4.8}) and moment estimates in
(\ref{chap1:thm3.3}), it is clear that $u_f \in C^\infty ([ 0 , \infty )
  \times R^n)$ and that   (\ref{chap1:eq4.5}) holds.  
\end{proof}

We next show that $u_f$ satisfies (\ref{chap1:eq4.6}). Clearly 
$$
\lim_{ t \downarrow 0} u_f (t.,) = f(.).
$$

Moreover, by (\ref{chap1:eq4.1})
$$
u_f (t+h, x)=E[f(\xi (h+t,x))]= E[u_f (t,\xi (h,x))]. 
$$

Let $\tau = \inf \{s \geq 0 : | \xi (s,x) -x| \geq 1| \}$. Then 
\begin{align*}
E[u_f (t,\xi (h,x))] & = E[u_f (t,\xi (h \Lambda \tau , x))]\\
& + E[u_f (t,\xi (h,x)), \tau \leq h].
\end{align*}\pageoriginale

Since $u_f(t,.)$ is slowly increasing, it follows from
(\ref{chap1:lem4.3}) that  
$$
1/h E[u_f (t,\xi (h,x)), \tau \leq h] \to 0 \text{ as } h \downarrow 0 .
$$

On the other hand, by It$\hat{o}'s$ formula 
$$
\frac{1}{h}E[u_f (t,\xi (h \Lambda \tau , x))]-u (t,x) 
$$
\begin{align*}
& = \frac{1}{h}E[ \int \limits^{h \Lambda \tau}_{0} L u_f (t,\xi
    (s,x))ds] \\ 
& \to L u_f (t,x) \text{ as } h \downarrow 0
\end{align*}
since $P (\tau > 0) =1$. Thus we have proved that 
$$
\frac{\partial u_f}{\partial t}= L u_f, t \geq 0 . 
$$

Finally, we must show that if $u \in C_\uparrow ( [0, \infty)\times
  R^n) \cap C^{1,2}((0 , \infty ) \times R^n$ satisfies (\ref{chap1:eq4.6}). Then
  $u = u_f$. To this end, let 
$$
\tau_R = \inf \{ t \geq 0 : | \xi (t,x)- x| \geq R \}.
$$

Then by $It \hat{o}'s$ formula for fixed $T > 0$ we know that
$$
(u (T - t \Lambda \tau_R , \xi (t \Lambda \tau_R, x)), F_t, P)
$$
is a martingale, $0 \leq t \leq T$. In particular,
$$
u(T,x) =E[u(T-T \Lambda \tau_R,\xi (T \Lambda \tau_R , x)].
$$
since $\tau_R \uparrow \infty $ as $R \downarrow \infty $ and $u$ is
slowly increasing, 
$$
E[u(T-T \Lambda \tau_R, \xi (T \Lambda \tau_R, x)] \to E[f (t,(x(T))]
\text{ as } R \uparrow \infty. 
$$

\setcounter{exercise}{8}
\begin{exercise}\label{chap1:exer4.9} % exercise 4.9
Under\pageoriginale the condition of theorem (\ref{chap1:thm3.3}),
show that for each 
$m \geq 0$ and $2 \leq p < \infty$ there exist $A_{m,p}$, $B_{m,p} <
\infty$ and $\lambda_{m,p}> 0$ (depending on $m,p,n$ and the bounds on
$\sigma $ and $b$ and their derivatives) such that  
\begin{equation*}
E \left| \Sup_{0 \leq t \leq m}\bigg [ \sum_{| \alpha | \leq m}| \frac
  {\partial ^{| \alpha |}\xi}{\partial x^\alpha}(t,x)|^2 \bigg
]^{p/2} \right| \leq A_{m,p}e^{B_{m,p}T}(1+
|x|)^{\lambda_{m,p}}.\tag{4.10}\label{chap1:eq4.10}  
\end{equation*}
\end{exercise}

Calculate from this that if $f \in C^\infty_\uparrow (R^n)$, then
$u_f \in C^\infty_\uparrow ([o,T] \times R^n)$ for all $T > o$. Check
also that for a given $m \geq 1$ and $2 \leq p < \infty$,
$\lambda_{m,p}$ does not depend on $\sigma (.)$ and $b(.)$ while
$A_{m,p}$ and $B_{m,p}$ depend only on the bounds on   
$$
\frac{\partial^{|\alpha|}\sigma}{\partial x^\alpha}(.)\text{ and }
\frac{\partial^{| \alpha|}b}{\partial x^\alpha}(.) \text{ for } 
|\alpha | \leq m. 
$$


