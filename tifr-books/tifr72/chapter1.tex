\part{Topics in Sieve Methods}\label{part1}

\chapter{The $\Lambda^{2}$-Sieve}\label{part1-chap1}

ONE\pageoriginale OF THE primary purposes in these lectures is to appreciate the
power as well as the sharpness of Selberg's fundamental sieve idea
---- the $\Lambda^{2}$ - sieve -- by employing it as a principal tool
in the investigation of the zeta- and  $L$-functions. Our actual
applications of his idea will, however, be made not in its original
form but rather in its hybridized version with the large sieve of
Linnik; indeed, there is a sort of duality relation between these two
fundamental sieve methods because of which they admit of a fruitful
unification. 

In the present chapter, we shall first study this aspect of the
$\Lambda^{2}$-sieve to some extent of generality and then, by
specializing main results, prepare basic aids for the applications to
be made in PART \ref{part2}. 

\section{Selberg's Sieve for Intervals}\label{part1-chap1:sec1.1}%SECTION 1.1

To begin with, we shall give a formulation of Selberg's fundamental idea:

Let $\Omega$ be a map of $\{p^{\alpha}\}$ the set of all prime- powers
into the family of all subsets of $\mathbb{Z}$, and for an arbitray
sequence $A$ of integers let us consider 
$$
A_{\Omega} = \{a \epsilon A; a \not\epsilon \Omega (P^{\alpha})
\text{ for all } p^{\alpha} (\alpha > 0)\} 
$$
which may be called the resulatant of sifting $A$ by $\Omega$. We extend
the\pageoriginale domain of $\Omega$ to $\mathbb{N}$ by putting
$$
\Omega(d) = \bigcap_{P^{\alpha}\| d} \Omega(P^{\alpha}), \Omega(1) = \mathbb{Z},
$$
and denote by $\delta_{d} \text{ and } \tilde{\omega}$ the
charcteristic functions of the sets $\Omega(d)$ and\break
$\mathbb{Z}_{\Omega'}$ respectively. Then Selberg's idea may be
formulated as follows. 

\begin{theorem}\label{part1-chap1:sec1.1:thm1}%the 1
  Let $\lambda$ be an arbitrary real-valued function with a
  compact support and satisfying $\lambda(1) = 1$. Then 
  $$
  \tilde{\omega} \leq \left(\sum_{d} \lambda (d) \delta_{d}\right)^{2}.
  $$
  PROOF is immediate.
\end{theorem}

In partticular, we have, for any finite sequence $A$ of integers,
\begin{equation*}
\mid A_{\Omega}\mid \leq \sum_{a \epsilon  A} \left(\sum_{d} \lambda(d)
\delta_{d} (a)\right)^{2}.\tag{1.1.1}\label{eq1.1.1} 
\end{equation*}

Naturally, it  is desirable to have the minimum value taken by this
quadratic form of $\lambda$ under the side condition $\lambda(1) = 1$;
but obviously that would be intractable without imposing certain
reasonable conditions on $\Omega, A \text{ and } \lambda$. Hence we
shall introduce the following specialization of them in order to
illustrate the process leading to the determination of a quasi-optimal
$\lambda$, and thus a satisfactory upper bound for $|A_{\Omega} |$. 

We assume that $A$ is in an interval of length $N \epsilon
\mathbb{N}$, i.e., there is an $M \epsilon \mathbb{Z}$  such that
$A \subseteq [M, M + N) \text{ and that } \Omega$ is defined locally
by congruence relations, i.e., 
\begin{equation*}
  \Omega(p^{\alpha)} =
  \left\{
  \begin{aligned}
    & n \pmod {p^\alpha} ~\text{ belongs to a given }~ \\
    n; & \\
    & \text{ set if residues } \pmod {p^\alpha} 
  \end{aligned}
  \right\}\tag{1.1.2}\label{eq1.1.2}
\end{equation*}\pageoriginale

Also, we assume, for the sake of simplicity, that for each prime $p$
there is an $\alpha_{p} \geq 1$ such that 
\begin{equation*}
\Omega(p^{\alpha}) = ~\text{ empty for all }~ \alpha \geq
\alpha_{p}.\tag{1.1.3}\label{eq1.1.3} 
\end{equation*}

Further, we restrict $\lambda$ by requiring that its support be
contained in the interval $[0, Q], Q > 1$ being a parameter. 

On these assumptions, we have, by \eqref{eq1.1.1}, 
\begin{equation*}
  | A_{\Omega} | \leq \sum_{M \leq n < M+N} \left(\sum_{d < Q} \lambda(d)
  \delta_{d} (n)\right)^{2}.\tag{1.1.4} \label{eq1.1.4}
\end{equation*}

However, to avoid the complexity arising from the possible inter-
relation among $\Omega(p^{\alpha}), \alpha \geq 1$, it is expendient
to transform $\Omega$ ~\text{into}~ $\tilde{\Omega}$ which is defined by  
$$
\tilde{\Omega}(p^\alpha) = \Omega (p^\alpha) -
\bigcup^{\alpha-1}_{j=1} \Omega(p^j) 
$$
so that $\tilde{\Omega}(p^{\alpha})$, $\alpha \geq 1$, are independent
of each other, i.e., 
\begin{equation*}
\tilde{\Omega}(p^\alpha) \cap \tilde{\Omega}(p^\beta) = \text{ empty
  if } \alpha\beta (\alpha - \beta) \neq 0.\tag{1.1.5} \label{eq1.1.5}
\end{equation*}

This does not cause any change in our present sieve situation, for we
have evidently $A_{\Omega} = A_{\tilde{\Omega}}$. Thus we shall
consider, instead of \eqref{eq1.1.4}, the expression 
\begin{equation*}
 |A_\Omega | \leq \sum_{M \leq n < M+N} \left(\sum_{d < Q} \lambda(d)
 \tilde{\delta}_d (n)\right)^{2}, \tag{1.1.6} \label{eq1.1.6}
\end{equation*}
where\pageoriginale $\tilde{\delta}_{d}$ is the characteristic function of the set
$$
\displaylines{\hfill
  \tilde{\Omega}(d) = \bigcap_{p^\alpha \| d} \tilde{\Omega}(p^\alpha),
  \hfill \cr
  \text{i.e.,}\hfill 
  \tilde{\delta}_d = \delta_d \prod_{p^\alpha \mid \mid d}
  \prod^{\alpha-1}_{j=1} (1 - \delta_p^j).\hfill} 
$$

Now we have to estimate the right side of \eqref{eq1.1.6}. The
conventional 
way of doing this is to expand out the lamda-squares, change the order
of summations, and single out the main-term while estimating
drastically the error thus caused; by an obvious reason, this does not
work well in our present situation. Thus we need to devise an
alternative argument. To this end, we observe that since we have
defined $\Omega$ by the congruence condition \eqref{eq1.1.2}, the
characteristic function $\tilde{\delta}_d$ can be expressed as 
\begin{equation*}
\begin{split}
\tilde{\delta}_d(n)& = \frac{1}{d} \sum^{d}_{\ell=1} \sum^{d}_{k=1}
\exp \left( 2\pi i \frac{k}{d} (n-\ell)\right) \tilde{\delta}_{d}{\ell}\\ 
&= \frac{1}{d} \sum_{q | d}  
\sum_{\substack{h=1\\ (h,q)=1}}^q \exp
\left(2\pi i \frac{h}{q} n\right) \sum^{d}_{\ell=1} \exp \left(-2 \pi
i \frac{h}{q} \ell\right) \tilde{\delta}_d(\ell).
\end{split}
\tag{1.1.7} \label{eq1.1.7}
\end{equation*}

Insertion of this into the right side of \eqref{eq1.1.6} gives
\begin{equation*}
  | A_{\Omega} | \leq \sum_{M \leq n < M+N} | \sum_{q < Q}
  \sum_{\substack{h=1\\ (h,q)=1}}^q b\left(\frac{h}{q}\right) \exp \left(2 \pi i
  \frac{h}{q} n\right)|^2, \tag{1.1.8}\label{eq1.1.8}
\end{equation*}
where
$$
 b \left(\frac{h}{q}\right) = \sum_{\substack{d \equiv 0 \pmod{q}\\ d< Q}}
 \frac{\lambda(d)}{d} \sum^{d}_{\ell=1} \exp \left(-2 \pi i \frac{h}{q}
 \ell\right) \tilde{\delta}_{d}(\ell). 
$$

Thus\pageoriginale we have got an expression fairly familiar in the theory of the
large sieve, and we recall the fundamental 

\begin{Lemma}\label{part1-chap1:sec1.1:lem1}%lemma 1
  Let $\{x_r \}$ be $a$ set of points in the unit interval
  which are spaced by $\delta > 0$. Then, for any $M \epsilon
  \mathbb{Z}, N \epsilon \mathbb{N}$ and complex numbers
  $\{b_{r }\}$, we have 
  $$
  \sum_{M \leq n < M + N} | \sum_{r } b_{r } \exp (2 \pi i n
  x_{r }) |^{2} \leq (N -1+ \delta^{-1}) \sum _{r } | b_{r }
  |^{2}. 
  $$
\end{Lemma}

Applied to the right side of \eqref{eq1.1.8}, this yields readily
\begin{equation*}
\begin{split}
  | A_{\Omega}| &\leq (N -1+Q^2) \sum_{q < Q}
  \sum_{\substack{h=1\\ (h,q)=1}}^q | b\left(\frac{h}{q}\right) |^{2}\\ 
  & = (N -1+Q^{2}) \sum_{d_1, d_2 < Q} \lambda (d_1) \lambda (d_2)
  f(d_1, d_2),
\end{split}
\tag{1.1.9} \label{eq1.1.9} 
\end{equation*}
say; here we have
$$
f(d_1, d_2) = \frac{1}{[d_1, d_2]} \sum_{\substack{\ell_1 = 1\\ \ell_1
    \equiv \ell_2}}^{d_1} 
\sum_{\substack{\ell_2 =1\\ \pmod{(d_1, d_2)}}}^{d_2}
\tilde{\delta}_{d_{1}} (\ell_1) \tilde{\delta}_{d_{2}} (\ell_2). 
$$

Taking into account the multilicative property of $\tilde{\delta}_d$,
this may be written as 
$$
f(d_1, d_2) = \frac{1}{[d_1, d_2]} \prod_{\substack{p ^{\alpha} \|
    d_1 \\ p^{\beta} \| d_2}} \left\{ \sum^{p^\alpha}_{\substack{\ell_1 = 1 \\ \ell _1
    \equiv \ell_2}} \sum^{p^\beta}_{\substack{\ell _2 = 1 \\ \pmod{p^{\min
      (\alpha, \beta)}}}} \tilde{\delta}_{p^{\alpha}} (\ell _1)
 \tilde{\delta}_{p^{\beta}} (\ell_2)\right\}. 
$$

If $\alpha \beta(\alpha - \beta) \neq 0$ then this double sum is zero,
for we have \eqref{eq1.1.5}; on the other hand, if, either $\alpha = \beta
\text{ or } \beta = 0$, then it is equal to the\pageoriginale number of residue
classes $\pmod{p^{\alpha}}$ defining the set
$\tilde{\Omega}(p^{\alpha})$, which we shall denote by
$\|\tilde{\Omega}(p^{\alpha}) \|$, in what follows. Hence we have  
\begin{equation*}
  f(d_1, d_2) = \prod_{\substack{p^{\alpha || d_1}\\ p^{\beta}|| d_2}}
  f(p^{\alpha}, p^{\beta}),\tag{1.1.10}\label{eq1.1.10}
\end{equation*}
where
\begin{equation*}
  f(p^{\alpha}, p^{\beta}) = f(p^{\beta}, p^{\alpha}) =
  \begin{cases}
    0 & \text{ if } \alpha \beta (\alpha - \beta) \neq 0,\\
    \| \tilde{\Omega}(p^{\alpha}) \| p^{-\alpha} &\text{ if either } \alpha
    = \beta \text{ or } \beta = 0.
  \end{cases}\tag{1.1.11}\label{eq1.1.11}
\end{equation*}

Now, let us proceed to the computation of the minimum value taken by
the quadratic form 
$$
I = \sum_{d_1, d_2 < Q} \lambda(d_1) \lambda(d_2) f(d_1, d_2)
$$
on the side condition $\lambda(1) = 1$. To this end, we need to have
$a$ diagonalization of the infinite matrix 
$$
F = (f(d_1, d_2)) (d_1, d_2 \epsilon \mathbb{N}).
$$

Formula \eqref{eq1.1.10} implies that $F$ can be expressed as the infinite
Kronecker product: 
\begin{equation*}
  F = \bigotimes _{p} F_{p'}\tag{1.1.12}\label{eq1.1.12}
\end{equation*}
where
$$
F_p = (f(p^\alpha, p^\beta)) (\alpha, \beta \leq \alpha _{p}\quad\text{(cf. \eqref{eq1.1.13})}).
$$

This should be taken for a symbolic interpretation of the
multiplicative property of the function $f$; so we may neglect the
question of the order of multiplication. 

Thus,\pageoriginale it suffices to consider a diagonalization of $F_P$.For this sake
we use the familiar algorithm of Gauss, and get 
\begin{equation*}
F_P=T_P D_P T_P^t,\tag{1.1.13}\label{eq1.1.13}
\end{equation*}
where $D_P$ is diagonal, and $T_P$ is lower triangular with all
diagonal entries being equal to 1. To see the precise form of $D_P$
and $T_P$, we consider the quadratic form $K(x_0, x_1, \ldots, x_r )
r =\alpha_P$, for which $F_P$ is the coefficient matrix;
\eqref{eq1.1.11} gives 
$$
k={x_{0^2}} + 2{x_0}({f_1} {x_1} + {f_2} {x_2} + \cdots + {f_r }
{x_r })+ {f_1} x^{2_1} + {f_2} x^{2_2} + \cdots + {f_r}
x^{2_r'} 
$$
where $f_j = \|\tilde{\Omega} (p^j) \| p^-j$.

We have
{\fontsize{10pt}{12pt}\selectfont
\begin{align*}
  K & = \left(x_0 + f_1 x_1 + \cdots+f_r
  x_r\right)^2+f_1(1-f_1) \left(x_1-\frac{1}{1-f_1}(f_2x_2+\cdots+f_r
  x_r)\right)^2\\ 
  & \qquad -\frac{1}{1-f_1} \left(f_2x_2+\ldots +f_r
  x_r\right)^2+f_2x^2_2+\cdots+f_r x^2_r\\ 
  &=\left(x_0+f_1x_1+\cdots +f_r
  x_r\right)^2+f_1(1-f_1) \left(x_1-\frac{1}{1-f_1}(f_2x_2+\cdots+f_r
  x_r)\right)^2\\
  &\qquad +f_2\frac{1-f_1-f_2}{1-f_1}\left(x_2-\frac{1}{1-f_1-f_2}(f_3x_3+
  \ldots+f_r X_r)\right)^2\\
  &\qquad -\frac{1}{1-f_1-f_2} (f_3x_3+\ldots+f_r x_r)^2
  +f_3x^2_3+\ldots f_r x^2_r; 
\end{align*}}\relax
thus inductiveIy we find

\begin{equation*}
  K=y^2_0+f_1(1-f_1)y^2_1+f_2 \frac{1-f_1-f_2}{1-f_1} y^2_2+
  \cdots+f_r \frac{1-f_1-f_2-\cdots -f_r}{1-f_1-f_2-\cdots
    -f_{r-1}} y^2_r \tag{1.1.14} \label{eq1.1.14}
\end{equation*}
where
\begin{equation*}
  y_0=x_0+f_1x_1+\cdots+f_r x_r \tag{1.1.15}\label{eq1.1.15}
\end{equation*}\pageoriginale
and,for $1\leq j\leq r$,
\begin{equation*}
  y_j = x_j-\frac{1}{1-f_1-f_2-\cdots - f_j}(f_{j+1}x_{j+1} +\cdots
  +f_r x_r). \tag{1.1.16} \label{eq1.1.16}
\end{equation*}

It should be remarked here that in the above transformation of $K$ we
have assumed that for $1 \leq j \leq$ 
\begin{equation*}
  \theta (p^{j}) = 1- f_1 - f_2 -\cdots -f_j
  \tag{1.1.17}\label{eq1.1.17} 
\end{equation*}
does not vanish. This causes no loss of generality. For, $p^j
(1-\theta (p^j))$ is obviously the number of residue of classes 
$\pmod{p^j}$ defining the set $\Omega (p) \cup \Omega (P^2) \cup \cdots \cup
\Omega (p^j)$, and if $\theta (p^j) =0$, then this sum coincides with
$\mathbb{Z}$, that is $|A_{\Omega}|=0$. 

Using the nitation  \eqref{eq1.1.17}, we may put the transformation
\eqref{eq1.1.15} -- \eqref{eq1.1.16} in the matrix from
\eqref{eq1.1.13} with  
$$
\begin{aligned}
  D_p &= 
  \begin{pmatrix}
    g(1)_{g(p)}&  & \bigcirc\\
    &\ddots & \\
    \bigcirc & & g(p^{\alpha_{p}}),
  \end{pmatrix}\\
  T_p &= (t( p^{\alpha},m p^{\beta})) (0 \leq \alpha, \beta \leq \alpha _p),
\end{aligned}
$$
where
\begin{equation*}
g(1) = 1, g (p ^{\alpha}) = (\theta(p^{\alpha-1})-\theta(p^\alpha))
\theta(p^\alpha)\theta(p^{\alpha-1})^{-1}  \tag{1.1.18} \label{eq1.1.18}
\end{equation*}
and
\begin{equation*}
  t(p^\alpha,p^\beta) =  
  \left\{
  \begin{alignedat}{2}
    &  \qquad  1  & &\text{if} \alpha = \beta,\\
    &\theta ( p^{\alpha-1}) - \theta(p^\alpha)\qquad & &\text{if} \alpha >
    0,  \beta = 0,\\ 
    & ( \theta(p^\alpha)- \theta (p^{\alpha-1}))\theta (p^\alpha)^{-1}~ &
    &\text{if} \alpha > \beta  > 0, \\ 
    &  \qquad 0 & &\text{if} \alpha < \beta. 
  \end{alignedat}
  \right. \tag{1.1.19}\label{eq1.1.19}
\end{equation*}\pageoriginale

In particular, we have
$$
f(p^\alpha, p^\beta) = \sum \limits^{\min(\alpha, \beta)}_{r = 0}
g(p^r) t(p^\alpha, p^r) t(p^\beta, p^r). 
$$

\noindent
Thus, in view of \eqref{eq1.1.10}, we obtain 
\begin{equation*}
f(d_1,d_2) = \sum_{u | (d_1,d_2)} g(u) t(d_1,u) t(d_2,u),
\tag{1.1.20}\label{eq1.1.20} 
\end{equation*}
in which we have put
\begin{equation*}
g(u) = \prod_{p^\alpha \| u} g(p^\alpha) \tag{1.1.21}\label{eq1.1.21}
\end{equation*}
and
$$
t(d,u) = \prod_{\substack{p^\alpha \| d \\p^\beta \| u}}t(p^\alpha,p^\beta).
$$

The formula \eqref{eq1.1.20} provides the quadratic form $I$ with the
diagonalized form: 
\begin{align*}
I &=  \sum_{u < Q} g(u) ( \sum_{\substack{d < Q \\ d \equiv 0
    \pmod{u}}} t(d,u) \lambda (d))^2 \\  
&= \sum_{u < Q} g(u) \xi ^2 _u,
\end{align*}
say.

To\pageoriginale proceed further, we need to express the side
condition $\lambda (1) 
= 1 $  in terms of  $ \xi_u$. To this end, we compute the inverse
matrix of $T_p$; this may be performed easily with  the aid of
\eqref{eq1.1.15} and  \eqref{eq1.1.16}. We have  
$$
T^{-1}_p = (t^* (p^\alpha, p^\beta)) (0 \leq \alpha,\beta \leq \alpha_p)
$$
with 
\begin{equation*}
  t^* (p^\alpha,p^\beta) =
  \begin{cases}
    \qquad \qquad 1 & \text{if}~ \alpha = \beta,\\
    ( \theta(p^\alpha)- \theta (p^{\alpha-1}))\theta (p^{\alpha-1})^{-1}
    & \text{if}~ \alpha > 0,\beta  = 0, \\ 
    -( \theta(p^\alpha)- \theta (p^{\alpha-1}))\theta (p^{\alpha-1}) 
    &\text{if}~ \alpha > \beta  > 0, \\ 
    \qquad \qquad 0 & \text{if}~ \alpha < \beta. 
  \end{cases} \tag{1.1.22}\label{eq1.1.22}
\end{equation*}

Then, putting
$$
t^* (d,u) = \prod_{\substack{p^\alpha \| d \\ p^\beta \| u}} t^*
(p^\alpha, p^\beta), 
$$
we have
\begin{equation*}
  \sum_{\substack{u | d_1. \\ u \equiv 0 \pmod{d_2} \\}} t(d_1,u)t^*
  (u,d_2) = \delta_{d_1, d_2} \text{(Kronecker's delta)}
  \tag{1.1.23} \label{eq1.1.23} 
\end{equation*}
as well as
\begin{equation*}
  \sum_{\substack{u \mid d_1 \\ u \equiv 0 \pmod{d_2}}} t^* (d_1,u)
  t(u,d_2) = \delta_{d_1, d_2}. \tag{1.1.24}\label{eq1.1.24} 
\end{equation*}

In\pageoriginale view of the definition of $\xi_u$,
\eqref{eq1.1.23} implies 
$$
\lambda(d)= \sum_{\substack{u<Q \\ u \equiv 0\pmod{d}}} t^{\ast}(u, d)\xi_u.
$$

Specifically, we have transformed the side condition $\lambda(1)=1$ into
$$
1=\sum_{u<Q}t^{*}(u,1)\xi_u. 
$$

Thus we have 
$$
I=\sum_{d<Q}g(d) \left(\xi_d - \frac{t^{*}(d,1)}{g(d)}D\right)^{2}+D
$$
where 
\begin{align*}
D&=\left\{\sum_{d<Q} \frac{t^{*}(d,1)^2}{g(d)}\right\}^{-1}\\ 
&=\left\{\sum_{d<Q}\prod_{p^{\alpha}\|d}(\frac{1}{\theta(p^{\alpha})} -
\frac{1}{\theta(p^{\alpha-1})})\right\}^{-1}.    
\end{align*}

Hence we find that
$$
\min_{\lambda(1)=1} I = D,
$$
and this is attained at
\begin{equation*}
  \lambda(d)=D \sum_{\substack{u<Q \\ u \equiv 0 \pmod{d}}}
  \frac{t^{*}(u,1)t^{*}(u,d)}{g(u)}.\tag{1.1.25} \label{eq1.1.25}
\end{equation*}

Summing up the above discussion, we have now established
\begin{theorem}[SELBERG'S SIEVE FOR
    INTERVALS]\label{part1-chap1:sec1.1:thm2}%thm 2 
  Let $A$ be a sequence of
  integers in an interval of length $N \epsilon \mathbb{N}$, and
  $\Omega$ be defined by\pageoriginale the conqruence relation
  \eqref{eq1.1.2}. Then have, for any $Q>1$,
  $$
  |A_{\Omega}|\le (N-1+Q^{2})\left\{\sum_{d<Q} \prod_{p^{\alpha} \|d}
  \left(\frac{1}{\theta(p^{\alpha})}-\frac{1}{\theta(p^{\alpha-1})}\right)
  \right\}^{-1}  
  $$
  where $\theta$ is defined by \eqref{eq1.1.17}.
\end{theorem}

\begin{remark*}
 By the exclusion-inclusion principle, we can show easily that
 $$
 \theta(p^{\alpha})=1+\sum^{\alpha}_{r=1}(-1)^r \sum_{1\le
   j_1<j_2< \cdots < j_r \le \alpha}\| \Omega (p^{j_1})\cap
 \cdots \cap \Omega (p^{-j_r})\| p^{-j_r} 
 $$
 where $\| \Omega(p^{j_1})\cap \cdots \cap \Omega (p^{j_r})\|$,
 $j_1<j_2<\cdots <j_r$, denote the number of residue classes
 $\pmod{p^{j_r}}$ defining the set $\Omega(p^{j_1})\cap \cdots
 \cap \Omega (p^{j_r})$. 
\end{remark*}

\section{The Hybrid Dual Sieve for Intervals}\label{part1-chap1:sec1.2}%sec 1.2

Next, we shall show a hybridization of
THEOREM \ref{part1-chap1:sec1.1:thm2} with the 
multiplicative large sieve inequality, and by doing so, we shall
stress that the occurrence of the additive large sieve inequality
(LEMMA \ref{part1-chap1:sec1.1:lem1}) in our discussion on the Selberg
sieve for intervals is by 
no means accidental; in fact, as already mentioned in the introduction
to this chapter, behind this phenomenon is an important relation
between Selberg's and Linnik's sieve methods which may be termed a
duality. 

In the present section, we shall retain the notation and conventions
introduced in the above; in particular, $\Omega$ is defined by the
congruence relation \eqref{eq1.1.2}. 

First, we make an observation on the nature of the optimal $\lambda$
which\pageoriginale has been obtained at \eqref{eq1.1.25}. It gives 
\begin{equation*}
  \sum_{u<Q}\lambda(u)\tilde{\delta}_u (n)=D
  \sum_{d<Q}\frac{t^*(d,1)}{g(d)}\Psi_d (n,\Omega ),
  \tag{1.2.1} \label{eq1.2.1} 
\end{equation*}
where
\begin{equation*}
  \Psi_d(n,\Omega)=\sum_{u| d}
  t^*(d,u)\tilde{\delta}_u(n).\tag{1.2.2}\label{eq1.2.2} 
\end{equation*}

Rec$\dot{a}$lling the definitions of $\tilde{\delta}$ and $t^*,$ this
may be written as  
\begin{equation*} 
  \psi_d(n,\Omega)=\prod_{p^\alpha \|
    d}\Theta(p^{\alpha-1})^{-1} \left\{\triangle_{p^{\alpha-1}}
  (n)\Theta(p^\alpha)-\triangle_{p^\alpha}(n)\Theta(p^{\alpha-1})\right\}\tag{1.2.3}\label{eq1.2.3} 
\end{equation*}
where
$$
\triangle_p^{\alpha}=\prod_{j-1}^\alpha (1-\delta_p{^j}).
$$
 
And we have  actually proved in the preceding section the inequality:
 $$
 \sum_{M\leq
   n<M+N}\left\{\sum_{d<Q}\frac{t^*(d,1)}{g(d)}\Psi_d(n,\Omega)
 \right\}^2 \quad
 \leq(N-1+Q^2)\sum_{d<Q}\left(\frac{t^*(d,1)}{g(d)}\right)^2 g(d). 
 $$

 This relation raises the anticipation that the norm of the matrix
 $$
 (\Psi_d(n,\Omega)g(d)^{-\frac{1}{2}})(d<Q,M\leq n<M+N)
 $$
 may not exceed $(N-1+Q^2){^{\frac{1}{2}}}$, i.e., for any complex
 numbers $ \{b_d\} $ 
 \begin{equation*}
\begin{split}
 & \sum_{M \leq n < M+N} | \sum_{d<Q} \frac{\psi_{d} (n, \Omega
   )}{\sqrt{g(d)}}b_{d} |^2 \\
  &\qquad \leq (N-1+Q^2)\sum_{d<Q}|b_d|^2. 
\end{split}
\tag{1.2.4}\label{eq1.2.4}
 \end{equation*} 

In\pageoriginale order to press the matter further, we quote the
well-known duality principle: 
 
\begin{Lemma}\label{part1-chap1:sec1.2:lem2}%lem 2
  Let $(c_{ij})$ be a matrix, and $E$ be such that for any complex
  numbers $\{x_i\}$ 
  $$
  \sum_j |\sum_i c_{ij}x_i |^2\leq E \sum_{i}| x_i |^2.
  $$

  Then we have, for any complex numbers $\{y_j\}$,
  $$
  \sum_i |\sum_j c_{ij} y_j |^2 \leq E \sum_j |y_j |^2,
  $$
  and vice-versa.
\end{Lemma} 

 Thus, if \eqref{eq1.2.4} is true, then its dual
\begin{equation*}
\begin{split}
& \sum_{d<Q} \frac{1}{g(d)}| \sum_{M\leq n<M+N} \psi _d (n,\Omega)a_n |^2\\
&\qquad \leq (N-1+Q^2)\sum_{M\leq n<M+N }| a_n|^2 
\end{split}
\tag{1.2.5}\label{eq1.2.5}
\end{equation*}
with arbitrary complex numbers $\{a_n\}$ will also be true. We should
note the strong similarity of this to the multiplicative large sieve
inequality. 
 
 Now we shall develop a descussion to confirm that
 \eqref{eq1.2.5}, and indeed a much more general result actually
 hold. To begin with, we introduce the expression  
 $$
 D=\sum_{\substack{qr<Q\\ (q,r)=1\\ (qr,k)=1}} \sum^*
 _{X \pmod{q}}\frac{q}{\varphi(q)g(r)}| \sum_{\substack{M\leq
     n<M+N \\ n \equiv \ell \pmod{k}}} \chi(n)\Psi_r(n,\Omega)
 a_n |^2, 
 $$\pageoriginale
 where $k, \ell, Q, N \epsilon \mathbb{N}, M \epsilon \mathbb{Z}
 $  are arbitary. But the direct estimation of $D$ is tedious if not
 difficult; so we consider, instead, the dual 
  $$
 D^*=\sum_{\substack{M\leq n< M+N \\ n \equiv \ell \pmod{k}}}|
 \sum_{\substack{qr<Q\\ (q,r)+1 \\ (qr,k)=1}}
 \sum^*_{\chi \pmod{q}}\left(\frac{q}{\varphi (q)g(r)}\right)^\frac{1}{2}
 X(n)\Psi _r(n,\Omega)b(r,X)|^2, 
 $$
 where $\{b(r,\chi)\}$ are arbitrary complex numbers. Inserting
 the expression \eqref{eq1.2.2} for $\psi_r(n,\Omega),$ we have 
 $$
 D^*=\sum_{\substack{M\leq n< M+N \\ n \equiv \ell \pmod{k}}}|
 \sum_{\substack{qd<Q\\ (q,d)=1 \\ (qd,k)=1}} \sum^*_{X
   \pmod{q}}\left(\frac{q}{\varphi(q)}\right)^\frac{1}{2}
 X(n)\tilde{\delta}_d (n)S(d,X)|^2, 
 $$
 where
\begin{equation*}
  S(d,X)=\sum_{\substack{u<Q/q \\ u\equiv 0\pmod{d}\\ (u,qk)=1}}
  b(u, X)t^*(u,d)
  g(u)^-\frac{1}{2},(X\pmod{q}). \tag{1.2.6} \label{eq1.2.6} 
\end{equation*}
 
Recalling \eqref{eq1.1.7}, we transfrom $D^*$ further into
\begin{equation*}
  D^*=\sum_{\substack{M\leq n< M+N\\ n\equiv \ell \pmod{k}}} |
  \sum^{**}_{u,h,q,X} \left(\frac{q}{\varphi
    (q)}\right)^{\frac{1}{2}}\chi(n)\exp\left(2
  \pi i \frac{h}{u}n\right) y(u,h,X)|^2 \tag{1.2.7} \label{eq1.2.7}
\end{equation*} 
where
\begin{equation*}
  y(r,\chi)= \sum_{\substack{d<Q/q\\ d\equiv 0 \pmod{u}\\ (d,qk)=1}}
  \frac{s(d,X)}{d}\sum^d_\ell=1 \exp\left(-2\pi i
  \frac{h}{u}\ell\right) \tilde{\delta}_d(\ell), \chi
  \mod{q}. \tag{1.2.8}  \label{eq1.2.8}
\end{equation*} 
 and\pageoriginale $\sum^{**}$ denotes the sum over $u$, $h$, $q$,
 $\chi$ satisfying 
 the conditions: $uq<Q,(u,q)= (uq, k)=1$; $1\leq h \leq
 u,(h,u)=1;\chi$ primitive $\pmod{q}$. 
 
 Then, regarding the right side of \eqref{eq1.2.7} as an
 Hermitian form of the variables $y(u,h,\chi),$ we its dual: 
 \begin{equation*}
   \sum^{**}_{u,h,q,\chi }\frac{q}{\varphi (q)}|\sum_{\substack{M\leq
       n<M+N \\ n\equiv \ell \pmod{k}}} \chi(n)\exp\left(2\pi i
   \frac{h}{u}n\right)c_n |^2,\tag{1.2.9}\label{eq1.2.9} 
 \end{equation*} 
 where $\{c_n\}$ are arbitrary complex numbers. as usual, we express
 $\chi(n)$ as a linear combination of additive characters via Gauss
 sum, and by the orthogonality of characters, we infer that
 \eqref{eq1.2.9} is not larger than 
\begin{multline*}
  \sum_{\substack {up<Q \\ (u,p)=1\\(uq,k)=1}}
  \sum^u_{\substack{h=1\\(u,h)=1}}
  \sum^q_{\substack{a=1\\(a,q)=1}}|
  \sum_{\substack{M\leq n<M+N\\ n\equiv \ell \pmod{k}}} \exp \left(2 \pi \text{in}
  \left(\frac{h}{u}+\frac{a}{q}\right)\right)c_n|^2 \\
  \leq \sum_{f<Q}
  \sum^f_{\substack{s=1\\(s,f)=1}}|\sum_{\frac{M-\ell}{k}\leq
    M<\frac{M+N-\ell}{k}} \exp \left(2\pi i \frac{s}{f}m\right) c'_m|^2, 
\end{multline*}
where $c'_m =c_{km+\ell}$. Thus, by the dual of LEMMA
\ref{part1-chap1:sec1.1:lem1}, we see 
that \eqref{eq1.2.9}  is not larger than 
$$
\left(\frac{N}{K}+Q^2\right)\sum_{\substack {M\leq n<M+N\\ n\equiv
    \ell \pmod{k}}} |c_n|^2, 
$$
whence we obtain, by LEMMA \ref{part1-chap1:sec1.2:lem2}, 
$$
 D^*\leq \left(\frac{N}{K}+Q^2\right) \sum^{**}_{u,h,q,\chi}|y(u,h,\chi)|^2.
 $$\pageoriginale
 
 Recalling \eqref{eq1.2.8}, we can compute the last sum just as
 \eqref{eq1.1.9}, getting 
 $$
 D^*\leq \left(\frac{N}{K}+Q^2\right) \sum_{\substack{d_1 q<Q\\ d_2 q<Q\\(d_1 
     d_2,q)=1\\(d_1 d_2 q,k)=1}}\sum^*_\chi\pmod{q}
 s(d_1,\chi)\overline{s(d_2,\chi)}f(d_1,d_2).   
$$
 
 Thus, by virtue of \eqref{eq1.1.20}, we have 
 $$
 D^*\leq \left(\frac{N}{K}+Q^2\right) \sum_{\substack{dq<Q\\(d,q)=1\\(dq,k)=1}}
 \sum^*_{\chi\pmod{q}} g(d)|\sum_{\substack{u<Q/q\\u=0
     \pmod{d}\\ (u,qk)=1}} t(u,d)S(u,\chi)|^2.  
 $$
 
 But by \eqref{eq1.1.24} and \eqref{eq1.2.6}, the last sum
 over $u$ is equal to 
 $b(d,\chi)\break g(d)^{-\frac{1}{2}}$, whence 
 $$
 D^*\leq \left(\frac{N}{K}+Q^2\right)\sum_{\substack{dq<Q\\(d,q)=1\\(dq,k)=1}} 
 \sum^*_{\chi\pmod{q}}|b(d,\chi)|^2.  
 $$
 Therefore, appealing to LEMMA \ref{part1-chap1:sec1.2:lem2} once
 more, we obtain  

\begin{theorem}[The Hybrid Dual Sieve for
    Intervals]\label{part1-chap1:sec1.2:thm3}  
Let $\Omega$ be
  defined by the corgruence relation \eqref{eq1.1.2},
  $\psi_d(n,\Omega)$ by 
  \eqref{eq1.2.2}, and $g(d)$ by \eqref{eq1.1.18} and
  \eqref{eq1.1.21}. Then we have, 
  for arbitrary  $k$, $\ell$, $Q$, $N$, $\epsilon \mathbb{N}$, $M
  \epsilon \mathbb{Z}$ and complex $\{a_n\}$,  
\begin{align*}
  \sum_{\substack{qr<Q\\(q,r)=1\\(qr,k)=1}}\sum^*_{\chi
    \pmod{q}}\frac{q}{\varphi(q)g(r)}| \sum_{\substack{M\leq
      n<M+N\\ n\equiv \ell \pmod{k}}} \chi
  (n)\psi_r(n,\Omega)a_n|^2 \\
  \leq \left(\frac{N}{K}+Q^2\right)\sum_{\substack{M\leq n<M+N\\n\equiv
      \ell \pmod{k}}}|a_n|^2. 
\end{align*}
 \end{theorem}\pageoriginale
 The sieve-effect of this remarkably uniform result is embodied in 
 
\smallskip
\noindent 
\textbf{Corollary to Theorem \ref{part1-chap1:sec1.2:thm3}}. 
Let $\Omega$ be defined by \eqref{eq1.1.2}, and $\Theta(p^{\alpha})$ by
\eqref{eq1.1.17}. Let $\{a_n\}$ be an arbitrary sequence of
complex numbers 
satisfying $a_n=0$ whenever there is a $p^\alpha(\alpha>0)$ such that
$n\epsilon  \Omega(p^\alpha)$. Then we have, for arbitrary $k,\ell,
Q, N \epsilon \mathbb{N}$ and $M \epsilon \mathbb{Z}$,
\begin{gather*}
  \sum_{\substack{qr<Q\\ (q,r)=1\\ (qr,k)=1}}
  \sum^*_{\chi \pmod{q}}\frac{q}{\varphi(q)}\prod_{p^\alpha
    ||r}\left(\frac{1}{\Theta(p^\alpha)}-\frac{1}{\Theta(p^{\alpha
      -1})}\right)|\sum_{\substack{M\leq n<M+N\\ n\equiv \ell \pmod{k}}} \chi
  (n)a_n|^2 \\
  \leq \left(\frac{N}{K}+Q^2\right) \sum_{\substack{M\leq n<
      M+N\\ n\equiv \ell \pmod{k}}} |a_n|^2. 
\end{gather*}

To deduce this from THEOREM \ref{part1-chap1:sec1.2:thm3}, we need
only to note that 
$\psi_r$ $(n, \Omega)=t^*(r,1)$ if $a_n\neq 0$. 

Specializing THEOREM \ref{part1-chap1:sec1.2:thm3} and the Corollary
to it, we can deduce 
various important inequalities known at present in the theory of the
large sieve; for instance, THEOREM \ref{part1-chap1:sec1.1:thm2} is contained in the
corollary. Also, a special attention should be paid for the case
arising from the simplest choice of $\Omega:\Omega(p^\alpha)$ is empty
for $\alpha \geq 2$ and $n \epsilon  \Omega(p)$ is equivalent to
$p|n$. For this $\Omega$, we\pageoriginale have
$g(r)=\mu^2(r)\varphi(r)r^{-2}$ and
$\psi_r(n,\Omega)=u(r)u((r,n))\varphi((r,n))r^{-1}$. 
thus THEOREM \ref{part1-chap1:sec1.2:thm3} gives,  for arbitrary $k$,
$l$, $Q$, $N \epsilon \mathbb{N}$, $M \epsilon  \mathbb{Z}$ and
complex numbers $\{a_n\}$,  
\begin{equation*}
  \begin{aligned}
    \sum_{\substack
      {qr<Q\\ (q,r)=1\\ (qr,k)=1}}\sum^*_{\chi
      \pmod{q}}&\frac{u^2(r)q}{\varphi(qr)}|\sum_{\substack{m\leq
        n< M+N\\n\equiv \ell \pmod{k}}}\chi (n)\Psi_r(n)a_n|^2\\
    &\leq \left(\frac{N}{K}+Q^2\right)\sum_{\substack{M\leq n<M+N\\ n\equiv \ell
        \pmod{k}}}|a_n|^2,
  \end{aligned}
  \tag{1.2.10} \label{eq1.2.10}
\end{equation*}
where
\begin{equation*}
\psi_r(n)=\mu((r,n))\varphi((r,n)).\tag{1.2.11}\label{eq1.2.11}
\end{equation*}

Also, recalling the well-known estimate
\begin{equation*}
\sum_{\substack{r<R\\ (r,f)=1}}\frac{\mu^2(r)}{\varphi(r)}\geq
\frac{\varphi(f)}{f} \log R \tag{1.2.12} \label{eq1.2.12}
\end{equation*}
for arbitrary $f,R \epsilon  \mathbb{N},$ we see readily that the
Corollary to THEOREM \ref{part1-chap1:sec1.2:thm3}, or rather
\eqref{eq1.2.10}, gives rise to the 
assertion that if $a_n=0$ whenever $n $ has $a$ prime factor less than
$Q$, then we have, for arbitrary $k$, $\ell$, $Q$, $N \epsilon  \mathbb{N}$
and $M \epsilon  \mathbb{Z}$, 
\begin{equation*}
  \begin{aligned}
    \sum_{\substack{q<Q\\ (q,k)=1}} \log \frac{Q}{q}\sum^*_{\chi \pmod{q}}
    |&\sum_{\substack{M\leq n<M+N\\ n\equiv \ell \pmod{k}}} \chi (n)a_n|^2 \\
    \leq \frac{1}{\varphi(k)}(N+kQ^2)&\sum_{\substack{M\leq n<M+N\\ n\equiv
        \ell \pmod{k}}}|a_n|^2.
  \end{aligned}
  \tag{1.2.13} \label{eq1.2.13}
\end{equation*}

Specifically,\pageoriginale we get, for $M\geq Q$,
\begin{equation*}
  \begin{aligned}
    &\sum_{\substack{q<Q\\(q,k)=1}}\log \frac{Q}{q} \sum^*_{\chi
      \pmod{q}}|\sum_{\substack{M\leq p<M+N\\ p\equiv \ell \pmod{k}}}\chi
    (p)|^2\\   
    \leq &\frac{1}{\varphi(k)}(N+KQ^2)(\pi (M+N; k,\ell)-\pi (M;k,\ell)),
  \end{aligned}
  \tag{1.2.14} \label{eq1.2.14}
\end{equation*}
which is a refinement of the Brun-Titchmarsh theorem:
\begin{equation*}
  \pi (M+N;k,\ell)-\pi (M;k,\ell)\leq \frac{(2+0(1))N}{\varphi(k)\log
  \frac{N}{K}} \tag{1.2.15} \label{eq1.2.15}
\end{equation*}
as $N/k$ tends to infinity.

\section{An Auxiliary Result Relating to the
  $\Lambda^2$-Sieve}\label{part1-chap1:sec1.3}%sec 1.3 

In the above, we have seen that the optimal lamda-weight
\eqref{eq1.1.25} has an important arithmetical property which
makes it possible to 
unite Selberg's and Linnik's sieve methods. In the present section,
digressing somewhat from the main theme of this chapter, we shall take
up a subject related to the asymptotic behaviour of the optimal
$\lambda$ which the simplest choice of $\Omega$ mentioned above; this
will also have important applications in PART \ref{part2}. 

Thus, let $\Omega$ be such that $\Omega(p^\alpha)$ is empty for all
$\alpha\geq 2$, and $n \epsilon  \Omega(p)$ is equivalent to
$P/N$. Then we have the simplest case of the Selberg sieve: the number
of integers $\leq N$ which are free of prime factors less than $z$ is
bounded by 
\begin{equation*}
  \sum_{1\leq n \leq N}\left(\sum_{\substack{d|n\\d<z}} \lambda(d)\right)^2
  (\lambda(1)=1);\tag{1.3.1} \label{eq1.3.1}
\end{equation*}\pageoriginale
here, for our convenience, we use $z>1$ instead of
$Q$. \eqref{eq1.1.25} gives the optimal weight 
\begin{equation*}
  \lambda(d)=\mu(d)\frac{d}{\varphi(d)}\left\{\sum_{\substack
    {r<z/d\\ (r,d)=1}}
  \frac{\mu^2(r)}{\varphi(r)}\right\}
  \left\{\sum_{r<z}\frac{\mu^2(r)}{\varphi(r)}\right\}-1
  \tag{1.3.2}\label{eq1.3.2}
\end{equation*}
which gives
\begin{equation*}
  \sum_{1\leq n \leq
    N}\left(\sum_{\substack{d|n\\d<z}}\lambda(d)\right)^2 \leq (N-l+z^2)/\log
  z. \tag{1.3.3}. \label{eq1.3.3}
\end{equation*}

On the other hand, if we fix $d$ and let $z$ tend to infinity then
\eqref{eq1.3.2} becomes the asymptotic relation: 
$$
\lambda(d)=(l+O(l))\mu(d)\frac{\log z/d}{\log z}.
$$

Now the new weight
$$
\tilde{\lambda}(d)=
\begin{cases}
  \mu(d)\frac{\log z/d}{\log z} if d <z,\\
  0 if d \geq z\\
\end{cases}
$$
has a striking property: we have, for any $N \geq z$,
\begin{equation*}
  \sum_{1\leq n \leq N}\left(\sum_{d|n}\tilde{\lambda}(d)\right)^2\ll \frac{N}{\log
  z.}\tag {1.3.4} \label{eq1.3.4}
\end{equation*}

The significance of this result lies in that, apart from a constant
multiplier to the main-term, the error-term corresponding to $z^2$ of
\eqref{eq1.3.3}\pageoriginale does not appaer at all. Because of
this uniformity, 
\eqref{eq1.3.4} has some important applications especially to
the theory of 
the zeta-and $L$-functions. In our later discussion on these functions,
however, we shall not require \eqref{eq1.3.4} in its full force,
but rather the following consequence of it: 
\begin{equation*}
  \sum_{n=1}^{\infty} \left(\sum_{d|n} \tilde{\lambda} (d)\right)^2 n^{-\omega}=
  O(l),\tag{1.3.5} \label{eq1.3.5}
\end{equation*} 
provided $\omega \geq 1 + c (\log z)^{-1}$. And for some special
problems on $L$-functions, it is more desrable to heve a similar result
in which the factor $\tau_{k} (n)$ occur in a sum corresponding to the
left side of \eqref{eq1.3.5}. For this sake, it would be expedient to
consider the Selberg sieve problem: 
$$
 \sum_{m \leq N} \tau_{k}(n) \left(\sum_{\substack{d|n \\ d<z}} \lambda
 (d)\right)^2 (\lambda (l) =l). 
$$ 

The standard argument shows that the quasi-optimal $\lambda$ is such
that, for each fixed $d$, 
$$
\lambda(d) = (l + O(l)) \mu (d) \left(\frac{\log z/d}{\log z}\right)^k
$$
as $z$ tends to infinity.

Thus we are led to the problem of estimating
\begin{equation*}
  J= \sum_{n=1}^{\infty} \tau_{k}(n) (\sum_{d|n} \xi (d))^2 n^{-\eta},
  \tag{1.3.6}\label{eq1.3.6} 
\end{equation*}
 where $\eta =1 + c (\log z)^{-1}$ and 
$$
\xi (d) = 
\begin{cases}
  \mu (d) ( \log ~  z/d)^k & \text{ if }  d < z,\\
  0   &  \text{ if }  d  \ge z.
\end{cases}
$$\pageoriginale

Expanding out the squares and changing the order of summation, we see that
\begin{equation*}
  \begin{aligned}
    J & = \zeta ( \eta )^k \sum_{d_1,d2 < z} \xi (d_1) \xi (d_2)
    \prod_{p | d_1 d_2} (1-(1-p^{-n})^k) \\
    & = \zeta (\eta)^k E, 
  \end{aligned}\tag{1.3.7}\label{eq1.3.7}
\end{equation*} 
 say. To diagonalize $E$, we employ a well-known device of Selberg, gett\-ing
 \begin{equation*}
   E= \sum_{d<z} \mu^2(d) \prod_{p | d} (1-p^{-n})^k (1-(1-p^{-n})^k
   |{ R_d (z/d )}^2, \tag{1.3.8} \label{eq1.3.8}
 \end{equation*} 
where
$$
R_d(x) =  \sum_{\substack{u<x\\(u,d)=1}} \mu (u) (\log
\frac{x}{u})^k  \prod_{p | u} (1-(1-p ^{-n}) ^k ). 
$$ 
 
There is an elementary argument to estimate  $R_d (x)$ which relies
 on the elementary prime number theorem with remainder term (cf. \S\
 \ref{chap4-sec4.1}). But, for the sake of simplicity, we take
 here an alternative way, an analytic one. We note first that 
 $$
\displaylines{\hfill 
  R_d (x) = \frac{k!}{2 \pi i} \int\limits^{2 + i \infty}_{2 - i \infty
  } \zeta (s + \eta)^{-k} P_d (s) \frac{x^s}{s^{k+1}}ds, \hfill \cr
  \text{where}\hfill 
  p_d(s) = \prod_{p | d} (l- \frac{l}{p^{s+n}})^{-k} \prod_{p \not\mid}
  \left(l- \frac{l}{p^{s+n}}\right)^{-k}
  \left(l-\frac{l}{p^s}\left(l-\left(l-\frac{l}{p^\eta}\right)^k\right)
  \right),\hfill }  
$$\pageoriginale
 which converges absolutely for $\text{Re}~(s) > -c$. Then we quote an
 elementary estimate of  $ \zeta^{-1} (s)$  (cf. \S 4.1): in the
 region  
 $$
 Re (s) > 1 -c (\log ( | t | + 2 ))^{-9}
 $$
 we have
 $$
 \zeta^{-1}(s) \ll (\log ( | t | + 2 ))^{7}.
 $$

 Thus shifiting the line  of integration to the left appropriately, we get
 $$
 R_d (x) = k! {\text{Res}_{s=0}} \left\{ \zeta (s+\eta)^{-k} P_d (s) x^s
 s^{-k-1}\right\}+0 \left(\prod_{p | d} \left(1+
 \frac{1}{\sqrt{p}}\right)k\right). 
 $$
 
 After some elementary estimations of derivatives of $\zeta^{-k} (s +
 \eta)$ and $P_d(s)$ at $s = 0$, we obtian 
 $$
   R_d (x) <<  \prod_{p | d} \left(1+
   \frac{1}{\sqrt{p}}\right)^k \sum^{k}_{j=0} ~((\eta-1) \log x)^j. 
 $$

 Inserting this into \eqref{eq1.3.8} we see, via
 \eqref{eq1.3.7}, that 
 \begin{equation*}
   J \ll ( \log z)^{2k}.\tag{1.3.9}\label{eq1.3.9}
 \end{equation*} 
 
 After these preparations, we can show
 
 \begin{theorem}\label{part1-chap1:sec1.3:thm4}%the 4
Let $z > 1$ and $\vartheta > 0 $, and let us put
 \begin{equation*}
   \Lambda^{(k)}_d  = \frac{1}{k !} (\vartheta \log z)^{-k}
   \sum^{k}_{j=0} (-1)^{k-j} (^k_j) \lambda^{(j,k)}_d,
   \tag{1.3.10} \label{eq1.3.10} 
 \end{equation*}
where
$$
   \lambda^{(j,k)}_d  =
   \begin{cases}
     \mu (d) \left( \log \frac{z^{1+j \vartheta}}{d}\right)^k  & \text{ if } d <
     z^{1+j \vartheta},\\ 
     0  \qquad & \text{ otherwise }.
\end{cases}
$$\pageoriginale

Then we have 
\begin{equation*}
\Lambda^{(k)}_d  =  \mu (d)  ~\text{for}~  d <
z. \tag{1.3.11}\label{eq1.3.11} 
\end{equation*}  

Also
\begin{equation*}
  \sum^{\infty}_{n=1} \tau_k (n) \left( \sum_{d | n} \Lambda^{(k)}_d \right)^2
  n^{- \omega} = O(l), \tag{1.3.12} \label{eq1.3.12}
\end{equation*}  
provided
 $$
  \omega \ge 1 + c ( \log z ) ^{-1}.
  $$
\end{theorem} 
 
 In fact, the second statement follows immediately from
 \eqref{eq1.3.9}. As 
 for the forst we note that for  $ d < z $  
 \begin{multline*}
   \sum^{k}_{j=0} (-1 )^{k-j} (^k_j) \lambda_d^{(j,k)} \\
   = \mu (d) \sum^{k}_{\ell = 0 } (-1)^{k-\ell} (^k_\ell) ( \log
   z)^\ell (\log d)^{k-\ell}  \sum^{k}_{j = 0 } (-1)^{k-j} (^k_j) (1 +
   j \vartheta)^\ell. 
 \end{multline*}
 
 But the last sum over $j$ is equal to $ \vartheta^k k! $ if $ \ell =
 k $, and to $0$ if $\ell < k $, whence we have \eqref{eq1.3.11}. 

 \section{The Hybrid Dual Sieve for Multiplicative
   Functions}\label{part1-chap1:sec1.4}%section 1.4 
  
 In the first two sections, we were concerned with problems  of
 sifting integers in an interval to each of which the simplest
 weight\pageoriginale 
 i.e. 1 is attached, and we had a very powerful tool: the additive
 large sieve inequality. We are now going to  investigate a similar
 problem on the  assumption that weights not necessarily equal to 1
 are given to the  elements to be  sifted. Then we have no longer such
 useful an aid as  LEMMA \ref{part1-chap1:sec1.1:lem1}, but can appeal
 only to the conventional 
 way of manipulating the  $\Lambda^2 $-sieve. 
 
 Let  us denote by $f$ the weight function, and consider 
 $$
 K= \sum_{n < N } f(n) \left( \sum_{\substack{d | n \\d < R}} \lambda (d)\right)^2.
 $$
 
 Here $R > 1$ is a parameter. We look for the optimal $\lambda$ which
 makes $K$ as small as possible on the side condition $ \lambda (1) =
 1$. We may discuss this problem on some fairly general assumption on
 the average property of the  sequence $\{ f (n)\}$. But, since we
 have particular applications in mind which will be made in  PART
 \ref{part2}, we shall confine ourselves to those $f$ which satisfy the
 following practical conditions: 
 
 \begin{itemize}  
 \item[($C_1$)]  $f$ is a non-negative multiplicative function such that 
  $$
   f(n)  = O(n^{\epsilon })
   $$
   for all $ n \epsilon  \mathbb{N} $.

\item[($C_2$)] There exist  $A > 0 $ and $ \alpha \ge 1 $ such that
  for all prime $p$ we have 
  $$
  \displaylines{\hfill 
  F_p - 1 \ge Ap^{-\alpha},\hfill \cr
  \text{where}\hfill 
  F_p = \sum^{\infty}_{m=0} f(p^m)p^{-m}.\hfill}
  $$\pageoriginale

\item[($C_3$)] There  exist  $ \beta \ge 0 $, $ 0, 0 < \gamma < 1,
  \mathcal{F} > 0 $, $D \ge 1$ such that 
\end{itemize}  
 $$
 \sum_{n < y} \chi(n)f(n) =  E (\chi)\mathcal{F}K(q)y  +  O(Dq^\beta y^\gamma),
 $$
 where $\chi \pmod{q}$, $K(q) = \prod\limits_{p | q} F^{-1}_p$; the
 constant implied by the $O$-symbol is absolute. 
 
 Now let us estimate $K$ on these assumptions. As usual, we may
 restrict $\lambda$ by 
 \begin{equation*}
   | \lambda(d) |  ~~ \leq | \mu (d)|; \tag{1.4.1}\label{eq1.4.1}
 \end{equation*} 
 in fact, this will be confirmed later for the optimal
 $\lambda$. Expanding out the  lamda-squares and  changing the order
 of summation, we have  
 \begin{equation*}
   K= \sum_{d_1,d_2 < R} \lambda (d_1)\lambda (d_2) \sum_{n < N/d}
   f(dn), \tag{1.4.2} \label{eq1.4.2}
 \end{equation*} 
 where $ d =$[$d_1,d_2$] is square-free. Introducing the convolution
 inverse  $f_1$ of $f$, the last factor is  expressed as  
 $$
f(dn) = \mu(d) \sum _{\substack{u | n\\ u | d^\infty}}
 f\left(\frac{n}{n}\right) f_1 (du). 
 $$
 
 This and  $(C_3)$ with the  trivial character give
 $$
 \sum_{n < y} f(dn) = \mu(d) \sum _{\substack{ u | d^\infty \\ u < y}}
 f_1(du) \left\{ \mathcal{F} \frac{y}{u}+ o\left( D
 \left(\frac{y}{u}\right)^\gamma \right)\right\}.
 $$
 
 We\pageoriginale note that we have
\begin{align*}
 \sum _{\substack{ u | d^\infty \\ u < y}} \frac{f_1(du)}{u} & =
 \sum_{u | d^\infty} \frac{f_1(du)}{u} \sum _{\substack{ u | d^\infty
     \\ u \ge y}} \frac{f_1(du)}{u}\\ 
 &= \mu(d)d \prod_{p | d} (1-F^{-1}_p )+ o\left\{ y^{\gamma-1} \sum_{u |
   d^\infty} \frac{| f_1 (du) |}{u^\gamma} \right\}.  
\end{align*}
 
Hence
$$
\sum_{n < y } f(dn) = \mathcal{F} y d \prod_{p | d} (1-F^{-1}_p )+ 0 \left\{
(D+ \mathcal{F}) y^\gamma  \sum_{u | d^\infty} | f_1(du)| u^{-\gamma}
\right\}. 
$$

Inserting this into \eqref{eq1.4.2} and reacalling
\eqref{eq1.4.1} we have  
\begin{multline*}
  K = \mathcal{F} N \sum_{d_1,d_2 <R } \lambda(d_1)\lambda(d_2) \prod_{p
  | d_1 d_2} (1-F^{-1}_p) \tag{1.4.3}\label{eq1.4.3}\\
 + O\left\{ (D+ \mathcal{F}) N^\gamma R^{2 (l-\gamma) + \epsilon}\right\},
\end{multline*}
where we have used the fact that $(C_1)$ implies $ f_1 (n) = O
(n^\epsilon )$ for all $n$. 

Then, by a routine  argument, we can conclude that the optimal
$\lambda$ is given by  

\begin{equation*}
  \lambda(d) = \mu(d)  \frac{G_d (R/d)}{G_1 (R)} \prod_{p | d}F_p,
  \tag{1.4.4} \label{eq1.4.4}
\end{equation*}
where
\begin{equation*}
  G_d (x) = \sum_{\substack{r< \chi \\ (r, d)=1}}
  \mu^2(r)/g(r) \tag{1.4.5} \label{eq1.4.5}
\end{equation*}
with\pageoriginale
\begin{equation*}
  g(\Gamma) = \prod_{p | \Gamma}
  (F_p-1)^{-1}. \tag{1.4.6}\label{eq1.4.6} 
\end{equation*}

And this choice of $\lambda$ gives
\begin{equation*}
\sum_{d_1,d_2 <R } \lambda(d_1)\lambda(d_2) \prod_{p | d_1 d_2}
(1-F^{-1}_p) = G_1 (R)^{-1}.\tag{1.4.7} \label{eq1.4.7}
\end{equation*}

Also, we have
\begin{equation*}
  G_d (R/d) ~ \leq G_1 (R) \prod_{p | d} F^{-1}_p
  \tag{1.4.8}\label{eq1.4.8} 
\end{equation*}
which implies, in particular, \eqref{eq1.4.1} for the $\lambda$
defined by \eqref{eq1.4.4}. Further, we should note that  we have 
\begin{equation*}
  G_d(R) \ge K(d)G_1 (R). \tag{1.4.9}\label{eq1.4.9}
\end{equation*}

Now, let us observe that the optimal $\lambda$ defined by
\eqref{eq1.4.4} yields the relation 
$$
\sum_{\substack{d | n \\ d < R}} \lambda(d) = G_1(R)^{-1} \sum_{r
  < R} \frac{\mu^2 (r)}{g(r)}  ~ \Phi_r (n), 
$$
where
\begin{equation*}
  \Phi_R(n) = \mu ((r, n)) ~  g((r, n)). \tag{1.4.10}\label{eq1.4.10}
\end{equation*}

This should be compared with \eqref{eq1.2.1}; we may expect that for this
$\Phi_r$ there will be an analogue of THEOREM
\ref{part1-chap1:sec1.2:thm3}. The object of 
the present section is to show that this is indeed the case. 

To\pageoriginale this end, we shall consider the estimation of the
expression 
$$
J = \sum_{\substack{q < Q \\ r < R \\ (q,r)=1}}
\frac{\mu^2(r)}{K(q)g(r)}  \sum^*_{\chi \pmod{q}} ~  |
\sum_{M \leq n < M+N} \chi (n) \Phi_r (n)f(n)^{\frac{1}{2}} a_n
|^2 
$$
with $\{ a_n\}$ being arbitrary complex numbers; we assume $(C_1),
(C_2),(C_3)$ naturally, and also 
$$
N = O(M).
$$

But, as before, it is advantageous to estimate, instead, the dual form
$$
J* = \sum_{M \leq n < M+N} f(n) |  \sum_{\substack{q < Q
    \\ r < R \\ (q, r)=1}} \left(
\frac{\mu^2(r)}{k(q)g(r)}\right)^{1/2} \Phi_r (n) \sum^*_{\chi
  \pmod{q}} \chi (n) b (r, \chi)|^2,
$$
where $\{ b(r,\chi)\}$ are arbitary complex numbers. Expanding
out the squa\-res and changing the order of summation we have 
\begin{align*}
  J* & = \sum_{\substack{q,q' < Q \\ r,r' < r \\ (q,r)
      = (q',r')=1}} \left\{ \frac{\mu^2 (r) \mu^2 (r')}{K(q) K
    (q') g(r)g(r')} \right\}^{\frac{1}{2}}\\ 
  & \times \sum_{\substack{ \chi (\mod q\\ \chi'\pmod{q'})}}^{*} \left\{ S(M+N,
  \chi \bar{\chi'}) - S(M, \chi \bar{\chi'};r, r'\right\}
  b(r,\chi) \overline{b(r', \chi')} \tag{1.4.11}\label{eq1.4.11}
\end{align*}
where
$$
S(y,\chi;r, r') = \sum_{n < y} \chi(n) \Phi_{r'} (n) f(n).
$$

In\pageoriginale order to estimate the  last sum, we  consider first
the  function 
\begin{equation*}
\sum^{\infty}_{n=1} \chi(n) \Phi_r(n) f(n) n^{-s},
\tag{1.4.12}\label{eq1.4.12} 
\end{equation*}
which converges absolutely for  $Re (s) > 1 $. Recalling that
$\Phi_r$ is multiplicative, and $r, r' $ are
square-free, this can be decomposed as  
\begin{align*}
  \left\{ \sum_{(n,rr')  =1} \chi(n)f(n)n^{-s} \right\} 
  & \left\{ \sum_{n |
    ( \frac{[r,r']}{(r,r')})^\infty}
  \chi(n)\Phi_r(n) \Phi_{r'}(n)f(n)n^{-s} \right\} \\
  \times &\left\{ \sum_{(n,rr')^\infty}
  \chi(n)\Phi_r(n) \Phi_{r'}(n)f(n)n^{-s} \right\} \\
  & = P_1P_2P_3,
\end{align*}
say. Introducing the functions
\begin{equation*}
  \begin{aligned}
    F (s, \chi) = \prod_{p}F_p (s, \chi),\\
    F_p (s, \chi) = \sum^{\infty}_{m=0} \chi(p^m) f(p^m)p^{-ms}, 
  \end{aligned}\tag{1.4.13}\label{eq1.4.13}
\end{equation*}
we have
$$
p_1 = F (s, \chi) \prod_{p | rr'} (F_p (s, \chi)^{-1}, 
$$
if $Re (s)$ is sufficiently large. Also \eqref{eq1.4.10} implies
$$
\displaylines{\hfill 
    \phantom{W}P_2 = \prod_{p | \frac{[r,r']}{(r,r')}}(1-(
    F_p-1)^{-1}(F_p (s,\chi) -1))\hfill \cr  
    \text{and} \hfill  P_3 = \prod_{p | (r,r')}  (1+(
    F_p-1)^{-2}(F_p (s,\chi) -1)).\hfill}  
$$

Thus,\pageoriginale we see that \eqref{eq1.4.12} is equal to 
$$
F(s,\chi) A_{r,r'} (s,\chi),
$$
where
\begin{equation*}
  \begin{aligned}
    A_{r,r'} (s,\chi), & = P_2P_3 \prod_{p | rr'}
    F_p (s,\chi)^{-1}\\ 
    & =  \sum_{n  | (r r')^\infty} \chi (n)f_2(n)n^{-1}, 
  \end{aligned}\tag{1.4.14}\label{eq1.4.14}
\end{equation*}
say; here $Re (s)$ is only to be positive. In particular, we have 
$$
\Phi_r(n) \Phi_{r'}(n)f(n) = \sum_{\substack{d | n \\ d |
    (rr')^\infty}} f \left(\frac{n}{d}\right)f_2(d). 
$$

This and  the condition $(C_3)$ give, for $\chi \pmod{q}$,
$$
S (y,\chi; r,r') = \sum_{\substack{d < y\\d |
    (rr')^\infty}} \chi (d)f_2 (d) ~ \left\{ E (\chi)
\mathcal{F}K(q) \frac{y}{d} + 0 (Dq^\beta
\left(\frac{y}{d}\right)^\gamma \right\}, 
$$
whence
{\fontsize{10pt}{12pt}\selectfont
$$
S(y,\chi;r,r') = \mathcal{F}E(\chi) K(q) A_{r,r'}
(1,\chi)y + 0 \left\{ (D+\mathcal{F})q^\beta y^\gamma \sum_{d |
  (rr')^\infty} | f_2 (d) | d^{-\gamma} \right\}. 
$$}\relax


By the definition \eqref{eq1.4.14} of $f_2$, the last sum over
$d$ is equal to  
\begin{multline*}
  \sum_{P | \left( \frac{[r,r']}{(r,r')}\right)^\infty} \left\{ 1 +
  (F_p-1)^{-1} \sum_{m=1}^{\infty} \frac{f(p^m)}{p^{my}} \right\}  \prod_{P |
  (r,r')}  \\ 
  \left\{ 1 + (F_p-1)^{-2} \sum_{m=1}^{\infty}
  \frac{f(p^m)}{p^{my}} \right\} 
  \times \prod_{p | rr'} \left\{ \sum_{m=0}^{\infty} \frac{| f_1
   (p^m)}{p^{m\gamma}}\right\}, 
\end{multline*}
and,\pageoriginale by $(C_1)$ and $(C_2)$, this is 
$$
0 (( rr')^{\alpha+\epsilon } [r,r']^{-\gamma}).
$$

We should remark also that if $\chi$ is principal $\pmod{q}$ and
$(rr', q) = 1 $ them, by \eqref{eq1.4.14}, we have 
$$
A_{r,r'} (1,\chi) = g(r) \delta_{r,r'}\quad \text{
  (Kronecker's delta)}. 
$$

Inserting these into \eqref{eq1.4.11}, and recalling that $ N = O(M)$ we
obtain, after some elementary estimations, 
$$
J* = \left\{ \mathcal{F} N+0 ( D+ \mathcal{F}) M_{Q}^{2 (1+\beta)
  +\epsilon _R 2\alpha+\epsilon } \right\} \sum_{\substack{q < Q
    \\ r < R \\ (q,r)=1}} \sum_{\chi \pmod{q}}^* | b
(r, \chi) |^2.   
$$

Hence, returning to $J$ via the duality principle (LEMMA
\ref{part1-chap1:sec1.2:lem2}), we get 
the following hybridization of the Selberg sieve for multiplicative
functions and the multiplicative large sieve inequality: 

\begin{theorem}[THE HYBRID DUAL SIEVE FOR MULTIPOICATIVE
    FUNCTIONS]\label{part1-chap1:sec1.4:thm5}%thm 5 
On the
  assumptions $(C_1),(C_2), (C_3)$ we have, for any $N = O(M)$
and arbitrary complex numbers $\{ a_n\}$, 
 \begin{gather*}
   \sum_{\substack{q < Q\\ r < R \\ (q,r)=1}}  \frac{\mu^2
     (r)}{K(q)g(r)} \sum_{\chi \pmod{q}}^* | \sum_{M \leq n <
     M+N} \chi(n) \Phi_r(n)f(n)^{\frac{1}{2}}a_n | 2\\ 
   \leq \{ \mathcal{F}N + 0 ( Y_f (M;Q,R )) \} \sum_{M \leq n < M+N} | a_n | ^2,
 \end{gather*}
 where $g(r)$ and $\Phi_r (n)$ are defined by \eqref{eq1.4.6}
 and \eqref{eq1.4.10}, respectively,\pageoriginale and  
 $$
 Y_f (M; Q, R) = (\mathcal{F} + D ) M^\gamma Q^{2(1+\beta) +\epsilon _R
  2 \alpha+\epsilon }. 
 $$
\end{theorem}

Next we turn to the basic lemmas which will be utilised  in PART \ref{part2}
when we make important applications of THEOREM
\ref{part1-chap1:sec1.4:thm5} TO Dirichlet's $L$-functions. 

First we qote the fundamental
\begin{Lemma}\label{part1-chap1:sec1.4:lem3}%lem 3
  We have, for  $ T \ge 1 $,
  $$
  \int\limits^{T}_{-T} | \sum^{\infty}_{n=1} a_n n^{it} |^2 dt << T^2
  \int^\infty_0 | \sum_{y \leq n < ye^{1/T}} a_n |^2 \frac{dy}{y}, 
  $$
  provided the right side converges.
\end{Lemma}

The combination  of  THEOREM \ref{part1-chap1:sec1.4:thm5} and LEMMA
\ref{part1-chap1:sec1.4:lem3} yields immediately  

\begin{Lemma}\label{part1-chap1:sec1.4:lem4}%lem 4
We have, for  $ T \ge 1 $,
   \begin{gather*}
     \sum_{\substack{q < Q \\ r < R \\ (q,r)=1}} \frac{\mu^2
       (r)}{K(q)g(r)} \sum_{\chi \pmod{q}} ^*
     \int\limits^{T}_{-T} | \sum^{\infty}_{n=1} \chi(n) \Phi_r
     (n)f(n)a_n n^{it} |^2 dt \\
     \ll \sum^{\infty}_{n=1} (\mathcal{F}n + TY_f (n:Q,R))f(n) | a_n |^2,
   \end{gather*}
provided the right side converges.
\end{Lemma}

In our applications of  THEOREM \ref{part1-chap1:sec1.4:thm5}, an
important r\^ole will be 
played by the multiplicative property of $\Phi_r$, which is
embodied in  

\begin{Lemma}\label{part1-chap1:sec1.4:lem5}%lem 5
Let\pageoriginale $r$ be square free and let b $\xi_d = o(|\mu (d)| d
^\epsilon)$. Then we have, for $s$ with sufficiently large real
part, 
  \begin{equation*}
    \sum_{n=1}^\infty \chi (n) \Phi_r (n) f (n) \left(\sum_{d|n} \xi_d\right)n
    ^{-s} = F (s,\chi )M_r (s, \chi  ; \xi),
    \tag{1.4.15} \label{eq1.4.15} 
\end{equation*}
where
{\fontsize{10pt}{12pt}\selectfont
\begin{equation*}
  M_r (s, \chi; \xi) = g(r) \sum_{d=1}^\infty \xi_d
  \mu((r,d)) \prod_{p|d} (1-f_p) (s,\chi)^{-1}) \prod_{p \not\mid
  d} (f_p (s,X)^{-1} f_p -1), \tag {1.4.16} \label{eq1.4.16}
\end{equation*}}\relax
$F(s,\chi) \text{and} F_p (s,\chi)$ being defined by \eqref{eq1.4.13} 
\end{Lemma}

To show this, we note first that, for square-free $r$, we have 
$$
\Phi_r (dn) = \Phi_r (d) \Phi_u (n), u = r/(r,d).
$$

Thus, the left side of \eqref{eq1.4.15} is equal to 
\begin{equation*}
  \sum_{d=1}^\infty \chi(d) \xi_d \Phi_r (d)d^{-s}
  \sum_{n=1}^\infty \chi(n) \Phi_u (n) f (dn)_n^{-s}. \tag
      {1.4.17} \label{eq1.4.17} 
\end{equation*}

Because of the multiplicativity of $\Phi_u$, this inner-sum may be written as 
$$
\left\{\sum _{(n,d) = 1} \chi(n) \Phi_u (n) f(n)n^{-s}\right\} \left\{
\sum_{{n|d}^\infty} \chi (n) \Phi_u (n)f(dn)n^{-s}\right\}. 
$$

But $n|d^\infty$ implies $\Phi_u (n) = 1$. Hence this product is equal to 
{\fontsize{10pt}{12pt}\selectfont
\begin{gather*}
  d^{s-} \chi^{(d)} \prod_{p \not\mid d} (1+\Phi_u (p) (F_p (s,X)-1))
  \prod_{p|d} (F_p (s,\chi) -1) \\
  = d^{s-} \chi^{(d)} f (s,\chi) \prod_{\substack{p \not\mid d \\p|r}}
  (F_p -1)^{-1} \prod_{p|d} (1-F_p (s, \chi)^{-1}) \prod_{\substack{p
    \not\mid d \\p|r}} (F_p (s, \chi)^{-1} F_p -1);  
\end{gather*}}\relax
here we have used the fact that $d$ can be assumed to be square
free. Inserting this into \eqref{eq1.4.17} and noticing that 
$$
\Phi_r(d) \prod_{\substack{p \not\mid d \\ p|r}} (F_p
-1)^{-1} = \mu ((r,d))g(r) 
$$\pageoriginale
we obtain the assertion of the lemma.

We now introduce THEOREM \ref{part1-chap1:sec1.3:thm4} into our
discussion: but, for this sake, 
we have to replace the condition $(C_1)$ on $f$ by the stronger $(C'_1)
f$ is a non-negative multiplicative function such that there exists a
$k$ satisfying  
$$
f(n) = o(\tau_k(n)) 
$$
for all $n$.

Then we have
\begin{Lemma}\label{part1-chap1:sec1.4:lem6}%lem 6
On the conditions $(C'_1)$, $(C_2)$ and $(C_3)$
  $$
    \sum_{r \le z} 1+k\zeta \frac{\mu^2 (r)} {g(r)}
    M_r \left(1, \chi_0 ; \Lambda^{(k)}\right)^2 = O((\mathscr{F} \log
    z)^{-1}) 
  $$
for any  $z > (D + \mathscr{F})^\epsilon $, where $\chi_0$ is the
trivial character, and the functions $\Lambda^{(k)}$ and $M_r$
are defined by \eqref{eq1.3.10} and \eqref{eq1.4.16},
respectively.  
\end{Lemma}

To prove this, we note first that 
$$
M_r (1, \chi_0 ; \Lambda^{(k)}) = \mu (r) g (r)
\sum_{\substack{d < z \\ d \equiv 0 \pmod{r}}} 1+k \zeta
^{\Lambda}d ^{(k)} \prod_{p|d} (1-F_p ^{-1}). 
$$

Hence, denoting by $H$ the sum to be estimated, we have
\begin{align*}
  H & = \sum_{r < z} 1+k \zeta \mu^2 (r) g (r) \left\{
  \sum_{\substack{d < z \\ d \equiv 0 \pmod{r}}} \Lambda^{(k)}_d
  \prod_{p|d} (1-F_p^{-1})\right\}^2\\ 
  &= \sum_{d_1,d_2 < z} 1+k \zeta \Lambda{_d}_{_1}^{(k)}
  \Lambda{_d}_{_1}^{(k)} \prod_{p|d_1d_2} (1-F_p^{-1}). 
\end{align*}\pageoriginale

Thus, just as \eqref{eq1.4.3}, we have
$$
\sum_{n < n} f(n) \left(\sum_{d|n} \Lambda_d^{(k)}\right)^2 = \mathscr{F} HN + 0
\left\{ (D+\mathscr{F}) N^\gamma{_z}^{2 (1+k \zeta)
  (1_{-\gamma})_{+\epsilon }}\right\} 
$$
whence, by partial summation, we have for $\omega > 1$ and $ b > 0 $,
\begin{multline*}
  \sum_{n > z}b f(n) \left(\sum_{d|n} \Lambda_d^{(k)}\right)^2 n ^{-\omega}\\
  = (\omega-1) ^{-1} \mathscr{F} Hz^{b(1-\omega)} + 0 \left\{ (D +
  \mathscr{F}) z^{b (\gamma-\omega) + 2 (1+k \zeta) (1_{-\gamma}) _{+
      \epsilon }}\right\}. \tag{1.4.18} \label{eq1.4.18}
\end{multline*}

If we set $\omega = 1 + (\log z)^{-1}$ and take $b$ sufficiently large
then this is equal to  
$$
e ^{-b} H \mathscr{F} \log z + 0(z^{- \epsilon }).
$$

But, by virtue of $(C'_1)$ and THEOREM \ref{part1-chap1:sec1.3:thm4},
the left side of 
\eqref{eq1.4.18} is bounded, whence the assertion of the lemma. 

\medskip
\begin{center} 
 \textbf{NOTES (I)}
\end{center}

The origin of Selberg's $\Lambda^2$ -sieve can be found in his deep
investigations \cite{key68} \cite{key71} (see also \cite{key70}) on the
distribution of zeros of the Riemann zeta-function in the vicinity of
the cirtical line. Refining the ideas of Bohr, Landau and Carleson,
Selberg was led\pageoriginale 
to the problem of making the following quadratic for of $\lambda$    
$$
\int\limits_{-T}^T |\zeta (\frac{1}{2} + \text{it}) \sum_{d < z}
\lambda(d)d^{-\frac{1}{2} -\text{it}} -1|^2 dt 
$$
as small as possible on the side conditon $\lambda(1) = 1$, where $z$
is to be taken suitably in connection with the sufficiently large
parameter $T$. Applying certain mean-value theorems for $\zeta (s)$,
he could reduce the problem to the one of determining the minimum
value of the quadratic from 
$$
\sum_{d_1, d_2 <z} \frac{\lambda (d_1) \lambda (d_2)} {[d_1,d_2]}
(\lambda (1) = 1), 
$$  
which corresponds just to \eqref{eq1.3.1} The sieve-effect of the argument
with which Selberg solved this extremal problem was explicitly
formulated on a general setting in his later papers \cite{key72}
\cite{key73} \cite{key74}. It
is noteworthy that the $\Lambda^2$-sieve was created in the course of
deeper studies of the analytical behaviour of the Riemann zeta
function, and that, as we shall see in PART \ref{part2}, our account of his
theory has also important applications to $\zeta(s)$ and $L(s,\chi);$
this seems to agree appreciably with Selberg's opinion expressed in
the last lines of \cite{key73} \cite{key74}.  

We formulated Selberg's idea in a generalized from as THEOREM
\ref{part1-chap1:sec1.1:thm1}, for 
we have hope that one may find applications of it to the problems with
$\Omega$ not necessarily defined by the congruence condition
\eqref{eq1.1.2}, on which, however, all applications know at present are
made.  

One\pageoriginale may want to see how well the right side of
\eqref{eq1.1.4} 
approximates 
to the left side. For this,we refer to NOTES (II) where we shall give
an explicit representation of the difference between the two sides,
revealing the mechanisum behind the device of Selberg which at first
may look somewhat $ad$ hoc.  

It is a remarkable coincidence that two fundamental sieve ideas,
Selberg's and Linnik's were created almost simultaneously, and this
fact becomes more interesting when we know that between
them is a duality relation as we have shown in the second section.  

LEMMA \ref{part1-chap1:sec1.1:lem1} is the latest version of Linnik's
large sieve, and is due to 
Selberg. To prove this, Selberg employed a delicately chosen function
in conjuction with his inequility of Bessel's type [\cite{key48} Lemma
  1.8]. $P$. Cohen has shown, however, that
LEMMA \ref{part1-chap1:sec1.1:lem1} is an 
immediate consequence of an inequality of Montgomery and Vaughan
\cite{key51} in which occurs the factor $N + \delta^{-1}$ instead of $N -1 +
\delta^{-1}$. For the details see the expository article \cite{key49} of
Montgomery.  

THEOREM \ref{part1-chap1:sec1.1:thm2} is due to Selberg \cite{key77}. This
remarkable result implies as 
its speical cases the large sieves of Montgomery [\cite{key48}, p.~25], Jhonsen
\cite{key35} and Gallagher \cite{key16}. Our proof of THEOREM
\ref{part1-chap1:sec1.1:thm2}  has a 
difference from Selberg's in that we have appealed to LEMMA
\ref{part1-chap1:sec1.1:lem1}, an 
argument which was employed formerly by Motohashi [\cite{key54},~II] in his
alternative proof of Montgomery's large sieve. We should\pageoriginale
point out the 
possibility of generalizing THEOREM \ref{part1-chap1:sec1.1:thm2} into
the directions indicated 
by Salerno-Viola \cite{key67} and Gallagher \cite{key17}. 

The duality relation between Selberg's $\Lambda^2$-sieve and Linnik's
large sieve was observed by not a few people simultaneously in
published and unpublished forms. THEOREM \ref{part1-chap1:sec1.2:thm3}
which is due to Motohashi 
[\cite{key54}, III] summarises the former discussions on this matter each of
which was made on some special assumptions on $\Omega$ It shows that $
\{ \psi_r (n,\Omega) g (r)^{-\frac{1}{2}} \}$  behaves just like
$\{\chi(n); \chi$ primitive$\}$, i.e., they share the property which
may be called quasi-orthogonality. This was first observed by Selberg
\cite{key76} when he obtained \eqref{eq1.2.10}, and called $\{ \psi_r (n)\}$
pseudo-charecters; but the relation betwen $\psi_r$ and the Selberg
sieve was remarked explicity by Motohashi [\cite{key58}, p.~166]. 

\eqref{eq1.2.13} and \eqref{eq1.2.14} are due to Bombieri
and Devenport \cite{key8} (see 
also Bombieri \cite{key4}), which, apart from the fundamental work \cite{key45} of
Linnik, was the first instance that the sieve effect of the large
sieve was clearly perceived \eqref{eq1.2.13} has had a deep
application to the theory of $L$-functions, as Gallagher showed in his
important work \cite{key15}. The same can be said about
\eqref{eq1.2.10}, as we shall show in \S\ \ref{chap5-sec5.2}. 

The Brun-Titchmarsh theorem \eqref{eq1.2.15} is introduced here
only for the 
sake of illustrating the generality of THEOREM
\ref{part1-chap1:sec1.2:thm3}; a further\pageoriginale 
discussion on this basic sieve result will be given in
\S \ref{chap4-sec4.3}.  

We have seen that a drasitc specialization of THEOREM
\ref{part1-chap1:sec1.2:thm3} yields 
important results knows already. In the proop of THEOREM
\ref{part1-chap1:sec1.2:thm3},we have 
used, however, nothing deeper than the additive large sieve inequality
and the duality principle, both of which are, in fact, of very
elementary character. Thus one may expect that, on some special
conditions, more sophisticated tools will produce improvements upon
THEOREM \ref{part1-chap1:sec1.2:thm3}. In the case of
\eqref{eq1.2.10} this was confimed by Motohashi 
[\cite{key54}, the first note], but the general case seems to be a difficult
problem. Relating to this question we should note that these might be a
possibility to improve, in some sense, upon LEMMA
\ref{part1-chap1:sec1.1:lem1} for the Farey 
sequence in place of general well-spaced sequence $\{ x_r\}$.   

\eqref{eq1.3.4} is due to Barban (\cite{key2}), and
\eqref{eq1.3.5} to Selberg 
\cite{key69}. Graham \cite{key19} gave an elegant proof of
\eqref{eq1.3.4}, and even 
succeeded in replacing it by an asymptotic relation. THEOREM
\ref{part1-chap1:sec1.3:thm4} is 
due to Motohashi \cite{key58}; Jutila \cite{key41} obtained an analogue of
Graham's result for the weights $\{\Lambda_d^{(k)}\}$.  

THEOREM \ref{part1-chap1:sec1.4:thm5} is due to Motohashi \cite{key58}. In
deriving the important 
artimitic function $\Phi_r$ from $f$, we used the standard argument of
manipulating the $\Lambda^2$-sieve, for, as already mentioned,we do
not have anything analogous to LEMMA \ref{part1-chap1:sec1.1:lem1}
in the situation of the 
fourth section. Hence it is desrable to have an additive large sieve
inequality which  admits the weight $f$. But to this end, we\pageoriginale would
have to find first a sort additive characters derived from $f$ which
substitute for $\exp (2 \pi i X)$ of LEMMA \ref{part1-chap1:sec1.1:lem1}.   

LEMMA \ref{part1-chap1:sec1.4:lem3} is the famous inequality of
Gallagher \cite{key15}. LEMMA \ref{part1-chap1:sec1.4:lem5} is 
essentially due to Selberg (\cite{key50}) who showed it for $\psi_r$; this
will be a key lemma in our application of THEOREM
\ref{part1-chap1:sec1.4:lem5} to Dirichlet's 
$L$-functions. 
