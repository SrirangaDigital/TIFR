\chapter{Markov Processes} % chapter 1

\section{Introduction}\label{chap1-sec1} 
\pageoriginale 
% section 1

In the following lectures we shall be mainly concerned with Markov
processes, and in particular with diffusion processes.  

We shall first give an intuitive explanation and then a mathematical
definition. The intuitive model of a Markov process is a phenomenon
changing with time according to a certain stochastic rule and
admitting the possibility of a complete stop. The space of the Markov
process has the set of possible states of the phenomenon as its
counter-part in the intuitive model. Specifically, consider a moving
particle. Its possible positions are points of a space $S$ and its
motion is governed by a stochastic rule. The particle may possibly
disappear at some time; we then say it has gone to its \textit{death
  point}. A possible motion is a mapping of $[ 0, \infty) $ into the
  space of positions. Such a function is a \textit{sample path}. The
  set of all sample paths is the \textit{sample space} of the
  process, denoted by $W$. A probability law $P_a$ governing the path
  of the particle starting at a point $a \in S$ is a probability
  distribution on a Borel algebra of subset of $W$. The stochastic
  rule consists of a system of probability laws governing the
  path. Finally, the condition on the system, that ``if the particle
  arrives at a position `$a$' at time `$t$' it starts afresh according
  to the probability law $P_a$ ingonoring its past history'' will
  correspond intuitively to the basic \textit{Markov property.} 

\begin{defins*}
We\pageoriginale turn now to the mathematical definitions. We first explain the
  notation and terminology which we shall use.  
\end{defins*}

Let $S$ denote a locally compact Hausdorff space satisfying the second
axiom of countability. Let $\mathbb{B}(S)$ denote the set of all Borel
sub-sets of $S$, $\mathscr{B}(S)$ the set of all
$\mathbb{B}(S)$-measurable bounded functions on $S$. Since $S$
satisfies the second axiom of countability, this class coincides
with the class of all bounded Baire functions on $S$. We shall add to
$S$ a point $\infty$ to get a space $S \cup \{\infty\}$. $S \cup
\{\infty\}$ has the topology which makes $S$ an open sub-space and
$\infty$ and isolated point. Then if $\mathbb{B} (S \cup \{
\infty\})$, and $\mathscr{B}(S\cup\{\infty\})$ are defined in the same
way, $\mathbb{B}(S)\subseteq \mathbb{B}(S\cup \{\infty\})$,
and for any $f \in \mathscr{B}(S)$ if we put $f (\infty) =
0$, then $f \in \mathscr{B}(S \cup \{\infty\}) $. A function $w : [0,
\infty] - SV \infty$ is called a \textit{sample path} if  
\begin{enumerate}
\renewcommand{\labelenumi}{(\theenumi)}
\item $w (\infty) = \infty$; 

\item there exists a number $\sigma_\infty (w)\in [ 0, \infty]$ such that
  $w(t) = \infty$ for $t \geq \sigma_\infty (w)$ and $w (t) \in S $
  for $t < \sigma_\infty (w)$; 
 
\item $w(t)$ is right continuous for $t < \sigma_{\infty} (w)$. 
\end{enumerate}

For any sample path $w, \sigma_\infty (w)$ is called the
\textit{killing time}  of the path. For any path $w$ we denote by $x_t (w)$ the
value of $w$ at $t$ i.e., $x_t (w) = w(t) $. Then we can regard $x$ as
a function of the pair $(t, w)$. Given a sample path $w$ the paths
$w^- _s$ and $w^+ _s$ defined for any $s$ by  
$$
x_t (w^-_s) = x_{t \wedge s} (w)_0 if t <
  \infty,
$$
and\pageoriginale
$$
x_\infty (w^-_{s}) = \infty,
$$
where
\begin{gather*} 
 t \wedge s = \min (t, s);\\
x_t (w^+_s) = x_{ t + s}(w),
\end{gather*}
are called the \textit{stopped path} and the \textit{shifted path} at
time $s$, respectively. A system $W$ of sample paths is called a
\textit{sample space}  if $w \in W$ implies $w^-_s \in W, w^+_s \in
W$ for each $s$. For a sample space $W$ the Borel algebra generated by
sets of the form $(w: w \in W, x_t (w) \in E)$, $t \in [ 0 , \infty)$,
$E \in \mathbb{B}(S)$ is denoted by $\mathbb{B}$ or $\mathbb{B} (W)$,
and $\mathscr{B}$ or $\mathscr{B}(W)$ denotes the set of all bounded
$\mathbb{B}$-measurable functions on $W$. The class of all sets of
the form $(w: w^-_s \in B) B \in \mathbb{B}$, is called the 
\textit{stopped Borel algebra} at $s$, and is denoted by $\mathbb{B}_s$ or
$\mathbb{B}_s(W)$. $\mathscr{B}$ will denote the system of all bounded
$\mathbb{B}_s$-measurable functions. Note that $\mathbb{B}_s$
increases with $s$ and $\mathbb{B}_ \infty = \mathbb{B}$. 

Consider the function $x (t, w)$ on $R \times W$ into $S \cup \{\infty
\}$. Let  
$$
x_n (t, w) = x \left(\frac{j +1}{2n}, w \right)= w \left(\frac{j +
  1}{2^n}\right) ~\text{ for}~ \frac{j }{2^n}< t \leq \frac{j + 1}{2^n }. 
$$

Then $x_n (t, w)$ is measurable with respect to $\mathbb{R}(R) \times
\mathbb{B}(W)$ and $x_n (t, w)\break \to x (t, w)$ pointwise. $x_t (w)$ is
therefore a measurable function of\pageoriginale the pair $(t, w)$  

\begin{defi*}
A {\em Markov process} is a triple 
  $$
  \mathbb{M} = (S, W, P_a , a \in S \cup \{\infty \})
  $$
  where 
  \begin{enumerate}
\renewcommand{\labelenumi}{(\theenumi)}
  \item $S$ is a locally compact Hausdorff space with the second axiom
    of countability;  
  \item $W$ is  a sample space; 
  \item $P_a (B)$ are probability laws for $a \in S \cup \{\infty \}$,
    $B \in \mathbb{B}$, i.e.,  
    \begin{enumerate}
    \renewcommand{\labelenumii}{(\theenumii)}
    \item $P_a (B)$ is a probability measure in $\mathbb{B}$ for every
      $a \in S \cup \{\infty \}$,  
    \item $P_a (B)$, for fixed $B$, is $\mathbb{B}(S)$-measurable in a, 
    \item $P_a (x_0 = a ) = 1$, 
    \item $P_a$ has the {\em Markov property} i.e., 
\begin{gather*}
B_1 \in \mathbb{B} _t , B_2 \in \mathbb{B} \text{ \ imply}\\
 P_a [ w: w \in B_1, w^+ _t \in B_2] = E_a [ w \in B_1; P_{x_t}(B_2)], 
\end{gather*}
    \end{enumerate}
  \end{enumerate}
\noindent
  where the second member is by definition equal to
    $\int\limits_{B_1} P_{x_t(w)} (B_2)dP_a$.  
    [For fixed $t, B_2, p_{x_t (w)}(B_2)$ is a bounded measurable
      function on $W$.] 
\end{defi*}

\setcounter{rem}{0}
\begin{rem}\label{chap1-sec1-rem1}% remark 1
  (d) ~ is equivalent to the following: 
  $$
  f \in \mathscr{B}, g \in \mathscr{B} \text{\ imply\ } \int f (w)g
  (w^+ _t) dP_a = 
  E_a [f (w) E_{x_t (w)}(g(w'))] 
  $$
  
More generally (d) is equivalent to  

(d$'$)~  $f \in
  \mathscr{B}_t$,\pageoriginale $g \in \mathscr{B}$, $B_1 \in 
  \mathbb{B}_t$, $B_2 \in \mathbb{B}$ imply  
  \begin{multline*}
    E_a [ f (w) g (w^+ _t) : w \in B_1, w^+ _t \in B_2]\\ 
    = E_a [ w \in B_1 ; f (w) E_{x_t (w)} (w' \in B_2: g (w'))].  
  \end{multline*}
\end{rem}

$S$, $W$, $P_a$ are called the \textit{state space, sample space} and
\textit{probability law} of the process respectively.  

We give below three important examples of the sample space in a Markov process. 
\begin{enumerate}
\renewcommand{\theenumi}{\alph{enumi}}
\renewcommand{\labelenumi}{(\theenumi)}
\item $W= W_{rc} =$ the set of all sample paths. 
These processes are called \textit{right continuous} Markov processes. 

\item $W = W_{d_1}= $ the set of sample paths whose only
  discontinuities before the killing time are of the kind, i.e., $w (t
  - 0)$, w (t + 0) exist and $w (t -0) \neq w (t +0) = w(t) , t <
  \sigma_\infty (w)$. These are called \textit{Markov processes of
    type $d_1$}.  

\item $W = W_c = $ the set of all sample paths which are continuous
  before the killing time. These are continuous Markov processes.  
\end{enumerate}


\begin{rem}\label{chap1-sec1-rem2}% remark 2
A Markove process is called {\em conservative } if $P_a
(\sigma_\infty = \infty ) = 1$ for all $a$. 
\end{rem}

\setcounter{section}{2}
\section{Transition Probability}\label{chap1-sec3} 
% section 3

The function $P(t, a, E) = P_a (x_t \in E)$ on $\mathbb{B}(S), a \in
S$ and $0 < t < \infty$ being fixed, is a measure on $\mathbb{B}(S)$
called the \textit{transition probability} of $P_a$ at time
$t$. The transition probability has the following properties:  
\begin{description}
\item[{\bf (T.1)}]
 $P(t, a, E)$ is a sub - stochastic measure in $E$, i.e., it is
  a measure\pageoriginale in $E$ with total measure $\leq 1$.  
  
  For $P(t, a, S) = P_a (x_t \in S) = 1 - P_a (X_t = \infty) \leq 1$.  

\item[{\bf (T.2)}] $P(t, a , E) \in \mathscr{B}(S)$ for fixed $t$ and $E$. 
  
  For $P(t, a, E) = P_a (B)$ where $B = \{ x_t \in E\}$ and $P_a (B)$
  is by definition $\mathbb{B}(S)$-measurable in a for fixed $B$. 

\item[{\bf (T.3)}] $P(t, a, E)$ is measurable in the pair $(t, a)$ for fixed
  $E$. For $f \in \mathscr{B}(S)$ let  
  \begin{align*}
    H_t (f (a)) & =\int\limits_S P(t,a , db )f (b) = \int\limits_{ W -
      \{x_t - \infty\}} f (w (t))dP_a. \\ 
    &= \int\limits_W f (w(t)) dP_a , \text{ since } f (\infty) = 0. 
  \end{align*}


If $f$ is a bounded continuous function and $\delta _n \downarrow 0$
\begin{align*}
 \lim_{\delta _n \to 0} H_{t + \delta_n} f(a) & = \lim _{ \delta _n
   \to 0} \int\limits_ W  f (w(t + \delta _n) ) dp_a. \\ 
 & = \int\limits_W f (\lim _{ \delta _n \to 0}) w (t + \delta _n)) d P_a\\
 &= \int\limits_W f (w(t))dP_a,  
\end{align*}
since $w(t)$ is right continuous. 

$H_t f(a)$ is thus right continuous in $t$, if $f$ is bounded and
continuous. It is not difficult to show (by considering simple
functions and then generalizing) that $H_tf(a)$ is measurable in a if
$f$\pageoriginale is measurable. Therefore $H_t f(a)$ is measurable in
the pair $(t,a)$ if $f$ is continuous and bounded. Further, if $\{ f_n\}$ is a
sequence of  measurable functions with $|f_n | \le \eta$ and $f_n \to
f$, then $H_t f_n \to H_t f$. The class of those measurable functions
$f$ for which $H_t f(a)$ is measurable in the pair $(t,a)$ thus
contains bounded continuous functions and is closed for
limits. Therefore $H_t f(a)$ is measurable in the pair $(t, a)$ for $f
\in  \mathscr{B}(s)$. If $f = \chi_E, H_t f(a)= P(t, a, E)$. 

\item[{\bf (T.4)}] $\lim\limits_{t\ 0} P(t, a, U_a) =1$, where $U_a$ is an
  open set containing $a$. 

Let $t_n \downarrow 0$, and $B_n = \{  w :  w (t_n) \in U_a\}$. Since
$w(t)$ is right continuous, $\{ w : w(0) \in  U_a \subset
\bigcup\limits_{n=1}^\infty \bigcap\limits_{m=n}^\infty B_m$.  

Therefore 
\begin{align*}
  \liminf\limits_{t_n \downarrow 0} P(t_n, a, U_a) & \ge P_a \left[
    \bigcup\limits^\infty_{n=1} \bigcap\limits_{m=n}^\infty B_m\right]\\
  & \ge P_a \{ w :  w(0) \in U_a\} \ge P_a \{ w : w(0) =a \} =1.
\end{align*}

\item[{\bf (T.5)}] \textbf{Chapman-Kolmogoroff equation~:}
\begin{align*}
    P(t+s, a,E) & = \int\limits_S P(t,a, db) P (s,b,E).\\
    P(t+s,a,E) &= P_a \{ x_{t+s} \in E \}= P_a \{ x_t \in S, x_{t+s} \in E \} \\
    & = P_a \{ x_t \in S. x_s (w^+_t) \in E \} \\
    &=E_a [ x_t \in S :   P_{x_t} \{  x_s (w) \in E \} ] \\
    &= E_a [x_t \in S :  P(s,x_t, E)] \\
    &= \int_S P(t,a,ab) P(s,b,E)
  \end{align*}\pageoriginale

\item[{\bf (T.6)}] 
  \begin{multline*}
    P_a ( x_{t_1} \in E_1, \ldots , x_{t_n} \in E_n)
    = \iint_{a_i \in E_{i}} P (t_1, a, da_1)\\ 
    P (t_2- t_1, a_1, da_2)
    \cdots P(t_n -t_{n-1},a_{n-1}, da_n) 
  \end{multline*}

We shall prove this for $n=2$.
\begin{align*}
  P_a & (x_{t_1} \in  E_1, x_{t_2} \in E_2)\\ 
  & = P_a (x_{t_1} \in E_1,
  x_{(t_{2} -t_1)+t_{1}}=\in \in E_2) \\
  &= P_a (x_{t_1} \in E_1, x_{t_{2}-t_1} w^+_{t_1}\in E_2)\\
  &= P_a ( w \in B_1, w^+_{t_1} \in B_2), B_1= \{  x_{t_1} \in E_1\}
  \text{ and } B_2 = \left\{ x_{t_{2}-t_1} \in E_2 \right\} \\ 
  &= \int\limits_{B_1}P_{x_{t_1}}  (B_2) dP_a = \int\limits_{B_1}
  P_{x_{t_1}} (w: w(t_2 - t_1) \in E_2) dP_a \\ 
  &= \int\limits_{E_1} P(t_1, a, da_1) P( t_2 -t_1, a_1, E_2) \\
  &= \iint\limits_{a_i \in E_{i}} P(t_1,  a, da_1) P(t_2-
  t_1, a_1, da_2). 
\end{align*}

\item[{\bf (T.7)}] Suppose that $\mathbb{M}_1= (S_1, W_1, P'_a, a \in S_1 \cup
  \{ \infty \})$ and $\mathbb{M}_2= (S_2, W_2,\break P^2_a$, $a \in  S_2 \cup
  \{  \infty \})$ are two Markov processes with $S_1 =
  S_2$,\pageoriginale 
$W_1= W_2$
  and $P' (t,a,E)=P^2 (t,a,E)$: then $\mathbb{M}_1 \equiv
  \mathbb{M}_2$, i.e. $P^1_a = P^2_a$. 
\end{description}

\begin{proof}
Any sub-set of $W$ of the form
  $$
  \left\{ (x_{t_1}, \ldots , x_{t_n}) \in E_1 \times \cdots \times E_n \right\},
  E_i \in \mathbb{B}(S), 
  $$
  is in  $\mathbb{B} (W)$. Since $\mathbb{B} (W)$ is a Borel algebra,
  any set of the form  
  $$
  \left\{ (x_{t_1} , \ldots , x_{t_n}) \in E^n  \in  \mathbb{B}(S^n) \right\}
  $$
  is in $\mathbb{B}(W)$. The class of all sets of the form
  $$
  \left\{ (x_{t_1}, \ldots, x_{t_n}) \in E^n, E^n \in  \mathbb{B}(S^n) \right\}
  $$
  for all $n$, for all n-tuples $0 \le t_1,  \ldots , t_n <  \infty$
  and all Borel sets $E^n$ of $S^n$, is an algebra $\mathbb{A} (W)
  \subset \mathbb{B} (W)$. Further $\mathbb{A} (W)$ generates
  $\mathbb{B} (W)$. 
\end{proof}

For fixed $0 \le t_1 , \ldots , t_n < \infty $, let 
$$
P^i_a (E^n) = P^i_a \left\{( x_{t_1} , \ldots , x_{t_n}) \in E^n \right\}, i=1,2.
$$

Then $P^i_a$ is a measure on the Borel sets of $S^n$. From (T.6) it
follows that $P^1_a (E^n) = P^2_a (E^n)$, for all sets $E^n$ which are
finite disjoint unions of sets of the form 
$$
E_1 \times \ldots \times E_n, E_i \in \mathbb{B}(S).
$$

Such\pageoriginale sets $E^n$ form an algebra which generates $\mathbb{B}
(S^n)$. Using the uniqueness part of the Kolmogoroff theorem, we get
$P^1_a (E^n) = P^2_a (E^n)$ for all $E^n \in \mathbb{B} (S^n)$. 

Thus $P^1_a = P^2_a$ on $\mathbb{A} (W)$. One more application of the
uniqueness of the extension gives the result. 

\begin{description}
\item[T.8] Suppose that $\mathbb{M}=(S,W,P_a ,a \in S \cup \{
  \infty\}) $ is a triple with $S$ and $W$ being as in the definition
  of a Markov process, and  $P_a, a   \in S \cup \{ \infty\}$ are
  probability distributions on $\mathbb{B}(W)$ and let  
  $$
  P(t,a,E) = P_a \{w: w(t) \in E \}.
  $$ 
\end{description}

Suppose further that $p(t,a,E)$ satisfies the properties $(T.2),
(T.4)$ and $(T.6)$. Then the contention is that $\mathbb{M}$ is a
Markov process with $P(t,a,E)$ as the transition probability of
$P_a$. 

To prove this we have to verify conditions (b), (c) and (d) on $P_a$. The
proof of b) is similar to that of $(T.6)$. $(T.6)$ shows that $P_a(B)$
is measurable in a if $B$ is of the form 
$$
\left\{ (x(t_1) , \ldots , x(t_a)) \in E^n, E^n \subseteq S^n \right\} 
$$
where $E^n$ is a finite disjoint union of sets of the form $E_1 \times
E_2 \times \cdots \times E_n$,  $E_i \in \mathbb{B}(S)$. For fixed
$t_1, \ldots , t_n$, consider the class $X$ of sets $E^n \in
\mathbb{B} (S^n)$ for which  
$$
P_a \left\{(x_{t_1}, \ldots , x_{t_n} \in E^n \right\} 
$$
is  measurable  in $a$. If $E^n_i$ is a monotone sequence of sets in $X$
and $\lim\limits_{i \to \infty} E^n_i = E^n$,\pageoriginale 
$P_a  \left\{ (x_{t_1}, \ldots , x_{t_n}) \in  E^n_i \right\}$ 
is a monotone sequence and 
$$
\lim\limits_{i
  \to \infty} P_a \left\{ (x_{t_1}, \ldots , x_{t_n} ) \in E^n_i \right\} = P_a
\left\{ (x_{t_1}, \ldots , x_{t_n}) \in E^n \right\}.
$$  
$X$ is therefore a monotone class and hence $X \supset
\mathbb{B}(S^n)$. We have thus shown that $P_a (B)$ is measurable in a for
all $B \in  \mathbb{A} (W)$. Similarly we show that the class of sets
$B \in \mathbb{B} (W)$ for which $P_a (B)$ is measurable in $a$, is a
monotone class. 

We now verify (c). Choose $t_{n} \downarrow 0$ such that 
$$
P_a \{ B_n \}= P_a \left\{  x_{t_n} \in U_a\right\} > 1 - \in.
$$  

Since $w(t)$ is right continuous
$$
\left\{ w: w (0) \in \bar{U}_a\right\} \supset \bigcap_{n=1}^\infty
\mathop{U}^{\infty}_{m=n} 
  [\bigcup^{\infty}_{m=n} B_{m}]. 
$$

Where $\bar{U}_a$ denotes the closure of $U_a$. Therefore 
$$
1 \ge P_a (w :  w(0) \in  \bar{U}_a ) \ge 1- \in. 
$$

Since $\in$ arbitrary, $P_a (w :w (0) \in \bar{U}_a)=1$. Now we choose
a decreasing sequence $\{ U^i_a\}$ of open sets such that $U^i_a
\supset \bar{U}_a ^{i+1}$ and $\bigcup\limits_{i=1}^\infty U^i_a = \{
a \}$. We then have  
$$
P_a (x_o =a) = P_a ( \bigcap_{i=t}^\infty (x_o \in U^i_a)) = \lim_{i
  \to \infty} P_a (x_o \in U^i_a) =1. 
$$

To prove (d) we proceed as follows. First remark that if  $f \in
\mathscr{B} (S^n)$\pageoriginale and $E^n \in \mathbb{B} (S^n)$ and
$B=  ((X_{t_1},\ldots, x_{t_n}) \in E^n$ then  
$$
\int\limits_{E^n} P(t_1, a, da_a) \cdots P(t_a- t_{n-1}, da_n) f( a_,
\ldots , a_n) = \int\limits_{B} f [x_{t_1} , \ldots , x_{t_n}] dP_a. 
$$

Let $B_1 \in \mathscr{B}_t$ be given by $B_1 = (w: w^-_t \in B')$
where $B' = (x_{t'_1} \in  E_1 , \ldots , x_{t'_n} \in E_n)$; then
$B_1= (x_{t_i} \in E_i, 1 \le i \le n)$ with $t_i = t \Lambda t'_i, 1
\le i \le n$. Let $B_2 \in \mathbb{B}_2 $ be given by  
$$
B_2 = (x_{s_j} \in F_j , 1 \le j \le m). 
$$

We have
\begin{align*}
  P_a & ( w \in B_1 , w^+_t \in  B_2) = P_a (x_{t_i} \in  E_i, x_{t+s_j}
  \in F_j)\\ 
  & = P (x_{t_i} \in E_i, x_t \in S, x_{t+s_j} \in F_j)\\
  & = \int\limits_{\substack{a_i \in E_i \\ c \in  S}}P(t_1,  a,  da_1 )
  - P(t_n - t_{n-1}, a_{n-1}, da_n) P (t- t_{n}, a_n, dc )\\
  & \quad \int\limits_{b_j \in F_j} P(s_1, c, db_{1}) \ldots P (s_m- s_{m-1} ,
  b_{m-1}, db_m) \\ 
  & = \int\limits_{a_i \in E_i , c \in S}P(t_1, a, da_1) \ldots P(t-
  t_{n}, a_n , dc) P_c (B_2)= \int\limits_{B} P_{x_t} (B_2) 
\end{align*}
by the above remark. We now fix $B_2$ and prove that the above
equation holds for all $B_1 \in \mathscr{B}_t$ [the proof runs along
  the same lines as the proof of b)]. Finally fix $B_1 \in
\mathscr{B}_t$ and prove the same for all $B_2 \in \mathbb{B}$. 

\section{Semi-groups}\label{chap1-sec4}
% \sec 4

Let $H_t f (a) = \int\limits_{S} P(t,a, db) f(b) = E_a \{
f(x_t)\}$. Then $H_t$ is a map\pageoriginale of $\mathscr{B}(S)$ into
$\mathscr{B}(S)$ with the following properties: 
\begin{itemize}
\item[(H.1)] It is linear  on $\mathscr{B} (S)$ into
  $\mathscr{B}(S)$. It is continous in the sense that if $|f_n |  \le
  M$ and $f_n  \to f$ then $H_t f_n \to H_t f$. 
\item[(H.2)] $H_t \ge 0$, in the sense that if $f \ge 0, H_t f \ge 0$. 
\item[(H.3)] It has the semi-group property i.e. $H_t H_s= H_{t+s}$.
  \begin{align*}
    H_{t+s}f(a) = E_a(f (x_{t+s})) &= \int\limits_{S}P(t+s, a, db ) f(b) \\
    &= \int\limits_{S} f(b) \int\limits_{S} P(t,a,dc) P(s,c, db) \\
    &= \int\limits_{S} P(t,a,dc) \left[ \int\limits_{S} f(b) P(s,c,db)\right] \\
    &= \int\limits_{S} P(t,a,dc) H_t f(c)\\
    &=  H_t H_s f(a)
  \end{align*}

\item[(H.4)]  $H_t |  \le 1$
\item[(H.5)] $H_t f(a) $ is $\mathbb{B}(R')$-measurable in $t$. 
\item[(H.6)] If $f$ is continuous at $a$, $\lim\limits_{t \downarrow
  0} H_t f(a) = f(a)$. 
\end{itemize}

For if $U_a$ is an open set containing a 
\begin{multline*}
  H_t f(a) = \int\limits_{S} P(t,a,db) f(b) = \int\limits_{U_a}
  P(t,a, db) f(a) \\ 
  + \int\limits_{U_a} P(t,a, db) [ f(b) - f(a) ] +
  \int\limits_{S-U_a} P(t,a,db) f(b).\\ 
   = f(a) P (t,a,u_a) + \int\limits_{U_a}P(t,a,db) [f(b) - f(a) ] +
  \int\limits_{S-U_a} P (t,a, db) f(b). 
\end{multline*}\pageoriginale

Now use the fact that $P(t,a, U_a) \to 1$ and $f$ is continuous at $a$.

\section{Green operator}\label{chap1-sec5} 
% \sec 5

We have seen that the operators $\{ H_t\}$ form a semi-group. We now
introduce one more operator, the Green operator, as the formal Laplace
transform of $H_t$, which will lead to the concept of a generator. 

Consider the operator $G_\propto = \int\limits_{0}^{\infty} e^{-
\propto t} H_t dt$, defined for $\propto >0$ by  
$$
G_\alpha f(a)= \int\limits_{0}^\infty e^{- \propto t} H_t f(a) dt, f
\in \mathscr{B}(S). 
$$
$G$ is called the \textit{Green operator} on
$\mathscr{B}(S)$. Interchanging the orders of integration, we also
have  
$$
G_\alpha f(a) = E_a \left[ \int\limits_{0}^\infty e^{- \alpha t} f(x_t
  (w)) dt \right]. 
$$

Let $G(\alpha, a, E) = \int\limits_{0}^\infty  e^{- \alpha t}
P(t,a, E) dt$. This measure on $\mathbb{B}(S)$ is called Green's
measure on $\mathbb{B} (S)$. We have  
\begin{align*}
  G_\alpha f(a) = \int\limits_{0}^\infty e^{- \alpha t}H_t f(a) dt &=
  \int\limits_{S} f(b) \int\limits_{0}^\infty e^{- \alpha t} P(t,a,db)
  dt \\ 
  &= \int\limits_{S}G(\alpha, a, db ) f(b).
\end{align*}

The operator $G_\alpha$ has the following properties:
\begin{itemize}
\item[(G.1)] $G_\alpha$\pageoriginale is linear, and continuous in the
  sense that if 
  $|f_n | < \eta$ and $f_n \to f$, then $G_\alpha f_n (a) \to
  G_\alpha f(a)$. 
\item[(G.2)] $G_\alpha \ge 0$, i.e.  $G_\alpha f \ge 0$ if $f \ge 0$.  
\item[(G.3)] $G_\alpha$ satisfies the following equation, called the
  \textit{resolvent} equation: 
  $$
  G_\alpha - G_\beta + ( \alpha - \beta) G_\alpha G_\beta =0.
  $$ 
\end{itemize}

We have
\begin{align*}
  H_s G_\alpha f(a) &= \int\limits_{S}P(s,a, db) G_\alpha f(b) \\
  &= \int\limits_{S} P(s,a, db) \int\limits_{o}^\infty e^{- \alpha t} H_t f(b) dt \\
  &= \int\limits_{0}^\infty e^{- \alpha t} H_{t+s}f(a)dt \text{
    (interchanging the order of integration)}\\ 
  &= e^{\alpha s}\int\limits_{s}^\infty e^{- \alpha t} H_t f(a) dt.
\end{align*}


Therefore
\begin{align*}
  G_\beta G_\alpha f(a) &= \int\limits_{0}^\infty e^{- \beta_s} H_s G_\alpha f(a) ds \\
  &= \int\limits_{0}^\infty e^{ ( \alpha - \beta )_s}ds
  \int\limits_{s}^\infty e^{- \alpha t} H_t f(a) dt \\ 
  &= \int\limits_{0}^\infty e^{- \alpha t} H_t f(a) dt
  \int\limits_{o}^t e^{(\alpha - \beta )_s} ds \\ 
  &= \frac{G_\beta f(a) - G_\alpha f(a)}{\alpha - \beta }
\end{align*}

\begin{remark*}
$H_t H_s = H_{t+s} =H_s H_t$\pageoriginale and 
$$
G_\propto G_\beta = \frac{G_\beta - G_\propto}{\propto - \beta}=
G_\beta G_\propto 
$$
\begin{itemize}
\item[(G.4)] $G_\alpha 1 \le \dfrac{1}{\alpha}$, because $H_tl \le 1$
\item[(G.5)] The integral defining $G_\alpha$ exists for complex
  numbers whose real part $> 0$ for every $f \in \mathscr{B}(S)$. Then
  $G_\alpha f(a)$ is analytic in $\alpha$ for every $f  \in
  \mathscr{B}(S)$ and every $a  \in S$.   
\item[(G.6)] $f$ is continuous at a implies
  $$
  \alpha G_\alpha f(a) \to f(a) \text{ as } \propto \to \infty.
  $$
  
  For $\alpha G_\alpha f(a) = \int\limits_{0}^\infty \alpha e^{-
    \alpha t} H_t f(a) dt = \int\limits_{0}^\infty e^{-t}
  H_{\dfrac{t}{\propto}}f(a) dt$\ 
  and\hfill\break $H_t f(a) \to f(a)$ as  $t \to 0$ if  $f$ is continuous at $a$.
\end{itemize}
\end{remark*}

\section{The Generator}\label{chap1-sec6}
%\sec 6

Define, for $f \in \mathscr{B} (S) $
$$
||  f || = \sup_{a \in S} | f (a) |.
$$

Then\qquad $| H_t f(a) |  \le || f ||$.

$\mathscr{B}(S)$ is a Banach  space with the norm $||  f || $, and
$H_t$ becomes a semi-group of continuous linear operators on
$\mathscr{B}(S)$. 

Consider the following purely formal calculations.
$$
\mathscr{G}= \lim_{t \to 0} \frac{H_t -I}{t} = [ \frac{dH_t} {dt}]_{t
  =0} 
$$

Then\pageoriginale 
$$
\dfrac{dH_t}{dt} = \lim\limits_{\delta  \to 0}
\dfrac{H_{t+\delta}- H_t}{\delta} = \lim\limits_{\delta  \to 0}
\dfrac{H_{\delta} - I}{\delta}\cdot H_t = \mathscr{G} H_t.
$$ 

Therefore $H_t = e^{t \mathscr{G}}$ and 
$$
G_\alpha = \int\limits_{0}^\infty e^{- \alpha t} H_t dt =
  \int\limits_{0}^\infty e^{- ( \alpha - \mathscr{G}) t} dt = (\propto -
  \mathscr{G})^{-1}
$$
or
$$
\mathscr{G}= \alpha - G_\alpha^{-1}.
$$

The above purely formal calculations have been given precise meaning,
and the steps justified by Hille and Yosida [~~ ] when $H_t$ satisfy
certain  conditions. In our case, however, $H_t$ do not in general
satisfy these conditions, and we shall define $\mathscr{G}$ with the
last equation in view. We now proceed to the rigorius definition. 

Let $\mathscr{R}_\alpha = G \alpha [\mathscr{B} (S)],
\mathfrak{N}_\alpha = G^{-1}_\alpha \{ 0\}$ be the image and kernel of
$G_\alpha$ respectively. We show that $\mathscr{R}_\alpha$ and
$\mathfrak{N}_\alpha$ are independent of $\alpha$ and that
$\mathscr{R}_\alpha \cap \mathfrak{N}_\alpha = \{0 \}$. The resolvent
equation gives  
$$
G_\alpha- G_\beta f +  ( \alpha - \beta) G_\alpha G_\beta f =0
$$
i.e. 
$$
G_\beta f=  G_\alpha [ f +  ( \alpha - \beta)
    G_\beta f]
$$

Since $f+  ( \alpha - \beta)~  G_{\beta}  f \in \mathscr{B} (S)$, it
follows that  
$$
G_\beta f \in G_\alpha [ \mathscr{B} (S)]= \mathscr{R}_\alpha,
$$
or that $\mathscr{R}_\beta \subset \mathscr{R}_\alpha$. Interchanging
the roles of $\alpha$ and $\beta$, $\mathscr{R}_\beta \supset
\mathscr{R}_\alpha $ or $\mathscr{R}_\alpha \equiv
\mathscr{R}_\beta$. We denote $G_\alpha [\mathscr{B} (S) ]$ by
$\mathscr{R}$. Similarly $f \in \mathfrak{N}_\beta$\pageoriginale 
gives $G_\beta f =0$ and the resolvent equation  then gives $G_\alpha
f= 0$ or $\mathfrak{N}_\beta \subset \mathfrak{N}_\alpha$. We denote
$G^{-1}_\alpha \{  0\}$ by $\mathfrak{N}$. Let $u \in \mathscr{R} \cap
\mathfrak{N}$ Then $u = G_\alpha f$ for some $f \in  \mathscr{B} (S)$, 
and for every $\beta$, $G_{\beta u}=0$. Now 
$$
H_s u(a) = H_s G_\alpha f(a) = e^{\alpha s} \int\limits^{\infty}_s
e^{- \alpha t} H_t f(a) dt, 
$$
and so $H_s u(a)$ is continuous in $s$ and $\to u(a)$ as $s \to
0$. Also, since $\int\limits_{0}^\infty e^{- \beta s} H_s u(a) ds = 
G_{\beta} u(a) =0$  for all $\beta, H_s u(a) \equiv 0$. 

Letting $s \to 0$ we see that $u(a)  \equiv 0$.

For $u \in R$ define
$$
\mathscr{G}_\alpha u = \alpha u - G^{-1}_\alpha u.
$$ 
$\mathscr{G}_\alpha u$ is then determined mod $\mathfrak{N}$. We now
prove that $\mathscr{G}_\alpha^u$ is independent of $\alpha$. If $f=
\mathscr{G}_\alpha  u (\mod \mathfrak{N})$ then $f= \alpha u -
G^{-1}_\alpha u$, $(\mod \mathfrak{N})$ and    
\begin{align*}
  G_\alpha f & = \alpha G_\alpha u-u \\
  G_\beta G_\alpha f & = \alpha G_\beta G_\alpha u- G_\beta u, \\
  \frac{G_\alpha - G_\beta}{\beta - \alpha} f &= \alpha \frac{G_\alpha
    - G_\beta}{\beta - \alpha} u - G_\beta u, \\ 
  G_\alpha f-  G_\beta f &= \alpha G_\alpha u - \beta G_\beta u, \\
  G_\beta f &= G_\alpha f - \alpha G_\alpha u+ \beta G_\beta u\\
  &= - u + \beta G_\beta u \\
  f &= \beta u - G^{-1}_\beta u \pmod {\mathfrak{N}} =
  \mathscr{G}_\beta u  \pmod {\mathfrak{N}} 
\end{align*}\pageoriginale

We denote $\mathscr{G}_\alpha u$ by $\mathscr{G} u$. Then if $G_\alpha
f=u $ we have  
$$
\mathscr{G}u = \alpha u-f \pmod{\mathfrak{N}}.
$$

Thus $u= G_\alpha f$ if and only if $( \alpha - \mathscr{G}) u  =f
(\mod \mathfrak{N})$. The domain $\mathscr{D} (\mathscr{G})$ of
$\mathscr{G}$ is $\mathscr{R}$ and we have $\mathscr{G}= \alpha -
G^{-1}_ \alpha$. $\mathscr{G}$ is called the \textit{generator} of the
Markov process. 

The following theorem shows that the generator determines the Mar\-kov
process uniquely. 
\begin{theorem*}
  Let $\mathbb{M}_i = (S, W, P^i_a, a  \in  S \cup \{  \infty\}), i =
  1,2$, be two Markov processes, and $\mathscr{G}_i , i=1,2$ their
  generators. Then if\ $\mathscr{G}_1 = \mathscr{G}_2$, $P^1_a =
  P^2_a$, i.e. $\mathbb{M}_1 = \mathbb{M}_2$. 
\end{theorem*}

\begin{proof}
$\mathscr{D} (\mathscr{G}_i) = G^i_\alpha [\mathscr{B} (S) ] =
  \mathscr{R}^i $. Since $\mathscr{G}_1 = \mathscr{G}_2$,
  $\mathscr{D}(\mathscr{G}_1) = \mathscr{D}(\mathscr{G}_2)$,
  i.e. $\mathscr{R}^1 = \mathscr{R}^2= \mathscr{R}$ (say). Since their
  ranges must also be the same $\mathfrak{N}_1 = \mathfrak{N}_2 =
  \mathfrak{N}$(say). We have therefore  
  \begin{align*}
(\alpha - \mathscr{G}_1) G^1_\alpha f &=f \pmod {\mathfrak{N}}\\
    & =f \pmod
    {\mathfrak{N}}[(\alpha-\mathscr{G}_{2})\mathscr{G}^{2}_{\alpha}f(\alpha
      - \mathscr{G}_1) G^1_\alpha f] \\ 
    &= (\alpha - \mathscr{G}_2) G^2_\alpha f  \pmod {\mathfrak{N}},\\ 
    (\alpha - \mathscr{G}) G^1_\alpha f &= (\alpha - \mathscr{G})
    G^2_\alpha f  \pmod {\mathfrak{N}} \text{ since }
    \mathscr{G}_{1}= \mathscr{G}_2 
  \end{align*}
\end{proof}

By\pageoriginale definition $\alpha - \mathscr{G} = \alpha -
\mathscr{G}_1 = G'^{-1}_\alpha$ Therefore 
\begin{align*}
  G^{1^{-1}}_\alpha G^{1}_\alpha f & = G^{1^{-1}}_\alpha \mathscr{G}^{2}_{\alpha}f \pmod {\mathfrak{N}} \\
  G^{1}_\alpha G^{1^{-1}}_\alpha G^{1}_\alpha f & = G^{1}_\alpha
  G^{1^{-1}}_\alpha G^{2}_\alpha f 
\end{align*}

Therefore $G^{1}_\alpha f =  G^{2}_\alpha f$. This gives 
$$
\int\limits_{0}^\infty e^{- \alpha t} H^1_t f(a) dt =
\int\limits_{0}^\infty e^{- \alpha t} H^2_t f(a) dt \text{ for every}
F \in \mathscr{B}(S) 
$$

Thus if $f$ is continuous, $H^1_t f(a) \equiv H^2_t f(a)$
$$
\int P^1 (t,a, db) f(b) = \int P^2 (t,a,db) f(b) 
$$
for every $f \in \mathscr{B} (S)$ which is continuous. Therefore 
$$
P^1 (t,a,E) = P^2 (t,a,E) ,
$$

Hence 
$$
P^1_a = P^2_a.
$$

\section{Examples}\label{chap1-sec7} 
% \sec 7

We first prove a lemma which will have applications later, and then we
give a few examples of Markov processes. 

Let $f$  be a real -valued  function on an open interval $(a,b)$. When
$f$ is of bounded variation in every compact sub-interval of $(a,b)$
we write $f \in \mathscr{B} (a,b)$ and then there exists a unique
signed measure $df$\pageoriginale 
Lebesgue-Stieltjes measure) such that $df(\alpha,
\beta ] = f(\beta +) - f( \alpha +)$, $(\alpha, \beta ] \subseteq
  (a,b)$. Suppose that $\mu$ is any measure on $(a,b)$ which is finite
  on compact subsets of $(a,b)$. Suppose further that there exists a
  function $\varphi$ on $(a,b)$ which is $\mu$-summbale on every
  compact sub-interval of $(a,b)$ and satisfies 
$$
f(\beta+)- f(\alpha + ) = \int\limits^{\beta}_\alpha \varphi (\xi) d
~\mu (\xi). 
$$

Then $df = \varphi d \mu$ and $f$ is absolutely continuous with
respect to $d \mu$. 

We now prove that following 

\begin{lemma*}
  If $f,g \in \mathscr{B} W (a,b)$ then $fg \in \mathscr{B} W(a,b)$ and 
  $$
  d(fg) x=  f(x+) dg (x) + g (x-) df (x).
  $$
\end{lemma*}

\begin{proof}
We can assume that $f$ and $g$ are non-negative and non-decreasing
  in $(a,b)$. It is enough to prove that if $h$ is continuous in
  $(a,b)$ and has compact support, then, 
  $$
  \int h(x) d (fg) (x) = \int h(x) f(x +) dg(x)  + \int h(x) g(x-) df (x).
  $$
\end{proof}

For $n= 1,2, \ldots$ let $\{ \alpha_{n,k}\}, k=0$, $\pm 1, \pm 2,
\ldots$ be a sequence of points such that  
$$
a \leftarrow \cdots <\  \alpha_{n,o} <  \alpha_{n,1} < \cdots \to b,
\alpha_{n,i} - \alpha_{n, i-1} <\frac{1}{n} 
$$

Define

$
\begin{aligned}
\varphi_n (x) &= \alpha_{n,i} \\
\psi_n (x) &= \alpha_{n, i-1}
\end{aligned}$
if $ \alpha_{n, i-1} < x < \alpha_{n,i}$.

Then\pageoriginale 
\begin{align*}
  I_n &= \int h [ \varphi_{n} (x) ] d (f\cdot g)(x) \\
  & = \sum^{\infty}_{i =  - \infty} h (\alpha _{n, i})  [f (\alpha_{n, i 1} + ) g (\alpha_{n, i} +) - f (\alpha _{n,i-1}+)g(\alpha_{n, i-1}+)\\ 
    & = \sum^\infty_{i = - \infty} h(\alpha_{n,i})
    f(\alpha_{n,i}+)\cdot 
[g(\alpha_{n, i-1}+)]- g (\alpha_{n,i-1}+)\\ 
    & \hspace{1cm}+ \sum_{i= - \infty}^\infty h(\alpha_{n, i -1})g(\alpha_{n,i-1}+) [ f (\alpha_{n, i-1}+)-f
      (\alpha_{n, i-1}+)]\\ 
    & =  \int h [\varphi_n(x)] f [\varphi_n(x)+] dg(x) + \int
    h [\psi_n (x)] g [\psi_n (x) +] df(x)   
\end{align*}

Since $h$ has compact support, letting $n \to \infty$ we get the result. 

\medskip
\noindent
{\bf Ex.1~ Standard Brownian motion}
\smallskip

Let $S = R^1$, $W = C [ 0, \infty)$ [we define $w(\infty) =
    \infty$]. Let $P$ be the Wiener measure on $W$ and define for $a
  \in S$,   
$$
P_a (B) = P \{ w : w + a \in B\},\quad B \in \mathbb{B}(W). 
$$

It is not difficult to show that $(S, W, P_a )$ is a Markov process ;
that is a continuous process and is called the \textit{Standard
  Brownian motion}. 

We shall determine the generator of this process. We have 
\begin{align*}
  P(t, a, E) & = P (w: w + a \in E)= \frac{1}{\sqrt{2 \pi} t} 
\int\limits_{E - a} e^{ - x^2/2t} dx\\  
  & = \int\limits _{E}  N(t, a, c) dc . \\
  H_t f(a) & =\int\limits_{R'} N(t, a, b) f(b) db =
  \int\limits^{\infty}_{-\infty}\frac{e^{ - (b - a)^2 / 2t}}{\sqrt{ 2
    \pi t}} f (b)db.  
\end{align*}\pageoriginale

If $u \in \mathscr{R}, u = G_\alpha f $ for some $f \in \mathscr{B}(R^1)$ and 
\begin{align*}
u(a) & = G_\alpha f (a)  = \int\limits^\infty_0 e^{- \alpha t}H_t
  f (a) dt = \int\limits^\infty_0  f(b) db  \int\limits^\infty_{-\infty}
  \frac{e^{- \alpha t - \frac{(b- a)^2}{2t}}}{ \sqrt{ 2 \pi t}} dt
  \\ 
  &  = \int\limits^\infty _{- \infty} \frac {i}{\sqrt{2 \alpha }}e^{-
    \sqrt{ 2 \alpha}|b - a|} f (b) db \\ 
  & = e^{ - \sqrt{2 \alpha a }} \int\limits^a _{ -\infty }
  \frac{1}{\sqrt{ 2 \alpha} }  e^{ \sqrt {2 \alpha b}} f(b)db + e ^{
    \sqrt{2 \alpha a}} \int\limits^\infty_{a} \frac{1}{\sqrt{2\alpha}}e
  ^{ - \sqrt{ 2 \alpha} b}  f (b)db.  
\end{align*}

Since $e^{- \sqrt{2 \alpha} a}$ and $\int\limits^a_{- \infty}e^{\sqrt{2\alpha}b} f
(b)db$ are both in $\mathscr{B} W (- \infty, \infty )$ we get from the
lemma 
\begin{multline*}
du (a) = - \sqrt{ 2 \alpha }e^{ -\sqrt{ -2 \alpha} a} da
\int\limits^a_{- \infty} \frac{1}{\sqrt{2 \alpha}} e^{\sqrt{2 \alpha} b} f(b) db + \frac{e^{-\sqrt{2 \alpha} a} e ^{\sqrt{2\alpha} a} f(a)}{\sqrt{2 \alpha }}da\\ 
+ \sqrt{2 \alpha} e^{\sqrt{2 \alpha} a} da \int\limits^\infty_a  \frac{1}{\sqrt{ 2
    \alpha}}e^{- \sqrt{2 \alpha} b} f (b)db - \frac{e^{\sqrt{ 2 \alpha}
      a }e^{- \sqrt{2 \alpha} a} f (a)}{\sqrt{2 \alpha}} da. 
\end{multline*}

Therefore\pageoriginale $u$ is absolutely continuous and  
$$
u (a )= - e ^{ - \sqrt{2 \alpha} a} \int\limits^a _{ - \infty} 
e^{\sqrt{2 \alpha} b} f (b) db + e ^{ \sqrt{ 2 \alpha}
  a}\int\limits^\infty_a 
e^{- \sqrt{2 \alpha} b} f (b) db  
$$
almost everywhere. Using the lemma again we see that $u'$ is
absolutely continuous and we get  
$$
u'' = 2 \alpha u - 2 f \text{\ almost everywhere}. 
$$

Let $\mathscr{R}_+ = \{ u : \in \mathscr{B}(R')$, $u$ abs. cont, $u'$
abs. cont, $u''\in \mathscr{B}(R^1)\}$. We have seen above that if $u \in
\mathbb{R}$, then $u \in \mathscr{R}_+$. Conversely let $u \in
\mathscr{R}_+$ and put $f = \alpha  u - \dfrac{1}{2} u''$. Then $f \in
\mathscr{B} (R^1)$ and $v = G_\alpha f$ satisfies  
$$
\frac{1}{2} v'' = \alpha v - f 
$$

Therefore $w = v - u$ satisfies 
$$
\frac{1}{2} w'' - \alpha w = 0.
$$

Hence $w = c_1 e^{\sqrt{2 \alpha} a} + c_2  e^{- \sqrt{2 \alpha} a}$. 
Since $w$ is bounded, $c_1 = c_2 = 0$ or $u = G_\alpha f$. Thus we
have proved that  
$$
\mathscr{R} = \left\{u : u \in \mathscr{B} (R^1), u~ \text{abs.cont}, u'
\text{\ abs.cont}, u'' \in \mathscr{B}(R^1) \right\} 
$$

If $f\in \mathfrak{N}$, $u = G_\alpha f = 0$ and since $u'' = 2 \alpha u
- 2 f$ a.e. we see that $f = 0$ a.e. Therefore  
$$
\mathfrak{N} = \{ f : f = 0 \text{ a.e.}\}.
$$

Also\pageoriginale the formula $u'' = 2 \alpha u - 2f (\text{a.e.})$
shows that  $\mathscr{G}=
\dfrac{u''}{2}(\text{a.e.})$ and hence $\mathscr{G} =
\dfrac{1}{2}\dfrac{d^2}{da^2}$.  

\medskip
\noindent
{\bf Ex.2~ Brownian motion with reflecting barrier at {\boldmath$t = 0$}}.  
\smallskip

Let $(S = (- \infty, \infty), \hat{W}, \hat{P}_a)$ denote the Standard
Brownian motion.  

Let $S = [ 0, \infty)$ and $W$ the set of all continuous functions on
  $[0, \infty)$ into $S$. If $B \in \mathbb{B}(W)$ then $B \in
    \mathbb{B} (\hat{W})$. Define $P_a (B) = \hat{p}_a [ w : | w| \in
      B ]$ for $a \in s $. Then $(S, w, P_a)$ is a continous Markov
    Process and is called the \textit{Brownian motion with reflecting
      barrier at $t = 0$.}  

We have 
\begin{align*}
  P(t, a, E) & = \hat{P}_a \{w : | w (t) | \in E \} \\
  & = \hat{P}_a \{ w :  w (t)\in E \cup (-E ) \} \\	
  & = \int\limits_E [ N (t, a, b)+ N(t, a, -b)]  db \\
  H_t f(a) & = \int\limits_0^\infty [ N (t, a, b)| + N(t, a, -b)\big ]
  f (b) db \\  
  & = \int\limits^\infty_{ - \infty} N(t, a, b) \hat{f} (d) db =
  \hat{H}_t \hat{f} (a)  
\end{align*}
where $\hat{f}(b) = f (|b|)$. Therefore 
\begin{multline*}
  u(a) = G_\alpha f(a) = \int\limits^\infty _ 0 e^{ - a t} H_t f (a) dt\\
  = \int\limits^{\infty}_0 e^{ - \alpha t } \hat{H}_t \hat{f}(a) dt =
  \hat{G}_\alpha \hat{f}(a) = \hat{u}(a) , say  
\end{multline*}

From\pageoriginale the previous example it follows that $\hat{u} \in
\mathscr{B}(\hat{S})$, $\hat{u}$ is absolutely continuous, $\hat{u}'$
is absolutely continuous and $\hat{u}''\in\mathscr{B}(\hat{S})$. 
Since $u(a) =\hat{u}(a)$ for $a > 0$, we see
that $u \in \mathscr{B}(S)$, $u$ is absolutely continuous for $a > 0$,
$u'$ is absolutely continuous, $u'\in\mathscr{B}(S)$.
Further since $\hat{u}(a)= \hat{u}(-a)$
we see that $\hat{u}' (a) = - \hat{u}' (-a)$ and hence $\hat{u}' (0) =
0$. This gives $u^+ (0) = 0$. The relation
$\dfrac{1}{2} \hat{u}'' = \alpha \hat{u} - \hat{f}$ gives
$\dfrac{1}{2}u'' = \alpha u - f$ 
\begin{align*}
 \mathfrak{N} &= \{ f : f = 0 ~\text{a.e.}\} \\
  \mathscr{R} & = \{ u : u \in \mathscr{B} (S), u, u'
  \text{\ abs.cont}, u^+ (0)=
  0 \text{\ and\ } u'' \mathscr{B} (S) \}\\ 
  \mathscr{G} u & = \alpha u - f = \frac{1}{2} u'' ~\text{(a.e.)}
\end{align*}

\medskip
\noindent
{\bf Ex.3~ Poisson process}
\smallskip

Let $(\Omega, P)$ be a probability measure space and $\{\xi (t,
\omega), 0 \leq t < \infty\}$ a Poisson process on $\Omega$.  

Let $S = \{ 0, 1, 2, \ldots\ldots \}, W = W_{d_1} = $ the set of all
sample paths whose only discontinuities are of the first kind, and
hence they are step functions with integral values. For almost all
$\omega , \xi (t, \omega)$ is a step function with jump $1$ and
vanishes at $t = 0$; therefore, for almost all $\omega , \xi (t, \omega)$
is a step function with integral values and hence belongs to $W$. 

Let $\eta^{(k)}(t, \omega) = k+ \xi (t, \omega)$ and define
$$
P_k (B )= P\{\omega : \eta^{(k)} (.,\omega)\in B\} , B \in
\mathbb{B}(W). 
$$

If $E \subset S$, 
\begin{align*}
  P(t, k, E) & = P(\omega : k + \xi (t, \omega) \in E)\\
  & = P(\omega: \xi (t, \omega) \in E - k) \\
  & = \sum_ { 0 \leq n \in E -k} e^{ - \lambda t} \frac{(\lambda t)^n}{n!}\\
  & = \sum_{k \leq n \in E } e^{ - \lambda t} \frac{(\lambda t)^{n -k}}{(n - k)!}\\
  H_t f(k)  & =  \sum^{\infty}_{ n = 0} f (n + k)e ^{ \lambda t}
  \frac{(\lambda t)^n}{n!}\\ 
  u(k) = G_\alpha f (k) & = \int\limits^\infty_0 e^{-\alpha t}
  \sum f (n + k) e^{-\lambda t} \frac{(\lambda t)^n}{n!}\\ 
  & = \sum^\infty_{n = 0}  f (n + k) \frac{\lambda^n}{(\alpha +
    \lambda)^{ n + 1}}. 
\end{align*}\pageoriginale

Therefore we obtain 
$$
u (k + 1) - u(k) = - \frac{f(k)}{\lambda}+ \frac{\alpha}{\lambda} u(k). 
$$

If $u = G_\alpha  f = 0$, from the above we see that $f \equiv 0$, and 
$$
\mathfrak{N} = \{ f : f  \equiv 0\}. 
$$

Let $u \in \mathscr{B}(S)$ and put $f (k) = \alpha u (k) - \lambda [ u
  (k + 1) - u (k)]$. If $v(k) = G_\alpha f (k), v $ satisfies  
$$
v(k +1) - v(k) -=- \frac{f(k)}{\lambda} + \frac{\alpha }{\lambda}v(k)
$$
and\pageoriginale hence, subtracting,  
$$
\alpha [ v (k) - u (k)] - \lambda [ v (k +1) - u (k+1) - v (k) + u(k)]
  = 0
$$
and so
$$ 
  v (k +1) - u (k +1) = \frac{\alpha + \lambda}{\lambda} [ v (k) - u
    (k )] 
$$

If $v(0) \neq u(0) , | v(k) - u(k) | = (\dfrac{\alpha +
  \lambda}{\lambda})^k  | v (0) - u(0) | \to \infty $ which is
impossible since $v - u \in \mathscr{B}(S)$. Therefore $v(0) = u (0)$
and hence $v(k) = u(k)$. Thus we have $\mathscr{R} = \mathscr{B}(S)$.  

\medskip
\noindent
{\bf Ex. 4~ Constant velocity motion}
\smallskip

Let $S = R^1 , W = C [ 0 , \infty)$. Let 
$$
P_a \{ w(t) \equiv a + \lambda t, 0 \leq t < \infty \} = 1.
$$

Then for any $B \in \mathbb{B}$ if $w(t) = a+ \lambda t \in B$, $P_a (B) =
1$ and otherwise $P_a (B) = 0$.  
\begin{align*}
  P (t, a, E) = \delta (E, a + \lambda t) & = \begin{cases}  1\ \text{
      if } a + \lambda t \in E \\0\ \text{ if }a + \lambda t \notin
    E \end{cases}\\ 
  H_t f(a) & = f (a + \lambda t) \\
  u(a) = G_\alpha f(a) & = \frac{1}{\lambda} e^{
    \frac{\alpha}{\lambda}a} \int\limits^ \infty _a e^{ - \frac{\alpha
    }{\lambda}t} f (t)dt.  
\end{align*}

From the lemma and the absolute continuity of\ $u$, 
$$
u'(a) = \frac{\alpha}{\lambda} u(a) - \frac{f(a)}{\lambda}\ \ \text{(a.e.)}
$$\pageoriginale

So if $G_\alpha f = 0, f = 0$ \ a.e. 
\begin{align*}
  \mathfrak{N} & = \Big\{ f : f = 0 ~\text{a.e.,}\Big\}\\
  \mathscr{R} & \subset \{ u : u \in \mathscr{B} (R^1) , u , \text{abs.cont},\
  u' \in \mathscr{B} (R^1)\} \\ 
  \mathscr{G} u & = \alpha u - f =\lambda u' 
\end{align*}

So that $\mathscr{G} = \lambda \dfrac{d}{da}$. 

If $u \in \mathscr{R}$, we have $u \in \mathscr{B}(R^1)$, $u$
abs.cont. and $u' \in\mathscr{B}(R^1)$. Conversely, let $u$ satisfy
these conditions and $f = \lambda u - u'$. Then $v = G_\alpha f$ satisfies  
$$
\alpha y - \lambda y = f. 
$$

The general solution therefore is 
$$
y = G_\alpha f + C e ^{ \frac{\alpha}{\lambda}a}.
$$

Since $y$ is to be bounded, $C = 0$. Thus 
$$
\mathscr{R} = \left\{ u : u \in \mathscr{B} (R^1), u \ \text{abs.cont},\ u ' \in
\mathscr{B}(R^1) \right\}. 
$$

\medskip
\noindent
{\bf Ex.5~ Positive velocity motion}
\smallskip

Let $S = (r_1 , r_2)$ and $v(x) > 0$ a function continuous on $(r_1,
r_2)$ such that for $r_1 < \alpha < \beta < r_2$ 
$$
\int\limits^ \beta_\alpha \frac{dx}{v(x)}<  + \infty \text{ \ and \ }
\int\limits^{r_2} \frac{dx}{v(x)} = + \infty.  
$$\pageoriginale

Then there exists a solution $\xi ^{(a)}(t) \text{ of } \dfrac{d
  \xi}{dt} = v (\xi )$ with the initial condition $\xi ^{(a)} (0) =
a$.  

Let $W = W_c$ and 
$$
P_a \left\{ x_t (w) = \xi ^{(a)} (t), 0 \leq t < \infty \right\} = 1. 
$$

This is similar to Ex.4 and we can proceed on the same lines. 

\section{Dual notions}\label{chap1-sec8}
% section 8

Let $\mathbb{M}= (S, W, P_a)$ be a Markov process and $\mathfrak{M}$
the set of all bounded signed measures on
$\mathbb{B}(S)$. $\mathfrak{M}$ is a linear space. For
$E\in\mathbb{B}(S)$ and $\mu \in \mathfrak{M}$ define  
\begin{align*}
  || \mu || & = \text{ total variation of }\mu = \sup_{E \in
    \mathbb{B}(S)}[\mu(E) - \mu (E^c)].\\ 
  H^*_t \mu (E) & =  \int\limits_S P(t, a, E) \mu (da) \\
  G^*_\alpha \mu(E) & = \int\limits^\infty_0  e^{ - \alpha t} H^*_t \mu (E) dt. 
\end{align*}
 
Then $H^*_t \mu$ and $G^*_\alpha \mu$ are in $\mathscr{M}$ and 
$$
|| H^* _t \mu || \leq || \mu || , || G^* _\alpha || \leq \frac{|| \mu
  ||}{\alpha } 
$$
 
Also, for $f \in \mathscr{B}(S)$, denote by $(f, H^* _t \mu) $ and
 $(f,G^{\ast}_{\alpha}\mu)$ the
 integrals $\int f (a) H^*_t \mu (da)$ and $\int f (a) G^* _\alpha \mu
 (da)$ respectively. We have  
 \begin{align*}
   (f , H^*_t \mu ) & = \int f (a) H_t^*\mu (da) = \iint  f(a) P(t , b,
   da) \mu (db)\\ 
   &  = \int H_t f (b) \mu (db)= (H_t f, \mu) \\
 \text{Similarly}\quad  (f, G^*_\alpha \mu) & = (G_\alpha f, \mu ). 
 \end{align*}\pageoriginale 

\setcounter{thm}{0} 
\begin{thm}\label{chap1-sec8-thm1}
% theorem 1
$$
G^*_\alpha -  G^*_\beta + ( \alpha - \beta )    G^* _\alpha G^*_\beta =0.
$$
\end{thm} 

 Follows easily from $(f, G^*_{\alpha} \mu) = (G_\alpha f, \mu )$ and
 the resolvent equation for $G_\alpha$. 

\begin{thm}\label{chap1-sec8-thm2}% theorem 2
  $\mathscr{R}_\alpha ^* = G_\alpha ^* \mathscr{M}$ is independent of
  $\alpha$. We denote this by $\mathscr{R}^*$.  
\end{thm} 

Follows from Theorem \ref{chap1-sec8-thm1}. 
\begin{thm}\label{chap1-sec8-thm3}% theorem 3
  If $G^*_\alpha \mu = 0, \mu \in \mathfrak{M}$, then $\mu = 0$. 
\end{thm} 

\begin{proof}
  Let $f \in C(S)$. Then since $\alpha G^*_\alpha \mu = 0$ we have 
$$
0 = (f , \alpha G^*_\alpha \mu) = (\alpha G_\alpha f, \mu ) \to (f,\mu)
$$
as $\alpha \to \infty$. Hence, for every $f \in C(S), (f, \mu) =
  0$. It follows that $\mu \equiv 0$.  
\end{proof} 

\begin{thm}\label{chap1-sec8-thm4}% theorem 4
  $\mathscr{G}_\alpha ^* = \alpha - (G^* _\alpha)^{ -1}$ is
  independent of $\alpha$. We denote this by $\mathscr{G}^* $, and
  call it the {\em dual generator } of $\mathscr{G}$.  
\end{thm} 
 
Proof is easy 
\begin{thm}\label{chap1-sec8-thm5}% theorem 5
If\pageoriginale $u \in \mathscr{R} = \mathscr{G}, v \in \mathscr{R}^* =
  \mathscr{D}(\mathscr{G}^*)$ then  
  $$
  (\mathscr{G} u, y ) - (u, \mathscr{G}^* v).
  $$
\end{thm}

\begin{proof}
Let $u = G_\alpha f, \nu = G^* _\alpha \mathscr{G}$. Then 
\begin{align*}
     (\mathscr{G} u, v ) & = (\alpha_{\nu - f}, \nu) = (\alpha_{u}, \nu) -
    (f, \nu)\\ 
    & = (\alpha_{u}, \nu ) - (f, G^*_\alpha \mu ) = (u, \alpha \nu) -
    (G_\alpha , f,\mu)\\ 
    & = (u, \alpha, \nu) - (u,\mu) = (u, \alpha \nu - \mu) = (u,
    \mathscr{G}^* \nu).  
\end{align*}
\end{proof} 
 
This theorem justifies the name \textit{dual generator} $\mathscr{G}^*$. 
\begin{thm}\label{chap1-sec8-thm6}% theorem 6
  $\mathscr{G}^*$ determines the Matkov process i.e. if $\mathbb{M}_{i} =
  (S^i , W^i, P^i_a)$, $i = 1, 2$ are two Markov processes with $S^1 =
  S^2 , W^1 = W^2 $ and $\mathscr{G}^{1*} = \mathscr{G}^{2*}$, then
  $P^1 _1 = P^2_a$.  
\end{thm}

\begin{proof}% proof 
Since $\mathscr{G}^{1*} = \mathscr{G}^{2*}$,
  $\mathscr{D}(\mathscr{G}^{1*}) = \mathscr{D}(\mathscr{G}^{2*})$. Let
  $\mu \in \mathfrak{M} $ and $\nu = G^1*_\alpha \mu$. Since $\nu \in
  \mathscr{D}(\mathscr{G}^{2*}), \nu = G^2*_{\alpha}\mu_1$. 
Now $\alpha \nu - \mu = \mathscr{G}^{1*} \nu = \mathscr{G}^{2*}\nu =
\alpha \nu - \mu_1$. Hence $\mu_1 = \mu_2$ i.e. $G^{1*}_\alpha \mu  =
  G^{2*}_\alpha \mu$. Now for any $f \in \mathscr{B}(S)$, and for any
  $\mu \in \mathscr{M}$,  
  $$
  (G^1 _\alpha  f, \mu ) = (f, G^{1*}_\alpha \mu) = (f, G^{ 2*}_\alpha
  \mu) = (G^2_\alpha f, \mu). 
  $$

  It follows that $G^1 _\alpha f \equiv G^2_\alpha  f$, i.e. $H^1 _t
  f(a) = H^2 _t f(a)$ for almost all $t$. If $f \in C (S)$, $H^i_t f(a)
  i = 1, 2$ are right continuous in $t$ and are equal almost
  everywhere. They are therefore identical. Now the proof can be
  completed\pageoriginale easily.  
\end{proof} 

\begin{example*}
Consider the standard Brownian motion. Then 
  $$
 \mathscr{R}^* = \{\nu: \nu(db) = db \int \mu (da) G( \alpha , | a-b | )\}.
  $$
 
This means $\nu (E) = \int\limits_E db \int \mu (da) G (\alpha , | a
  - b| )$ where  
$$
G(\alpha , | a - b| ) = \int\limits^ \infty_0  e^{-dt} N (t, a,
 b) dt = \frac{1}{\sqrt{2\alpha}} e^{-\sqrt{2 \alpha} | b - a|}. 
$$
 
The formula shows that $\nu$ has the density 
  \begin{align*}
    u (b) & = \int\limits^ \infty _{ - \infty} \frac{1}{\sqrt{2 \alpha
    }}e^{ - \sqrt{ 2 \alpha} | b - a|}\mu (da )\\ 
    & = e^{ - \sqrt{ 2 \alpha} b} \int\limits^b_{ - \infty}
    \frac{1}{\sqrt{ 2 \alpha}}e^{\sqrt{2\alpha}a} \mu (da) + e^{\sqrt{2 \alpha} b}
    \int\limits^ \infty_ b \frac{1}{\sqrt{2 \alpha}}e^{ -
      \sqrt{2\alpha} a} \mu (da).  
  \end{align*} 
 
Now using the lemma of \S\ \ref{chap1-sec7} we see that 
$$
du (b) = e^{ - \sqrt{ 2 \alpha} b} db \int\limits^b _{ - \infty} \sqrt{2\alpha}a\mu
(da) +e ^{ \sqrt{ 2 \alpha} b} db \int\limits^\infty_{b} e ^{ -
\sqrt{ 2 \alpha} a} \mu (da)  
$$
and hence $u$ is absolutely continuous and 
$$
u' (b) = -e^{ - \sqrt { 2 \alpha} b} \int\limits^b _{ - \infty} e^{ \sqrt{
2 \alpha }a} \mu (da) + e^{ \sqrt{ 2 \alpha} b} \int\limits
^\infty _b  e^{ - \sqrt{ 2 \alpha} a} \mu (da ) 
$$
 
Using the same lemma again we see that 
\begin{align*}
  du' (b) & = - 2 \mu (db) + \sqrt{ 2 \alpha } db \int\limits^ \infty
  _ { - \infty} e^{ - \sqrt{ 2 \alpha} | b- a|} (da)\\ 
  & =  -2 \mu (db) + 2 \alpha \nu (db). 
\end{align*}\pageoriginale
 
Thus we have $\mathscr{G}^* \nu =\alpha v - \mu = \dfrac{1}{2}du^1$.
\end{example*}

\section{A Theorem of Kac} % section 9
 
We prove the following 
\begin{theorem*}[Kac]
  Let $\mathbb{M} = (S, W , P_a)$ be a Markov process. For $k, f , \in 
  \mathscr{B}(S)$  we define  
  $$
  v(a) = v(\alpha, a ) = E_a \left[\int \limits^\infty_0 e^{-\alpha t} f
  (x_t) e^{-\int^t_0k (x_s) ds} dt \right] 
  $$
  where $\alpha > || k ^- || \sup (-k (a) v 0), \{(avb) = max (a, b)\}$. Then 
  $$
  (k + \alpha - \mathscr{G})v = f. 
  $$
  [If $k \geq 0 , || k^- || = 0$ and $\alpha > 0$].
\end{theorem*}

\begin{proof}
  We have 
  \begin{align*}
    v - u & = E_a \left(\int\limits^\infty _0\ e^{ - \alpha t} f (x_t)
[e^{- \int\limits^t _0} k (x_s) ds -1]dt\right)\\ 
    & = - E_a \left(\int\limits^\infty _0\ e^{ - \alpha t} f(x_t)
    \int\limits^t_0 e^{-\int\limits^t _s k (k \theta)d \theta}
    k (x_s) ds\cdot dt \right) 
  \end{align*}

  Now 
  \begin{gather*}
    \int\limits^\infty _0 \int\limits^t _0\left| e^{- \alpha t} f
    (x_t) e^{ - \int\limits^t _0 k (k_\theta)d \theta}  k (x_s)
    \right| ds dt\\ 
    \leq \int\limits^\infty_0 || f ||\ || k || e ^{ - (\alpha - || k^-
      || )t } tdt < \infty .  
  \end{gather*} 

Changing\pageoriginale the order of integration 
\begin{align*}
v - u & = -  E_a \left(\int \limits^ \infty _ 0 k(x_s) ds \int\limits ^
\infty _s e^{ - \alpha t } f (x_t) e^{- \int \limits^ t _s  k
(x_\theta) d \theta }  dt\right) \\ 
& = -  E_a \left(\int \limits^ \infty _ 0 k(x_s) ds \int\limits ^
\infty _s e^{ - \alpha (t + s)} f (x_{t+s}) e^{- \int
\limits^{t+s}_s  
k (x_\theta) d \theta}  dt\right)\\ 
& = -  E_a \left(\int \limits^ \infty _ 0  e^ { \alpha s }k(x_s) ds
\int\limits ^ \infty _s e^{ - \alpha t } f (x_{t + s }) e ^{- \int
\limits^ {t} _0  k (x_{\theta +s} ) d \theta }  dt\right)\\ 
& =- E_a \left( \int \limits^ \infty _0  e^ {-\alpha s } k (x_s) ds
\int\limits^{\infty}_{0} e^{- \alpha t} f [x_t (w^+_s)]e^{-
\int\limits^t_0 k[x_\theta (w^+_s)]d \theta} dt \right)\\ 
& = - \int\limits^ \infty _ 0 e^{ - \alpha s } ds\ E_a \left[
k(x_{s})\int\limits^{\infty}_{0}e^{-\alpha
  t}f[x_{t}(w^{+}_{s})]\right]e^{-\int\limits^{t}_{0}k[x_{\theta}(w^{+}_{s})]d\theta}dt\\  
    & = - \int\limits^\infty_0 e^{-\alpha s} ds\ E_a \Bigg[ k
      (x_s) E_{x_s}\left(\int\limits^\infty_0 e^{-\alpha t}
      f(x_t)e^{-\int\limits_0^t k(x_\theta) d \theta} dt\right)\Bigg]\\ 
      & = - \int\limits^\infty_0 e^{-\alpha s} ds\ E_a \left[ k (x_s)
        v (x_s) \right]\\ 
      & = - G_\alpha (k, v )(a) \in \mathscr{D}(\mathscr{G}).
  \end{align*}

Since
\begin{align*}
 & u \in \mathscr{D} (\mathscr{G}) ,  \\
 & v \in \mathscr{D} (\mathscr{G})
\end{align*}

Further\pageoriginale 
\begin{align*}
G^{-1}_\alpha [ v - u] & = - kv \mod (\mathfrak {N}) \text{ and
    } G^{ -1} _ \alpha = \alpha - \mathscr{G} \\ 
     (\alpha - \mathscr{G}) (v - u) & = - kv \pmod {\mathfrak{N}}\\
     (\alpha - \mathscr{G}) v-(\alpha - \mathscr{G}) u & = - kv \pmod
    {\mathfrak{N}} \\ 
    (\alpha - \mathscr{G}) v -f & = - kv \pmod {\mathfrak{N}}, (\alpha
    - \mathscr{G}) u = f \pmod{\mathfrak{N}}\\ 
     & = (\alpha + k - \mathscr{G}) v =f. 
  \end{align*}

This proves the result.
\end{proof}  

As an application of Kac's theorem consider the standard Brownian
motion $(S, W, P_a)$. Let  
\begin{align*}
\Phi (t) & = \text{ the Lebesgue measure of ($s :x_s > 0$ and $ 0 <
    s\leq t$)}.\\  
  & = \text{ the time spent in the positive half line up to $t$}. 
\end{align*} 

Note that $\Phi (t)$ is continuous in $t$. 

Then  we shall prove that 
$$
\frac{P_0 [\phi (t) \in d \tau ]}{d \tau } = \frac{1}{\pi
     \sqrt{\tau (t-\tau)}}
$$
so that
$$  
P_0 (w: \Phi (t) < \tau ) = \frac{2}{\pi} \text { are } \sin
   \sqrt{\frac{\tau}{t}} , 0 \leq \tau \leq t.
$$

We have $\beta \Phi (t) = \int\limits^t_0 k (x_s)ds$ where 
\begin{align*}
  k(a) &= \beta~~ \text{ if }~~ a > 0 \\
  &= 0 ~~\text{ if }~~ a \leq 0.
\end{align*}\pageoriginale

Therfore $\beta \Phi (t) = \int \limits^{t}_{0} ~ k  [ x (s,w)  ] ds$,
considered as a function of $w$ is measurable in $w$. Let 
$$
  \varphi ( \beta, t, a ) = E_a \left( e^{-\beta \Phi (t)}\right).
$$

Then 
\begin{align*}
\varphi ( \beta,t,a ) &= E_a \left(e^{-\int\limits_0^t k(x_s)ds}\right)\\ 
  &= \int^{\infty}_{-\infty} e^{-\beta \tau} P_a ( \Phi (t) \in d \tau ) \\
  &=\int^{\infty}_{0} e^{-\beta \tau} P_a ( \Phi (t) \in d \tau ) 
\end{align*}
for, if $B \subset (-\infty, 0)$ then $P_a \left\{ w : \Phi (t) \in B
\right \} = 0 $. Also if  $v (a) = v ( \beta, \alpha, a) =  \int
\limits^{\infty}_{0} e^{-\alpha t} \varphi ( \beta, t,a ) dt$\ 
we have 
$$
v (a) = E_a \left( \int^{\infty}_{0} e^{- \alpha t} f(x_t )e
^{-\int^{t}_{0} k (x_s)ds} dt\right) \text{ where } ~ f \equiv 1. 
$$

From Kac's theorem, $v$ is a solution of the differential equation 
$$
\left(\alpha + k - \frac{1}{2} \frac{d^2}{da^2} \right) y = 1 ~ (a.e.)
$$
i.e., $v$ satisfies
\begin{align*}
  \left( \alpha + \beta - \frac{1}{2} \frac{d^2}{da^2}\right)y & = 1  ~\text{ if
  }~ a > 0 \\ 
  \left( \alpha - \frac{1}{2} \frac{d^2}{da^2} \right) y & = 1
  ~\text{ if }~ a < 0  
\end{align*}\pageoriginale

The general solution of this equation is 
\begin{align*}
  y &= \frac{1}{\alpha + \beta} + A_1 e ^{- \sqrt{2(\alpha + \beta)}
      x} + A_2 e ^{\sqrt{2 (\alpha + \beta)} x},\quad  x > 0 \\ 
  &=  \frac{1}{\alpha} + B_1 e^{-\sqrt{2 \alpha} x} + B_2 e ^{\sqrt{2
      \alpha} x},\quad x < 0. 
\end{align*}

Since $v$ is bounded $A_2 = B_1 = 0 $ and using the fact $v$ is
continuous and $v'$ is continuous at $0$ we have  
$$
v (0) = v ( \beta, \alpha, 0) = \frac{1}{\sqrt{\alpha} \sqrt{\alpha +
    \beta}}. 
$$

Now 
\begin{align*}
 \int \limits^{\infty}_{0} e^{- \alpha t}
 & \int \limits^{t}_{0} \frac{1}{\sqrt{\pi (t-s)}} ~ \frac{1}{\sqrt{\pi
    s}} e^{-\beta s} ds ~ dt\\
  &= \int \limits^{\infty}_{0} e^{- \beta s} \frac{ds}{\sqrt{\pi s}} ~
  \int \limits^{\infty}_{s} \frac{1}{\sqrt{\pi (t-s)}} e^{-\alpha t}
  dt  \\ 
  &= \int \limits^{\infty}_{0}  e^{-\beta s} \frac{ds}{\sqrt{\pi s}}
  \int \limits^{\infty}_{0} \frac{1}{\sqrt{\pi t}} e^{-\alpha (t+s)}
  dt \\ 
  &= \int \limits^{\infty}_{0} e^{-(\alpha + \beta) s}
  \frac{ds}{\sqrt{\pi s}} \int \limits^{\infty}_{0} \frac{1}{\sqrt{\pi
      t}} e^{- \alpha t} dt \\ 
  &= \frac{1}{\sqrt{\alpha (\alpha + \beta)}}.
\end{align*}

Therefore,
$$
\int \limits^{\infty}_{0} e^{-\alpha t} \varphi ( \beta, t, 0) dt = v
(0) = \int \limits^{\infty}_{0} e^{-\alpha t} \int \limits^{t}_{0}
\frac{1}{\sqrt{\pi (t-s)}} \frac{1}{\sqrt{\pi s}} e^{-\beta s} ds dt. 
$$\pageoriginale


Fixing $\beta$, since this is true for all $\alpha$, and $\varphi (
\beta, t, a )$ and  $\int \limits^{t}_{0} \frac{1}{\sqrt{\pi (t-s)}} ~
\frac{1}{\sqrt{\pi s}}\break e^{-\beta s} ds $ are continuous in $t$, we
have  
$$
\displaylines{\hfill 
  \varphi ( \beta, t, 0) \equiv \int \limits^{t}_{0}  \frac{1}{\sqrt{\pi
      (t-s)}} \frac{1}{\sqrt{\pi s}} e^{- \beta s}~ ds\hfill \cr  
  \text{i.e.,}\hfill 
  \int \limits^{\infty}_{0} e^{-\beta \tau} P_0 ( \Phi (t) \in d \tau )
  = \int \limits^{t}_{0} e^{-\beta s} \frac{1}{\pi \sqrt{s (t-s)}}
  ds.\hfill } 
$$

Thus finally  
$$
P_0 ( \Phi (t) \in ds ) = \frac{1}{\pi \sqrt{s (t-s)}} ds .
$$
